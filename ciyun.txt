desc
"职位描述：
        
        岗位职责：
1、主导龙渊游戏业务大数据解决方案的制定与推行 ；
2、负责龙渊游戏大数据平台规划与建设游戏大数据工程师；

岗位要求：1、熟练掌握java语言，熟悉java web开发，具有良好的编码能力； 
2、熟悉SQL，具备良好的数据建模和数据处理能力；
3、三年以上java经验，一年大数据工作经验；
4、具备良好的学习能力、沟通能力及执行力； 
5、有主动思考能力，能够不断了解探索新技术以改进现有工作方式方法； 

加分项：1、有BI经验者优先； 2、熟悉spark，有大数据平台建设经验者优先；3、熟悉scala/python者优先；"
"职位描述：
        
        岗位职责：
1、负责金融数据库结构设计、数据处理需求的设计和开发；
2、负责从各类数据源的ETL流程设计、功能实现及运行优化；
3、开发数据库可编程对象，关系型数据库的函数、触发器、存储过程和视图等；
4、协助其他开发人员进行SQL代码编写，并优化性能；
5、数据库规范化文档编写及管理；
6、前瞻性数据库技术与解决方案研究。
任职资格：
1、本科以上学历，计算机专业，掌握数据库理论与开发技术；
2、5年以上数据分析、数据挖掘、数据仓库建模的项目实践经验，有金融类数据业务经验者优先；
3、熟悉ETL开发相关技术，有开源项目Kettle开发经验者优先；
4、熟练使用MySQL、MongoDB数据库，精通SQL、存储过程，熟悉数据库性能调优及服务器性能调优者优先；
5、优秀的分析能力和沟通能力，对数据的有一定的敏感性；
6、有大数据部署开发经验优先考虑；
7、良好的沟通能力、团队合作精神。

本职位上海、杭州、北京同步招聘"
"职位描述：
        
        
工作内容:
1、企业数据仓库和数据平台的研发
2、提供高性能, 高可用的离线/实时存储服务和计算服务
3、数据应用核心系统的需求设计评审和代码开发

工作要求:
1、2年以上Linux环境下的Java/Scala开发经验, 有Python或者Go经验者加分
2、掌握常用开源数据架构(批处理及流式处理)及组件(HDFS, Hbase, Spark/Spark Streaming, Flume, Kafka, ElasticSearch,?Redis等), 参与过实际数据仓库, 数据平台或数据分析应用的开发
3、有多种数据库/数据存储服务(RDBMS, MongoDB, ElasticSearch, Redis, InfluxDB等)及数据中间件的使用经验, 了解其原理和适用场景
4、关注代码风格和单元测试
5、熟悉分布式系统和微服务架构, 理解数据治理, 作业调度等概念者加分
6、有数据挖掘和机器学习算法开发经验者加分
7、有大数据集群的搭建和维护, 或公有云服务数据类组件使用经验者加分
8、具备优秀的团队协作能力, 责任心与抗压能力"
"职位描述：
        
        岗位职责
1、根据需求进行离线和实时数据的开发；
2、生产任务的维护与调优；
3、集群的搭建和维护；
4、和其他部门或团队沟通、资源协调并落实工作；

任职要求
1、大数据实际项目经验至少2年及以上；
2、精通java/python/scala等至少一种开发语言，能根据需求给出技术架构
3、掌握常用大数据组件hadoop/hive/spark/hbase/elasticsearch等原理、使用和调优；
4、掌握至少一种实时处理组件/spark streaming/storm/fink/kafka原理、使用和调优，并有实际项目经验；
5、能熟练理解、使用常见的关系型数据库，例如：Oracle、MySQL、ProgreSQL；
7、善于沟通，思维活跃，性格开朗，善于沟通，责任感强，工作积极主动，执行力强，有良好的团队协作意识；
6、有金融征信系统工作经验择优。"
"职位描述：
        
        1、大学本科以上学历，统计学、数学、计算机、信息处理等相关专业；
2、熟练掌握SQL编程、熟练掌握office办公工具；
3．熟悉或了解数据规划与数据架构建设、数据管控、数据治理等；
4．具有数据仓库或数据湖的建设经验；
5．具有需求分析、数据分析或者项目管理相关工作经验；
6．5年以上工作经验，金融行业背景优先；"
"职位描述：
        
        岗位职责：
1、根据业务需求实时/批量采集数据、加工处理后落地到公司的大数据平台。
2、参与开发基于各类结构化、半结构化、非结构化数据的数据分析和挖掘应用。
3、编写测试案例、配合测试人员测试、完成交叉/联调测试。
4、根据业务人员或项目组要求分析各类测试和生产问题。?
?
技能要求：
1、熟悉Linux操作系统并有Shell开发经验，熟悉Oracle等传统关系型数据库。
2、熟悉Kettle等ETL工具，有Hadoop、Hive、Spark等大数据开发经验者优先。
3、熟悉SQL、HQL、存储过程等开发，有Python、Scala开发经验者优先。
4、有较强的逻辑思维能力和创新精神，具备良好的沟通能力和文字表达能力。
5、有较强的学习能力，对技术有钻研精神，热衷于新技术的学习和实践。
6、有较强的团队合作意识，对工作有热情，能够承受压力、接受挑战。
其他：
1、有良好的环境适应、沟通表达能力。
2、有良好的思维分析、自我学习能力。
3、有一定的团队合作意识，乐于奉献。
4、认同项目组的加班需要。"
"职位描述：
        
        1、熟悉ORACLE、SQLSERVER等数据库，能熟练运用PL/SQL编写存储过程、函数等；

2、能熟练使用DataStage，必须有2年以上Data Stage开发经验；

3、熟悉UNIX/LINUX，能熟练在UNIX/LINUX环境下编写脚本编程；

4、对数据仓库概念和技术架构有比较深的了解，有数据仓库类BI项目实施经验；熟悉调度，能够持续优化并提升调度系统；

5、有证券行业工作经验优先；"
"职位描述：
        
        岗位职责：1、参与计算框架和服务的定制和改进，为公司批处理和流式计算能力提供支撑；2、基于业务需求和应用场景，设计和实现公司大数据相关产品；3、负责设计，开发，优化数据接入、数据存储、数据计算服务框架；4、负责优化分布式框架，解决大并发下的各种问题；5、为公司所有业务线提供数据支持和服务。任职要求：1、本科或以上学历，计算机专业，5年以上大数据项目开发经验；2、具有Hadoop/Spark开发与应用经验，有较大规模的项目经历并应用在生产环境；3、具有独立完成从方案选型设计到原型系统开发实现的能力；4、有较好的团队管理和沟通能力，较强的责任心和事业心。"
"职位描述：
        
        职位描述：
1.负责基于阿里云odps计算平台的开发与优化工作；
2.负责离线，流式计算平台开发结合业务的应用和开发；
3.负责设计，开发，优化数据接入、数据存储、数据计算服务框架；
4.负责优化分布式框架，解决大并发下的各种问题；
5.有过数学建模经验，有较强的数据分析能力；
任职要求：
1.5年以上相关工作经验，本科或以上学历，计算机相关专业；
2.具备扎实的Java语言基础，熟练使用Linux操作系统，熟悉Shell编程；
3.熟悉统计类sql；
4.熟悉前端开发html，css，js等；
5.熟悉python开发、JavaWeb开发的优先；
6.有阿里云odps开发和使用经验的优先；
7.有Spark、Hadoop等数据平台的开发和使用经验的优先
8.有团队管理经验"
"职位描述：
        
        工作职责：
-负责基于Hadoop和OLAP框架的海量数据平台建设
-负责分布式数据平台框架下数据系统开发与新数据应用开发架构研究
-理解用户数据统计、分析和挖掘应用场景，抽象为数据产品需求，不断完善基础数据平台的建设
?
职位要求：
-具备较强的数据敏感度以及数据抽象能力
-精通Java/Scala之一，具备良好的coding素养和习惯
-熟练掌握至少一种脚本语言，如Python、Shell等
-2年以上Hadoop ecosystem的项目实际研发经验，如Zookeeper/HDFS/Hive/HBase/Spark/Impala/Gobblin/Flume/Kafka等其中一个或多个
-1年以上ETL/Adhoc query/OLAP等实践经验
-强烈的责任心和主动Push能力
?
优先原则：
-有互联网行业基础数据建设经验者
-有大规模分布式数据框架开发经验者
-熟悉流式计算框架，如Storm/Jstorm等
-熟悉Protocol Buffer, Avro, Parquet"
"职位描述：
        
        职位描述：1.负责基于阿里云odps计算平台的开发与优化工作；2.负责离线，流式计算平台开发结合业务的应用和开发；3.负责设计，开发，优化数据接入、数据存储、数据计算服务框架；4.负责优化分布式框架，解决大并发下的各种问题；5.有过数学建模经验，有较强的数据分析能力；任职要求：1.3年以上相关工作经验，本科或以上学历，计算机相关专业；2.具备扎实的Java语言基础，熟练使用Linux操作系统，熟悉Shell编程；3.熟悉统计类sql；4.熟悉前端开发html，css，js等；5.熟悉python开发、JavaWeb开发的优先；6.有阿里云odps开发和使用经验的优先；7.有Spark、Hadoop等数据平台的开发和使用经验的优先"
"职位描述：
        
        职位描述：
1.负责基于阿里云odps计算平台的开发与优化工作；
2.负责离线，流式计算平台开发结合业务的应用和开发；
3.负责设计，开发，优化数据接入、数据存储、数据计算服务框架；
4.负责优化分布式框架，解决大并发下的各种问题；
5.有过数学建模经验，有较强的数据分析能力；
任职要求：
1.3年以上相关工作经验，本科或以上学历，计算机相关专业；
2.具备扎实的Java语言基础，熟练使用Linux操作系统，熟悉Shell编程；
3.熟悉统计类sql；
4.熟悉前端开发html，css，js等；
5.熟悉python开发、JavaWeb开发的优先；
6.有阿里云odps（maxcompute）开发和使用经验的优先；
7.有Spark、Hadoop等数据平台的开发和使用经验的优先"
"职位描述：
        
        工作职责：1.负责大数据基础设施建设：数据集成，任务调度系统，数据仓库工具以及数据可视化平台的设计和开发；2.参与数据仓库中数据模型梳理和建设；3.负责数据可视化平台和运营支撑系统的开发，构建丰富多样的BI应用；4.优化系统架构，提升海量数据的处理性能；任职资格：1.3年以上Java开发经验，有数据平台相关工作经验尤佳；2.熟悉Hive、Spark、Kafka、Flume等类框架 或者熟悉阿里云MaxCompute和DataWorks者优先；3.熟悉维度建模和数据仓库数据管理相关的知识；4.逻辑思维严密，具备一定的项目管理和良好的沟通能力；"
"职位描述：
        
        职位描述：
1. 负责电商行业数据整合与数据仓库模型的建立,维护和优化；
2. 对业务问题进行深入分析，为公司运营决策、产品方向、商务判断提供数据支持；
3. 沉淀分析思路与框架， 提炼数据产品需求，与相关团队（如技术开发团队） 协作并推动数据产品的落地；
4. 与相关团队协作进行数据建模和快速迭代，推动业务部门的数据化运营。
职位要求：
1. 统计、数学、信息技术、计算机等本科以上学历，3年以上相关工作经历（能力强者可以不受年限限制）；
2. 熟练运用SQL、EXCEL等工具，有丰富的数据分析、挖掘、清洗和建模的经验；
3. 良好的数据敏感度,能从海量数据，包括外部数据和定性数据中，提炼核心结果，解决实际问题，创造实际价值；
4. 有客户数据模型建立和运营经验、数据化运营经验、数据类产品类规划经验，尤其是电商相关的优先；
5. 熟悉数据分析工具（SAS、R、Python）、可视化工具（DataV）、数据工具（ETL, Hive, HQL）、阿里云数据产品（MaxCompute、DataWorks、Blink、QuickBI）的优先。"
"职位描述：
        
        岗位职责：1、负责魔方互联网+房产租赁业务的数据平台研发，数据集市建设；2、协接数据产品经理，对业务指标体系、数据模型和报表分析体系进行交付，按质按时完成；3、数据架构的规划和实现，整合并合理抽象不同的业务需求和产品，进行设计并且实现统一的数据规范，负责数据质量，元数据的监控，整合；任职要求：1.?熟练掌握主流的关系型数据库，分布式数据库如SQLServer，?Oracle，MYSQL、MongoDB、redis、neo4j等数据库2.?精通SQL等数据查询语言，?熟悉微软BI解决方案（SSIS，SSAS，SSRS和PowerBI），参加过完整的BI和大数据项目并有成功案例；3.?熟练掌握python开发语言，具有爬虫开发实践者优先4.?熟悉H5?E-chart组件和报表分析开发框架，能够快速搭建PC和移动报表分析功能5.?有酒店行业，长租行业，商业地产，零售业相关大数据研发和分析预测经验优先考虑，有机器学习和AI研发应用经验者优先工作地址"
"职位描述：
        
        2019年应届硕士，计算机相关专业。
有一定java开发实践经验，并对大数据开发技术有一定了解。

研以谨，发以专，与高端玩家亦师亦友。
在互联网时代，心有多大，舞台就有多大！"
"职位描述：
        
        岗位职责：
1、根据医药零售业务需求，为业务端提供日常所需的数据报表，包含日、周、月报等数据；
2、不断根据业务变化优化或开发新的报表，并保证数据的及时性及准确性；
3、跟踪观察日常数据，及时发现业务端数据异常情况或预估将来可能遇到的问题，并和业务端沟通问题产生的原因并提出有效建议；
4、根据业务端的需求完成专项的数据分析报告，同时进行包括不限于对其他业务部门数据分析技能培训、整理各业务部门的数据及其他领导交代事项。?

岗位要求:
1、统招本科及以上学历，5年及以上数据分析和数据应用经验。
2、熟悉项分布式计算平台,例如Hadoop , Spark , Hive , HBase、 Storm , Kafka等。
3、精通SQL、Hive，熟悉python或java优先 ,有一定的hqlsq性能调优经验。
4、有日志采集、数据处理、数据仓库建模、ETL等经验。
5、可搭建自动化数据系统，有独立完成专项数据分析能力，有bi系统相关经验优先。
6、具有优秀的数据建模和沟通能力, 能把应用问题转化为数据问题。
7、有独立负责数据某一模块的实际项目经验,有独立设计完成报表的能力。
8、优秀的抗压能力和责任心，能适应创业阶段公司的工作强度。"
"职位描述：
        
        【岗位职责】1、参与公司数据平台的架构设计和实施，提供实时、离线的数据统计框架2、参与数据仓库的设计与实施，为业务部门提供数据分析服务3、参与用户质量系统的开发，监控指标异常、反作弊、对用户进行画像分析等
4、我们鼓励学习和分享，并提供肥沃的土壤，你只需要肆意的疯长！
【岗位要求】
1、统招本科及以上学历，计算机、软件工程等相关专业，3-5年工作经验；2、扎实的计算机基础，熟悉?Java/Python/Scala/Golang?等编程语言之一；3、熟悉大数据开发常用的框架，如Hadoop、Spark、Hive、HBase、Impala、Storm等，并有较强的性能调优经验；4、有丰富的数据仓库经验，从数据采集到数据报表的整个全链条有比较深刻的理解；5、有较强的逻辑思维和数据分析能力；6、有较强的学习能力、主动性和上进心，具有良好的沟通能力和团队合作精神；7、希望你是个热爱教育事业的同学。

如果你是下面这几种人才1.?如果你是有产品思维的T型人才2.?如果你是某个数据领域的专家3.?如果你在不断的走出自己的舒适区，走在不断挑战自己的路上请不要犹豫，赶快来加入我们吧！"
"职位描述：
        
        工作内容:

 负责数据仓库、数据集市的数据模型设计；
 参与数据仓库ETL规则设计和开发；
 参与数据仓库需求调研和需求分析；
 负责多系统数据融合；
 参与数据分析；
 满足业务方的数据需求，提供面向业务报表、数据提取等数据服务。


希望的小伙伴:

 具备数据仓库模型设计、ETL设计的相关经验；
 熟练掌握hql,sql；
 了解hadoop、hive、sqoop、datax工作原理；
 熟悉java,python等编程语言中至少一种；
 有多系统、多数据源处理整合能力；
 快速的业务学习和理解能力；
 沟通能力强，工作认真负责；
 具备海量数据处理、性能调优经验优先。



关于团队：

 高瓴资本（Hillhouse Group）是国内最大最有影响力的VC/PE之一。投资了百度腾讯京东uber摩拜滴滴美的格力等（可自行百度）
 我们是高瓴资本投后管理团队（Hillinsight），主要负责为高瓴投资/控股的企业进行产品/技术方面的规划和开发；目前负责新零售相关业务；
 团队成员大多来自世界顶尖高校，拥有国内外知名公司研发背景。?
 互联网风格，工作节奏快但不倡导加班，工作之余我们希望每一位小伙伴都热爱生活；
 办公地点：环球贸易中心c座17层
 弹性作息时间 / 扁平管理
 年度涨薪评估 / 年终奖金丰厚
 不重样的下午茶 / 不尴尬无趣的 team building"
"职位描述：
        
        岗位职责：
1、? 负责大数据平台开发需求沟通和分析，产出需求分析文档；
2、? 负责需求设计和开发，包括大数据存储、数据仓库、即席查询、olap分析、数据爬取、机器学习等平台的技术选型和开发实施，并交付生产，按时按质输出开发成果；
3、? 负责大数据平台应用的优化，精益求精，提高应用效率，提升用户体验，降低资源成本；
4、? 负责预研新技术，并择机在公司内的推广应用、培训，以及对外对内合作交流，不断提升公司的技术和应用能力。



岗位要求：

1、? 计算机科学、应用数学、物理学等相关专业，本科以上学历；
2、? 具有3年以上大数据平台研发相关工作经验，熟练掌握Java/Python/Scala等一种或者多种开发语言，有完整项目实施经验。
3、精通Hadoop上面数据存储技术如Kudu、计算引擎Impala等组件应用并有完整项目实施经验；或者利用Spark、ES等组件实现海量数据高并发即席查询、Olap应用并有完整项目实施经验；或者精通爬虫框架技术，有搭建爬虫平台并完整实施爬虫项目实施经验。
4、? ?优秀的职业素养，善于主动思考和行动，有良好的口头和书面表达能力。
5、? 有承压能力和良好的结构化问题解决能力。
6、? 互联网、银行、信用卡、保险等金融机构或主流金融公司工作经验优先考虑。"
"职位描述：
        
        岗位职责：
1.?负责大数据平台的部署、开发和维护；
2.?利用大数据平台实现对数据的分析和处理；
3.?参与大数据平台系统设计、开发；
4.?数据平台前后端可视化系统开发；
5. 保证所负责项目的交互质量，达到质量考核要求。
?
任职要求：
1. 3年以上java开发经验 ；
2. ambari hdp集群运维、线上问题定位及排错能力，有数据迁移经验更佳；
3.对hive,spark,storm,hbase有使用经验，具有离线和实时数据抽取，hive数据仓库搭建经验；
4. 具有数据治理，元数据管理项目经历；
5．熟悉linux操作，扎实的java基础。"
"职位描述：
        
        岗位职责：
1.?负责大数据平台的部署、开发和维护；
2.?利用大数据平台实现对数据的分析和处理；
3.?参与大数据平台系统、架构设计；
4.?数据平台前后端可视化系统开发；
5. 保证所负责项目的交互质量，达到质量考核要求。
任职要求：
1.计算机相关专业毕业,3年以上java开发经验 ；
2.熟练掌握spring,springmvc等开源框架，精通面向对象编程；?
3.熟悉掌握linux msql，熟练nosql数据库更佳；
4.熟练掌握html,javaScript jquery,css 等常用技术，有echarts前端开发经验更佳；
5.熟悉 hadoop,storm等大数据产品，有大数据开发经验，有大数据运维经验更佳；
6.具有良好的沟通能力和团队协作精神。
7.熟练常用数据挖掘算法和工具优先考虑."
"职位描述：
        
        岗位职责：
1. 参与数据产品的开发，包括数据的采集，清洗，处理
2. 根据业务用户需要分析数据，提供数据支持
3. 参与公司数据产品的运维和监控，保障数据质量和服务稳定性

任职要求：?
1. 具备本科以上学历, 计算机, 软件以及相关专业, 2年以上数据开发经验
2. 具备1年以上ETL工作, 熟悉至少1种以上ETL工具
3. 熟练掌握hive SQL, 并能快速学习其他数据库上的SQL使用
4. 熟练使用至少一种以上的关系型数据库
5. 熟练掌握Shell或者Python中的一种
6. 具备Hadoop或Spark开发经验者优先
7. 具备数据仓库知识，维度建模，数据分析或数据挖掘方面经验者优先
8. 具备BI报告开发经验者优先"
"职位描述：
        
        岗位职责：
1. 参与数据产品的流程和模型设计?
2. 参与数据产品开发，包括数据的采集，清洗，处理，分析等
3. 根据业务用户需要分析数据，提供数据支持
4. 参与公司数据产品的运维和监控，保障数据质量和服务稳定性
?
任职要求：?
1. 具备本科以上学历, 计算机, 软件以及相关专业, 5年以上数据开发经验。
2. 具备数据仓库的维度建模的能力
2. 具备3年以上ETL工作, 熟悉至少2种以上ETL工具。
3. 熟练掌握hive SQL, 并能快熟学习其他数据库上的SQL使用。
4. 熟练掌握Java/Scala, 对Hadoop相关的技术和组件(HDFS, MR, Hbase, Hive, Spark, Storm, Kafka等）有全面了解
5. 熟练掌握Shell或者Python中的一种
6. 使用过至少一种BI报告开发工具
7. 具备数据分析和数据挖掘方面经验者优先"
"职位描述：
        
        职责： ? ? 1．参与大数据产品的设计和开发，包括数据的采集，清洗，预处理，存储，建模，分析挖掘等 ? ? 2. 根据业务用户需要分析数据，提供数据支持 ? ? 3. 参与公司大数据产品的运维和监控，保障数据质量和服务稳定性 ? ?  ? ? 要求： ? ? 1. 具备本科以上学历, 计算机, 软件以及相关专业, 2年以上大数据开发经验 ? ? 2. 具备1年以上数据仓库建模和开发经验者优先 ? ? 3. 熟练掌握Java, 对Hadoop相关的技术和组件(HDFS, MR, Hbase, Hive, Spark, Storm, Kafka等）有全面深入了解 ? ? 4. 熟练掌握Shell或者Python中的一种 ? ? 5. 具备1年以上Spark调优经验者优先 ? ? 6. 具备实时计算(Kafka+Storm/Spark Streaming)经验者优先 ? ? 7. 具备数据分析和数据挖掘方面经验者优先"
"职位描述：
        
        职责：
1．参与大数据产品的设计和开发，包括数据的采集，清洗，预处理，存储，建模，分析挖掘等
2. 根据业务用户需要分析数据，提供数据支持
3. 参与公司大数据产品的运维和监控，保障数据质量和服务稳定性

要求：
1. 具备本科以上学历, 计算机, 软件以及相关专业, 2年以上大数据开发经验
2. 具备1年以上数据仓库建模和开发经验者优先
3. 熟练掌握Java, 对Hadoop相关的技术和组件(HDFS, MR, Hbase, Hive, Spark, Storm, Kafka等）有全面深入了解
4. 熟练掌握Shell或者Python中的一种
5. 具备1年以上Spark调优经验者优先
6. 具备实时计算(Kafka+Storm/Spark Streaming)经验者优先
7. 具备数据分析和数据挖掘方面经验者优先"
"职位描述：
        
        岗位职责：
1. 参与大数据产品的设计和开发，包括数据的采集，清洗，预处理，存储，建模，分析挖掘等
2. 根据业务用户需要分析数据，提供数据支持
3. 参与公司大数据产品的运维和监控，保障数据质量和服务稳定性
任职要求：?
1. 具备本科以上学历, 计算机, 软件以及相关专业, 3年以上大数据开发经验
2. 具备3年以上数据仓库建模和开发经验者优先
3. 熟练掌握Java, 对Hadoop相关的技术和组件(HDFS, MR, Hbase, Hive, Spark, Storm, Kafka等）有全面深入了解
4. 熟练掌握Shell或者Python中的一种
5. 具备2年以上Spark调优经验者优先
6. 具备实时计算(Kafka+Storm/Spark Streaming. 经验者优先
7. 具备数据分析和数据挖掘方面经验者优先"
"职位描述：
        
        岗位职责:
1、大数据平台的设计与开发，解决海量数据服务面临的挑战；
2、基于对业务的理解，实现用户数据分析模型，为产品,运营,分析提供有力的数据支撑
3、根据马蜂窝自身的大数据，建立数据交换,融合,分享的平台,让数据驱动业务

任职资格:
1、计算机专业，本科及以上学历，3年以上Hadoop生态系统开发经验；
2、熟悉Hadoop、HBase、Kafka、Hive、Spark等组件的工作原理；
3、搭建、调优并维护过Hive、Presto、Spark、Kafka、Redis等服务；
4、精通一门以上脚本语言(java，shell等）,有开发经验者优先；
5、熟悉Linux软硬件环境、系统管理和优化，有做过大数据服务监控者优先；
6、主动性强，具有良好的沟通、协调和组织能力，富有团队精神，有较强的文档编写能力；
7、有Druid,Kylin,ELK使用经验者优先。"
"职位描述：
        
        岗位职责：
1.?负责微服务架构平台的维护和优化等工作
2.?负责数据中台数据服务中心的开发和维护等工作
3.?负责平台应用产品后端服务的开发和维护工作
4.?参与线上系统环境的升级,运维监控和性能调优


任职要求:

1.?扎实的JAVA技术功底，善于JAVA多线程编程，有高并发服务器编程经验或互联网大型分布式应用开发经验者。

2.?熟悉SpringCloud、SpringBoot、dubbo等开源框架，熟悉RESTful接口规范；

3.?熟悉消息队列(如RabbitMQ)、缓存(如Redis)、NOSQL等常用中间件工具

4.?熟悉微服务架构，有平台化实施经验者，有大数据量、高并发系统和大型网站构建经验者优先

5.?熟悉k8s,docker,ci/cd持续集成者优先"
"职位描述：
        
        条件要求：

 熟悉Python, Java, Scala, C++, Golang等一种或多种编程语言；
 熟悉Hive/Spark/Presto等计算引擎，熟悉Yarn/Mesos等资源管理和调度平台，对相关系统源码有研究更佳;
 熟悉Hadoop、Hbase、Hive、Zookeeper、MapReduce等分布式存储和分布式计算技术;
 熟悉数据处理及存储（hadoop、hbase、pig、hive、mahout、storm、sqoop、spark、gora、dubbo、hsf），消息分发及日志收集（scribe、chukwa、kafka、flume、ActiveMQ、RabbitMQ、RocketMq），资源调度（yarn、zookeeper）等，了解其实现原理及应用特点，精通一套或多套大数据处理框架;
 有互联网公司大规模平台建设经验者优先，有架构意识;
 了解常用深度学习算法者优先。


岗位描述：

 负责数据平台建设，以及大数据领域的产品研发；
 负责spark平台的构建、集群部署和调优，以及大数据方向技术跟踪、研究和应用；
 负责大数据平台的规划，海量数据存储、分布式计算和数据仓库的研发"
"职位描述：
        
        条件要求：

 熟悉Python, Java, Scala, C++, Golang等一种或多种编程语言；
 熟悉Hive/Spark/Presto等计算引擎，熟悉Yarn/Mesos等资源管理和调度平台，对相关系统源码有研究更佳;
 熟悉Hadoop、Hbase、Hive、Zookeeper、MapReduce等分布式存储和分布式计算技术;
 熟悉数据处理及存储（hadoop、hbase、pig、hive、mahout、storm、sqoop、spark、gora、dubbo、hsf），消息分发及日志收集（scribe、chukwa、kafka、flume、ActiveMQ、RabbitMQ、RocketMq），资源调度（yarn、zookeeper）等，了解其实现原理及应用特点，精通一套或多套大数据处理框架;
 有互联网公司大规模平台建设经验者优先，有架构意识;
 了解常用深度学习算法者优先。


岗位描述：

 负责数据平台建设，以及大数据领域的产品研发；
 负责spark平台的构建、集群部署和调优，以及大数据方向技术跟踪、研究和应用；
 负责大数据平台的规划，海量数据存储、分布式计算和数据仓库的研发"
"职位描述：
        
        职责描述：
1?? 负责数据分析、加工、清理、处理程序的开发?
2?? 负责数据相关平台的搭建、开发、维护、优化
3?? 分布式平台应用开发（Hadoop/Spark/Hive/Hbase）
4?? 开发数据统计系统，各类统计程序报表。
技能描述
1?? 1年以上Python或Java开发工作经验；
2?? 熟悉常见在线与离线大数据系统, 如Hive, HBase, ES, Kafka等的工作原理与开发调优;?具有MapReduce开发经验，有实际大数据项目经验
3?? 熟练掌握Oracle、MySql等主流数据库上的开发
4?? 对数据有敏锐度, 掌握常见数据分析方法, 如概率统计, 回归分析, 相关性分析等;
5?? 具有良好的沟通能力、组织能力及团队协作精神，有较强的分析和解决问题的能力."
"职位描述：
        
        工作职责：
1. 负责大数据平台的维护与开发，包括ETL开发、数仓建模等等；
2. 与采集组、业务研发组相互协作，共同完成任务；
3. 参与需求的确认、方案的研讨以及方案的实施；
4. 研究新技术，为大数据平台提供更好的解决方案。

职位要求：
1. 具有扎实的数仓基础理论知识，以及数据库优化、查询优化等。
2. 掌握大数据平台常用组件的原理，可熟练运用：Flume， Hive， kylin，HDFS，Hbase等等；
3. 具有一定的Java、Python、golang编程基础，可以完成一些组件二次开发或者其他需求的开发；
4. 具有团队协作意识，责任心强，可以独立，快速高效得完成分配的工作；
5. 了解数据挖掘、机器学习等知识，有项目经验更佳；
6. 了解大数据周边其他新产品，可以为大数据平台添砖加瓦。"
"职位描述：
        
        岗位职责：
1、基于游戏数据，完成指标统计任务；
2、参与数据/工具平台相关的功能接口、数据接口，实现业务功能；
3、参与数据平台/工具平台的架构、设计以及实现。

任职要求：
1、本科及以上学历，专业：计算机、软件、信息、数学等相关专业，熟悉Java、PYTHON等至少一种语言；
2、有Hadoop/spark等大数据工具开发经验或实习经验；
3、掌握常用的数据结构和算法；
4、具备一定的linux操作基础。"
"职位描述：
        
        岗位职责：
1、负责集团基础数据平台架构并实施建设开发；
2、负责构建设计良好的信息源数据采集、传输、存储、计算、分析和挖掘技术实施方案；
3、实现优化调度系统、查询引擎、数据工具等降低数据的使用门槛，保证平台稳定高效运行；
3、负责应对处理每天千亿增量的玩家行为数据；
4、负责对接并支持业务系统的数据分析工作，支持对内对外部数据进行梳理、整合及共享；
任职要求：
1、计算机或数学相关专业，3年以上数据从业经验；
2、深入Hadoop大数据生态体系，对包括Flume、Kafka、Hbase、Hive、Spark等有深刻理解，了解过Flink、Impala、Kylin等；
3、精通Kafka/Redis/RabbitMQ等其中至少一种消息队列技术，擅长Mysql存储原理及索引优化；
4、有过支撑每日亿级别数据处理经验，在离线数据处理、在线检索方面有丰富的经验，了解集群管理、资源调度等综合实现；
5、熟练使用Scala/Java/Python开发，具有较强的数据敏感性，熟悉WEB开发技术，有游戏相关数据处理与分析平台开发经验者优先。"
"职位描述：
        
        岗位职责：
1.负责构建数据仓库（设计、开发、维护），大数据处理架构；
2.负责基于cloudera的Hadoop、Spark、Kudu、Impala技术的海量数据自动化分析处理和统计工作。
3.分布式平台应用开发（Hadoop/CDH）；?
4.开发数据统计系统，各类统计程序报表 ；?
5.支撑各业务线数据需求。

任职要求：
1. 有海量数据分析和统计相关经验；
2. 对hadoop生态、实时计算框架非常熟悉，具备集群搭建、维护、监控能力；
3. 熟悉Flume、Kafka、Storm、Spark、Hive、Kudu、Impala等大数据技术, 至少精通其中三项以上；
4. 熟练掌握scala/Java语言，Spark、Spark streaming编程.
5. 有大数据平台的数据流监控经验优先。
6. 至少实践过1个大数据平台建设项目，平台数据量不小于10T；

符合以下条件者优先
1. 有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验
2. 对开源分布式系统cloudera源码有研究
3. 有处理海量数据的经验
4. 有数据分析、数据挖掘经验"
"职位描述：
        
        工作职责:1.负责零售业务线上、线下的实时数据计算及监控。2.负责流式计算平台开发，结合业务应用，实现实时数据、实时应用场景的开发。3.负责实时计算系统的运维，保证系统的高可用性和稳定性。4.负责设计、开发和优化数据接入、数据存储、数据计算服务框架。5.负责优化分布式框架，解决大并发下的各种问题。任职资格:1.3年以上大数据经验，精通Flink、Storm、Spark Streaming等流式计算框架中的一项。2.熟悉大数据处理相关技术，有使用包括但不限于Hadoop、Hive、Kafka、Spark、Presto等开源框架的开发经验。3.有实时计算平台的开发经验，对于相关业务和技术有深刻理解，处理过高并发低延迟的业务场景的优先。4.具备良好的coding素养和习惯，熟悉Java/Scala/Python/Shell中的一种或多种。5.具备良好的沟通表达能力，具备极强的团队精神和合作精神。6.极强的责任心和耐压能力，对项目质量有很高的要求。"
"职位描述：
        
        工作职责:1.深入了解公司业务，规划、建设企业级数据仓库。2.熟悉Dataphin大数据平台开发流程和规范，完成数据模型的落地，包括从DWD到DWS层的建设，产品对应的业务指标开发等。3.熟悉数据仓库领域知识，从架构和技术层面参与建设数据仓库，包括元数据管理、数据质量、主数据管理、性能优化和调优。4.持续迭代优化数据模型，快速响应公司业务上的变化。5.参与需求评审，针对业务需求设计，调整数据模型并考虑数据影响。6.设计开发BI报表数据模型，快速应用可视化分析报表满足决策层的数据需求。7.将分析逻辑和分析决策固化，参与应用级数据产品的设计，开发和实施。8.主动了解日常业务，通过从业务到数据的转换，发现并解决数据问题。任职资格:1.电商行业、互联网、金融或零售等行业数据平台建设经验（包含数据仓库建模，ETL开发，BI报表开发等一种或多种开发经验）。2.熟悉大数据相关技术能力（Hadoop/MapReduce/Hive/Hbase等）。3.具备较强的数据敏感度以及数据抽象能力。4.熟悉数据仓库和数据建模的相关技术细节，了解各种数据建设模型和ETL开发规范。5.具备良好的coding素养和习惯 熟悉Java/Python/Shell中的一种或多种。6.熟练掌握Oracle,Mysql了解Vertical, 精通SQL，具备海量数据处理能力。7.2年以上大规模分布式数据仓库建设经验 优秀的逻辑思维能力和业务需求分析能力。8.较好的沟通交流能力，学习能力强，有强烈的责任心。"
"职位描述：
        
        工作职责:1、参与数据应用平台设计、开发、优化。2、参与涵盖数据接入、分析、提供接口服务。3、维护开发数据管理后台。4、涵盖数据接入、分析、提供服务。5、基于海量用户行为，为运营系统提供准确的数据。6、探索新的算法模型。任职资格:1、两年以上java开发经验2、熟悉mysql等数据库，了解sql的优化3、熟悉ETL开发者优先4、熟悉hadoop生态圈、ELK、keras、linux等开源组件者优先5、有后台界面开发者优先6、扎实的计算机基础，数据结构和算法7、良好的语言表达能力，团队协作精神，业务责任心和技术研究能力"
"职位描述：
        
        岗位职责：
1、参与数据仓库ETL设计开发；
2、参与BI项目设计和相关文档编写；?
3、按照业务需求及系统设计组织完成数据报表展现、图表展现的开发；?
4、配合项目管理和进度、质量控制，组织进行系统测试，验证正确性。
任职要求：
1、本科及以上学历，2年以上工作经验，数学、计算机、统计、信息相关专业优先；
2、有较强的数据分析能力，对数字敏感，较好的逻辑思维能力和理解能力；?
3、精通SQL，深入理解DW/BI相关的知识，包括：ETL、数据仓库、OLAP、多维数据模型等；
4、熟悉Python、shell脚本语言优先，掌握 Tableau 等 BI 工具尤佳；?
5、熟悉hadoop/hive/spark等优先；
6、责任心强，良好的沟通、学习及团队合作能力。"
"职位描述：
        
        1.负责云平台大数据存储系统的开发和优化
2.参与云平台大数据存储系统的设计

任职资格:
1.硕士以上学历，1年以上大数据平台开发经验
2. linux系统
3.熟悉分布式存储系统原理"
"职位描述：
        
        岗位职责：

 参与构建符合公司业务需求的数据仓库（基于Hadoop生态）；
 参与构建和维护用户画像系统；
 参与研发供业务人员使用的数据可视化产品；
 探究前沿大数据技术在教育中的应用。

岗位要求：

 硕士学历优先，有数据工程师岗位实习和工作经历者优先；
 计算机科学等理工背景优先，编程基础扎实;
 具有1年及以上的数据库开发和优化经验；
 具有1年及以上的Python的项目经验，熟悉Python 后端开发与数据处理模块；
 熟悉Linux操作系统，熟练shell 编程；
 有Docker使用经验，了解DevOps工作流；
 渴望在职业中获得成就感，具有明确的职业发展目标和方向。
 严谨、开放，具有强大的学习内驱力，具备良好的职业素养。

加分项：

 加分项：熟悉MongoDB/Hive 数据库，并有过实际项目经验；
 加分项：了解Hadoop/Spark，有过Hadoop平台使用经验；
 加分项：有个人知识管理习惯，有个人公号/博客/项目站点。"
"职位描述：
        
        岗位职责：
1、主要负责对运营/内容与产品测试/学习行为等相关数据的处理/分析/建模等工作；
2、建立互联网教育行业数据架构，管理数据质量，探索教育大数据分析与挖掘方法与技术；
3、快速敏捷响应产品、运营、内容、设计提交的数据需求。

任职要求：
1、熟练掌握SQL编写，具备基本的数据库调优和性能优化能力；
2、熟练使用python或R等编程语言并独立开展数据分析工作；
3、有较好的统计学和实验设计基础，理解A/B test原理；
4、了解数据可视化原理，有丰富的tableau/Python/R可视化经验；
5、了解机器学习建模/大数据/分布式计算/web开发等相关技术；
6、对技术有热爱，对学习有热情，对工作有耐心，对教育有理想；
7、有2年及以上互联网和教育行业数据分析与挖掘经验者优先。"
"职位描述：
        
        【岗位职责】
利用Python进行数据预处理、建模、可视化，并输出数据分析报告；
参与构建符合公司业务需求的数据仓库，参与开发ETL程序；
参与构建和维护用户画像系统；
参与研发供业务人员使用的数据可视化产品；
探究前沿大数据技术在教育中的应用。

【岗位要求】
硕士学历优先，有数据工程岗位实习和工作经历者优先；
计算机科学等理工背景，编程基础扎实;
具有1年及以上的数据库开发和优化经验；
具有1年及以上的Python的项目经验，熟悉Python 后端开发与数据处理模块；
熟悉Linux操作系统，熟练shell 编程；
有Docker使用经验，了解DevOps工作流；
渴望在职业中获得成就感，具有明确的职业发展目标和方向。
严谨、开放，具有强大的学习内驱力，具备良好的职业素养。

【加分项】
熟悉MongoDB/Hive 数据库，并有过实际项目经验；
了解Hadoop/Spark，有过Hadoop平台使用经验；
有个人知识管理习惯，有个人公号/博客/项目站点。"
"职位描述：
        
        数据工程师：
工作职责：
1，负责金融数据平台的搭建和规划，将各类数据进行整合，实现方便快捷的调用接口。
2，对原始的金融数据进行清洗，保证数据的完整性，以满足策略端的开发和回测的需要。
3，数据的定期维护，包括数据的入库，归档，校验等等。

任职要求：
1，热爱数据方面的工作，做事细心负责， 富有激情。
2，有一定的数据库操作经验，比如mysql。
3，如果有数据仓库，海量数据的处理方面的经验，将优先考虑。
4，有一门熟悉的数据处理的语言，比如Python，C++， 至少要能完成数据处理的任务。
5，最好有一年及其以上的工作经验，特别优秀的应届生也可以。
6，本科及以上学历"
"职位描述：
        
        工作职责：
1、负责公司大数据相关业务系统研发工作；
2、负责团队规划，日常管理工作；
3、负责大数据前沿技术在业务落地；
4、与产品团队密切合作，保证项目及时完成和交付；
任职要求：
1、大学本科及以上学历，5年以上开发经验；
2、熟悉分布式系统设计，有高并发、高可用、低延迟系统研发经验者优先；
3、精通大数据技术生态，对ES、HBase、Redis等NoSQL数据存储方案有深入的认识，熟悉Kafka/Storm/Spark Streaming/Flink等实时技术框架各自的适用场景，并有丰富的大数据应用系统研发经验；
4、熟练掌握服务化系统架构，如SOA、服务治理、Zookeeper、Thrift、分布式事务处理等；?
5、思路清晰，主动积极，喜欢钻研技术，有良好团队合作精神；
6、管理过10+人技术团队，具备良好的系统架构和技术规划能力，有3年以上经验者优先；
7、有物流、电商、O2O行业工作经验者优先。"
"职位描述：
        
        岗位职责：
1. 负责数据可视化项目整体规划及研发落实；
2. 负责数据可视化相关产品的研发和维护工作，持续优化质量、性能、用户体验，交付高质量的可视化产品和服务；
3. 了解相关系统的数据上下游关系，协助数据研发工程师完成数据信息的梳理与数据模型的搭建；
4. 熟悉数据可视化的主要展现形式，协助设计师完成可视化表达的视觉及交互设计；
5. 研究学习最新的可视化理论和技术，积极交流和分享。
岗位要求：
1. 全日制本科及以上学历，8年以上研发经验；
2. 有丰富的数据可视化相关开发经验，主导负责过成熟的数据可视化项目；
3. 熟练掌握至少三个以上如Kylin、Presto、Hadoop、Hive、Flink、Spark、Kafka、HBase等大数据处理/分析相关的工具/框架；
4. 有应对万亿级的大数据处理、高并发访问等方面的研发落地能力；
5. 强悍的编码能力、架构能力、生产环境快速trouble-shooting能力，对新技术有强烈的学习热情；
6. 了解最新的数据可视化方向及技术，对数据可视化有自己深刻理解者优先；
7. 有报表、BI、数据挖掘、可视化数据分析等相关产品的开发经验优先；
8. 具有良好的英文读写能力，有独立研读学习领域相关的英文学术文献的并转化为开发技术的能力优先。"
"职位描述：
        
        岗位职责：
1. 负责数据可视化项目整体规划及研发落实；
2. 负责数据可视化相关产品的研发和维护工作，持续优化质量、性能、用户体验，交付高质量的可视化产品和服务；
3. 了解相关系统的数据上下游关系，协助数据研发工程师完成数据信息的梳理与数据模型的搭建；
4. 熟悉数据可视化的主要展现形式，协助设计师完成可视化表达的视觉及交互设计；
5. 研究学习最新的可视化理论和技术，积极交流和分享。
岗位要求：
1. 全日制本科及以上学历，8年以上研发经验；
2. 有丰富的数据可视化相关开发经验，主导负责过成熟的数据可视化项目；
3. 熟练掌握至少三个以上如Kylin、Presto、Hadoop、Hive、Flink、Spark、Kafka、HBase等大数据处理/分析相关的工具/框架；
4. 有应对万亿级的大数据处理、高并发访问等方面的研发落地能力；
5. 强悍的编码能力、架构能力、生产环境快速trouble-shooting能力，对新技术有强烈的学习热情；
6. 了解最新的数据可视化方向及技术，对数据可视化有自己深刻理解者优先；
7. 有报表、BI、数据挖掘、可视化数据分析等相关产品的开发经验优先；
8. 具有良好的英文读写能力，有独立研读学习领域相关的英文学术文献的并转化为开发技术的能力优先。"
"职位描述：
        
        岗位职责：
1、负责大数据平台的架构设计、产品开发，包括但不限于分布式处理、搜索等大数据技术的产品化工作；
2、负责大数据应用的架构设计及产品开发，如物联网应用、实时计算应用等；
岗位要求：
1、大学本科及以上学历，8年以上开发经验；
2、精通Java及J2EE相关开发；
3、精通服务治理组件如Dubbo，有实际的使用经验；
4、精通Redis/Ehcache/Memcache等任一种缓存技术，精通MySQL；
5、熟悉Kafka并有实际经验， 熟悉分布式系统及相关开发，有实际的开发经验；
6、有高并发、大流量的应用架构及开发能力；
7、对大数据感兴趣，了解大数据技术生态，尤其是ES/Hbase/Storm和Spark；
8、思路清晰，主动积极，喜欢钻研技术，有良好团队合作精神。"
"职位描述：
        
        职责描述：1. 负责数据可视化项目整体规划及研发落实；2. 负责数据可视化相关产品的研发和维护工作，持续优化质量、性能、用户体验，交付高质量的可视化产品和服务；3. 了解相关系统的数据上下游关系，协助数据研发工程师完成数据信息的梳理与数据模型的搭建；4. 熟悉数据可视化的主要展现形式，协助设计师完成可视化表达的视觉及交互设计；5. 研究学习最新的可视化理论和技术，积极交流和分享。
任职要求：1. 全日制本科及以上学历，5年以上研发经验；2. 有丰富的数据可视化相关开发经验，主导负责过成熟的数据可视化项目；3. 熟练掌握至少三个以上如Kylin、Presto、Hadoop、Hive、Flink、Spark、Kafka、HBase等大数据处理/分析相关的工具/框架；4. 有应对万亿级的大数据处理、高并发访问等方面的研发落地能力；5. 强悍的编码能力、架构能力、生产环境快速trouble-shooting能力，对新技术有强烈的学习热情；6. 了解最新的数据可视化方向及技术，对数据可视化有自己深刻理解者优先；7. 有报表、BI、数据挖掘、可视化数据分析等相关产品的开发经验优先；8. 具有良好的英文读写能力，有独立研读学习领域相关的英文学术文献的并转化为开发技术的能力优先。"
"职位描述：
        
        岗位职责：
1、负责大数据平台的架构设计、开发和维护，需要做到高可靠、高性能、易扩展、安全、易使用、标准化等。
2、深入理解业务，从平台层面提供框架、模板、规范和最佳开发实践，简化业务逻辑开发，降低难度，提高开发效率和质量。
3、跟进并评估最新大数据平台、大数据分析、AI技术发展方向，并应用到平台中。

任职要求：
1、有三年以上大数据平台开发和架构设计经验。有海量大数据业务系统设计、线上问题解决经验、优化经验的优先。
2、熟练掌握常见的分布式计算、存储技术如Kafka、ELK、MongoDB、Hadoop、Hbase、Spark、Hive、Hdfs、Storm等原理及使用。
3、精通一门或多门语言（Python、java、PHP、GO、C/C++、shell）的使用；有Python、GO、Scala经验优先；
4、熟悉容器平台开发或大数据管理工具平台开发优先，有docker、kubernetes、hdp、ambari相关经验更佳。"
"职位描述：
        
        岗位职责：
1、负责大数据平台的架构设计、开发和维护，需要做到高可靠、高性能、易扩展、安全、易使用、标准化等。
2、深入理解业务，从平台层面提供框架、模板、规范和最佳开发实践，简化业务逻辑开发，降低难度，提高开发效率和质量。
3、跟进并评估最新大数据平台、大数据分析、AI技术发展方向，并应用到平台中。

任职要求：
1、有三年以上大数据平台开发和架构设计经验。有海量大数据业务系统设计、线上问题解决经验、优化经验的优先。
2、熟练掌握常见的分布式计算、存储技术如Kafka、ELK、MongoDB、Hadoop、Hbase、Spark、Hive、Hdfs、Storm等原理及使用。
3、精通一门或多门语言（Python、java、PHP、GO、C/C++、shell）的使用；有Python、GO、Scala经验优先；
4、熟悉容器平台开发或大数据管理工具平台开发优先，有docker、kubernetes、hdp、ambari相关经验更佳。"
"职位描述：
        
        岗位职责：
1、顺丰科技实时计算平台的设计、开发；
2、顺丰科技统一计算模型(Dataflow)的设计、开发。

任职要求：
1、三年以上Java或者C++开发及设计经验，优秀的编程能力及良好的开发习惯。具备独立沟通需求，设计，架构，开发的能力；
2、至少熟悉一种大数据处理引擎。如：Storm、Spark、Flink、Hadoop等；
3、熟悉Dataflow模型的优先考虑；
4、在开源社群活跃并有积极贡献者优先；
5、具备强烈的进取心、求知欲及团队合作精神，具有良好的沟通能力。"
"职位描述：
        
        岗位职责：
1.负责基于Spark Streaming的海量数据处理、分析和挖掘2.负责准实时数据组合分析的产品功能开发；3.深入探索业务数据，创造性的思考和发现问题，能够提出有效解决方案，并应用数据挖掘、机器学习等技术优化业务，数据驱动业务；

任职要求：
1.熟练常用Spark Streaming/JStorm/Flink中至少一种实时开发框架，具有实时数据处理的项目经验2.熟练使用Hive/SQL,熟悉常用调优方法3.熟悉Linux开发环境，精通java/python/scala中至少一种编程语言4.对大数据相关组件:Hadoop、Spark、Kafka、Hive、HBase、ElasticSearch等架构与底层实现有深入理解5.熟悉机器学习和数据挖掘常用方法6.具备良好的沟通能力、学习能力、分析解决问题能力7.熟悉Spark ML 或Spark MLlib者优先"
"职位描述：
        
        岗位职责
1、负责数据仓库建设，构建统一的数据仓库
2、负责数据集市搭建，跟进业务需求
3、负责业务应用开发、实施与测试
4、参与平台数据产品建设，为数据产品提供数据""

任职要求
1、计算机或相关专业，3年以上大数据相关开发经验
2、熟练掌握java、python、scala中至少一种编程语言，熟悉网络服务器编程基本知识，具备3年以上JVM语言或python开发经验。
3、熟悉SQL以及SHELL脚本开发
4、了解hadoop、MapReduce、hive、spark等开源技术框架
5、有BATJ相关大数据应用开发经验者优先。"
"职位描述：
        
        岗位职责
1、熟知公司业务数据和业务变化，构建业务数据模型；2、维护业务数据模型，验证数据质量，保障数据完整和可靠；
3、进行数据研发和分析，支持业务优化、监控和考核；4、不断学习数据技术，使用新技术高效完成任务；5、平台的搭建与数据维护
?
岗位要求
?1、国内外高校计算机、数学类相关专业，本科以上学历；?2、3年以上大规模数据研发、挖掘、分析相关工作经验；?3、熟悉MySQL、Oracle、SQLServer或至少其中之一，熟悉SQL语言；?4、具有Hadoop、Hive、HBase、Spark、Strom、Kylin ? 、Druid等开源工具的使用经验，并能结合不同的业务场景使用；?5、具有Python、Shell开发经验；?6、有物流行业相关工作经验者优先；?7、了解数理统计、数据分析及挖掘，熟知常用算法，有运用机器学习算法建模的理论基础或实际经验者优先。"
"职位描述：
        
        岗位职责
1、熟知公司业务数据和业务变化，构建业务数据模型； ? ? 2、维护业务数据模型，验证数据质量，保障数据完整和可靠； ? ? 3、进行数据研发和分析，支持业务优化、监控和考核； ? ? 4、不断学习数据技术，使用新技术高效完成任务； ? ? 5、平台的搭建与数据维护。 ? ? ?? ?
岗位要求
1、国内外高校计算机、数学类相关专业，本科以上学历； ? ? 2、6年以上大规模数据研发、挖掘、分析相关工作经验； ? ? 3、熟悉MySQL、Oracle、SQLServer或至少其中之一，熟悉SQL语言； ? ? 4、具有Hadoop、Hive、HBase、Spark、Strom、Kylin ? 、Druid等开源工具的使用经验，并能结合不同的业务场景使用； ? ? 5、具有Python、Shell开发经验； ? ? 6、有物流行业相关工作经验者优先； ? ? 7、了解数理统计、数据分析及挖掘，熟知常用算法，有运用机器学习算法建模的理论基础或实际经验者优先。"
"职位描述：
        
        岗位职责：
1.负责搭建数据仓库，建设大型数据集市和数据管理，实现高质量数据的互通和共享?
2.和业务部门紧密配合，构建丰富多样的BI应用，助力业务产品不断优化?
3.带领研发团队完成数据平台的建设

岗位要求：?
1.熟悉大型数据仓库架构，精通ETL开发?
2.精通数据治理方法，包括数据标准化、数据质量、主题数据模型、元数据管理等?
3.熟悉开源大数据软件栈 （hadoop、hbase、sqoop、kylin、palo等）
4.较强的自我驱动能力，结果导向并极具责任感?
5.良好沟通能力和团队协作精神?
6.有在大型互联网公司相关工作经验者优先"
"职位描述：
        
        岗位职责：
1.参与公司大数据项目的开发、规划、设计；
2.负责相关业务模块设计及核心代码的搭建及实现。
任职要求：
1.熟悉Linux的操作；
2.熟悉MYSQL或者ORACLE等数据库开发技术，能够熟练运用SQL，编写存储过程；
3.熟悉Hadoop整个生态环境体系，对HDFS、MapReduce、Hbase、Hive、Sqoop等Hadoop技术框架工具有一定研究；
4.有基于Hadoop平台数据仓库项目或其他项目开发经验者优先；
5.较强的学习能力和业务理解能力、良好的沟通、团队合作精神。"
"职位描述：
        
        职位诱惑：
弹性工作,电脑补贴,双倍年假,美女多

职位描述：
?工作职责：?1、对网站内容数据，用户行为数据分析，推动产品优化?2、参与并负责大数据架构的搭建、开发和维护监控?3、完成产品经理对数据的各类提取需求?4、从数据的角度，预测和量化运营活动效果?
任职资格：?1.本科以上学历，计算机或数学相关专业，2~5年工作经验?2.熟练操作linux，有python/shell/java/php开发能力?3.能搭建并优化hadoop/spark/impala/kudu等大数据平台?4.具备海量数据处理以及性能优化的能力?5.有应用过阿里相关大数据处理技术优先?6.有过开发用户精准营销系统研发经验的优先"
"职位描述：
        
        数据/爬虫工程师
岗位描述：
1、参与爬虫系统的架构设计与开发；
2、负责设计和开发分布式网络爬虫系统，进行多平台信息的抓取和分析；
3、设计爬虫策略和防屏蔽规则，提升网页抓取的效率和质量；
4、能独立解决实际开发过程碰到的各类问题。
5、参与Mysql，redis，mongdb等常用数据库的建立和运维；
6、对大量数据进行统计、分析。
?
职位要求：
1、计算机、数学、统计等相关专业本科及以上学历，必须211毕业。985高校优先；
2、精通python（熟悉pandas，numpy、scipy等库）（数据处理）
3、熟悉Mysql，redis，mongdb三者至少之一，有过数据库调优和海量数据存储经验优先；
4、懂分布式爬虫（scrapy-redis、nutch） （数据获取）. 熟悉基于#则表达式、XPath、CSS等网页信息抽取技术；
5、熟悉网页抓取原理及技术，熟悉基于Cookie的网站登录原理；
6、熟悉数据分析，熟悉excel,对数据有敏感（python/R）（数据分析）；
7、做过vnpy或其它系统开发优先；"
"职位描述：
        
        岗位职责：
1. 参与大数据分析平台和数据仓库设计、建模、研发
2. 开发ETL工具对各种数据来源进行聚合和清洗
3. 建模计算数据特征得到分类标签
4. 数据存储的维护和备份
5. 基于阿里云数加平台，针对业务需求开发相应接口服务

岗位要求：
1. 三年以上大数据相关工作经验
2. 熟悉Hadoop、Spark、Flink等大数据框架，熟悉HiveSql
3. 熟悉MySQL数据库相关数据备份、恢复等维护
4. 熟悉Java开发语言和Spring Boot开发框架，有接口业务开发经验
5. 了解linux操作系统，ElasticSearch Kafka等中间件
6. 了解数据挖掘、机器学习的概念和算法"
"职位描述：
        
        岗位职责：1、深入理解公司产品需求，对海量数据处理的业务需求进行评估和方案设计；2、负责项目中数据处理工作(数据采集、清洗、汇总、集成等),保证数据的准确性和稳定性；3、对用户数据进行分析和挖掘，提供决策支持；4、负责整体提升大集群的高可靠、高性能、高扩展性；职位要求：1.计算机相关专业，大专学历以上；三年及以上大数据开发经验；2.熟练掌握Hadoop、Spark、Hive、Hbase等大数据技术，并精通java语言；3.熟悉linux系统，常规的shell操作，了解消息队列、缓存、数据库等技术；4.能够独立完成项目的系统分析、设计，并主导完成详细设计和编码的任务；5.有较强的责任心，具有良好的沟通能力和团队合作精神；6.具有金融行业从业经验者、机器学习经验者、图数据库经验者优先。
7.熟悉阿里云服务，表格存储、datawork等大数据处理技术优先。
8.熟悉数据仓库设计与实现，有过金融信贷相关实践经验者优先
9.熟悉大数据在信贷风控及反欺诈系统中的应用者优先，如：GraphX在反欺诈关联关系中的应用、Spark在风险模型实时计算模型中的应用等"
"职位描述：
        
        湖南省电力-常驻岗位
1.2年以上大数据开发经验，有过大型项目经验优先；
2.熟练掌握Linux操作系统，了解shell等脚本编程；
3.掌握Spark、Strom、Spark Streaming、flink等一到两种流式离线处理架构；
4.熟悉Elastic、solr等其中一种数据库技术；
5.熟练掌握MySQL、Oracle等其中一种数据库技术；
6.熟悉Redis、MongoDB、memcache等其中一种NoSQL技术优先；
7.熟悉ActiveMQ、Kafka等其中一种消息队列技术优先；
8.熟悉Hadoop、HBase、Hive、Zookeeper等开源框架优先；
9.有责任心，工作积极主动，勤恳踏实，能承担一定的工作压力，具备良好的沟通能力和团队合作精神。"
"职位描述：
        
        岗位职责：
1.负责大数据分析系统的需求分析和整体架构设计，负责确认软硬件实施方案
2.负责核心技术问题攻关，带领团队解决项目开发过程中的技术难题
3.负责大数据相关应用具体算法的设计、开发
4.协助管理大数据产品项目的开发进度和质量，协助管理项目
任职要求：
1、本科及以上学历，计算机科学与技术、软件工程、网络工程等相关专业；
2、5年以上从事软件开发工作经验，3年以上大数据分析、设计和实施经验；
3、熟悉数据库，包括结构化的Mysql，Oracle和非结构化的MangoDB、Redis等
4、具有分布式开发和应用经验，熟练掌握hadoop，storm，spark等分布式系统的开发和实践
5、具有数据仓库工作经验，熟练掌握数据仓库的维度建模
6、熟悉Hive、Hbase、Pig，sqoop，zookeeper，kafka等组件的适应和调优
7、具有大数据平台架构经验，有多个数据产品的开发和实施经验。
8、具备高度的工作热情，较强的团队领导能力及逻辑思维能力。"
"职位描述：
        
        1、数据仓库搭建和业务处理
2、负责构建Spark/HDFS大数据处理架构,基于Spark技术的海量数据的自动化分析处理和统计工作；
3、基于Spark框架大数据架构的设计、开发和维护；
4、根据相关需求使用SparkStreaming、SQL进行数据处理、查询和统计等工作；
职位要求：
1、熟悉Java/Scala，容器，多线程和CRUD；?
2、熟悉Hadoop体系：hive ，hbase，mongodb等，熟悉elasticsear优先；
3、熟悉spark底层原理，rdd编程、spark sql等；?
4、熟悉mysql等常用数据使用，sql优化；
5、有批处理，流式处理的经验，有用户人群画像，线上行为分析的经验优先。
6、熟悉kafka使用，有java后台经验优先"
"职位描述：
        
        此岗位面向2020年毕业生，坐标深圳南山科技园，实习期薪资为3.5-4.5k；要求在公司全职实习半年以上，实习满3个月且评审通过后可签订三方协议，实习满6个月且评审通过后签订劳动合同，无试用期。

岗位职责：
1、从事大数据分布式存储/应用服务的设计和开发，挑战大规模、高并发、易运维的分布式系统设计构建；
2、参与负责大数据运营/风控/分析等数据应用产品开发迭代，包括需求讨论需求/系统/算法的讨论、设计及实现；
3、定位和解决集群组件如Spark、Hive、HBase、Kafka的性能和高可用问题，协助集群监控系统的开发。

任职要求：
1、2020年统招本科及以上学历，计科类相关专业；
2、良好的计算机基础；了解面向对象和设计模式，了解 spring , mybatis 等常用框架，数据库基础扎实；?
3、对技术有强烈的兴趣，喜欢钻研，具有良好的学习能力、沟通和团队合作能力。

加分项：?
1、熟悉Python、Ruby等语言；
2、熟练掌握常见Linux shell命令；??
3、喜欢在Mac/Linux下进行开发；
4、有代码洁癖，看到代码中的坏味道有浑身不自在的感觉；
5、自我驱动、喜欢Coding。"
"职位描述：
        
        岗位职责：
1、从事大数据分布式存储/应用服务的设计和开发，挑战大规模、高并发、易运维的分布式系统设计构建；?
2、负责大数据应用产品的开发工作（营销、推荐、搜索、分析统计等），包括系统/算法的设计及实现；
3、解决海量数据高效处理、交互式查询、流式分析等技术难点，对现有系统的不足进行分析，难点攻关；
4、跟踪评估数据产品线上效果，参与各业务部门的产品设计讨论，促进大数据产品的广泛落地各产品线；
5、梳理当前团队技术瓶颈、技术栈短板评估，业务线大数据需求技术预判相关技术预研。

任职要求：
1、统招本科及以上学历，5年及以上大数据相关工作经验，精通Java/Python服务端设计开发经验；
2、具备成熟的系统设计架构能力，丰富的高并发、分布式的系统设计经验；
3、熟悉业界先进的大数据生态组件（MR/Spark/HBase/ElasticSearch/ClickHouse），有成熟的系统设计应用经验；
4、对新技术保持求知欲，有优良的Trouble Shooting能力；
5、熟悉Mysql/Redis/MongDB等系统原理机制以及线上应用经验原则；
6、具有优秀的代码治理经验，良好的表达能力和团队协作精神；
7、具备知识图谱、算法平台、实时多维分析、搜索可视化经验者优先；
8、有大数据产品线上大型系统设计开发/线上算法设计实践经验者优先。"
"职位描述：
        
        岗位职责：
1、负责数据仓库模型设计、主题梳理、分层体系构建、元数据管理以及核心应用产品开发；
2、负责海量数据实时同步和分发系统的开发和优化、ETL框架的开发和监控工作；
3、支撑多样的海量数据OLAP分析场景，负责底层大规模数据的存储、索引和实时查询功能设计和开发；
4、基于海量特征数据，挖掘用户标签和构建用户画像，负责用户画像系统的基础建设和应用监控；
5、负责前瞻技术的调研选型、分享和推广。

任职资格:
1、统招本科及以上学历，计算机基础扎实，5年以上相关经验；
2、丰富的Java/Scala/Python/SQL开发经验，了解JVM调优，追求代码洁癖、熟练在Linux上工作；
3、熟悉企业级数据仓库方法论，熟悉元数据管理和数据质量监控过程、具备丰富的ETL开发经验；
4、熟悉用户标签体系和画像系统开发流程；
5、熟悉2个以上分布式存储和计算组件原理和应用，如Hadoop、Hive、Spark、HBase、Kafka、Druid和Elasticsearch等，从事过性能调优及阅读过部分源码者优先；
6、了解流式/实时计算，拥有海量数据OLAP系统开发经验者优先；
7、有较强的学习能力和快速解决问题能力，对技术有较高的热情，愿意钻研，热衷于新技术学习和分享。"
"职位描述：
        
        【岗位职责】
1、从事大数据分布式存储/应用服务的设计和开发，挑战大规模、高并发、易运维的分布式系统设计构建；?
2、负责大数据应用产品的开发工作（营销、推荐、搜索、分析统计等），包括系统/算法的设计及实现；
3、解决海量数据高效处理、交互式查询、流式分析等技术难点，对现有系统的不足进行分析，难点攻关；
4、跟踪评估数据产品线上效果，参与各业务部门的产品设计讨论，促进大数据产品的广泛落地各产品线；
5、梳理当前团队技术瓶颈、技术栈短板评估，业务线大数据需求技术预判相关技术预研。

【任职要求】
1、统招本科及以上学历，计算机、数学等相关专业，3年及以上大数据相关工作经验，精通Java/Python服务端设计开发经验；
2、具备成熟的系统设计架构能力，丰富的高并发、分布式的系统设计经验；
3、熟悉业界先进的大数据生态组件（MR/Spark/HBase/ElasticSearch/ClickHouse），有成熟的系统设计应用经验；
4、熟悉Mysql/Redis/MongDB等系统原理机制以及线上应用经验原则；
5、对新技术保持求知欲，有优良的Trouble Shooting能力；
6、具有优秀的代码治理经验，良好的表达能力和团队协作精神。

有以下工作经验PLUS:
1、有大数据产品线上大型系统设计开发/线上算法设计实践经验者优先；
2、具备数据仓库建设、搜索可视化经验者优先；
3、有知名互联网公司大数据工作经验者优先。"
"职位描述：
        
        【岗位职责】
1、负责基于Hadoop/Spark/Hive/HBase/kafka等分布式计算平台实现离线分析、实时分析的计算框架；
2、负责大数据应用产品（营销、推荐、搜索、分析等）的设计、开发、维护工作，包括系统/算法的设计及实现；
3、在线推荐及广告营销系统开发，实时数据和离线数据的加工分析及可视化等。

【任职要求】
1、统招本科及以上学历，2年及以上工作经验，熟悉Java/Python编程，良好的计算机领域理论基础；
2、熟悉业界先进的分布式计算平台和分布式文件系统，如MR、Spark、Hive、HBase、ElasticSearch等；
3、熟悉Redis,MongoDB等分布式缓存数据库至少一种；
4、积极乐观，有责任心，较好的抗压能力，良好的表达能力；
5、具备搜索可视化经验者（ElasticSearch、ClickHouse、SnappyData等组件）优先；
6、有大数据产品线上大型系统设计开发/线上算法设计实践经验者优先。

【关于公司】
行业独角兽：国内最大的金融服务提供商，旗下拥有随手记、卡牛信用卡管家两款App；
用户基数大：服务用户超过3亿，是国内最大的互联网金融流量入口之一；
发展空间大：上升空间大，专业与管理双线程并行，深度接触名企大咖；
福利待遇佳：有市场竞争力的薪酬，六险一金、年度体检、下午茶、生日会、节日福利、出境旅行、带薪年假、班车等。"
"职位描述：
        
        岗位职责：
1. 负责大数据反欺诈平台建设，参与系统整体分析、设计，编码，技术方案制定以及相关技术调研；
2. 深入理解业务各环节，与具体业务对接负责大数据反欺诈能力具体落地至集团各业务场景，提高业务风控能力；
3. 对技术有较强的钻研精神，保持对业界先进方案的跟踪和及时跟进、持续推进相关系统的迭代升级保证系统面对高速发展业务的有效支持；
4. 对接风控策略、风控算法等其他上下游配合部门，保持对相关领域的了解跟进，保持对接的高质量高效率。

任职要求：
1. 本科及以上学历，3年及以上大数据/风控应用开发的经验，扎实编码能力和一定系统架构能力；
2. 熟悉分布式系统的设计和应用，熟悉分布式、缓存、消息等机制，能有效设计相关技术解决方案；??
3. 精通Java，掌握多线程及高性能的设计与编码及性能调优；有高并发和微服务开发应用经验；
4. 熟悉MySQL、Redis、RabbitMQ、Kafka、Zookeeper等中间件，熟悉Hadoop生态技术优先；
5. 有成熟互金风控相关系统建设经验优先。"
"职位描述：
        
        岗位职责：
1、参与数据仓库模型设计、主题梳理、分层体系构建、元数据管理以及核心应用产品开发；
2、负责海量数据实时同步和分发系统的开发和优化、ETL框架的开发和监控工作；
3、支撑多样的海量数据OLAP分析场景，负责底层大规模数据的存储、索引和实时查询功能设计和开发；
4、基于海量特征数据，挖掘用户标签和构建用户画像，负责用户画像系统的基础建设和应用监控；
5、负责前瞻技术的调研选型、分享和推广。

任职资格:
1、统招本科及以上学历，计算机基础扎实，3年以上相关经验；
2、丰富的Java/Scala/Python/SQL开发经验，了解JVM调优，追求代码洁癖、熟练在Linux上工作；
3、熟悉企业级数据仓库方法论，熟悉元数据管理和数据质量监控过程、具备丰富的ETL开发经验；
4、熟悉用户标签体系和画像系统开发流程；
5、熟悉2个以上分布式存储和计算组件原理和应用，如Hadoop、Hive、Spark、HBase、Kafka、Druid和Elasticsearch等，从事过性能调优及阅读过部分源码者优先；
6、了解流式/实时计算，拥有海量数据OLAP系统开发经验者优先；
7、有较强的学习能力和快速解决问题能力，对技术有较高的热情，愿意钻研，热衷于新技术学习和分享。"
"职位描述：
        
        工作职责
1.负责实时数据流应用系统的开发，包括大规模流数据处理、查询统计、AI模型集成落地进行在线预测等计算服务。
2.善于发现系统的性能瓶颈、设计缺陷，提出改进方案并实施。
任职要求
1.本科及以上学历，计算机相关专业（211、985院校优先）;
2.3年以上JAVA开发工作经验，熟悉JVM、多线程、设计模式;
3.掌握分布式实时流处理框架的底层工作原理，深入使用过某种流处理技术，如Spark Streaming、Flink或Storm，熟悉Flink的优先；
熟悉并理解Kafka工作原理；熟悉并使用过NoSQL数据库，包括redis，hbase、elasticsearch等开源存储； 
4.具有快速定位和解决问题的能力;
5.具有强烈的责任心，良好的团队合作意识，勇于接受技术挑战，对新技术研究有浓厚兴趣。"
"职位描述：
        
        工作职责
1.负责公司大数据离线、实时平台（如Hadoop/Hive/Storm/Spark/Flink）的建设、优化
2.负责开发大数据工具，如报表平台、多维度分析工具、ETL平台、调度平台的研发；
3.负责数据可视化分析平台设计和开发
任职要求
1. 3年以上大数据基础架构相关工作经验，有数据仓库建设的相关工作经验；良好的英文阅读能力；
2.扎实的Java、Scala语言基础，对JVM运行机制有深入了解；
3.熟悉Hadoop、Spark并有丰富的开发经验；有深入研究过Hadoop/Spark源码者优先
4.熟悉SQL和noSQL的设计和开发，熟悉SQL性能调优；
5.善于思考，能独立分析和解决问题，热衷于新技术的研究和创新；
6.责任心强，沟通能力好，具备良好的团队合作精神；"
"职位描述：
        
        职位描述
1、通过大数据处理、数据分析、挖掘等技术，对海量用户行为数据进行挖掘与分析；
2、与搜索、推荐等业务相关产品、运营同学深度配合，通过用户数据挖掘产品痛点、探寻优化思路，并参与到产品优化的各环节；用数据说话，用数据推动产品迭代；
3、参与产品和业务宏观层面评估体系构建，设计并研发评估指标，推进规范化评估流程；
4、参与海量用户行为日志设计、数据仓库设计、日志分析计算等相关工作。

职位要求
1、3年以上大数据开发及数据仓库经验，熟悉常用大数据处理、挖掘、BI分析等技能；
2、精通SQL/python/java 等脚本或高级语言的一种或多种，熟悉linux平台；
3、具有良好的数据嗅觉，优秀的逻辑思维、沟通能力、推动能力；
4、计算机或者相关专业本科以上学历。"
"职位描述：
        
        1、负责高德LBS服务中台的建设与维护，满足内外部需求
2、基于大数据挖掘成果构建基础能力，赋能上层商业化应用
3. 用户画像构建
职位要求：
1. 本科以上从事java开发3+年以上，熟悉shell、python等
2. 熟练使用sql，较强的编码/调试诊断能力,扎实的数据结构和算法功底
3. 有hadoop MR开发经验，熟悉Hive，Spark，Storm，Kafka等大数据处理框架是加分项
4. 用户画像、机器学习、数据挖掘等相关项目经验优先
5. 有知名互联网公司或大数据背景者优先
6. 沉稳厚重，严谨皮实，具备强烈的进取心、求知欲及团队合作精神"
"职位描述：
        
        1. 线上日志打点/埋点服务;原始日志实时分析抽取合并
2. 用户画像构建
3. 核心指标统计报表系统开发
职位要求：
1. 本科以上从事java开发3+年以上，熟悉shell、python等
2. 熟练使用sql，较强的编码/调试诊断能力,扎实的数据结构和算法功底
3. 有hadoop MR开发经验，熟悉Hive，Spark，Storm，Kafka等大数据处理框架是加分项
4. 用户画像、机器学习、数据挖掘等相关项目经验优先
5. 有知名互联网公司或大数据背景者优先
6. 沉稳厚重，严谨皮实，具备强烈的进取心、求知欲及团队合作精神"
"职位描述：
        
        职位描述：
1、通过大数据处理、数据分析、挖掘等技术，对海量用户行为数据进行挖掘与分析；
2、与搜索、推荐等业务相关产品、运营同学深度配合，通过用户数据挖掘产品痛点、探寻优化思路，并参与到产品优化的各环节；用数据说话，用数据推动产品迭代；
3、参与产品和业务宏观层面评估体系构建，设计并研发评估指标，推进规范化评估流程；
4、参与海量用户行为日志设计、数据仓库设计、日志分析计算等相关工作。

任职要求：
1、3年以上大数据开发及数据仓库经验，熟悉常用大数据处理、挖掘、BI分析等技能；
2、精通SQL/python/java 等脚本或高级语言的一种或多种，熟悉linux平台；
3、具有良好的数据嗅觉，优秀的逻辑思维、沟通能力、推动能力；
4、计算机或者相关专业本科以上学历。"
"职位描述：
        
        职位描述:
UC头条数据平台,上亿级流量用户行为收集计算处理支撑推荐策略算法,数据分析统计报表
工作职责：
1. 线上日志打点/埋点服务;原始日志实时分析抽取合并
2. 用户画像构建
3. 核心指标统计报表系统开发
职位要求：
1. 本科以上从事java开发3+年以上，熟悉shell、python等
2. 熟练使用sql，较强的编码/调试诊断能力,扎实的数据结构和算法功底
3. 有hadoop MR开发经验，熟悉Hive，Spark，Storm，Kafka等大数据处理框架是加分项
4. 用户画像、机器学习、数据挖掘等相关项目经验优先
5. 有知名互联网公司或大数据背景者优先
6. 沉稳厚重，严谨皮实，具备强烈的进取心、求知欲及团队合作精神"
"职位描述：
        
        职位描述：
1、负责用户产品日志收集系统开发，保障系统稳定，建立有效日志收集监控体系；
2、负责日志实时处理系统开发，稳定产出实时统计指标；
3、负责项目数据仓库的建设和离线数据统计，提供可视化报表；
4、负责对外数据服务的开发，保障服务安全，稳定；
职位要求：
1、计算机或相关专业本科及以上学历，3年以上大数据开发经验，对数据搜集、数据处理、数据仓库建模有实战经验；
2、熟悉Linux/Unix开发环境，精通python/java/shell，扎实的数据结构和算法功底
3、熟悉Hadoop、Spark、Hive、flink等批量和流式体系结构，并有实际开发经验；
4、熟悉底层中间件、分布式技术（如RPC框架、缓存、消息系统等），对高并发java web系统有一定实际经验；
5、有信息流相关项目经验是加分项；
6、技术专家 增加要求：能够在整体在线和离线系统架构设计方面，保证系统的正确性和稳定性；"
"职位描述：
        
        职位描述：
UCAds广告平台是依托于在印度，印度尼西亚排名第一的UC浏览器建立起来的自有流量变现广告平台。当前国内互联网已是一片红海， 竞争十分激烈，出海已是必然趋势。UCAds选择深耕南亚、东南亚等新兴互联网市场，利用自身技术优势，抓住出海这波浪潮并获得了快速的发展机遇。

1、负责离线和实时大数据处理流程建设
2、负责广告大数据平台的仓库模型设计、数据模型建模
3、负责数据对接海内外知名DSP平台（facebook、admob、adsense、mobvista等），数据ETL的设计、开发与性能优化
4、负责大数据平台基础设施建设

职位要求：
1、熟悉python或java语言，熟悉hive/hadoop/flink/hbase等分布式计算技术，熟悉其运行机制和体系结构，有Map Reduce作业编写经验优化
2、灵活运用SQL实现海量数据ETL加工处理，有较好的SQL性能调优经验
3、熟悉数据仓库领域知识和相关技能
4、有足够的代码质量意识，时间管理意识，团队协作意识
5、有广告大数据领域相关工作经验者优先"
"职位描述：
        
        职位描述：
1、负责阿里文学实时数据流、数据服务引擎、ABTest、个性化推荐平台系统搭建和开发，降低数据使用门槛，实现数据最大业务价值；
2、参与底层工具、平台、部署等技术体系建设和研发；
3、负责数据可视化分析平台设计和开发。

任职要求：
1、本科及以上学历，计算机相关专业，3年以上大数据平台相关工作经验；
2、熟悉Python/C/C++/Java中的一种，具备良好的编码习惯和算法基础；
3、熟悉Linux平台开发，熟悉多线程开发；，
4、熟悉Hadoop、Spark、Storm、Flink、YARN、Zookeeper等大数据平台开源软件，有实际项目架构经验，开源社区贡献者优先；
5、熟悉HDFS、HBase等分布式文件存储开源软件，开源社区贡献者优先；
6、熟悉搜索、推荐系统系统算法平台者优先。"
"职位描述：
        
        职位描述：
1.参与头条，浏览器数据集市规划、数据架构设计与研发；
2.负责产品的数据分析工作，挖掘数据分析需求。
3.结合分析结果及对业务需求的深入理解，设计业务指标体系及数据产品并驱动研发。

任职要求：
1.从事数据仓库或挖掘领域至少5年以上，熟悉数据仓库模型设计与ETL开发经验 ，掌握维度建模设计方法，具备海量数据处理经验；
2.熟悉数据仓库领域知识和技能者优先，包括但不局限于：元数据管理、数据开发测试工具与方法、数据质量、主数据管理；
3.有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验着优先，如Hdfs、Mapreduce、Hive、Hbase、Spark、Storm；
4.熟练掌握一门或多门编程语言，并有大型项目建设经验者优先，如Java、Python、Shell；
5.良好的语言沟通与表达能力，自我驱动。"
"职位描述：
        
        职位描述
1、开发并维护DNS数据管控系统，管理规模化分布在全球的DNS集群服务；
2、为业务中台服务，保障其HA，对数据分发的性能及数据一致性负责；
3、参与管控架构的技术演进，稳定的兼容各类商业化场景技术要求；

能力要求
1、5年以上分布式、高并发、高负载、高可用性系统设计和维护的实施经验；
2、熟悉python/Java，对开源框架Django、flask及缓存技术、消息系统等关键中间件技术；
3、较好的代码能力和系统bug排查能力，经历过平台型技术重构和演进者优先；"
"职位描述：
        
        1.较为丰富的数据仓库及数据平台的架构经验，期望通过对业务的深入理解，发挥数据价值，并反哺数据体系的建设，有零售行业、营销、供应链、品类规划背景尤佳；较为系统的海量数据性能处理经验
2.有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关开发经验，有Spark/Flink的开发经验尤佳
3.具有良好的商业敏感度，对业务问题能高效的转化为算法和数据问题，为业务带来数据价值。能综合运用现有数据、算法、产品等能力，形成数据化解决方案，并形成某一领域内可复用的方法论
4.有非结构化数据建设、知识图谱构建经验尤佳，反哺数据资产能力，给业务带来更多数据价值增量"
"职位描述：
        
        工作职责：

 参与口碑数据仓库的架构设计与研发，建设PB级的数据集市和数据管理，实现高质量数据的互通与共享
 参与口碑数据产品与应用的数据研发，发掘数据商业价值，与产品技术团队一起打造极致体验的数据产品
 参与口碑数据化运营，构建丰富多样的BI应用，助力业务产品不断优化
 参与口碑数据对外开放的建设工作，帮助ISV服务商更好的服务每个线下商户


职位要求

 从事数据仓库领域3年及以上，熟悉仓库模型设计与ETL开发经验，有O2O领域数据建设经验优先
 掌握Kimball的维度建模设计方法，具备海量数据加工处理（ETL）相关经验,灵活运用SQL实现海量数据ETL加工处理
 熟悉数据仓库运维管理相关领域，包括但不局限于：元数据管理、数据质量、主数据管理、ETL流程运维等
 熟悉JAVA语言，有分布式数据存储与计算应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验，重点考察Hdfs、Mapreduce、Hive等
 掌握实时流计算技术，有spark streaming开发经验者优先
 良好的语言沟通与表达能力、较强的自我驱动能力"
"职位描述：
        
        【大数据处理、特征工程平台、知识图谱 开发工程师】
职位描述
1、参与特征中心、特征计算以及样本中心开发
2、关注机器学习、大数据处理、索引和排序等技术的前沿方向，前瞻性地进行搜索和推荐系统的架构设计，并推动落地。

职位要求
1、学习能力强，有良好的较好的创新能力和逻辑思维能力，善于主动思考，对技术有强烈激情；
2、有良好的沟通能力，跨团队协作能力，具备出色的计划和执行力，强烈的责任感；
3、熟悉一种以上海量数据处理平台/框架，如Hadoop、Storm、Flink 、Spark、HBase，Elasticsearch等开源系统者优先；
4、有搜索引擎、推荐系统、广告系统、用户行为挖掘、大数据处理方面经验者优先。"
"职位描述：
        
        岗位职责：
1、?语音识别系统的数据处理，声学、语言模型训练，结果分析，实验验证；
2、?对新业务的语音识别率进行测试、分析与优化；?
3、?定期监控、检查模型的准确率及运行效率；
4、?语音算法与技术进展跟踪；
5、?语音功能探索、研发；
?
任职要求：
1、?计算机、电子、自动化等相关专业硕士及以上学历，能够熟练阅读英文技术文档，具有声学背景优先；
2、?了解基于深度学习的语音识别模型，例如CNN，BiLSTM，CTC等；
3、?有智能语音平台相关工作经验者优先；
4、?熟练掌握C/C++，Python；
5、?至少掌握Kaldi、TensorFlow或PyTorch等开源框架中的一种。"
"职位描述：
        
        岗位职责：
1、?语音识别系统的数据处理，声学、语言模型训练，结果分析，实验验证；
2、?对新业务的语音识别率进行测试、分析与优化；?
3、?定期监控、检查模型的准确率及运行效率；
4、?语音算法与技术进展跟踪；
5、?语音功能探索、研发；
?
任职要求：
1、?计算机、电子、自动化等相关专业硕士及以上学历，能够熟练阅读英文技术文档，具有声学背景优先；
2、?了解基于深度学习的语音识别模型，例如CNN，BiLSTM，CTC等；
3、?有智能语音平台相关工作经验者优先；
4、?熟练掌握C/C++，Python；
5、?至少掌握Kaldi、TensorFlow或PyTorch等开源框架中的一种。"
"职位描述：
        
        岗位职责：
1、负责生产环境数据库系统高可用、高性能架构方案，分库分表策略，数据库扩展方案；
2、排查数据库故障，分析和解决疑难问题，提出预防方案；
3、制定数据库监控策略,备份策略,容灾策略；探查系统潜在的问题和可能的性能瓶颈,并进行优化；
4、对开发工程师的SQL语句进行审核，SQL优化；
5、参与前瞻性新技术研究，解决数据库相关疑难问题；
6、负责redis,MongoDB等非关系数据库的管理和扩展。

任职要求：
1、具备5年以上专职DBA工作经验，包括：MySQL、Oracle；
2、计算机及相关专业，本科以上学历；
3、具备优秀的数据库架构设计能力，精通关系型数据库性能优化；
4、精通关系型数据库的运行机制和体系架构；
5、精通数据库核心参数设置和调整；
6、精通redis,MongoDB等非关系数据库管理；
7、需具备IO与系统性能优化的经验；
8、需具备良好的职业道德，工作认真、踏实，责任心强，有团队协作精神；
9、有大型网站数据库高并发量设计经验、熟悉大型数据库的设计、容量/性能管理和调优者优先；
10、有大数据实践经验者优先；
11、有ETL、数据仓库、数据建模开发实施经验者优先。
12、有Hadoop/Hive/Storm/Spark等系统的开发经验者优先；
13、有机器学习、数据挖掘、数据可视化开发经验者优先。"
"职位描述：
        
        岗位职责：
1、负责生产环境数据库系统高可用、高性能架构方案，分库分表策略，数据库扩展方案；
2、排查数据库故障，分析和解决疑难问题，提出预防方案；
3、实施数据库监控策略,备份策略,容灾策略；
4、对开发工程师的SQL语句进行审核，SQL优化；
5、支持数据库SQL上线发布；
6、参与redis,MongoDB等非关系数据库的管理和扩展。

任职要求：
1、具备3年以上专职DBA工作经验，包括：MySQL、Oracle；
2、计算机及相关专业，本科以上学历；
3、熟悉关系型数据库的运行机制和体系架构；
4、熟悉Linux系统管理和操作，有Shell或者python开发能力；
5、熟悉redis,MongoDB等非关系数据库管理；
6、需具备良好的职业道德，工作认真、踏实，责任心强，有团队协作精神；
7、oracle OCP优先；
8、有ETL、数据仓库、数据建模开发实施经验者优先；
9、有Hadoop/Hive/Storm/Spark等系统的开发经验者优先。"
"职位描述：
        
        岗位职责：
1、负责开发测试环境数据库管理、迁移、部署等管理；
2、参与排查数据库故障，分析和解决疑难问题；
3、实施数据库监控策略,备份策略,容灾策略；
4、参与对开发工程师的SQL语句进行审核，SQL优化；
5、支持数据库SQL上线发布。

任职要求：
1、具备2年以上专职DBA工作经验，包括：MySQL、Oracle；
2、计算机及相关专业，本科以上学历；
3、熟悉关系型数据库的运行机制和体系架构；
4、熟悉Linux系统管理和操作，有Shell或者python开发能力；
5、需具备良好的职业道德，工作认真、踏实，责任心强，有团队协作精神；
6、oracle OCP优先；
7、有ETL、数据仓库、数据建模实施经验者优先。"
"职位描述：
        
        岗位职责：
1、参与数据平台相关业务的设计和大数据平台开发?
2、保障和提升数据平台业务支撑能力
3、负责相关模块的研发，保证系统性能、稳定和安全
4、基于Hadoop生态系统相关开源技术的开发和优化等工作
5、完成领导交办的其他工作
职位要求： ?
1. 互联网或金融行业5年以上java/scala项目开发经验，JVM内存模型、对gc性能调优有一定经验 ?
2. 熟悉常用设计模式、IO编程、多线程开发、常用算法、数据结构等，熟悉http/https、tcp/ip等通讯协议 ?
3.? 熟悉分布式工作原理，其中3~4年以上大数据平台或项目开发经验。。有金融类项目经验者优先
4. 熟练掌握hadoop/zookeeper/kafka/hive/flume/es/spark/spark streaming/flink等大数据生态圈开源技术
5. 熟练掌握mysql或oracle, 至少掌握以下主流nosql中的1种:　redis/mongodb/hbase?
6.? 有Linux下开发、部署和调试能力。熟练掌握常用Linux命令，具备shell编程能力?
7.? 熟练掌握git/svn 版本管理工具, maven构建工具。Eclipse、IDEA等开发工具
8. ?有较强的责任心和良好的沟通能力，有独立解决问题的能力和排查分析定位问题的能力
9.? 关注大数据生态圈和开源论坛社区，有开源代码贡献者优先
岗位任职条件：
1、学历与专业：计算机相关专业
2、年龄与性别：35以内 男
3、工作经验：5年以上java/scala等项目开发经验，其中需包含3~4年以上大数据
4、行业背景：互联网、金融、IT等
5、计算机使用技能：java hadoop spark Kafka es等
6、素质能力及性格特征：有团队意识 积极主动 热爱钻研技术
7、其他：英语良好"
"职位描述：
        
        岗位职责：
1、参与数据平台相关业务的设计和大数据平台开发?
2、保障和提升数据平台业务支撑能力
3、负责相关模块的研发，保证系统性能、稳定和安全
4、基于Hadoop生态系统相关开源技术的开发和优化等工作
5、完成领导交办的其他工作
职位要求： ?
1. 互联网或金融行业5年以上java/scala项目开发经验，JVM内存模型、对gc性能调优有一定经验 ?
2. 熟悉常用设计模式、IO编程、多线程开发、常用算法、数据结构等，熟悉http/https、tcp/ip等通讯协议 ?
3.? 熟悉分布式工作原理，其中3~4年以上大数据平台或项目开发经验。。有金融类项目经验者优先
4. 熟练掌握hadoop/zookeeper/kafka/hive/flume/es/spark/spark streaming/flink等大数据生态圈开源技术
5. 熟练掌握mysql或oracle, 至少掌握以下主流nosql中的1种:　redis/mongodb/hbase?
6.? 有Linux下开发、部署和调试能力。熟练掌握常用Linux命令，具备shell编程能力?
7.? 熟练掌握git/svn 版本管理工具, maven构建工具。Eclipse、IDEA等开发工具
8. ?有较强的责任心和良好的沟通能力，有独立解决问题的能力和排查分析定位问题的能力
9.? 关注大数据生态圈和开源论坛社区，有开源代码贡献者优先
岗位任职条件：
1、学历与专业：计算机相关专业
2、年龄与性别：35以内 男
3、工作经验：5年以上java/scala等项目开发经验，其中需包含3~4年以上大数据
4、行业背景：互联网、金融、IT等
5、计算机使用技能：java hadoop spark Kafka es等
6、素质能力及性格特征：有团队意识 积极主动 热爱钻研技术
7、其他：英语良好"
"职位描述：
        
        业务技能要求：
1、3年以上智慧城市项目交付经验，熟悉智慧城市交付范围、典型业务场景、典型组网、国家标准及规范体系；
2、熟悉智慧城市基本技术架构，熟悉云平台/ICT使能平台/大数据平台基本技术，掌握大数据的分布式存储和计算等知识；
3、针对智慧城市各子系统，掌握其架构设计、业务流设计、对接设计、场景化功能验证、对接验证、非功能性验证、集成实施等能力；

专业知识要求：
1、理解智慧城市整体架构及各模块相关领域知识，如IOC、智慧应用、城市物联网、政务大数据等。

其他要求：
1） 工作汇报对象：在常住地期间，向智慧城市解决方案服务负责人汇报；在项目组期间，向相关项目干系人汇报
2） 可全国出差
3） 具备英语沟通交流能力
4） 在项目组期间，可直接面对客户，承担TL/SA岗位"
"职位描述：
        
        岗位要求
1、扎实的Java、Scala语言基础，对JVM运行机制有深入了解；
2、有hadoop和spark实际开发经验。了解大数据组件的使用限制和应用场景，如hdfs,yarn,hbase,hive,flume,kafka,zk,ES,Storm等
3、熟悉mysql、ElasticSearch、Redis等关系型或NoSQL数据库，了解应用场景和使用限制。有实际调优经验者更佳。
以下优先考虑：
1、熟悉并行计算或者分布式计算，熟悉Spark框架,熟练掌握RDD，SQL, Streaming, MLLIB，SparkR编程；
2、有深入研究过Hadoop/Spark源码者优先；
3、深入理解HDFS分布式文件系统架构；熟练掌握Hadoop/Hive/HBASE的运维和调优方法；
4、熟悉linux常用命令，有实际CDH或HDP或apache版本的hadoop部署经验者优先；
5、掌握或使用过Storm、Spark、flume、kafka等工具；
6、1-2年以上大数据相关工作经验，最好参与并成功部署过1个日均TB级的集群项目。"
"职位描述：
        
        工作职责:1、负责大数据BI设计和开发。 2、负责阅文日常数据统计分析3、数据仓库、数据集市的模型设计与开发4、负责ETL数据准确性验证及ETL任务的优化5、参与大数据平台和数据仓库的的搭建任职资格:1、熟悉大数据处理相关产品架构和技术（如Hadoop/Hive/HBase/Spark/Kafka/Storm/Flume等） 2、熟悉数据仓库理论与技术，对ETL及BI有概念并具有丰富的实际操作经验，熟悉ETL开发流程； 3、熟悉BI项目，具有数据仓库、BI系统开发经验者优先4、对mysql、oracle有丰富经验，有较强的数据库脚本编程能力，有较强的存储过程编写能力； 5、熟练操作linux系统，熟悉shell脚本或python； 6、有较强的逻辑思维能力，善于分析、归纳、快速定位并解决问题； 7、性格积极且沉稳，勤奋严谨，强烈的进取心、求知欲和团队合作精神"
"职位描述：
        
        工作职责:负责大数据BI设计和开发；负责阅文日常数据统计分析；数据仓库、数据集市的模型设计与开发；负责ETL数据准确性验证及ETL任务的优化；参与大数据平台和数据仓库的的搭建。
任职资格:熟悉大数据处理相关产品架构和技术（如Hadoop/Hive/HBase/Spark/Kafka/Storm/Flume等） ；熟悉数据仓库理论与技术，对ETL及BI有概念并具有丰富的实际操作经验，熟悉ETL开发流程；?熟悉BI项目，具有数据仓库、BI系统开发经验者优先；对mysql、oracle有丰富经验，有较强的数据库脚本编程能力，有较强的存储过程编写能力；?熟练操作linux系统，熟悉shell脚本或python；?有较强的逻辑思维能力，善于分析、归纳、快速定位并解决问题；?性格积极且沉稳，勤奋严谨，强烈的进取心、求知欲和团队合作精神。"
"职位描述：
        
        工作职责:负责大数据BI设计和开发。 负责阅文集团日常数据统计分析数据仓库、数据集市的模型设计与开发负责ETL数据准确性验证及ETL任务的优化参与大数据平台和数据仓库的的搭建任职资格:熟悉大数据处理相关产品架构和技术（如Hadoop/Hive/HBase/Spark/Kafka/Storm/Flume等） 熟悉数据仓库理论与技术，对ETL及BI有概念并具有丰富的实际操作经验，熟悉ETL开发流程； 熟悉BI项目，具有数据仓库、BI系统开发经验者优先对MySQL、Oracle有丰富经验，有较强的数据库脚本编程能力，有较强的存储过程编写能力； 熟练操作linux系统，熟悉shell脚本或python； ?有较强的逻辑思维能力，善于分析、归纳、快速定位并解决问题； 性格积极且沉稳，勤奋严谨，强烈的进取心、求知欲和团队合作精神"
"职位描述：
        
        岗位职责
1. 主要负责阅文集团（QQ阅读、起点、各分子公司）业务数据结算系统开发与维护；
2. 负责实时数据业务开发。

岗位要求?
1. 3年以上工作经验，数据库基础扎实，熟悉主流数据库产品、如MySQL，精通SQL、存储过程开发，有较好SQL性能调优经验；
2. 至少熟练使用Python、Shell、Perl等脚本语言之一；
3. 熟悉hadoop、hive、spark、storm等分布式系统开发与维护，有流式计算开发经验者优先；
4. 熟悉ETL开发、数据建模，有数据仓库设计实施经验者优先；
5. 有数据分析、机器学习经验者优先；
6. 有计费、支付经验者优先；
7. 学习能力强，抗压能力强；具备耐心/细心的品质。"
"职位描述：
        
        工作职责:负责阅文集团-腾讯合作业务（手机QQ阅读中心）用户行为数据采集，数据仓库、ETL任务设计及开发，大数据BI平台开发等工作；负责相关业务的数据梳理以及流程优化，完善数据指标体系建设，为产品迭代提供数据化分析的方法论以及数据支撑；承担策略分析、用户行为分析、业务运营分析等多方数据开发需求。任职资格:计算机、通信、数学相关专业毕业，大学本科以上学历，计算机基础扎实，2年以上工作经验；熟悉数据采集、清洗入库；有扎实的代码编程能力；熟悉Hive、MapReduce等Hadoop生态系统，熟悉Linux命令、shell脚本，具有较强Sql开发能力；优秀的理解沟通能力；责任心强，具有良好的团队沟通与协作能力；对数据敏感，有数据挖掘、数据分析能力者优先；"
"职位描述：
        
        岗位职责：1、负责阅文集团日常数据统计分析2、数据仓库、数据集市的模型设计与开发3、负责ETL数据准确性验证及ETL任务的优化4、负责ETL任务的各种异常和技术问题的解决5、参与大数据平台和数据仓库的的搭建 岗位要求：1、本科及以上学历，计算机应用科学等相关专业2、有Hadoop/hive/Hbase/spark/storm等大数据工具应用和开发经验3、熟悉Java/Python编程，能够使用java或者python等编程语言对数据进行处理；4、对数据敏感、对新技术敏感，有一定技术研究能力5、有海量数据开发经验和数据挖掘项目经验者优先6、性格积极且沉稳，勤奋严谨，强烈的进取心、求知欲和团队合作精神"
"职位描述：
        
        1. 本科及以上学历，计算机相关专业，1年以上大数据相关工作经验，2年以上Java开发经验；2. 熟练掌握大数据生态圈相关技术的开发及使用,?如：Hadoop、Hive、Hbase、Spark、Zookeeper、Flume、HDFS、Sqoop、storm、kafka、mongoDB、redis等，熟悉上述三种或以上；3. 熟悉Java，及常用框架Spring?Cloud、Spring?MVC，能用Java进行大数据开发；4. 熟悉kafaka、zookeeper、nginx、tomcat、weblogic等常用中间件技术；5. 善于思考，能独立分析和解决问题，热衷于互联网技术的研究和创新。"
"职位描述：
        
        大数据研发工程师

职位描述：
1、参与公司数据平台的架构设计及实施；
2、参与数据仓库的设计与实施；
3、参与符合业务的数据工具的抽像及研发。

任职条件
1、熟练应用大数据常用框架，如spark,hive,hbase等；
2、熟练开发spark streaming流式分析作业及离线分析作业，熟练应用spark 2.x新特性。
3、掌握scala开发语言，具有面向对象编程思想，对底层实现有一定研究；
4、有丰富的数据仓库经验，从数据采集到数据报表的整个全链条有比较深刻的理解；
5、有较强的学习能力、主动性和上进心，具有良好的沟通能力和团队合作精神。"
"职位描述：
        
        工作内容

 闪银贷前、贷中、贷后的大数据基础平台的规划、架构、部署和优化，保障平台稳定可靠高效运行
 负责核心模块研发，负责大数据平台的搭建，完成系统调试、集成与实施，以及大数据计算集群、存储集群、管理集群的设计与实现；
 负责建立和维护大数据平台技术标准规范，指导开发人员编写代码；负责建立和维护大数据平台技术标准规范，指导开发人员编写代码；
 负责大数据的分析和挖掘，接入和管理各业务数据，为产品决策提供数据的支持和建议，帮助产品进行优化改进。
 负责内部深度学习数据分布式存储和处理平台。技术调研，探索数据高效易用的新方法和系统落地。


任职要求：
1.本科及以上计算机、数学相关专业毕业；具有3年以上的、大型数据平台、从数仓到应用的搭建相关工作经验；2、精通离线和实时数据处理流程，掌握离线数据处理框架，掌握实时数据处理常用技术工具等；3、熟悉大数据技术生态圈，精通大数据技术架构，有大数据平台构建经验；
4.熟练掌握海量数据处理技术，精通spark/hadoop/hive海量数据分析建模，对hdfs、hbase、hive等分布式体系有丰富的研究及实践；
5.熟悉分布式系统的设计和应用，具备【很强的工程落地】实现能力?
6. 有Caffe/TensorFlow/Theano等深度学习开源框架实际应用经验优先
7、?对服务器集群有较深的理解；"
"职位描述：
        
        岗位职责：
风控数据平台建设，包括分布式机器学习平台、数据获取、特征提取、数据挖掘、用户画像等；

任职要求：
1、统招本科及以上学历，2年及以上大数据处理相关工作经验；
2、精通spark，熟悉hadoop生态常用技术；
3、熟悉Java/Scala/Python至少一门编程, 掌握面向对象编程思想和常见的设计模式；
4、对算法和数据结构有深刻的理解, 编码能力扎实；
5、熟练使用hive、sparkSQL、hbase，了解kafka、MQ、ES等。

加分项
1、对常用机器学习算法有一定了解者优先；
2、对分布式机器学习平台感兴趣者优先。"
"职位描述：
        
        岗位职责：
风控数据平台建设，包括分布式机器学习平台、数据获取、特征提取、数据挖掘、用户画像等；

任职要求：
1、统招本科及以上学历，2年及以上大数据处理相关工作经验；
2、精通spark，熟悉hadoop生态常用技术；
3、熟悉Java/Scala/Python至少一门编程, 掌握面向对象编程思想和常见的设计模式；
4、对算法和数据结构有深刻的理解, 编码能力扎实；
5、熟练使用hive、sparkSQL、hbase，了解kafka、MQ、ES等。

加分项
1、对常用机器学习算法有一定了解者优先；
2、对分布式机器学习平台感兴趣者优先。"
"职位描述：
        
        岗位职责：
风控数据平台建设，包括分布式机器学习平台、数据获取、特征提取、数据挖掘、用户画像等；

任职要求：
1、统招本科及以上学历，2年及以上大数据处理相关工作经验；
2、精通spark，熟悉hadoop生态常用技术；
3、熟悉Java/Scala/Python至少一门编程, 掌握面向对象编程思想和常见的设计模式；
4、对算法和数据结构有深刻的理解, 编码能力扎实；
5、熟练使用hive、sparkSQL、hbase，了解kafka、MQ、ES等。

加分项
1、对常用机器学习算法有一定了解者优先；
2、对分布式机器学习平台感兴趣者优先。"
"职位描述：
        
        岗位职责：
1、负责数据接入、数据清洗、底层重构，业务主题建模等工作；
2、负责大数据整体平台的架构与方案编写。

任职要求：
1、计算机、软件工程等相关专业，本科及以上学历，具有3年及以上大数据开发与架构分析经验优先考虑；??2、?熟悉Hadoop或Spark生态相关技术，包括MapReduce、hdfs、Hive、Spark等，1个以上大数据平台项目实施经验；?熟悉Oracle或MySQL数据库技术；有5年及以上大数据平台开发方面相关工作经验；?3、熟悉数据仓库和数据建模的相关技术细节，有编程经验，熟悉JAVA语言；熟悉SQL/Hadoop/Hive/Hbase/Spark等大数据工具。?4、具有海量数据处理经验，或有互联网行业数据挖掘工作经验者优先。"
"职位描述：
        
        职位描述：大数据研发主管岗位职责： ? ? ? ? ? ? ? ? ? ? ? ?1、带领团队根据项目大数据处理业务需求，设计大数据处理方案，实现相关功能。 ? ? ? ? ? ? ? ? ? ? ? ?2、搭建和维护大数据集群，保证集群规模持续、稳定、高效平稳运行。 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 3、制定大数据处理平台维护、优化、安全及高可用方案。 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?任职资格： ? ? ? ? ? ? ? ? ? ? ? ?1、本科以上学历8年以上工作经验，其中3年以上团队管理经验。有丰富项目开发经验。精通Java等主流编程语言。 ? ? ? ? ? ? ? ? ? ? ? ?2、精通Hadoop、Hbase、Hive、Spark等工作原理，3年以上实战经验，熟悉分布式计算实施过程中的各种问题。 3、熟练Zookeeper、Kafka、Elasticsearch、Logstash、Mysql等，有丰富的运维经验者优先。 ? ? ? ? ? ? ? ?4、熟悉Linux/Unix系统，熟悉Shell脚本语言。5、具有较强的沟通能力，团队协作能力，学习能力，执行力和组织能力。 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 7、工作态度积极主动、细致、有全局观，有较强的抗压能力，良好的团队合作意识。"
"职位描述：
        
        岗位职责：1、协助分析师进行项目相关资料搜集和研究；2、协助分析师进行数据抽取、数据清洗、数据探索、数据建模分析等工作；3、协助分析师完成数据分析报告、建模报告、数据报表项目相关文档工作；4、其他日常支撑工作。
任职要求：1、本科以上学历，大四在校生，刚毕业学生也可；2、专业背景是应用数学、统计学、计算机等相关专业， 熟悉 mysql数据库，会sql语言；具备编程能力；3、每周至少4天时间上班；4、能够利用工具进行筛选、合并、匹配等数据处理；5、良好的数理统计基础，熟悉python脚本者优先；6、具备良好的沟通能力和表达能力，逻辑清晰；7、具备良好的团队协作能力。"
"职位描述：
        
        工作职责：1、负责大数据相关产品的前端开发工作2、大数据产品前端设计工作职位要求：1、985，211本科及以上学历，从事web前端开发工作3年以上;
2、精通JS，并熟练使用react/vue任一框架；熟悉gulp/ webpack工程化构建，有前端自动化工作经验3、精通html5、css3、JS，对web标准化有深入见解4、有前端性能、工具研发方面的实践经验优先5、有良好的沟通能力、团队协作能力和学习能力，关注前沿技术6、有数据可视化产品或者大数据应用开发经验者优先"
"职位描述：
        
        职责描述：1.负责自动驾驶数据中心的搭建、维护及使用；2.支持人工智能及自动驾驶仿真工作开展任职要求：1.学历：本科以上学历；?2.专业：计算机、车辆工程等相关专业；?3.资历：具有3年以上云平台工作的开发。?4.技能要求：掌握一定的关系数据库知识，熟悉 SQL 语言，有 oracle, mysql 等任一一种使用经 历，对海量数据挖掘分析有浓厚兴趣，了解 Hadoop，NoSql 技术。"
"职位描述：
        
        一、专业知识技能：
1、3年工作经验，2年以上报表开发和银行工作经验，熟练使用永洪BI、SmartBI，Cognos，帆软等报表工具。
2、掌握ORACLE、DB2等数据库，并熟练通过SQL进行编程开发。
3、掌握数据仓库技术，能进行数据仓库数据模型的设计，能编写相关设计文档。
4、理工类专业，计算机、数学、统计学等相关专业优先。
二、基础能力：1、具有较强的学习能力，上进心强。
2、具备良好的逻辑思维能力和沟通表述能力。
3、工作积极主动，敢于挑战自我。
4、有清晰的职业规划和人生目标。
5、较好的责任心、客户服务意识。
三、岗位职责：
1、负责需求分析、Biee报表开发等实施工作。"
"职位描述：
        
        岗位职责：
?1、负责大数据应用功能开发，以及整体平台解决方案的产品化输出；
?2、负责编写对数据进行装载抽取，转换，去重，排序，去噪，特征提取，降维等大数据程序；
?3、负责数据采集程序，爬虫等程序按照预定规则清洗入库；?
4、负责基于大数据 ETL的处理方案的实施。


?任职资格：?
1、数学、统计学、计算机等相关专业本科及以上学历
?2、基础扎实， 熟悉 linux 系统， 熟练使用 javascalapythonshell 等语言
?3、熟悉Hadoop、HBase、HivePig、Storm、Spark、Mahout、NoSQL、ES中至少一种技术，阅读过源代码者优先；
?4、充分理解大数据背景下的计算模型，熟悉MapReduce、Spark开发流程模型中任一，并具有分布式开发经验；
?5、具备较强的逻辑思维能力、学习创新能力、数据分析能力，以及良好的沟通技巧和团队合作能力。"
"职位描述：
        
        1、参与大数据应用平台的设计与开发，解决海量数据面临的挑战；
2、负责大数据机器学习等模型的优化和集成工作，实现各类模型按统一的规范对外提供restful服务。
3、负责智能化决策平台的优化完善，实现大数据资源、模型资源能够实时对接到业务系统。
3、协助团队成员建立数据模型，对数据进行挖掘、优化及统计。
?
?
岗位要求：
1、数学、统计、计算机等相关理科专业，全日制本科及以上学历；
2、三年以上海量数据下数据挖掘和算法实施相关工作经验；
3、熟练运用python或者spark进行数据建模，熟悉hive、hadoop大数据处理技术的优先考虑；
4. 有金融行业、风险防控等领域经验的优先考虑。"
"职位描述：
        
        工作职责：?
1、参与公司数据类项目；?
2、参与ETL工作、建模、ORACLE数据仓库和GP数据仓库开发和维护等工作；?
3、参与数据类项目中数据探索、分析等工作；?
4、与团队内部机型有效的沟通，跟进项目进度以及解决相关数据问题；?
5、工作认真细致，愿意与人交流沟通； ?
?
任职资格：?
1、2年以上相关工作经验；?
2、熟悉BI类项目的实施方法论，熟悉项目的实施和开发过程，具有实施和开发经验；?
3、能够独立或部分独立完成数据模型的设计与开发；?
4、熟练使用Oracle、Postgresql、Mysql等数据库中的一种或几种，熟练使用存储过程、函数等；?
5、熟悉BI工具中的一种或几种；?
6、有GPVERTICATeradata等分布式数据仓库实施经验大数据经验者优先考虑；?
7、熟悉Java、Python等编程语言，并有大数据环境中处理数据经验者优先考虑；?
8、了解数据治理或者有相关经验者优先考虑；?
9、对数据有敏锐的感觉；"
"职位描述：
        
        岗位职责：1.负责公司的大数据处理框架的研发工作，设计与开发，基于Hadoop平台的海量日志的分布式存储与数据分析架构。2.负责Hadoop集群配置管理，性能调优；Hadoop集群日常维护，提供稳定的系统服务。3.负责数据采集及预处理程序开发、维护，优化。4.负责项目相关设计、开发、测试文档的撰写。岗位要求：1. 本科及以上学历，计算机相关专业，2019或2018应届毕业生；2. 了解Java开发工具和调试工具的使用；3. 了解大数据分析处理（Hadoop，HDFS, MapReduce，Hbase，Pig，Hive）等技术内部机制；4. 熟悉Linux系统，能使用一种shell/perl/python脚本处理问题；5. 具有较强的团队意识与良好的沟通能力，高度的责任感，对工作积极严谨，勇于承担压力，较强的学习能力以及快速解决问题的能力。"
"职位描述：
        
        岗位职责： 1. 参与整体数据仓库的建设：包括数据模型、数据仓库的设计、实现、维护； 2. 进行批量、实时任务性能优化； 3. 建设公司数仓管理系统包括：元数据建设，权限管理，数据血缘关系管理等； 任职要求： 1. 重点大学计算机相关专业本科以上学历，工作4年以上； 2. 熟练使用Hadoop、Spark、Hive，并理解其原理；对新技术有探索欲望； 3. 熟悉各类数据仓库，精通SQL ； 4. 有流式系统构建经验的优先； 5. 思维灵活，有毅力；具有团队精神与敬业精神，学习钻研能力强，有上进心，具有良好的协调沟通能力；"
"职位描述：
        
        任职要求：
1、扎实的编程基础,了解jvm，web开发、缓存、线程池、分布式架构； 2、有至少一个大数据项目开发经验，熟悉Hadoop、Spark、kylin、hbase等； 3、熟练掌握java?或scala语言,熟悉并行计算或者分布式计算,理解MapReduce、HDFS原理、spark?RDD/DataFrame原理； 4、熟悉git、maven等项目协同管理工具； 5、熟悉ETL处理,BI报表开发,spark实时计算,MongoDB数据库使用,有实践经验优先； 6、有良好的沟通能力,对技术有激情,喜欢钻研,能快速接受和掌握新技术,有较强的独立、主动学习能力。"
"职位描述：
        
        数据仓库工程师工作职责：1.参与或负责数据产品或数据仓库应用项目的ETL设计、开发、维护及质量核查；2.参与或负责数据仓库模型的规划和设计，建立并执行统一的数据开发规范；3.参与或负责数据仓库基础设施和平台的建设，搭建教育行业领域的企业级数据仓库；4.和数据分析师团队及其他需求部门进行有效沟通，完成数据需求及数据问题解决等；5.完成日常数据质量的监控，跟踪处理各类数据质量问题。职位要求：1.熟悉主流关系数据库,熟练SQL开发，熟悉linux系统、shell编程；2.精通数据仓库的ETL的开发,有海量数据处理相关经验；3.熟悉数据仓库领域数据模型设计方法，并有相关数仓模型设计经验；4.熟悉Hadoop、HIVE、HBase、Kafka、 Flume、Spark等开源框架，优先考虑；5.较好的沟通理解能力，性格乐观，态度踏实，积极上进。"
"职位描述：
        
        职责：
1、负责数据仓库工具开发
2、负责核心系统建设和数据仓库建设
3 、针对业务场景编写ETL通用工具脚本
4、开发数据血缘关系管理系统，优化调度与任务依赖系统

要求：
1. 计算机或数学相关专业大学本科及以上学历?
2. 3年以上大数据开发（ETL方向）经验?
3. 熟悉Linux开发环境，熟练掌握Python，
4. 掌握mysql、postgresql、greenplum、redis、mongodb等一种或多种数据库，掌握sql调优技术?
5. 熟悉Hadoop生态圈开源技术，掌握包括HDFS、Spark、Kafka、flume、sqoop、datax等?
6. 熟悉ETL系统，包括元数据、数据质量、调度系统（azkaban）、影响分析等等，有开发过调度系统经验者优先?
7. 有TB级别实时数据处理经验者优先，有mysql DBA工作经验者优先，对Apache顶级开源项目有深入理解者优先"
"职位描述：
        
        要求：
1、专科及以上学历
2、至少1年以上数据库或大数据开发经验
3、精通Sql编程及性能调优
4、熟练使用Hadoop生态圈技术，如：Hive、Hbase、Spark、Oozie等等
5、熟悉Linux系统及shell编程
6、具备较高的程序开发及调试能力；具备一定的系统设计能力
7、良好的沟通技巧和团队合作意识"
"职位描述：
        
        岗位职责：1、负责大数据产品的架构设计，优化Hadoop/Spark集群2、负责核心功能的实现，数据抽取、清洗、转化等数据处理程序开发3、实现大数据分析计算需求，支持海量数据挖掘招聘要求：1、全日制统招本科及以上学历，计算机相关专业2、3年以上大数据相关工作经验3、熟悉Hadoop、Hive、HBase、Spark等相关技术，具备架构设计能力4、有数据仓库、数据挖掘等大数据金融/证券行业项目经验优先"
"职位描述：
        
        工作职责：
1. 主导大数据平台的研发、建设；
2. 主导数据仓库建模架构设计；
3. 主导大数据技术难点攻关，集群的性能调优；
技能要求：
1. 统招本科或以上学历，5年以上软件研发、2年以上大数据开发经验；
2. 熟练java、scala等大数据开发相关的语言;
3. 熟悉Hadoop生态，灵活运用Hbase、Spark、Storm等技术实现PB量级数据的加工处理；
4. 熟悉Linux平台，精通Shell脚本，编码基本功扎实 ；
5. 良好的大数据视野和思维，高效的沟通能力；
加分项：
1. 加分项增加一个对证券业务有所了解；
2. 在GitHub等平台上参与过有影响力的开源项目；
3. BAT或国内知名互联网公司工作经验背景；
4. 数据架构在技术以及商业层面都获得过公司高层的认可。"
"职位描述：
        
        任职要求：
1、具有3年以上互联网基于Hadoop/Hbase等应用开发经验，对分布式计算理论有深刻理解；
2、熟悉JAVA、对Hadoop、Hbase、Hive等主流云计算、大数据相关软件有充分的了解，研读过源代码者优先，并且有实践经验，能解决应用中的复杂问题；
3、熟悉BI工具及方法论，有大数据分析与数据仓库设计及开发经验；
4、熟悉linux/UNIX Shell、熟悉(Perl/python/shell)任意一种脚本语言；
5、熟悉Spark、SparkSQL、SparkStreaming等框架并能实际使用
6、对技术钻研好学、逻辑思维能力强，沟通能力优秀，有团队合作精神
7、金融证券管理项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先；"
"职位描述：
        
        任职要求:
1、计算机科学或相关专业本科及以上学历；
2、具备扎实的Java基础，熟悉J2EE体系结构，熟悉分布式、缓存、消息、搜索等机制；，熟悉Spark相关技术，至少有1年的Spark开发经验；
3、熟悉Spark内核，熟练掌握Scala和Python语言，至少有1年及以上的Spark开发经验，
4、熟悉Spark SQL, Spark Streaming，Storm，Hadoop，Mesos，kafka等，对Spark体系结构、运行机制和源码有深入研究；
5、对Spark调优、统计学应用有实际工作经验者优先；
6、具备后台业务系统或相关产品研发经验者优先；
7、追求代码质量和程序效率；能适应短期出差，有意愿投入证券金融行业
工作职责：
1、协助业务方梳理业务需求，提供业务规划方案、架构设计方案，并能根据方案展开研发工作；
3、带领团队攻克高并发、高稳定性，业务模型复杂等带来的各种挑战及技术难关；
4、参与项目的系统设计和核心代码开发，指导和培训其他工程师；?
5、负责大数据平台的部署和维护，相关后台服务的设计与开发；
6、负责基于Spark技术的海量数据的处理、分析、挖掘工作；"
"职位描述：
        
        招聘要求：
1、本科及以上学历、计算机及数学相关专业； ? ? ? ? ? ?
2、2年以上Java开发经验，1年以上算法开发经验； ?
3、具备技术专研精神，并保持对技术的强烈兴趣。
4、具有大数据相关开发经验者优先。
岗位职责：
1、参与大数据产品开发及需求设计；
2、根据业务需求构建算法模型；"
"职位描述：
        
        工作职责:1、协助业务方梳理业务需求，提供业务规划方案、架构设计方案，并能根据方案展开研发工作；3、带领团队攻克高并发、高稳定性，业务模型复杂等带来的各种挑战及技术难关；4、参与项目的系统设计和核心代码开发，指导和培训其他工程师； 5、负责大数据平台的部署和维护，相关后台服务的设计与开发；6、负责基于Spark技术的海量数据的处理、分析、挖掘工作；任职资格:1、计算机科学或相关专业本科及以上学历；2、具备扎实的Java基础，熟悉J2EE体系结构，熟悉分布式、缓存、消息、搜索等机制；，熟悉Spark相关技术，至少有1年的Spark开发经验；3、熟悉Spark内核，熟练掌握Scala和Python语言，至少有1年及以上的Spark开发经验，4、熟悉Spark SQL, Spark Streaming，Storm，Hadoop，Mesos，kafka等，对Spark体系结构、运行机制和源码有深入研究；5、对Spark调优、统计学应用有实际工作经验者优先；6、具备后台业务系统或相关产品研发经验者优先；7、追求代码质量和程序效率；能适应短期出差，有意愿投入证券金融行业"
"职位描述：
        
        1、专科及以上学历
2、至少2年以上数据库或大数据开发经验
3、精通Sql编程及性能调优
4、熟练使用Hadoop生态圈技术，如：Hive、Hbase、Spark、Oozie等等
5、熟悉Linux系统及shell编程
6、具备较高的程序开发及调试能力；具备一定的系统设计能力
7、良好的沟通技巧和团队合作意识"
"职位描述：
        
        岗位职责：  1.负责财务数据科目标准化映射；  2.负责多来源数据库数据整合，数据清洗；  3.负责财务科目数据准确性校验；  4.负责财报数据库的日常管理，行情数据的定期更新；  5.数据模块的文档说明，接口开发等其他系统性工程。
 岗位要求：  1.全日制本科以上学历，计算机、统计、数学等相关专业，3年以上大型数据处理经验；  2.熟练掌握SQL，熟悉Numpy和Pandas等Python数据处理工具；  3.工作严谨，细致，有耐心和责任心，能在Tech Leader的带领下，参与项目设计、功能开发、自动化部署等工作； 4.能遵守公司制定的开发规范，接受Coding Style、Code Review、测试覆盖等方面的指导和规范。 金融行业相关经验是加分项"
"职位描述：
        
        职位职责：
1、负责大数据套件平台的前端架构设计、开发和持续优化；?
2、负责大数据的报表、图标等功能的组件化、模块化、可视化自定义模板的设计和开发；?
3、参与部门前端技术的前沿追踪和应用，参与建设前端公共组件库；?
4、协调或指导团队里其它开发人员的工作。

任职要求：
1、大学本科以上学历，5年以上工作经验；?
2、精通XHTML/HTML(5)/JavaScript/JSX/CSS(3)等相关技术，熟练使用vue等常用前端框架；?
3、深度掌握JavaScript核心技术（DOM、BOM、Ajax、JSON等），精通JavaScript性能、多浏览器兼容、组件开发；?
4、熟练掌握apache/nginx等web服务器的配置、调优及问题定位分析；?
5、掌握前端开发常用安全技术；?
6、编程基本功扎实，基础数据结构和算法掌握良好，具备较强的模型抽象能力；?
7、关注前端技术发展，具备良好的学习能力、分析解决问题的能力和沟通协调能力，高度责任心和团队合作精神。"
"职位描述：
        
        工作职责：
1、根据业务部门提出的指标需求，按时提交高质量代码，完成开发任务。
2、规范文档的编写、维护以及其他与项目相关工作。
任职要求：
1、熟悉Hadoop、Hive、Spark的使用，有丰富的调优、数据处理优化实战经验。
2、能够独立完成ETL程序（批处理和实时流）的开发，面对共性痛点问题能够深入优化和解决，在开发中解决过实际问题优先考虑。
3、熟悉Linux shell及java编程。
4、熟悉sqlserver、kettle的使用。
5、良好的学习能力、团队协作能力和沟通能力，善于思考，能独立分析和解决问题。"
"职位描述：
        
        1、负责大数据平台的规划和搭建及业内选型
2、负责规划数据挖掘的整体流程，并参与用户产品和数据产品的决策
3、与业务部门密切配合，寻求数据层面的业务价值，利用数据分析结论推动产品优化

岗位要求：
1、有5年以上大数据相关项目经验
2、了解大数据框架技术如Hadoop等
3、熟悉金融业务包括：证券、保险、公募基金、交易所等业务"
"职位描述：
        
        职责描述：
1、参与集团数据仓库以及大数据平台的建设；2、根据业务应用进行数据整理和模型开发。

任职要求：
1、计算机及相关专业统招本科及以上学历；2、3年以上hadoop的应用开发经验；3、熟悉hadoop生态圈，可独立搭建hadoop平台，具备hadoop组件调经验；4、深入理解大数据处理体系架构，熟悉hadoop/storm/spark/hive等常用开源技术体系，具备复杂项目的实施落地能力；5、精通JAVA语言，熟悉Linux开发环境，具有实际系统开发经验；?
6、有金融行业背景；?
7、具有很强的学习能力、钻研精神、较强的沟通能力以及团队精神；8、企业级数据仓库(EDW)/BI系统的建设经验，有海量数据建模实践经验优先考虑。"
"职位描述：
        
        【职位描述】
负责公司大数据平台的开发和维护。
【任职资格】
1.熟悉Java语言，熟悉Spring/mybatis等框架，熟悉mysql，熟练使用一种脚本语言?????????????????????????????
2.熟练使用Linux；???????????????????????????
3.熟悉常用算法和数据结构；???????????????????????????
4.有Hadoop/Spark/Hive/Kafka等实战经验优先；有数据挖掘或者推荐系统的经验优先
5良好的沟通和学习能力，对技术有强烈热情，喜欢钻研，能够快速学习新知识； ??
6. 3年及以上工作经验"
"职位描述：
        
        工作职责：
1.?负责用户行为数据分析平台提供用户画像能力及其他业务支撑能力
2.?组建在线及离线的数据分析系统
3.?负责业务数据分析平台及相关子模块需求理解及方案设计开发
4.?负责数据分析平台数据组织以及维护
5.?负责项目的数据收集架构设计
6.?负责报表系统设计开发 ??
任职要求：
1.?有用户画像相关的工作经验
2.?精通HadoopSpark生态圈技术，如：HDFS，MR，ZK，Kafka，Hbase，Hive，Storm，Spark等
3.?对HADOOP维护和调优有丰富经验
4.?能够设计完整的数据收集分析平台
5.?熟悉至少一种NoSql数据库
6.?精通一种或多种以下几种语言（python、scala、java、shell、golang）
7.?有基于云的数据分析平台实施经验 ??
8.?了解AWS EMR、ElasticSearch优先"
"职位描述：
        
        岗位职责：
1、负责公司内大数据平台的开发需求；
2、对接第三方业务系统，完成数据回流入仓；
3、与外部公司数据接口、交互等的开发、沟通等；
?
任职资格：
1、3年以上数据开发经验，熟悉大数据生态圈，尤其是实时计算部分；
2、熟练使用hadoop、spark、storm、hive、python等；
3、掌握Linux基本操作 ；
4、具有金融背景或是有从0到1搭建数据平台经验优先"
"职位描述：
        
        职责描述：
1. 负责大数据平台的设计以及开发工作；
2. 根据需求完成数据系统模块设计、编码、测试以及文档编写等工作；
3. 优化数据系统性能，保障数据系统质量
任职要求：
1. 计算机、数学等专业本科或以上学历，3年及以上大数据相关工作经验；
2. 了解hadoop生态、实时计算常用技术原理，清楚每个技术组件可应用的业务场景；
3. 熟悉Spark、Hive、Elasticsearch、Hbase、Canssadra技术,至少深入研究过其中一项；
4. 具备扎实的java的开发能力、具有针对计算、存储框架优化业务代码能力；
5. 掌握常用关系型和非关系型数据库的设计和开发，有SQL查询优化经验，有数据库水平和垂直扩展经验；
6. 有数据分析和数据挖掘经验优先；
7. 有知名互联网公司工作经历优先考虑"
"职位描述：
        
        岗位职责
1.?负责大数据平台的架构设计与研发。?
2.?根据产品需求设计高扩展性、高性能的系统架构和应用架构。
3.?大数据平台资源管理、多租户改造等
任职要求
1.?3年以上大数据平台研发经验，计算机或相关专业本科以上学历，具备良好的沟通能力和表达能力。?
2.?熟悉常用的算法和数据结构。?
3.?熟悉Linux系统，具备shell/python/java/scala/golang等一种或几种语言的开发能力。?
4.?熟悉常见的开源分布式计算/存储相关技术，包括hdfs、mapreduce、spark、flink、kafka、hive、elasticsearch等。?
5.?熟悉Yarn工作原理及深入开发、熟悉linux容器技术
6.?有大数据系统项目经验，掌握如何搭建分布式处理系统，有海量数据处理和分析经验。?
7.?学习能力强，热衷开源技术，有团队观念，具备独立解决问题的能力?。"
"职位描述：
        
        岗位职责
1.负责实时/流计算平台设计、开发与调优
2.负责实施/流计算平台线上运维、保障系统稳定和高可用，解决大并发下的各种问题
任职要求
1.?两年以上流计算应用开发或流计算平台开发相关经验。至少一年Flink相关经验。
2.?源码级精通Flink、Spark?Streaming任一一项，熟悉Kafka底层机制。
3.?精通Java，熟悉Scala语言。
4.?具备Hadoop、RocksDB调优经验。
5.?熟悉Streaming?SQL相关概念或产品。
6.?有Streaming?On?K8S或者Apache?Beam经验者优先。"
"职位描述：
        
        岗位职责
1.负责数据引擎底层开发及测试
2.负责数据引擎的性能优化
任职要求
1. 3年以上Java开发经验，JAVA基础扎实，理解io、多线程、集合等基础框架，对JVM原理有一定的了解； 熟悉python/shell脚本等其他开发语言；?
2. 熟悉常用的算法和数据结构。?
3. 熟悉微服务架构，高并发、高性能的分布式系统的设计和应用。
4.熟悉jdbc协议，mysql、postgresql、oracle、redis等。
5. 熟悉一种或多种开源框架，包括elasticsearch、Hbase、zk等
6.熟悉kylin，phoenix，presto等，熟悉calcite开源框架优先，熟悉sql parser优先?
7. 学习能力强，热衷开源技术，有团队观念，具备独立解决问题的能力 。"
"职位描述：
        
        任职要求
1.参与及负责金山云大数据项目的实施落地、定制化开发等工作;?
2.负责公司软件产品的实施、安装、调试，部署;?
3.负责大数据产品实施文档编写优化及培训等工作；??
岗位职责
1、本科以上学历，应用数学、计算机、网络工程、信息安全等相关专业；
3.?熟悉Linux系统，具备shell/python/java/scala/golang等一种或几种语言的开发能力。?
4.?熟悉常见的开源分布式计算/存储相关技术，包括hdfs、mapreduce、spark、flink、kafka、hive、elasticsearch等
5、熟悉Java?Web相关框架
6、有大数据平台类项目实施经验优先
7、具有团队合作精神。
8、能适应较强强度出差"
"职位描述：
        
        任职要求
1.负责根据项目需求进行系统设计
2. 负责平台相关系统开发
岗位职责
1. 本科及以上学历，计算机软件相关专业，有较强的项目推进、协调沟通能力，5年以上工作经验，3年大数据项目经验。
2.熟悉CDH Hadoop发行版部署，熟悉Spark、Hive、Presto、Elasticsearch等大数据组件，对Oozie、Hue源码、CM API熟悉优先
3.JAVA和Python基础扎实，深刻理解计算机原理，有良好的数据结构和算法基础，有多线程开发经验，了解JVM工作原理；
4. 熟悉MySQL、NoSQL、消息队列等常用组件；
5. 熟悉Spring，Mybatis等Web常用框架"
"职位描述：
        
        工作职责:1、负责大数据分析需求设计和开发，包括数据集市、实时分析、数据展示等的开发，并交付生产，确保输出成果；2、指导协助同事解决大数据开发工作中的问题；3、对大数据分析系统存在的问题进行跟踪和定位并及时解决；任职资格:1、计算机或相关专业本科以上学历；2、有3年及以上大数据平台开发方面相关工作经验；3、熟悉数据仓库和数据建模的相关技术，熟悉JAVA语言；4、熟悉Hadoop或Spark生态相关技术，包括MapReduce、HDFS、Hive、HBase、Spark等，1个以上大数据平台项目实施经验；5、熟悉Oracle或MySQL数据库技术；6、具有BI系统的开发实施经验，熟悉数据仓库、ETL设计、Cube建模、OLAP开发、报表开发等；7、一定的应用系统分析与设计能力，有良好、规范的编程习惯和文档编写习惯；8、有较强的学习能力，对技术有钻研精神，并有较高的热情，热衷于新技术、新理论、新开发实践的学习和实践；9、有良好的口头和书面表达能力。"
"职位描述：
        
        岗位职责""1、负责和参与公司大数据基础架构平台的建设，保障数据平台服务的稳定性和可用性；2、参与多机房数据同步、数据ETL、数据仓库的整体框架规划和设计。""任职要求""1、本科及以上学历，5年以上大数据开发经验；2、熟悉Hadoop、Storm、Spark、Flume、Kafka、Hbase等组件的原理，有良好的系统性能优化及故障排除能力；3、负责和参与大数据基础架构平台的监控、资源管理、数据流管理，能够开发各种Hadoop大数据自动化运维与监控工具；4、对Hadoop平台架构能够不断优化，提升数据产品的质量和响应速度；5、精通Shell/Python/Java语言的一种或多种；6、有大规模hadoop运维经验者优先，有hadoop/hbase开发经验者优先。"""
"职位描述：
        
        职位描述： 1.?参与公司数据中台建设，持续优化和完善相关组件； 2. 支撑公司应用项目中的数据仓库设计和数据开发工作；  任职要求： 1.?正直、诚信、敬业、有激情，有良好的沟通能力和学习能力； 2.?计算机/软件工程相关专业本科以上学历，两年以上数据仓库项目开发经验，熟练使用SQL以及大数据平台工具（比如CDH、hive等）； 3. 能根据项目需求快速进行数据清洗、存储设计、数据开发和性能优化； 4. 有java/scale/python语言基础，能进行相关数据接口开发工作；
5. 加分项：有阿里云/亚马逊/微软云实际使用经验；"
"职位描述：
        
        岗位职责:1. 负责大规模海量数据的清洗、过滤、入库、特征提取、分析和挖掘工作；2. 负责Hadoop/Spark集群生产环境搭建，性能调优和日常维护；3.?负责数仓设计，数据建模，SQL 存储过程开发和测试，及SQL查询的性能调优。任职资格:1、计算机相关专业本科学历；?
2、有2年以上大数据开发处理经验，编程能力强。3、熟练掌握Hadoop/Spark平台开发技能
4、熟练掌握java和python5、熟悉第三方ETL工具，例如kettle
注：本岗位接受实习生"
"职位描述：
        
        岗位职责：
1 负责公司大数据平台架构设计和业务代码开发；
2 负责数据迁移、同步及 ETL 开发；
3 进行数据和功能维护、性能分析及改进，保证系统性能, 稳定性和安全性；
4 从事海量数据分析、挖掘相关工作；
任职要求：
1 计算机相关专业，本科及以上学历；
2 两年以上java开发经验、一年以上数据分析和数据建模相关工作经验；
3 熟悉Hadoop、HBase、Hive、Kylin、ES、Zookeeper、Kafka、Spark、Storm、Flink等基本原理和应用场景;
4. 对数据挖掘算法和深度学习算法有一定的了解；"
"职位描述：
        
        工作职责:1、负责业务风控安全大数据系统设计和研发工作； 2、负责直播业务风控安全的平台架构设计和研发； 3、协助风控安全人员推进业务项目,提供大数据系统技术支撑； 4、使用大数据手段推进风控安全业务发展。 ?任职资格:1、JAVA基础扎实，熟悉io、多线程、集合等基础框架，熟悉分布式、缓存、消息等机制； 2、3年以上使用java进行开发的经验，一年以上海量数据开发经验，熟练使用spring 、MVC等框架，熟悉Linux下的常用命令，熟悉MySQL；3、熟悉常用设计模式，有大型分布式、高并发、高负载、高可用性系统设计开发经验； 4、具有良好的抽象设计能力，思路清晰，善于思考，能独立分析和解决问题,责任心强，具备良好的团队合作精神和承受压力的能力； 5、具有良好的项目规划和决策能力，善于捕捉业务需求、架构设计中存在的问题，并给出有效的解决措施和方法；6、熟悉大数据系统搭建与维护，熟悉hadoop、spark、clickhouse、zookeeper等数据系统与组件； 7、熟悉风控安全相关业务，熟悉与黑产对抗过程优先；8、具备自然语言处理、文本挖掘、数据挖掘、机器学习等算法能力优先。"
"职位描述：
        
        工作职责:1、负责数据仓库的开发工作； 2、指导协助同事解决日常工作中的问题； 3、对系统存在的问题进行跟踪和定位并及时解决； 4、严格执行工作计划，主动汇报并高效完成任务保证部门及个人工作目标实现。任职资格:1. 熟悉hadoop集群,有spark，hbase使用经验更佳；2. 熟悉hive，在项目中有使用半年以上的经验，有hive优化经验； 3. 熟悉Java 或python，能编写mapreduce；4. 有一定的BI开发经验，实施过数据仓库项目； 5. 善于沟通，善于分析。"
"职位描述：
        
        工作职责:1、负责酷狗海量用户个性化推荐系统的服务端开发与维护；2、参与高并发高可用系统的架构设计与技术攻关；3、参与实时计算平台的研发，结合机器学习特性，完成实时模型更新；4、对系统稳定性、服务可用性、数据准确性负责。任职资格:1、本科以上学历，3年以上大型服务端开发工作经验；2、至少精通JAVA/SCALA/GO一门语言，有Mapreduce、Spark、Storm、kafka等大数据项目经验者优先；3、熟悉使用linux平台、shell编程、熟悉MySQL、Redis、Pika、Nginx；4、熟悉TCP/IP、DNS等底层协议，精通HTTP协议，熟练掌握各种工具进行网络问题诊断；5、熟悉分布式系统的高可用、数据一致性、高容错性的架构设计，有安全防范意识；6、参与过实时监控告警平台研发，有数据质量监控意识，熟悉prometheus、druid.io开源项目者优先；7、富有工作热情与合作精神，善于沟通，学习能力强，责任心和团队意识强，能阅读英文资料；8、以用户为中心，良好的技术工具化产品化的封装意识和能力，注重降低用户使用和学习成本；9、对大数据生态圈技术感兴趣。"
"职位描述：
        
        工作职责:1、负责酷狗直播大数据平台可视化产品，服务接口整体规划，设计和开发等工作，持续改进平台的可用性、易用性；2、跟进大数据平台的技术更新，编撰技术规范，接口协议，协助业务开发人员完成数据采集，数据获取。任职资格:1、计算机相关专业本科及以上学历；两年以上相关工作经验；2、至少熟悉Java但不限于go，Python,熟悉spring框架，如springboot，springmvc等等；3、需要扎实的java后端开发经验，有基本的服务架构思维，能编写高性能、高可读性、高可维护性的代码；4、需要扎实的前端开发经验，能独立完成后端到前端的交互，包括友好的前端页面展示；5、有熟悉hadoop生态组件作用优先。"
"职位描述：
        
        工作职责:1、负责酷狗直播大数据平台可视化产品，服务接口整体规划，设计和开发等工作，持续改进平台的可用性、易用性；2、跟进大数据平台的技术更新，编撰技术规范，接口协议，协助业务开发人员完成数据采集，数据获取。任职资格:1、计算机相关专业本科及以上学历；两年以上相关工作经验；2、至少熟悉Java但不限于go，Python,熟悉spring框架，如springboot，springmvc等等；3、需要扎实的java后端开发经验，有基本的服务架构思维，能编写高性能、高可读性、高可维护性的代码；4、需要扎实的前端开发经验，能独立完成后端到前端的交互，包括友好的前端页面展示；5、有熟悉hadoop生态组件作用优先。"
"职位描述：
        
        工作职责:1、负责酷狗直播kafka以及采集网关设计、规划、开发等工作，持续改进平台的可用性、易用性；2、负责实时、离线数据拉取方案的调研及落地；3、负责实时监控告警平台研发；4、基于业务目标，为业务部门提供技术支撑；5、跟进大数据平台的技术更新，编撰技术规范，指导开发人员完成任务。任职资格:1、计算机相关专业本科及以上学历；两年以上相关工作经验；2、熟悉以下编程语言（至少一种）：Java, Scala, Python, lua；3、有一项或多项如下经验者优先：Hadoop/Hive/Kafka/Canal/Sqoop/Camus/Gobblin/Hbase；4、有大数据服务架构思维，如服务稳定性，高可用。"
"职位描述：
        
        岗位职责：

1、负责酷狗直播大数据离线平台设计、规划、开发等工作，持续改进平台的可用性、易用性。

2、负责实时计算、监控产品的设计、开发工作。

3、负责数据产品功能模块需求的分析、设计、开发及日常维护。

4、基于业务目标，为业务部门提供技术支撑。

5、根进大数据平台的技术更新，编撰技术规范，指导开发人员完成任务


任职要求：

1、计算机相关专业本科及以上学历；两年以上相关工作经验；

2、熟悉以下编程语言（至少一种）：Java, Scala, Python；

3、有一项或多项如下经验者优先：Hadoop/Hive/spark/presto/Kafka/Spark Streaming/Hbase

4、熟悉Linux系统，具备shell或python脚本开发能力；

6、逻辑思维及沟通交流能力强，善于学习，能够独立分析和解决问题，具备良好的团队合作精神；

7、敬业且能够适应高强度压力环境，具备互联网大数据开发及应用经验者优先。"
"职位描述：
        
        工作职责:1、负责数据仓库的开发工作； 2、指导协助同事解决日常工作中的问题； 3、对系统存在的问题进行跟踪和定位并及时解决； 4、严格执行工作计划，主动汇报并高效完成任务保证部门及个人工作目标实现。任职资格:1. 熟悉hadoop集群,有spark，hbase使用经验更佳；2. 熟悉hive，在项目中有使用半年以上的经验，有hive优化经验； 3. 熟悉Java 或python，能编写mapreduce；4. 有一定的BI开发经验，实施过数据仓库。"
"职位描述：
        
        工作职责:1、负责酷狗海量用户个性化推荐系统的服务端开发与维护；2、参与高并发高可用系统的架构设计与技术攻关；3、参与实时计算平台的研发，结合机器学习特性，完成实时模型更新；4、对系统稳定性、服务可用性、数据准确性负责。任职资格:1、本科以上学历，3年以上大型服务端开发工作经验；2、至少精通JAVA/SCALA/GO一门语言，有Mapreduce、Spark、Storm、kafka等大数据项目经验者优先；3、熟悉使用linux平台、shell编程、熟悉MySQL、Redis、Pika、Nginx；4、熟悉TCP/IP、DNS等底层协议，精通HTTP协议，熟练掌握各种工具进行网络问题诊断；5、熟悉分布式系统的高可用、数据一致性、高容错性的架构设计，有安全防范意识；6、参与过实时监控告警平台研发，有数据质量监控意识，熟悉prometheus、druid.io开源项目者优先；7、富有工作热情与合作精神，善于沟通，学习能力强，责任心和团队意识强，能阅读英文资料；8、以用户为中心，良好的技术工具化产品化的封装意识和能力，注重降低用户使用和学习成本；9、对大数据生态圈技术感兴趣。"
"职位描述：
        
        工作职责：
1） 负责大数据集成平台的研发；
2） 负责参与系统需求分析、架构设计和概要设计；
3） 负责后端模块的设计、核心代码的编写以及系统性能优化；
4)? ?负责大数据项目研发。?

任职要求：
1） 大学本科以上学历、计算机或相关专业毕业；
2） 2年以上Java项目或大数据项目开发经验；
3） 熟练掌握关系型数据库如MySql或Oralce等，有分布式缓存、分布式存储技术经验者优先；
4） 了解Hadoop/Spark分布式大数据计算平台，熟悉消息中间件技术(Kafka、Zero MQ)；
5） 有Nosql数据库如HBase或Cassandra 开发经验者优先；
6） 能熟练使用Linux/CentOS系统，熟练使用shell脚本；
7） 具备优秀的学习能力，能快速掌握各种开源工具；善于独立解决问题，具备团队协作精神。"
"职位描述：
        
        工作职责：
1） 负责大数据集成平台的研发；
2） 负责参与系统需求分析、架构设计和概要设计；
3） 负责后端模块的设计、核心代码的编写以及系统性能优化；
4) 负责大数据项目研发。?
任职要求：
1） 大学本科以上学历、计算机或相关专业毕业；
2） 2年以上Java项目或大数据项目开发经验；
3） 熟练掌握关系型数据库如MySql或Oralce等，有分布式缓存、分布式存储技术经验者优先；
4） 了解Hadoop/Spark分布式大数据计算平台，熟悉消息中间件技术(Kafka、Zero MQ)；
5） 有Nosql数据库如HBase或Cassandra 开发经验者优先；
6） 能熟练使用Linux/CentOS系统，熟练使用shell脚本；
7） 具备优秀的学习能力，能快速掌握各种开源工具；善于独立解决问题，具备团队协作精神。"
"职位描述：
        
        职位一：大数据工程师（数据仓库方向） 
工作职责：
1、负责收集相关业务分析需求，有针对性的进行大数据仓库设计、建模以及ETL开发；
2、建立和维护系统及业务层数据字典，参与制定并实施数据质量的监控与保障方案；
3、根据各方需求整合优化数据架构，保证集市的及时性、可靠性和稳定性

工作要求：
1、熟悉数据仓库建模方法、元数据管理、数据质量体系管理。
2、熟练掌握Hive sql，有丰富的性能调优经验 ，有Shell、Python等脚本编程经验?
3、主动性和责任心强，对数据敏感，逻辑性强，有良好的抗压能力?
4、有3年以上实际互联网数据数仓项目开发经验者优先，有海量数据处理经验者优先
职位二：大数据工程师（BI方向） 
工作职责:
1、负责BI指标体系建设：收集和挖掘业务需求，提出解决方案；
2、完成指标口径的设计与开发，向业务和管理层提供智能的可视化服务；
3、建立用户反馈渠道，搜集和梳理用户反馈信息，基于用户反馈及数据分析，及时调整指标策略，制定优化方案并推动整个指标体系的持续迭代；

工作要求:
1、具备3年以上互联网BI产品设计开发经验，参与过大数据相关的知识与指标体系建设，具备良好的数据分析能力，进行BI项目规划设计和管理；
2、熟悉主流BI工具，如Tableau、Finereport、PowerBI等，有数据可视化经验者优先
3、熟练掌握Hive sql，有丰富的性能调优经验，有Shell、Python等脚本编程经验，有海量数据处理经验者优先?
4、主动性和责任心强，对数据敏感，逻辑性强，有良好的抗压能力"
"职位描述：
        
        【岗位职责】
1. 负责公司各项目和产品的大数据平台的开发、维护；
2. 负责大数据平台数据分析、用户行为分析；
3. 参与调研和评估关键技术，并选择相关技术（如开源软件）用于产品开发；
4. 参与分析系统需求，确定软件规格说明；
5. 负责大数据产品模块的设计、编码、测试和集成；
6. 协助完成产品或模块的项目管理和项目实施。

【岗位要求】
1. 计算机相关专业本科以上学历，有2年以上大数据开发经验。
2. 熟悉J2EE主流框架，精通JAVA编程工具，软件调试开发工具的使用，撰写技术文档的能力； ?????????????????????????????
3. 熟悉软件开发流程、设计模式、体系结构；
4. 对Hadoop架构及相关生态有深入理解，有Hive，Hbase，Spark，Kafka，Solr,?ElasticSearch等2种以上使用经验。
5. 在用户行为日志采集、数据建模、业务理解方面有丰富经验，能挖掘数据需求做好业务支撑。
6. 保持技术敏感性，持续关注开源社区并推动团队技术演进。
7. 熟悉Linux系统，具备shell、python等脚本开发能力；
8. 学习能力强，喜欢研究新技术，有团队观念，具备独立解决问题的能力。"
"职位描述：
        
        工作职责：

1. 完善和优化现有实时流计算系统和存储系统，编写核心开发框架；

2. 善于发现系统的性能瓶颈、设计缺陷，提出改进方案并实施；

3. 对现有系统进行宏观的思考，规划形成统一的框架、平台或组件；

4. 能够与产品经理、管理团队进行良好的沟通合作，按时保质保量完成开发任务。

岗位要求：

1. 计算机科学或相关技术学科的学士、硕士学位（或同等学历）；

2. Java相关开发经验3年以上，熟悉多线程，高并发处理，有实际项目开发经验； 同时熟悉Python/Scala更佳

3. 精通分布式数据处理底层技术，包括但不限于：hadoop/Flink/Spark/elasticsearch/hbase/kafka/flume等，用过mysql，redis，hbase等开源存储，懂druid.io佳；

4. 熟悉ETL流程，使用过Hive，Impala处理数据作业， 有Kudu经验者更佳

5. 能够主动去分析数据，发现数据异常，不符合业务逻辑的问题，并推动解决

6. 具有强烈的责任心，良好的沟通、学习能力，良好的团队合作意识，勇于接受技术挑战；"
"职位描述：
        
        岗位职责: ? ? ? ?1、参与数据平台内部系统的分析、设计，并主导完成详细的设计，负责核心功能与底层基础功能的功能设计、代码实现； ? ?2、从业务和技术出发，对现有产品和系统进行持续改进和优化；实现面向未来的系统规划、设计和落地； ? ?3、技术预研和技术难点攻关，保障系统可用性、稳定性和可扩展性； ? ? ? ?职位要求: ? ? ? ?1、扎实的Java基础，熟悉Java web开发，熟悉restful服务设计开发； ? ?2、熟悉Spring MVC、Spring Boot、Spring Cloud、MyBatis等J2EE开源框架术； ? ?3、较强的SQL及优化能力； ? ?3、熟悉JS，CSS，HTML； ? ?4、熟悉系统分析设计，熟练使用常见设计模式，有模块化开发意识，有一定系统架构能力； ? ?5、掌握Docker、Hadoop、HDFS、HBase、Spark、Kafka； ? ?6、学习能力强，责任心强，有良好的沟通能力；"
"职位描述：
        
        工作职责
1.负责公司大数据离线、实时平台（如Hadoop/Hive/Storm/Spark）的建设、优化；
2.负责开发大数据工具，如报表平台、多维度分析工具、ETL平台、调度平台的研发；
3.负责数据可视化分析平台设计和开发。

任职资格
1. 计算机及相关专业，3年以上工作经验；
2. 扎实的java基础，2年以上大数据开发经验，对分布式存储和计算原理有较深的理解；
3. 熟练使用spark streaming、 Hbase、kafka、elasticsearch、redis等相关工具；
4.具有1年以上的基于spark streaming/flink/storm等实时数据统计分析开发经验；
5. 熟悉Linux/Unix操作系统，熟练使用scala语言；
6. 热爱开发，有较强的学习能力和快速解决问题的能力，具备较强的责任心和良好的沟通能力"
"职位描述：
        
        岗位职责?1、负责互联网金融相关产品的用户库构建，特征抽取和建模，指标挖掘，实现用户行为分析和用户刻画；?2、参与风险控制方面的建模和数据分析，从数据角度进行风控；?3、负责数据仓库的维护、数据的清洗、建模、数据从采集到入库、出库的整个流程的设计和控制。??岗位要求?1、计算机、统计、数学等相关专业本科及以上学历；?2、熟练使用JAVA、Python或R语言，有扎实的编程基础；?3、熟悉数据仓库的设计和建设，熟悉Mysql等数据库，精通SQL；?4、熟悉分类、回归、聚类等常用的机器学习/数据挖掘方法，并有实际数据挖掘项目经验；?5、具有良好的逻辑分析能力、沟通能力和文字表达能力，有金融行业从业经验者优先考虑。"
"职位描述：
        
        岗位职责：1、?负责公司大数据平台的建设与维护工作；2、?负责构建Spark/HDFS大数据处理架构，不断研究、改进分布式微服务架构的功能、性能等问题；3、?跨部门/团队协作，协同分析并解决各类大数据平台相关的运行或数据问题。职位要求：1、?计算机、数学相关专业本科以上学历；1年以上大数据相关经验；2、?至少掌握Java/Scala/Python其中一种语言；3、?有大数据分布式计算平台开发经验,熟悉Hadoop,?Spark，MapReduce，Hive等原理及应用；4、?熟悉linux?或macOS开发环境，熟悉linux系统基本操作，能编写shell或python脚本；5、?至少掌握一种大数据存储相关数据库，如：MongoDB、Cassandra、hbase；了解elasticsearch全文检索引擎的优先考虑；6、?工作认真、负责、仔细，有良好的团队合作精神，良好的分析能力、沟通技巧。"
"职位描述：
        
        岗位职责： 
1.?负责大数据平台基础架构的架构设计、技术选型、搭建、开发和管理，对数据应用提供数据存储、查询引擎、实时计算、元数据管理的架构设计；
2.?系统核心部分代码编写、指导和培训工程师、不断进行系统优化；
3.?负责构建用户画像、用户标签系统，用于支持运营营销；
4.?跨团队/部门协作，系统分析解决各类大数据平台相关的运行或者数据问题。
?
?
任职要求：
1.?计算机相关专业本科以上学历，5年以上工作经验，3年大数据相关经验；
2.?熟练掌握JAVA、Python等开发语言，深刻理解面向对象编程
3.?对用户画像、用户标签系统有实践经验，并运用于具体的互联网运营；
4.?对大数据技术体系有深入认识，具备相关技术（如Hadoop、Hive、HBase、Flink、Spark、Storm、?Flume、Kafka、ES等）中一个或者多个有深入的了解和实践；
5.?熟悉常见的数据结构，深入理解分布式算法和以上提到的分布式系统;
6.?具有一定的项目规划和决策能力，善于捕捉业务需求、架构设计存在的问题并给出有效的解决办法和措施;"
"职位描述：
        
        ?岗位职责：
1.??????? 负责数据仓库及BI项目的建设需求调研，业务沟通，数据分析，编写调研报告；
2.??????? 负责数据仓库及BI项目的系统接口的设计；
3.??????? 负责设计数据仓库的模型结构，ETL流程及mapping逻辑，管理元数据；
4.??????? 负责应用分析模块的模型和展现设计；
5.??????? 负责基于hadoop平台的数据仓库项目实施。
?
任职要求：
1.????? 计算机相关专业，全日制本科以上学历；
2.????? 熟悉Hadoop大数据生态圈技术，包括分布式存储Hdfs,Hbase等、资源调度Yarn和计算框架Spark,MR,Hive等，如果有相关源码研究的优先考虑；
3.????? 熟悉Linux环境，能够熟悉使用shell脚本；
4.????? 熟悉azkaban调度系统；
5.????? 熟练掌握实时数据处理常用技术工具Flume、Flink、kafka等；
6.????? 二年以上Java Web应用开发经验的优先考虑；
7.????? 有金融行业、互联网行业数据项目实施经验者优先。"
"职位描述：
        
        1. 计算机或相关专业大专及以上学历，熟练使用常用算法和数据结构，3年以上数据开发/数据分析相关经验；
2. 有丰富的SQL使用经验，熟练使用ORALCE/MYSQL等数据库；
3. 有足够的银行业务知识，熟悉银行存、贷款业务，支持各类监管报送，需求分析、开发、运维；
4. 有较强的数据分析能力和逻辑判断能力，有一定的银行会计基础知识；
5. 对解决挑战性问题充满热情，善于分析解决问题，吃苦耐劳；
6. 有HSQL开发经验者优先，有MAST/EAST/反洗钱/征信等报送经验者优先。"
"职位描述：
        
        岗位职责
1、负责产品业务日常数据统计、数据分析、报表开发、数据维护等相关工作
岗位要求
1、本科及以上学历
2.熟练掌握数据处理的ETL过程
3、精通oracle,mysql,postgre数据库，熟练使用SQL语句进行数据处理
4.熟练使用hive sql 计算程序完成数据清洗、建模和结果输出
5.具备良好的沟通表能力和团队合作精神，有进取心和责任心，能承受一定强度的工作压力；"
"职位描述：
        
        驻点政法机关单位，负责安平项目系统的开发

工作职责：
1、基于hadoop/spark/mppdb的大数据、数仓平台架构设计及开发工作
2、数据处理流程设计及开发
3、海量数据的采集、存储、管理、分析、建模
4、负责大数据、数仓平台的监控及优化，针对持续增长的数据提供相应的解决方案
5、负责大数据、数仓项目的疑难问题解决，性能优化

岗位要求：
1、有3年以上相关岗位工作经历，或者非金融业的数据服务或信息数据管理工作经验
2、数学、计算机技术等相关专业
3、精通大数据（MPPDB、Hadoop）等相关技术，并精通Hbase/Hive/MR/Spark/Solr/storm/flink其中的任意3个组件技术。
4、至少精通主流数据库技术Oracle/PostreSql/MySQL/SQL server中的一种，精通数据仓库理论架构，包括但不限于数据调度、ETL、元数据管理、数据监控；
5、精通1-2门开发语言（JAVA/Python/Scala/Shell）
6、具有比较突出的组织、策划、协调及沟通能力，有强烈的结果导向和客户导向。

面试流程：简历筛选--视频面试
福利待遇
A：薪资：基本工资+加班费+差旅补助+季度奖金+年终奖

B：按照工资额缴纳五险一金

C、出差住宿报销标准为400元/人天，实报实销；差旅补助标准为200元/人天

D、加班费计算按照：加班费计算=（员工当月出勤工资）/21.75天/8小时*(法定节假日加班工时*3+普通周末*2+普通加班工时*1.5）的标准执行。
F、季度绩效考核结果直接影响员工在本季度的季度奖金；年度绩效考核结果将直接影响员工的年终奖金"
"职位描述：
        
        1、熟悉Spark应用和开发框架、具有较丰富的Spark大数据平台应用开发经验、有至少2年的大数据工作经验
2、熟练使用hive、spark sql、spark mlib、H2O、有Tensorflow经验更佳。
3、数学基础扎实（统计算法、机器学习算法、聚类算法等）、有实际项目应用经验、能针对不同场景进行算法建模。
4、熟练使用python、java
5、至少4年同岗位经验，全日制本科学历。"
"职位描述：
        
        1、全日制统招本科学历，理工科专业；
2、有两年或以上hadoop, Hive, spark，hbase技术应用经验，有两年以上JAVA技术技能，有两年以上ORACLE数据库技能；
3、hadoop方面主要是这个几个关键组件的原理理解和实际应用经验。"
"职位描述：
        
        工作职责：负责自然语言对话的数据研发及业务数据挖掘等；负责自然语言对话机器人的数据优化研发，完成业务部门的各项数据需求研发。参与数据治理相关研发工作，参与数据系统质量、数据一致性及稳定性保障等建设任职要求：3年以上软件开发经验；熟悉主流数据库，精通SQL，有一定SQL编码及调优经验；熟悉分布式存储和NoSQL数据库技术，有实际生产项目应用经验；了解如Spark,?Kafka,?Druid,?ElasticSearch等常用组件，有源代码级问题解决和优化改造能力者优先；具备良好的逻辑分析能力和学习能力,责任心强;?具有良好的团队合作意识,沟通能力,协调能力;"
"职位描述：
        
        职位描述：参与公司大数据平台整体规划,?支撑公司不同业务线对数据平台的需求。深入研究大数据相关技术,?负责大数据平台相关组件的性能调优,?技术难点攻关；把控大数据平台日常需求和设计,?负责核心模块的开发挖掘大数据平台的价值，拓展其应用空间,?驱动业务的发展任职要求：本科及以上学历,?3年以上大数据平台核心模块的开发,设计,?运维经验,?有较强的设计能力;擅长hadoop生态系统各个组件的运用和调优，?如Spark、hadoop、hbase、hive等开源项目，对其中某一领域有较深研究；至少熟悉Java编程语言了解最新大数据业界相关技术和动态有良好的团队合作和沟通表达能力,?较强项目推动力有BAT级别互联网数据平台核心模块的设计&开发经验的优先"
"职位描述：
        
        1.?? 负责公司数据仓库建设
2.?? 负责公司数据应用开发
负责数据质量保证等
任职资格：
1.? oracle、MySQL、SQL Server
2.? 精通SQL开发，熟悉Hadoop平台相关组件，熟练使用Hive
3.? 熟悉主流ETL工具，如DataStage，Informatica，Kettle等
4.? 熟悉相关脚本语言、如Shell，python等，有Java相关工作经验更好
熟悉数据仓库、维度建模等相关领域知识"
"职位描述：
        
        1. 熟悉Unix/Linux操作系统下的开发，熟悉Java，熟悉其他如 Scala，Python，Shell 等一种或多种语言是加分项；2. 熟悉JVM，有较强的分析问题和解决问题的能力；3. 熟悉大数据领域常用开源软件，如 Hadoop、Spark、Flink、Storm、Kafka 等，对其中一种或多种原理有比较深的理解是加分项;4. 熟悉使用 SpringBoot 和 MyBatis 开发 Web 接口;5. 有数据大数据算法经验、机器学习平台建设经验者优先。"
"职位描述：
        
        岗位职责：1.负责公司财务模块的需求分析和设计、数据接入、数据开发2.参与系统稳定性、扩展性提升和性能调试岗位要求：1.本科及以上学历，计算机或数学相关专业；2.熟悉常用的数据库，能够编写SQL语句、存储过程；3.熟悉Hadoop、Hive、Impala等大数据平台；4.较强的逻辑思维能力和独立思考能力；5.关注新业务和新技术，学习能力强，具有一定的创造力和承压能力。"
"职位描述：
        
        岗位职责:

1，负责公司大数据平台相关组件的研发设计； 2，负责业务系统数据收集、处理、存储方案的设计开发； 3，持续关注大数据前沿技术，优化公司平台相关架构。 
任职资格:

1、一年以上开发经验，热爱软件开发，做事认真细致负责，沟通能力强，有团队合作精神； 2、java基础扎实，如多线程、IO、同步、反射等； 3、熟悉Linux下开发，熟练使用命令，能编写shell脚本，熟悉python； 4、熟悉数据库：mysql、redis 5、熟悉大数据相关技术原理与架构：hadoop/flume/kafka/Spark/elasticsearch，能够独立部署相关组件； 6、精通SQL查询，mysql、impala、hive 7、掌握数据分析的基本流程，具备数据采集、清洗、分析等环节的实战经验者优先； 8、有实时日志数据收集处理经验，有spark开发经验者优先； 9、研究过大数据开源项目者优先；"
"职位描述：
        
        工作职责：1、负责公司大数据分析、数据实时/离线处理业务的开发、优化工作；2、参与数据产品架构设计、方案讨论；3、负责跟踪、解决产品研发团队及客户遇到的产品问题；4、负责产品系统的持续跟进和优化；5、其他临时性工作。职位要求：1、熟练使用Java、scala、python其中至少一门语言，2年以上同岗位经验；2、熟练使用Spark、Spark?SQL、hive等开发，系统设计、调优经验；3、有海量在线、离线数据分析系统设计和开发经验；4、有较强的学习能力和执行力，能独立完成复杂技术任务；5、正直、阳光、善于沟通，对海量数据分析业务充满热情，敢于迎接挑战。"
"职位描述：
        
        岗位描述：
1.负责数据接入，数据清洗，数据爬虫，数据仓库的建立；
2.有建立画像相关经验及使用机器学习能力建立相关标签；
3.根据实际业务需求，输出对应所需结构化数据模型；

?岗位要求：
?1.精通JAVA语言，2年以上批处理/流处理实际项目开发经验
?2.精通hadoop、spark、kafka、solr、flink等主流大数据技术；
?3.具有大规模数据收集、日志处理等项目经验；
?4.熟悉k8s,docker等容器技术，并拥有实际的项目经验；
?5.熟悉常用数据算法和模型（推荐、画像等);
?6.良好的设计和编码品味，热爱写代码，有代码洁癖更佳"
"职位描述：
        
        数禾科技，上市公司分众传媒（股票代码002027）旗下互联网金融子公司，团队成员来自于招商银行、中国银联、大众点评、群硕科技等知名金融互联网企业。
公司致力于成为中国最有影响力的个人/家庭财务管理的科技金融企业，现已面市APP产品包括：
还呗－低息代还信用卡，千万用户之选
拿铁智投－优质基金理财，智能投资顾问
用户量正处于快速增长趋势，详询我司官网或分众传媒旗下楼宇/框架/电影院等广告展示，也可关注微信公众号(huanbei_loan、lattebank)、官网(http://www.lattedata.com)

工作职责：
1. ? 熟悉数据仓库体系架构、建模理论和模型设计思路，能用于项目实践。
2. ?负责数据仓库模型设计和优化，基于Hadoop／Hive／Python参与数据仓库ETL开发工作。

岗位要求:?
1. ? 三年以上数据仓库／ETL／数据处理相关开发经验。
2. ?具备MySQL、Oracle或Hive等主流平台的数据开发及调优经验，熟悉Python优先。
3. ? 具备良好的学习能力，善于沟通，具备较强的业务推动能力和执行力。
4. ? 对技术有激情，对代码有苛刻要求。
5. ? 有良好的快速学习能力和团队协作能力。
6. ? 有产品意识，善于沟通，积极主动，能够以目标为导向理解工作中相关任务的处理优先级关系。"
"职位描述：
        
        分析客户业务报表，根据客户提供的数据库文档认识业务系统数据结构，编写sql语句查询统计业务报表中需要的指标，利用报表工具设计报表。利用数据分析工具设计BI交互分析图表，Olap多维分析表等"
"职位描述：
        
        
岗位描述：
1. 参与资管数据基础平台的建设，完成平台的构建与维护、离线计算平台、实时流计算平台、分布式调度、可视化报表等平台的架构与研发。
2. 深入了解业务背景，能抽象业务需求，负责数据应用、数据服务层的平台架构设计与研发。

岗位需求：
1. 全日制本科及以上学历，计算机相关专业，扎实的Java语言基础和Linux编程基础；?
2. 3年以上大数据相关系统研发经验，2年以上大数据平台规划与设计、架构研发经验；?
3. 对大数据相关组件：Hadoop、Spark、Hbase、Hive、Kafka、Flume、Kylin、ElasticSearch等架构与底层实现有深入理解，具备相应的定制和研发能力；
4. 具备构建稳定的大数据基础平台的能力，具备数据收集、数据清洗、数据仓库建设、实时流计算等系统研发经验；
5. 对技术有热情，有不错的数据思维和敏感度，有一定的数据分析能力优先，对深度学习、机器学习有一定的了解优先；?
6. 工作有计划性，责任心和执行能力强，具备高度的责任心、诚信的工作作风、优秀沟通能力及团队精神。"
"职位描述：
        
        工作职责：
-参与数据仓库和大数据平台的环境搭建、架构设计和程序开发
-参与分布式结构化数据的数模设计
-主要负责大数据实时计算的新技术落地及平台提升
-负责分布式批量计算、分布式内存计算、数据仓库类SQL查询统计等离线计算
-满足公司各部门日常的数据需求

职位要求：
-本科及以上学历，计算机、软件工程或相关专业出身，工作4年以上，具有Hadoop、Spark、Spark Streaming、Flink开发与应用经验，熟悉Flume与Kafka等数据采集和消息通道技术，熟练掌握HDFS、Hbase、Hive、Spark、Flink等大数据技能，熟练掌握Spark Streaming、Flink等流计算技术
-有较好的Java或Scala基础
-熟悉Linux环境及脚本开发（Python/Perl/Shell等）
-熟悉MySQL，Redis，Druid，能够快速的理解业务模型及数据模型
-理解ETL过程，拥有DW项目开发经验，熟练掌握SQL/HQL
-积极主动参与讨论、发现并解决问题
-学习能力强，拥有优秀的逻辑思维能力、良好的理解和表达能力、较强的抗压能力
-能迅速融入团队，与其他团队成员保持良好的合作

加分项：
-有大型互联网公司流量项目开发经验
-有Linux操作系统及Tomcat中间件运维经验
-熟悉CDH集群管理并有kerberos及sentry权限管理经验
-有过Hadoop开源项目经历"
"职位描述：
        
        工作职责：
-参与数据仓库和大数据平台的环境搭建、架构设计和程序开发
-参与大数据平台的自主组件的研发及日常运行维护工作
-参与离线计算基础平台的封装及开放工作
-参与实时计算基础平台的封装及开放工作
-参与数据服务总线的统一封装及可用性保障
-基于公司业务，构建模型算法，发掘数据的价值
-满足公司各部门日常的数据需求
?
职位要求：
-本科及以上学历，计算机、软件工程或相关专业出身，工作3年以上
-有扎实的Java基础，熟悉Spring?MVC、Spring?Boot框架及MyBatis框架
-负责过某个大数据平台的系统研发，如调度系统、元数据、数据交换、数据质量、自助报表等
-熟悉主流的大数据计算和存储引擎，如Hive、Spark、Presto、Flink、Hbase、HDFS及ES等
-熟悉基于Hadoop的数据仓库建设过程及原理
-积极主动参与讨论、发现并解决问题
-学习能力强，拥有优秀的逻辑思维能力、良好的理解和表达能力、较强的抗压能力
-能迅速融入团队，与其他团队成员保持良好的合作
?
加分项：
-有大型互联网公司流量项目开发经验者尤佳
-有Linux操作系统及Tomcat中间件运维经验
-熟悉CDH集群管理并有kerberos及sentry权限管理经验
-有过Hadoop开源项目经历"
"职位描述：
        
        岗位职责：

1、参与数据仓库和大数据平台的环境搭建、架构设计和程序开发

2、参与分布式结构化数据的数模设计

3、负责离线和在线数据的采集、清洗和加载

4、负责分布式批量计算、分布式内存计算、数据仓库类SQL查询统计等离线计算

5、参与实时数据流的数据处理、查询统计和分析预测等在线计算

6、基于公司业务，构建模型算法，发掘数据的价值

7、满足公司各部门日常的数据需求



任职资格：

本科及以上学历，计算机、软件工程或相关专业出身，工作3年以上，具有Hadoop、Spark、Spark Streaming开发与应用经验，熟悉Flume与Kafka等数据采集和消息通道技术，熟练掌握Hadoop、Hbase、Hive、Spark及Spark SQL等大数据技能，熟练掌握Spark Streaming等流计算技术

2、有较好的Java基础，熟练SpringMVC框架及MyBatis框架

3、熟悉Linux环境及脚本开发（Python/Perl/Shell等）

4、熟悉MySQL，Redis，能够快速的理解业务模型及数据模型

5、理解ETL过程，拥有DW项目开发经验，熟练掌握SQL/HQL

6、积极主动参与讨论、发现并解决问题

7、学习能力强，拥有优秀的逻辑思维能力、良好的理解和表达能力、较强的抗压能力

8、能迅速融入团队，与其他团队成员保持良好的合作"
"职位描述：
        
        工作职责：
-参与数据仓库和大数据平台的环境搭建、架构设计和程序开发
-参与分布式结构化数据的数模设计
-负责离线和在线数据的采集、清洗和加载
-负责分布式批量计算、分布式内存计算、数据仓库类SQL查询统计等离线计算
-参与实时数据流的数据处理、查询统计和分析预测等在线计算
-基于公司业务，构建模型算法，发掘数据的价值
-满足公司各部门日常的数据需求
?
职位要求：
-本科及以上学历，计算机、软件工程或相关专业出身，工作2年以上，具有Hadoop、Spark、Flink开发与应用经验，熟悉Flume与Kafka等数据采集和消息通道技术，熟练掌握Hadoop、Hbase、Hive、Spark及Spark SQL等大数据技能，熟悉Spark Streaming/Flink等流计算技术
-有较好的Java或者SCALA基础
-熟悉Linux环境及脚本开发（Python/Perl/Shell等）
-熟悉MySQL，Redis，ES，能够快速的理解业务模型及数据模型
-理解ETL过程，拥有DW项目开发经验，熟练掌握SQL/HQL
-积极主动参与讨论、发现并解决问题
-学习能力强，拥有优秀的逻辑思维能力、良好的理解和表达能力、较强的抗压能力
-能迅速融入团队，与其他团队成员保持良好的合作
?
加分项：
-有互联网流量项目开发经验
-有Linux操作系统及Tomcat中间件运维经验
-熟悉CDH集群管理并有kerberos及sentry权限管理经验
-有过Hadoop开源项目经历"
"职位描述：
        
        职位描述:
? 1、负责公司产品和项目功能开发和维护
? 2、评审产品需求, 分析并给出最优的开发解决方案
? 3、主导复杂数据产品的开发，能快速分析和解决开发中问题使项目顺利进行
? 4、对负责的系统后续发展和规划有一定思考和建议
职位要求:
? 1、精通J2EE开发,3年以上项目开发经验
? 2、熟练掌握SpringMVC、SQL、Tomcat配置维护，熟悉Linux平台并能独立完成产品开发和发布
? 3、掌握并能使用freemarker(不限)，jQuery，Bootstrap，CSS等技术进行前端开发
? 4、具有强烈的责任心和团队合作精神
? 5、具有较强的人际沟通能力，性格开朗、乐观
? 6、有大数据应用开发经验更佳"
"职位描述：
        
        工作职责：
1、负责建设公司大数据平台，为公司用户提供稳定、易用的大数据平台工具和便捷、酷炫的数据产品；
2、参与并主导大数据平台工具链的设计、开发以及后续维护；
3、参与数据产品的研发，助力数据商业价值的发掘；
4、不断迭代优化已有平大数据台工具和数据产品，推动大数据平台的发展。
?
任职要求：
1、从事数据仓库领域开发2年及以上，熟悉数据仓库理论且具备数据平台搭建经验，对元数据管理、权限管理等系统有较好理解者优先；
2、熟练掌握前端开发技能，至少有一种前端开发框架的使用经验；
3、能够独立完成后端系统的设计开发，熟悉Java，对Spring、Mybatis等开发框架有较好的理解；
4、了解Hadoop、Spark、Hive、Mapreduce者优先；
5、熟悉Linux系统和常用的shell命令，有大数据相关系统开发维护经验者优先；
6、良好的语言沟通能力与表达能力，能够自我驱动。

更多技术团队信息，可以关注我们达达技术公众号：达达技术。"
"职位描述：
        
        岗位职责：
1.???? 参与分布式爬虫系统和数据采集系统的设计、开发
2.???? 参与大数据平台hadoop、spark、hbase、ELK等维护、开发和管理工作
3.???? 与产品经理，前后端工程师等一起完成项目和业务系统的设计、开发和测试等工作
4.???? 参与实现数据的统一采集、分析、管理等相关的工作
5.???? 参与爬虫策略和防屏蔽规则研究，提升网页抓取的效率和质量
6.???? 根据项目需求进行开发实现,文档撰写,项目实施等
?
任职要求：
1.????? 计算机相关专业，本科及以上学历
2.????? 扎实的编程功底，熟悉常用的数据结构和算法，有过c，c++，python或java等开发经验
3.????? 在校成绩优秀者优先，参加过
4.????? 对大数据技术有浓厚的兴趣，了解Hadoop, Hive, Pig, ELK, Spark, Cassandra等一个或多个大数据相关项目者优先
5.????? 熟悉爬虫技术，有过大规模爬取经验者优先
6.????? 熟悉JVM, 能够解决项目中遇到的JVM相关的问题, 进行与JVM相关的性能优化等
7.????? 对机器学习、数据挖掘、人工智能、NLP、搜索、推荐等算法熟悉者优先
8.????? 对http协议熟悉者优先
9.????? 对技术有激情，喜欢钻研，能快速接受和掌握新技术
10.?? 具备较强的沟通能力及团队协作精神；"
"职位描述：
        
        职位描述 
1、负责基于Hadoop/Spark/Hive/Storm/kafka等分布式计算平台实现离线分析、实时分析的计算框架； 
2、负责平台数据仓库的选型、设计、开发、维护工作； 
3、负责上述计算平台系统的可用性、容量、性能、监控、发布、安全等运维管理工作，确保系统持续稳定、高效运行； 
4、协调大数据团队高效的进行数据处理、分析、统计、挖掘工作； 
岗位要求： 
1、 熟悉服务器/存储/网络/OS等基础架构基本元素，熟悉linux操作系统，具备较强的调优排障能力； 
2、熟悉Hadoop、Spark等大数据框架，有大型分布式计算开发、部署等相关经验； 
3、熟悉shell/python或其他脚本语言中的任意一门，有扎实的Java开发基础，了解jvm的运行机制以及相应调优； 
4、能够独立完成项目的系统分析、设计，并主导完成详细设计和编码的任务。 
5、注重性能，良好的代码管理及重构意识。具备独立沟通需求，设计，架构，开发的能力； 
6、熟悉主流的数据存储产品，有开发经验者优先。如：HBase，Hive，Redis，MongoDB，MySQL等； 
7、有团队管理经验者优先。"
"职位描述：
        
        1、负责基于Hadoop/Spark/Hive/Storm/kafka等分布式计算平台实现离线分析、实时分析的计算框架；2、负责平台数据仓库的选型、设计、开发、维护工作；3、负责上述计算平台系统的可用性、容量、性能、监控、发布、安全等运维管理工作，确保系统持续稳定、高效运行；4、协调大数据团队高效的进行数据处理、分析、统计、挖掘工作；

岗位要求：
1、熟悉服务器/存储/网络/OS等基础架构基本元素，熟悉linux操作系统，具备较强的调优排障能力；2、熟悉Hadoop、Spark等大数据框架，有大型分布式计算开发、部署等相关经验；3、熟悉shell/python或其他脚本语言中的任意一门，有扎实的Java开发基础，了解jvm的运行机制以及相应调优；4、能够独立完成项目的系统分析、设计，并主导完成详细设计和编码的任务。5、注重性能，良好的代码管理及重构意识。具备独立沟通需求，设计，架构，开发的能力；6、熟悉主流的数据存储产品，有开发经验者优先。如：HBase，Hive，Redis，MongoDB，MySQL等；7、有团队管理经验者优先。"
"职位描述：
        
        职位描述
1、负责基于Hadoop/Spark/Hive/Storm/kafka等分布式计算平台实现离线分析、实时分析的计算框架； 2、负责平台数据仓库的选型、设计、开发、维护工作； 3、负责上述计算平台系统的可用性、容量、性能、监控、发布、安全等运维管理工作，确保系统持续稳定、高效运行； 4、协调大数据团队高效的进行数据处理、分析、统计、挖掘工作；

岗位要求：
1、熟悉服务器/存储/网络/OS等基础架构基本元素，熟悉linux操作系统，具备较强的调优排障能力； 2、熟悉Hadoop、Spark等大数据框架，有大型分布式计算开发、部署等相关经验； 3、熟悉shell/python或其他脚本语言中的任意一门，有扎实的Java开发基础，了解jvm的运行机制以及相应调优； 4、能够独立完成项目的系统分析、设计，并主导完成详细设计和编码的任务。 5、注重性能，良好的代码管理及重构意识。具备独立沟通需求，设计，架构，开发的能力； 6、熟悉主流的数据存储产品，有开发经验者优先。如：HBase，Hive，Redis，MongoDB，MySQL等； 7、有团队管理经验者优先。"
"职位描述：
        
        岗位职责

1、负责公司大数据产品组件模块的设计、编码及测试；

2、配合产品、设计、测试人员，完成大数据产品持续优化；基于产品组件设计、研发体验，提出优化建议；

3、配合项目实施人员，解决现场实施中遇到的问题；

4、负责大数据项目功能模块的设计、编码及测试；

任职要求

1、本科或本科以上学历，计算机相关专业；

2、具有3年以上JAVA或大数据项目经验；

3、熟练使用Java语言编程，熟悉常用的中间件、开发框架等；

4、 熟悉大数据生态圈相关组件，熟悉HDFS、YARN、MapReduce原理，熟练使用Hive、Spark、Storm、HBase进行数据应用开发；

5、熟悉常用的任务调度工具（oozie、Azkaban、kettle等），熟悉Flume、Kafka、RabbitMQ、Redis等，熟悉Oracle、mysql 等数据库系统；

6、有算法经验者优先。"
"职位描述：
        
        职位诱惑：
不打卡、定期团建、年终奖、每年境外旅游

岗位职责：
1.?熟悉大数据体系相关知识，协助客户运维大数据系统，协助客户应用数据纳入大数据体系；
2.?基于大数据平台开展数据采集、清洗、存储，根据业务需求编写数据分析程序，进行数据分析和决策。

岗位要求：
1.计算机相关专业，本科及以上学历，3年以上工作经验，2年以上大数据开发相关经验；
2.精通Java、Scala、Python等其中一种语言，能够快速编写数据处理相关的程序；
3.熟悉HDSF、Hadoop、Hive、Spark等大数据生态技术，熟练使用MapReduce、Hive、Spark等进行数据处理；
4.熟悉数据分析模型方法，对数据采集、数据清洗，数据建模、数据可视化等有实战经验；
5、清晰的逻辑分析和表达能力，热爱技术，乐于分享，对行业和技术的发展有自己的见解；
6、良好的团队精神和合作意识，强烈的责任心，对工作有激情，良好的沟通能力。"
"职位描述：
        
        1）熟练hbase、hive、spark开发；
?2）做过hadoop平台调优、代码调优；
?3）了解kafka flume；"
"职位描述：
        
        、负责大数据开发及平台稳定性保障工作2、负责处理大数据平台Hadoop/Hive/Spark/Storm等问题及性能优化3、根据业务需求开发相应工具任职资格1、三年以上工作经验，有大型互联网行业从业经验2、有Hadoop/Hive/Spark/Storm/Zookeeper?等相关开发经验或从事分布式相关系统的开发工作3、熟悉Linux/Unix系统和丰富的Java开发经验4、具有强烈的责任心，求知欲望强"
"职位描述：
        
        岗位职责;

 负责业务支撑系统数据平台相关数据开发和管理工作,如研发规范、质量规范、保障规范的制定与推动实施落地;
 负责大数据平台基础架构的架构设计、技术选型、搭建、开发、管理、监控和性能调优，保证集群高效稳定允许，对数据应用提供数据存储、查询引擎、实时计算、元数据管理的架构设计；
 参与业务团队的数据分析、报表和基础模型；
 参与数据特征仓库的构建和基础算法的应用落地。
 系统核心部分代码编写、指导和培训工程师、不断进行系统优化；
 跨团队/部门协作，系统分析解决各类大数据平台相关的运行或者数据问题。


岗位要求：
1.本科及以上学历。5年以上大数据相关经验,有良好的创新意识、沟通能力、团队合作精神；
2.熟悉JAVA、Python等至少一门编程语言
3.具有扎实的大数据和分布式系统的经验，对于大数据基础组件有深入研究优先。
4.对大数据技术体系有深入认识，具备相关产品（如Hadoop、Hive、HBase、Flink、Spark、Storm、 Flume、Kafka、ES等）项目应用研发经验优先；
5.具有一定的项目规划和决策能力，善于捕捉业务需求、架构设计存在的问题并给出有效的解决办法和措施。
6.有大数据资产管理与治理有一定成功产品化经验者优先；
7.精通数据仓库领域知识和管理技能，包括但不局限于：元数据管理、数据质量、主数据管理、性能调优等；
8.了解数据挖掘和机器学习算法原理者优先。"
"职位描述：
        
        n?岗位职责
1. 负责大数据分析平台中部分子系统的搭建和相关开发；
2. 解决开发过程中的关键技术问题；
3. 诊断和解决现行系统可能存在的问题，保证系统的安全、稳定、高效率运行；

n?任职要求
1. 本科及以上学历，2年以上大数据系统开发经验；
2. 熟悉HDFS、Spark、Storm，至少精通其中一种；
3. 深入了解分析框架的性能优化、可用性、伸缩性问题；
4. 熟悉关系数据库；
5. 有较大规模数据处理经验；
6. 熟悉Kafka、Flume；
7. 有良好的沟通和表达能力。"
"职位描述：
        
        岗位职责：
1. 基于海量数据，支持业务对数据的分析和使用；
2. 支持业务处理数据的流式处理、分析用户行为等；
3. 通过海量数据，分析与挖掘各种潜在关联。
任职资格：
1. 计算机相关专业本科及以上学历 ??
2. 有扎实的编程能力，有优秀的设计和代码品位，对解决具有挑战性问题充满激情
3. 精通至少一门编程语言(java/python/php)，熟练运用各种常用算法和数据结构，有独立的实现能力
4. 熟悉常用的开源组件：Hadoop/Hive/Spark/Storm，并了解其特性和使用场景优先
5. 熟悉机器学习、数据挖掘、数据分析、分布式计算至少某一方面，有较深的理论研究和实践经验优先
6. 优秀的沟通理解能力，能快速理解业务，用数据解读业务
7. 数据分析、推荐、机器学习、数据挖掘相关的开发工作优先"
"职位描述：
        
        岗位描述：
1、搭建大数据平台，设计数据接入的技术流程和规范，整合用户数据
2、基于海量数据，对用户和车源画像，构建图谱关系，支持用户运营、个性化服务、风控模型等核心业务需求
3、负责核心系统的架构和实现，开发与维护核心功能模块 ? 
?
任职要求：1、计算机相关专业本科及以上学历，5年以上互联网工作经验，3年以上大数据实践经验优先~2、具备扎实的编程能力，有优秀的设计和代码品位，对解决具有挑战性问题充满激情3、精通至少一门主流编程语言(java/python/php)，熟练运用各种常用算法和数据结构，有独立的工程实现能力4、熟悉常用的大数据开源组件：Spark/HBase/Kafka/Hive/Storm等，对某一组件有深入研究和实践经验者优先5、熟悉分布式计算、数据整合、数据挖掘、数据分析、机器学习至少某一方面，有较深的理论研究和实践经验优先6、优秀的沟通理解能力，能快速理解业务，用数据解读业务７、具备一定的团队管理能力"
"职位描述：
        
        岗位职责：
1. 负责大数据上各种平台的设计搭建；
2. 参与系统需求分析与设计，完成接口规范制定；
3. 完成平台的开发和测试；
4. 保证平台的稳定性并持续优化；
任职要求：
1. 本科及以上学历，3年以上Java或Go开发经验；
2. 基础扎实，有一定的算法coding能力；
3. 熟悉Linux操作系统、常用命令和shell脚本；
4. 掌握多线程及高性能的设计、编码和性能优化，有高并发应用经验；
5. 具备较强的沟通能力、逻辑思维能力、观察理解能力、学习创新能力。
6. 懂JVM内核的优先"
"职位描述：
        
        岗位职责：
1、负责公司大数据平台的规划和建设；
2、负责制定数据建模、数据处理、数据运维和数据安全等架构规范并落地实施；
3、设计并实现数据仓库、数据挖掘、BI、机器学习等数据系统建设、开发；
4、利用统计机器学习、深度学习算法改进数据系统的智能；
5、主导并身体力行整个技术团队的DevOps建设和实践；
6、 辅导团队，提升公司整体数据研发能力。

任职资格：
1、计算机、数学、统计学等相关专业硕士及以上学位，8年以上的大数据建模、分析和软件开发经验；
2、熟悉大数据生态，掌握常见分布式计算框架和技术原理，如Hadoop、MapReduce、Yarn、Hbase、Flink、Spark等；
3、熟悉Linux操作系统和Shell编程，至少精通Java/Python/Scala/R等语言中的一种编程；
4、熟悉大规模并行计算的基本原理并具有实现并行计算算法的基本能力；
5、性格积极乐观、诚信，能自我驱动，有较强的语言表达能力；具有良好的沟通、团队协作、计划和创新的能力；
6、具有智能交通、互联网行业经验优先考虑。"
"职位描述：
        
        岗位职责

 负责智能汽车行业大数据平台的规划和建设；
 实现智能汽车全生命周期（设计、制造、销售、服务、售后）数据统一管理；
 设计并实现车辆实时数据采集、归集和存储相关系统，包括车机CAN总线数据、ADAS数据、GPS、自动驾驶等相关数据；
 负责车机CAN总线数据、雷达数据的数据分析，为自动驾驶提供数据支撑；
 基于公司的智能汽车、电商、金融、出行等全面的IOT大数据，积极探索深度学习等人工智能技术的应用，实现大数据在智能汽车行业的商业价值；
 大数据已在移动互联网中发展到高峰，下一个风口就在智能汽车。

任职资格

 计算机、数学、统计学等相关专业本科及以上学位，5年以上的大数据建模、分析和软件开发经验；
 具备扎实的数学、AI知识，至少在以下某一领域有深入的研究：统计机器学习、视觉识别、深度学习；
 掌握常见分布式计算框架和技术原理，如Hadoop、MapReduce、Yarn、Hbase、Flink、Spark等；
 熟悉Linux操作系统和Shell编程，熟悉SQL编程以及性能调优；
 精通Java/Scala或者其他主流开发语言；熟悉常用的Java类库以及框架，如Spring等；
 性格积极乐观、诚信，能自我驱动，有较强的语言表达能力；
 具有智能交通、车联网、电子商务、金融行业经验优先考虑。"
"职位描述：
        
        工作内容：
1、 自动驾驶算法研发和评测相关的数据工具和服务研发
2、 仿真系统相关的数据工具和服务研发
任职要求；
1、 ?电子工程、计算机科学与技术、自动化及其他相关领域本科及以上学历，硕士及以上学历优先；
2、 精通数据库研发，有丰富的大数据处理经验，了解知名公开数据评测集，有大规模传感器数据样本标注评测工具和服务研发经验者优先。
3、 有强烈的上进心和求知欲，很强的解决问题和分析能力，较强的沟通表达能力和团队合作意识。"
"职位描述：
        
        工作职责

 负责车和家自动驾驶数据处理的后台开发；
 负责后台服务器开发框架的研究；
 负责自动驾驶数据工艺研发和工艺流程的优化；
 负责自动驾驶仿真系统的设计和研发。


任职资格

 计算机相关专业，本科及以上学历；
 掌握C/C++或PHP其中一种开发语言，熟悉常用算法和数据结构；
 熟悉python、shell、Lua等一种或几种脚本语言，有一定的脚本开发经验；
 熟悉Linux服务器框架，掌握调试技巧，有分析问题和解决问题的能力；
 良好的学习能力、沟通能力、团队协作能力，责任心强；
 有海量数据及海量服务器开发经验优先，有大型软件研发经验者优先。"
"职位描述：
        
        
岗位职责：
1. 与业务部门保持密切沟通合作，掌握业务和产品动态和规划
2. 负责全站或具体产品的用户分析，通过对海量数据的分析挖掘，提取用户特征、行为轨迹、及变动趋势
3. 建立分析模型，通过公司的海量数据，应用统计分析、数据挖掘方法解决业务部门的实际需求
4. 参与大数据挖掘工作，从网站运营、营销传播、用户分析等方向为客户提供数据分析服务，并根据分析结果提出决策建议
5. 响应并管理业务部门的其他数据分析需求，协调相关部门推动分析项目的高效完成
任职要求：
1.全日制统招本科及以上学历，统计学、经济学、计算机等和数据处理高度相关专业（理工科背景优先），1年及以上相关工作经验；扎实的统计学、数据挖掘理论基础；
2. 熟练使用Hadoop ,Hive, Spark, AWS, NLTK ,Unix/Linux等工具集；有数据建模和机器学习经验者优先；
3. 熟练使用Java, Python, Bash, Scala, R, SQL等语言,熟练使用关系型数据库MySQL ,PostgreSQL ,Oracle中的至少一种；
4. 具有较强结构化思维、逻辑思维能力，对数据敏感，具备优秀的信息整合和分析能力，能够形成清晰的业务观点和前瞻判断；
5. 具有良好的商业敏感度和优秀的数据分析技能，能够开发创新而实际的分析方法以解决复杂的商业问题；擅长与内部及外部商业伙伴的交流沟通，具有优秀的报告讲解能力及沟通能力；
6. 有互联网数据分析、运营优化相关背景；有网站用户行为研究和数据挖掘经验者优先，有搭建数据库经验优先拥有海量数据处理经验者优先；
关于我们：
1、五险一金，带薪年假，带薪病假，年终奖金应有尽有~
2、公司位于5号线附近，交通便利，周围餐饮发达，每天都有四菜一汤自助餐！正式入职后每天有餐补哦~
3、各种节日福利，神马端午，中秋...礼物不重样~
4、每月定期员工举办生日会，还有各种零食礼品哦~
5、每年都有员工旅游，比如夏天去露营，冬天去滑雪泡温泉等等；
6、大型年会party，各种主题各种嗨；"
"职位描述：
        
        工作职责:1.负责大数据平台（CDH）优化和维护；2.负责数据的ETL；3.负责算法模型上线。任职资格:1. 具有5年以上大数据相关工作经验；2. 熟悉Hadoop架构和生态（如：kylin、kafka、Flink、canal、hdfs、hive、hbase、yarn、ElasticSearch等）3. 熟悉spark架构（如：spark streaming、spark graphx、spark sql等）；4. 具有团队合作、良好的沟通技巧和主动挑战困难能力。"
"职位描述：
        
        地图数据开发工程师
工作职责：
1. 地址数据和POI等数据的分析和二次处理、提取引擎用关键信息。
2. 引擎用数据编译、发布和内部自测。
3. 完成线上引擎数据问题的跟踪、分析和处理。
4. 数据检查和处理工具的开发
职位要求：
1. 熟悉主流的地图交换格式，如四维/高德/kiwi/nds中的一种。
2. 熟练使用mapinfo/ arcgis/qgis等软件中的一种。
3. 熟悉C++开发，熟练使用python。
4. 有过地图数据转换和处理经验优先。"
"职位描述：
        
        职位描述
1.负责相关网站网页信息和APP数据抽取、清洗、消重，挖掘, ETL等工作，提升抓取效率；
2.参与爬虫算法和策略优化；
3.监控爬虫的进度和警报反馈；

职位要求
1. 熟练使用linux，擅长Python开发；"
"职位描述：
        
        岗位职责：
1. 负责大数据核心业务需求开发；
2. 负责大数据平台系统设计和开发；
3. 参与数据平台的监控、维护与优化；

基本要求：
1. 计算机相关专业本科及以上学历，1年及以上数据开发经验；
2. 熟悉hadoop相关技术，包括Mapreduce、Hive、Storm、flume、spark 等；
3. 熟悉python、java等至少一门语言的使用；
4. 熟练掌握mysql数据库的使用；
5. 对大数据技术有兴趣和热情，对工作有强烈的责任感，有较强的学习能力和创新精神；"
"职位描述：
        
        岗位职责：
1. 负责大数据核心业务需求开发；?
2. 负责大数据平台系统设计和开发；?
3. 参与数据平台的监控、维护与优化；?
?
基本要求：
1. 计算机相关专业本科及以上学历，4年及以上数据开发经验；?
2. 熟悉hadoop相关技术，包括Mapreduce、Hive、Storm、flume、spark 、kafka等；?
3. 熟悉python、java等至少一门语言的使用；?
4. 对大数据技术有兴趣和热情，对工作有强烈的责任感，有较强的学习能力和创新精神；"
"职位描述：
        
        岗位职责
1、针对公司产品，通过数据分析进行数据价值挖掘，提供产品和运营策略支持；
2、完善和优化数据分析体系和数据报表体系，及时准确监控运营状况。
通过对部门运营数据研究，提出改善运营质量的方法和建议，为部门决策提供支持;
任职要求
1、计算机/数学/统计学等相关专业，本科及以上学历
2、精通一门或多门开发语言（Python、Java等）
3、对算法、数据挖掘有实践经验，熟悉机器学习、数据挖掘方法优先考虑；
4、善于独立思考，逻辑清晰，热爱挑战，具备快速学习能力；
5、良好的沟通能力、学习能力及团队协作能力；"
"职位描述：
        
        岗位职责：
1.负责业务数据报表的开发；
2.协助数据仓库的开发与ETL工作；
3.协助数据挖掘与分析工作；

岗位要求：
1、本科以上学历，计算机相关专业毕业；
2、2年以上数据分析、ETL开发、报表开发等工作经验，参与过大中型数据类项目，熟悉数据报表开发流程；
3、熟悉SQL语言；
4、了解至少一种编程语言；了解至少一种关系型数据库；
5、有一定的数据挖掘分析能力，有在线教育行业开发经验优先考虑。

福利待遇：
1、签固定劳动合同、月薪+餐费补贴，办理六险一金；
2、周末双休；
3、每年福利体检、带薪年假、员工旅游、学习机会等。"
"职位描述：
        
        岗位描述：
1、负责BI团队数据统计分析需求，并提供适当的解读分析；
2、负责数据提取工具的整理与设计,结合业务特点，探索并建立分析主题，对数据进行深度分析和挖掘
3、负责BI团队数据指标统计逻辑的整理；
任职资格：
1、有敏捷的逻辑思维能力、文字表达能力、学习能力及业务理解能力；
2、有良好的团队协作及沟通能力；
3、工作积极主动，严谨认真，肯吃苦，肯钻研；
4、精通HQL语句编程及优化
5、熟悉Linux，Shell & Python & PHP脚本优先；"
"职位描述：
        
         职位描述：
1.??????负责设计和搭建公司各数据平台的建设和维护
2.??????负责公司数据仓库和内部数据产品的架构设计、应用开发、优化完善
3.??????配合业务、产品，根据不同的业务需求，灵活快速地完成具有挑战性的项目，甚至创造更好的数据分析交互方式
职位要求：
1.??????熟练掌握Hadoop/Spark/storm等，有丰富的ETL经验
2.??????具备良好的编程能力和代码风格，熟练掌握Java/Python/shell语言，熟练使用SQL，并具有一定优化能力
3.??????有数据统计系统或熟悉BI DW原理和实施,有BI系统开发经验者优先
4.??????有对业务数据进行分析，挖掘用户行为特征，构建用户精准营销的指标体系，辅助运营决策、产品改进经验者优"
"职位描述：
        
        大数据平台架构师 
高级大数据平台开发工程师 

工作职责： 
1.?负责基于Hadoop开源系统的大数据平台设计、开发、维护。 
2.?开发统一平台，负责任务调度、资源分配、抽象元数据、自动优化、监控报警、等等。 ? 

职位要求： 
1.?本科及以上学历，3年以上大数据平台研发经验。 
2.?具有扎实的编程功底，熟悉常用的算法和数据结构，掌握Java/Python/Scala/Golang等一种以上语言的开发能力。? 
3.?熟悉Linux系统，?精通一门?脚本语言(Shell/Perl/Python等) 
4.?熟悉开源分布式计算/存储相关技术，包括Hadoop、HBase、Hive、Spark、Presto、Kafka、Cassandra、ES、Flink、K8S等。? 
5.?独立，负责，团队沟通协作，技术意识，自驱驱他。"
"职位描述：
        
        工作职责： 1. 负责基于Hadoop开源系统的大数据平台设计、开发、维护。 2. 开发统一平台，负责任务调度、资源分配、抽象元数据、自动优化、监控报警、等等。
任职资格
1. 本科及以上学历，3年以上大数据平台研发经验。 2. 具有扎实的编程功底，熟悉常用的算法和数据结构，掌握Java/Python/Scala/Golang等一种以上语言的开发能力。 3. 熟悉Linux系统， 精通一门 脚本语言(Shell/Perl/Python等) 4. 熟悉开源分布式计算/存储相关技术，包括Hadoop、HBase、Hive、Spark、Presto、Kafka、Cassandra、ES、Flink、K8S等。 5. 独立，负责，团队沟通协作，技术意识，自驱驱他。"
"职位描述：
        
        工作职责：
1. 负责基于Hadoop开源系统的大数据平台设计、开发、维护。
2. 开发统一平台，负责任务调度、资源分配、抽象元数据、自动优化、监控报警、等等。
?
职位要求：
1. 本科及以上学历，3年以上大数据平台研发经验。
2. 具有扎实的编程功底，熟悉常用的算法和数据结构，掌握Java/Python/Scala/Golang等一种以上语言的开发能力。
3. 熟悉Linux系统， 精通一门 脚本语言(Shell/Perl/Python等)
4. 熟悉开源分布式计算/存储相关技术，包括Hadoop、HBase、Hive、Spark、Presto、Kafka、Cassandra、ES、Flink、K8S等。
5. 独立，负责，团队沟通协作，技术意识，自驱驱他。"
"职位描述：
        
        岗位职责:

1、负责公司的数据平台和数据产品研发。2、开发并实现优秀的数据流、数据仓库、查询引擎、数据工具/产品，提供高可用的数据服务，发挥数据价值。3、持续优化系统性能，攻克技术难题。 
任职资格:

1、计算机或相关专业本科及以上学历，2年以上工作经验，1年以上大数据开发经验, 扎实的数据结构和算法功底。2、熟悉Linux/Unix开发环境，熟练掌握PYTHON/JAVA/PHP/GO其中至少一种以上。3、熟悉一项或多项大数据生态框架，如Hadoop、Druid、Storm、Spark、Hive、Kafka、Flume、Hbase、Kylin、Canal、Sqoop等。4、较好的编码能力。5、有后端开发经验者优先。"
"职位描述：
        
        岗位职责：
1、负责数据源和报表数据结构设计、建模以及ETL开发;2、参与报表数据校验;3、支撑各业务渠道的数据提取需求，为日常运营分析提供数据统计支持;

任职要求：1、计算机、统计、信息技术等相关专业，2-5年相关经验2、熟悉MySQL数据库，使用过OLAP数据库优先3、熟练使用SQL，包括关联查询和优化；4.熟练使用Java语言，有Java项目经验。熟悉Python、GO语言优先5、熟悉数据挖掘算法及其原理优先；"
"职位描述：
        
        任职要求：
1、计算机或相关专业本科及以上学历；
2、3年以上大数据应用开发经验；
3、精通Java或Scala语言；
4、熟练实施安装部署Hadoop运行环境；
5、能够熟练进行MapReduce、Spark、Storm应用打包部署和调试；
6、熟练使用Hadoop、Spark、Storm、Hive、HBase进行应用开发；
7、具备基本的Hadoop运行环境的运维管理经验；
8、有实际的大数据应用工程开发经验；
9、 能够接受根据项目要求进行异地出差；
10、熟悉金融领域相关知识或有金融系统开发经验的优先。
岗位职责：
1、 基于大数据平台的应用系统设计、开发、维护；
2、承担公司大数据相关项目的需求分析、开发、实施、现场支持。"
"职位描述：
        
        任职要求：
1、计算机或相关专业本科及以上学历；
2、3年以上大数据应用开发经验；
3、精通Java或Scala语言；
4、熟练实施安装部署Hadoop运行环境；
5、能够熟练进行MapReduce、Spark、Storm应用打包部署和调试；
6、熟练使用Hadoop、Spark、Storm、Hive、HBase进行应用开发；
7、具备基本的Hadoop运行环境的运维管理经验；
8、有实际的大数据应用工程开发经验；
9、 能够接受根据项目要求进行异地出差；
10、熟悉金融领域相关知识或有金融系统开发经验的优先。
岗位职责：
1、 基于大数据平台的应用系统设计、开发、维护；
2、承担公司大数据相关项目的需求分析、开发、实施、现场支持。"
"职位描述：
        
        岗位描述：
1. 快速、高质量完成复杂模块业务的开发工作，制定开发计划并能够分析解决软件开发过程中的问题
2. 独立完成业务模块的开发，与团队高效协作
3. 负责bug修改等相关工作
4. 负责数据清洗、挖掘、整理，良好的数据敏感度，能从海量数据提炼核心结果
5. 跟踪并深入了解部分技术的发展方向，并转化为实际应用方案
6. 能够编写高质量的相关文档，不断完善团队知识库

任职要求：
1. JAVA基础扎实，2-3 年JAVA开发经验，精通主流的开源框架
2. 熟悉常见Java开源框架，如SpringBoot、Spring Cloud、Hibernate等架构
3. 熟悉前端开发，熟悉HTML5，CSS，Bootstrap，JavaScript，熟悉Vue框架
4. 熟悉MySQL等关系型数据库，有较强的sql编写能力，熟悉复杂查询及数据库调优，熟悉MySQL等常用数据库管理
5. 有图数据结构，和使用Neo4j经验者优先
6. 熟悉Docker构建、运维，熟悉Linux常用操作者优先
7. 熟悉数据可视化，熟练使用Echarts，AntV，Tableau等可视化工具者优先
8. 有成功案例、大型系统软件架构设计经验优先
9. 综合能力：技术功底扎实，编程习惯优良，对新技术敏感，具有问题分析与解决能力，具有沟通与协调能力，可独立承担相关任务
10. 了解最新的技术及发展趋向，重视个人成长

大数据团队整体产品技术导向，团队崇尚学习分享文化，在这里，你将会从资深行业前辈的分享中，得到快速的成长。我们期待同样年轻、优秀、热爱技术有自我追求的你来加入，希望和热爱技术的同道人一起共事和进步。"
"职位描述：
        
        岗位职责：
1.负责P2P网贷机构金融数据分析建模；
2.负责金融业务数据梳理；
3.负责与企业端金融数据分析联调；
4.负责与P2P网贷相关的其他数据的预处理和分析。
任职要求：
1.3年以上的大数据开发经验；
2.熟悉Java、Python等编程语言；
3.熟悉HDFS常见文件格式，能处理avro、parquet等文件格式的常见问题；
4.熟练使用Spark、Hive，熟悉组件的运行原理，能独立完成测试、联调等环境的搭建和优化；
5.熟悉Spark SQL，有使用Spark SQL进行数据预处理和离线分析的相关开发和优化经验；
6.熟悉使用Kafka、Flume、Hive、HBase组件，并能独立处理组件问题和调优，熟悉flume二次开发；
7.思路清楚，理解和沟通能力强；
8.有金融领域相关业务分析经验者优先。"
"职位描述：
        
        1、 负责大数据处理模块的架构设计和开发、性能调优；
2、 负责基于Spark技术的海量数据的处理、分析、统计、挖掘工作；
3、 负责基于Spark Streams技术完成流数据开发工作；
4 、负责大数据平台API对接；
5 、大数据平台开技术难点攻克；
任职资格：
1、 计算机、电子信息学科相关专业，大学以上学历，5年以上相关行业经验；
2、熟悉Hadoop/Spark生态系统组件的使用，至少有1年的Spark(Core/Streaming/SQL)开发经验；
3. 熟悉Scala/Java语言，对Scala/Java原理、底层技术有深入研究者优先；
4.对新技术有孜孜不倦的热情，具有良好的学习能力、团队协作能力和沟通能力；
5 有过海量数据系统开发经验者优先；6. 有HBase、Kafka等开发经验；
7. 有统计学数学知识，海量数据处理、数据分析和挖掘经验者优先。"
"职位描述：
        
        工作职责:1、负责公司级的通用数据平台和分析型产品建设，服务于货拉拉全公司各产品线； 2、为大数据的全生命周期提供服务，覆盖数据产生，传输，建模，统计分析，实验评估，可视化的全流程； 3、构建设计良好的数据流、数据仓库、调度系统、查询引擎，数据服务、分析系统、流程规范，数据工具/产品，降低数据的使用门槛，保证系统稳定高效运行，以实现数据的最大价值。 任职资格:1、 3年以上大数据平台工作经验，熟练掌握至少一种编程语言；2、熟悉多项大数据处理/分析相关的工具/框架，如Hadoop,、MR、Hive、Storm、Spark、Kylin、Kafka、HBase等；3、对新技术有强烈的学习热情，有快速 trouble-shooting能力； 4、有OLAP大数据平台开发经验者优先。"
"职位描述：
        
        工作职责:1、负责公司大数据分析平台的搭建，处理海量数据；2、负责数据模型的制定和实现；3、负责数据清洗和过滤、特征抽取、参数选择、算法实验、效果分析；4、负责数据的实时计算、检索、查询、处理。任职资格:1、本科及以上学历，计算机、数学、人工智能等专业；2、2年以上互联网行业数据分析经验，有扎实的数据结构及算法功底；3、有丰富的算法应用和开发经验，能熟练搭建大数据分析平台；4、熟练使用Java、Python等至少一种编程语言，具有一定的工程开发能力；5、有机器学习和深度学习框架使用经验，有数据挖掘平台开发经验者优先；6、熟悉数据仓库的ETL流程和数据建模，有开源数据分析工具使用经验者优先；7、能够运用Hadoop、 Spark等大数据计算平台进行数据分析挖掘者优先；8、具有良好的沟通能力、学习能力、分析解决问题能力；9、具有高度的责任心和团队合作精神。"
"职位描述：
        
        工作职责:1. 负责公司大数据应用产品的数据开发工作，包括但不限于用户行为、用户画像、智能客服、实时流平台、监控系统等；2. 离线和实时处理海量数据，包括数据上报、数据清洗、数据分析统计、数据校验、数据挖掘、机器学习等相关工作；3. 按项目进度要求完成分配的开发任务，开发过程和成果符合质量控制要求。任职资格:1. 计算机或相关专业本科及以上学历，3年以上（中级）/5年以上（高级）大数据开发经验； 2. 熟悉Java/scala语言及常用类库，熟练掌握常用开发工具；3. 熟悉Spark、Hive、HBase、Redis、Elasticsarch、Kafka等开源平台的应用和数据分析处理开发；4. 熟练使用HSql，并能够编写自定义udf，有一定的SQL编写和优化调优经验； 5. 熟练使用Linux系统，有Shell、Python等脚本编程经验； 6. 加分项：熟悉机器学习框架/工具（Spark MLLib，tensorflow，caffe等），了解原理并能应用于项目。"
"职位描述：
        
        岗位描述?
1. 负责贝贝大数据平台相关产品的设计和研发，包括数据同步、数据开发、调度中心、数据管理等。
2. 与数据架构、数仓、BI、算法等团队合作，构建准确、高效、安全的数据开放平台。
3. 具备较强的产品化和平台化能力，对大数据平台建设有较强认识。
岗位要求
1. 对Java 语言基础有良好的掌握，对面向对象软件开发有较深入的认识。
2. 有良好的编程习惯、熟悉代码规范、简洁清晰的代码风格。
3. 熟悉Linux操作系统，熟练使用Shell/Python一种脚本语言。
4. 精通Spring、MyBaits等主流Java开源框架。
5. 熟悉Mysql、Redis等常用数据库。
6. 熟练使用HTML,Css,JavaScript等前端基础技术以及相应的前端框架，如Jquery等。
7. 熟悉Hadoop生态相关技术，熟悉Hadoop、Hive、Hbase、Spark、Storm、Flink等一种或者多种数据处理技术，对相关技术平台化有深入思考者优先。
8. 有大数据平台开发经验、分布式数据存储或计算平台应用开发经验者优先。"
"职位描述：
        
        岗位描述?
1. 负责贝贝大数据平台相关产品的设计和研发，包括数据同步、数据开发、调度中心、数据管理等。
2. 与数据架构、数仓、BI、算法等团队合作，构建准确、高效、安全的数据开放平台。
3. 具备较强的产品化和平台化能力，对大数据平台建设有较强认识。
岗位要求
1. 对Java 语言基础有良好的掌握，对面向对象软件开发有较深入的认识。
2. 有良好的编程习惯、熟悉代码规范、简洁清晰的代码风格。
3. 熟悉Linux操作系统，熟练使用Shell/Python一种脚本语言。
4. 精通Spring、MyBaits等主流Java开源框架。
5. 熟悉Mysql、Redis等常用数据库。
6. 熟练使用HTML,Css,JavaScript等前端基础技术以及相应的前端框架，如Jquery等。
7. 熟悉Hadoop生态相关技术，熟悉Hadoop、Hive、Hbase、Spark、Storm、Flink等一种或者多种数据处理技术，对相关技术平台化有深入思考者优先。
8. 有大数据平台开发经验、分布式数据存储或计算平台应用开发经验者优先。"
"职位描述：
        
        岗位职责:
1. 负责贝贝大数据平台研发工作，支持公司的大数据业务发展
2. 综合考虑复杂度、资源使用率和具体业务场景，制定科学的技术方案
3. 负责大数据平台的建设，包括稳定性建设、性能优化、资源优化、运维优化等等
?
任职要求:
1. 必须精通JAVA或者SCALA语言中的一门，具有良好的代码功底，能够在架构上思考代码设计。参与开发过大型分布式系统的优先
2. 熟悉若干hadoop组件的原理，如HDFS、YARN、SPARK、HBASE、HIVE、STORM、KAFKA、KYLIN、DRUID等等。至少熟悉其中一个组件，修改过源码的优先
3. 有很强代码阅读能力，能够结合具体问题从代码中分析和解决的优先
4. 具有较强逻辑思维能力的优先
5. 有大规模生产集群经验的优先
6. 熟悉操作系统原理，如内存、cpu相关知识的优先
7. 熟悉运用bash，Python，awk，sed，grep等等工具的优先
8. 对挑战性工作充满激情的优先"
"职位描述：
        
        岗位描述
1. 负责企业级数据仓库架构设计、建模以及ETL开发，构建可扩展的数据仓库解决方案；
2.负责公司日常运营报表开发维护，和业务及分析部门沟通协作，提供多层面数据服务；
3.提供完善的数据保障体系，包括元数据管理、数据质量、数据安全等；
?
岗位要求
1. 计算机或相关专业本科及以上学历?
2. 具有丰富的数据开发经验，对数据处理、数据建模、数据分析等有深刻认识和实战经验
3. 熟悉SQL，有一定的SQL性能优化经验
4. 熟练掌握Java语言，MapReduce编程，脚本语言Shell/Python/Perl之一
5. 业务理解力强，对数据、新技术敏感，对云计算、大数据技术充满热情
6. 积极乐观、诚信、有责任心；具备强烈的进取心、求知欲及团队合作精神"
"职位描述：
        
        岗位描述1.负责企业级数据仓库架构设计、建模以及ETL开发，构建可扩展的数据仓库解决方案；2.负责公司日常运营报表开发维护，和业务及分析部门沟通协作，提供多层面数据服务；3.提供完善的数据保障体系，包括元数据管理、数据质量、数据安全等； 岗位要求1. 计算机或相关专业本科及以上学历 2. 具有丰富的数据开发经验，对数据处理、数据建模、数据分析等有深刻认识和实战经验3. 熟悉大数据体系的常用框架（hadoop，hive，spark，hbase等），具备大数据项目强实战经验。4. 熟悉SQL，有一定的SQL性能优化经验5. 熟练掌握Java或Scala语言，脚本语言Shell/Python/Perl之一6. 有Storm、Flink等实时开发经验者优先7. 业务理解力强，对数据、新技术敏感，对云计算、大数据技术充满热情8. 积极乐观、诚信、有责任心；具备强烈的进取心、求知欲及团队合作精神"
"职位描述：
        
        工作职责：
1. 负责大数据平台的搭建、问题解决和调优；
2. 负责项目中和公司已有系统及外部系统的数据对接和 ETL 工作；
3. 负责大数据平台上的模型构建和数据挖掘算法的实现；
4. 负责其他和大数据平台相关的项目的设计和实现；
5. 维护大数据平台的稳定和可靠。


职位要求：
1. 全日制本科及以上学历，计算机相关专业，硕士学历优先考虑；
2. 5 年以上开发经验，至少3年基于 Hadoop 的大数据平台开发经验；
3. 具备基于 Hadoop 大数据处理和分析的多项技术应用技能，包括但不限于 HDFS，MapReduce，Hive，Mongo，Spark，Hbase 等；
4. 了解 OLTP/OLAP 数据库的相关新技术，如：Greenplum，Kudu，TiDB 等；
5. 熟悉 ETL 相关开发工具和技术，精通 Spark，Kafka，Storm 等技术；
6. 了解主流关系型数据库，精通 SQL；
7. 具有很强的学习能力，分析能力和沟通能力。"
"职位描述：
        
        
1、参与理房通大数据基础架构和技术体系的规划建设；
2、负责平台数据的抽取、清洗、转换、加工。
3、参与报表开发。
?
任职要求：
1、本科以上学历，4年以上工作经验；
2、精通sql、python等开发，熟悉mysql、oracle、MongoDB、hive等数据库；
3、熟悉大数据处理相关技术，包括但不限于FLume、kafka、Redis等；
4、有数据仓库/大数据平台/ETL中一项或多项项目开发经验，有TIDB经验优先;
5、有支付项目经验加分；"
"职位描述：
        
        工作职责:1. 带领大数据团队，包括数据建设、数据质量治理、数据应用和数据产品；2. 设计并优化贝壳大数据架构，包括数据建设流、数仓模型、数据集市架构；3. 构建数据质量保障体系，包括全流程监控、预警和数据快速恢复、数据质量评估4. 完善数据应用体系，包括数据产品构建、数据分析需求响应、数据集市5. 数据工程架构迭代，包括实时流、权限管理、调度、应用输出等任职资格:1、5年以上大数据平台开发、搭建相关经验2、具有前沿的大数据技术实践经验3、很强的项目驱动和团队管理能力4、统招本科以上学历"
"职位描述：
        
        工作职责:1. ?负责公司大数据平台底层技术架构的规划、设计、实施和优化。2. ? ?负责公司大数据平台资源调度系统的规划、设计、实施和优化。3.负责结合软硬件持续对公司大数据平台基础架构层进行优化和整合。任职资格:1. ? 具有扎实的大数据和分布式系统的理论知识，对大数据基础组件有深入的研究。2. ? ?熟悉 Java、C/C++语言，熟悉 Linux 操作系统。3. ? 参与过大型分布式系统架构设计和实施，有具体的实践经验。4. ? ?参与过大型调度系统的研发，并在线上实际运行并取得较好的效果。5. ? 基于Hadoop的大数据体系有深入认识，具备相关产品（Hadoop、Hive、HBase、Spark、Storm、 Flume、Kafka、ES、flink等）项目应用研发经验6.具有良好的问题分析和追踪能力，具有正确的团队合作意识和良好的沟通能力。7. 3年工作经验以上，硕士学历者优先"
"职位描述：
        
        
工作职责:1、负责离线/实时 大数据平台的开发和维护工作；2、通过设计运用合适的技术方案来支撑各种业务场景：信用，风控，推荐，商业化等；任职资格：1.本科及以上学历，一年以上相关工作经验；2.熟练掌握Linux操作系统，精通Scala/Java/Python语言的一种或多种；3.熟悉主流大数据工具Hadoop、spark、Storm、ELK中两个及以上,并熟悉所使用工具的技术原理、主要特点；4.熟练使用flume、Kafka、hbase、redis、mysql等常用工具；5.有SparkStreaming的实时统计或实时推荐整体架构开发经验优先、有sparkML开发经验优先；6.有OLAP大数据平台开发经验者优先。"
"职位描述：
        
        工作职责:- 负责贝壳找房平台大数据平台架构的规划、设计与实施- 参与建设、维护、优化基于实时技术的数据平台，为业务提供易用的数据工具和平台。- 关注开源技术动态。- 通过大数据平台和工具，支撑海量数据分析、数据挖掘、机器学习工作，提升贝壳找房平台线上产品效果与线下运营效率任职资格:- 丰富的Java研发经验，精通Java，熟悉Python中的一种- 熟悉Mysql，熟悉网络编程及并发技术，熟悉安全解决方案- 有丰富后端服务系统的设计和实现经验，有独立的系统级设计能力- 扎实的计算机基础，熟悉常用的数据结构和算法，熟悉Linux系统环境- 熟悉大数据技术栈，对Hadoop、Hive、Spark、Hbase、Kafka、ELK等开源组件有使用及优化经验者优先- 有互联网公司中大型分布式系统经验优先- 负责过项目、有业务思维产品思维优先。 - 简单、真诚、负责、主动"
"职位描述：
        
        工作职责：1. 负责与集团平台的基础架构团队、基础数据平台协同，实现全局数据规划建设和数据治理；2. 负责基于业务场景的数据流和数据仓库系统的开发，构建业务迭代及运营营销的数据基础；3. 负责大规模数据处理系统的开发，数据特征平台的建设，构建核心策略产品；4. 负责业务相关的数据分析产品的系统规划、设计、建设。

任职资格：1. 统招本科及以上学历，计算机或数学相关专业毕业，有扎实的数据结构和算法基础；2. 编程基础扎实，熟练使用至少一种常用的编程语言，包括但不限于C++、Python、Scala、Go、Java；3. 熟练掌握海量数据处理技术，有使用Hadoop/Hive/Kafka/Spark 分析海量数据的能力和经验；4. 有学习热情，关注业界前沿技术和人工智能国际会议研究动态，不断提升自己在机器学习、运筹优化、机制设计、数理统计等方向的能力。"
"职位描述：
        
        工作职责:1、负责离线/实时 大数据平台的开发和维护工作；2、通过设计运用合适的技术方案来支撑各种业务场景：信用，风控，推荐，商业化等。任职资格:1.本科及以上学历，一年以上相关工作经验；2.熟练掌握Linux操作系统，精通Scala/Java/Python语言的一种或多种；3.熟悉主流大数据工具Hadoop、spark、Storm、ELK中两个及以上,并熟悉所使用工具的技术原理、主要特点；4.熟练使用flume、Kafka、hbase、redis、mysql等常用工具；5.有SparkStreaming的实时统计或实时推荐整体架构开发经验优先、有sparkML开发经验优先；6.有OLAP大数据平台开发经验者优先。"
"职位描述：
        
        工作职责:1、负责离线/实时 大数据平台的开发和维护工作；2、通过设计运用合适的技术方案来支撑各种业务场景：信用，风控，推荐，商业化等；任职资格:1.本科及以上学历，一年以上相关工作经验；2.熟练掌握Linux操作系统，精通Scala/Java/Python语言的一种或多种；3.熟悉主流大数据工具Hadoop、spark、Storm、ELK中两个及以上,并熟悉所使用工具的技术原理、主要特点；4.熟练使用flume、Kafka、hbase、redis、mysql等常用工具；5.有SparkStreaming的实时统计或实时推荐整体架构开发经验优先、有sparkML开发经验优先；6.有OLAP大数据平台开发经验者优先；"
"职位描述：
        
        岗位职责：
1. 负责公司数据仓库（关系型数据库）和数据集市的设计、开发和优化；
2. 负责监督数据的收集、ETL、特征抽取等工作；
3. 负责数据质量的可视化监控；
4. 负责公司数据安全；

岗位要求：（3和4必须掌握）
1至少3年及以上相关的工作经验；
2本科以上，计算机相关专业；
3掌握Shell/Python等一门脚本语言，熟悉Linux环境，扎实计算机系统知识
4精通SQL，能写出高性能的SQL代码；
5了解HDFS, 熟悉HIVE, HBASE等相关组件；
6熟悉数据分析的流程，有地图数据处理经验者优先考虑，有丰富PostgreSQL者优先考虑；"
"职位描述：
        
        岗位职责：
1. 负责豆果网数据统计系统的开发。
2. 负责公司各部门对电商&网站相关数据的统计。
任职要求：
1. 有数据展示系统及服务器端系统开发经验者优先。
2. 熟悉常用设计模式，对代码的美观和优化有想法和追求。
3. Java功底扎实，熟悉JavaEE架构，练掌握Struts，Hibernate，Spring等常用开发框架。
4. 熟悉Linux操作系统及常用Shell命令。
5. 熟练掌握SQL,有使用过Mysql等数据库的经验，懂得常用的SQL语句优化方法者优先。
6. 熟悉hadoop、hive、sqoop等开源系统。
综合素质：
1. 具有开放的心态，具备快速接受新技术和新知识的能力，对前沿技术有浓厚的兴趣。
2. 具有较强的独立工作能力、工作积极主动和富有团队协作精神。
3. 具有优秀的自我管理、自我学习能力、富有创造力。"
"职位描述：
        
        岗位职责：
1、负责公司广告、菜谱等业务个性化推荐系统的研发；
2、分析APP用户行为数据，设计合理的推荐算法模型及策略，并优化推荐排序；
3、通过用户行为数据的挖掘，能对用户进行建模并精确刻画用户各种属性。?
任职要求：
1. 熟练掌握各类个性化推荐算法，并有开发个性化推荐系统的实际项目经验；熟练掌握各类回归及排序算法，能够利用相关算法进行推荐排序的优化；
2. 熟练掌握分类、聚类、回归、降维等经典机器学习算法和技术，能够根据实际问题选择合适的模型和算法并进行相应的开发；
3. 熟悉Linux操作系统及常用Shell命令；有较强的工程架构和开发能力，能够实现支撑千万级用户和TB级用户行为数据的推荐系统或算法；
4.熟悉SparkStreaming和SparkSQL，有Spark平台&hadoop平台开发经验；
5. 精通Scala语言，对Scala原理底层技术有深入研究者优先；
6. 熟悉hadoop、hive、Hbase等开源系统；熟悉各类数据挖掘工具（如weka、Mahout），能够快速建立模型并进行验证；
7. 能快速理解业务场景，从具体问题中抽象出通用的解决方案；
8. 对数据敏感，善于发现数据中的潜在规律，善于分析问题，了解业界的最新动态；
9.有一线互联网公司推荐系统开发经验者优先；"
"职位描述：
        
        岗位职责：
1.负责大数据产品技术方向授课，教材开发，项目支持等工作
2.熟悉云计算，大数据架构
要求：
1.本科及以上学历，通信，计算机相关专业优先
2.熟悉java ?python等程序设计语言
3.有软件开发经验者优先
4.具备较好的英语读写能力
5.有大数据，云计算相关证书者优先"
"职位描述：
        
        1、负责ETL开发及性能调优工作；
2、负责数据仓库建设和系统维护；
3、负责ETL调度中心开发；
4、参与数据仓库系统与应用系统的接口设计工作，处理海量数据；
5、负责数据实施过程中的数据库数据管理、数据提取等工作。
任职要求
1、熟悉ETL工具：Kettle，3年以上ETL工作经验；
2、熟悉主流数据库技术如：Sqlserver,MySql,Oralce等，熟悉Vertica更佳；
3、熟悉Hadoop大数据平台：mapreduce,Hive,HBase,Spark,Impala等，有项目开发经验；
4、熟悉linux系统的基本命令；
5、熟悉python开发语言基础"
"职位描述：
        
        岗位职责：
1、负责大数据平台搭建、功能设计、及核心模块的开发；
2、对现有大数据架构进行分析，给出优化方案并带领技术人员共同完成实施，参与公司内外部大数据项目需求分析及数据建模、方案评估;
3、负责大数据平台运维、优化、改造，现有产品的部署实施和二次开发工作；
4、软件开发过程中，依据项目要求和相关规范，完成系统的详细设计和相应文档的编写。

职位要求：
1、本科及以上学历，计算机相关专业；拥有3年以上Java开发经验，有DEVOPS开发经验者优先；
2、精通Java程序开发，尤其是线程、网络、I/O方面的开发。
3、熟练使用Oracle/Postgresql/GreenPlum/Mysql等关系型数据库。
4、熟练使用HDFS/Hive/Spark/HBase，清楚基本交互原理。
5、了解数据挖掘和机器学习算法，包括聚类、分类、回归等。
6、有大规模分布式系统开发/故障处理能力/大型互联网大数据平台架构设计经验者优先
7、熟悉Linux环境，能够熟练使用Linux基础命令。
8、要求能够适应短期出差的工作性质。"
"职位描述：
        
        岗位职责：
1、负责各业务模块的需求分析、沟通，数据产品设计，模型设计；
2、负责数据仓库各模块的数据探查，模型设计，存储过程开发,并交付生产，确保输出成果；
3、根据公司技术文档规范编写相应的技术文档；
4、负责数据库相关的增值服务项目实施工作，如SQL优化、历史数据分离、数据提取等。

任职要求：
1、本科及以上学历，计算机或数学相关专业毕业，2年以上相关工作经验；
2、熟练掌握数据库开发知识，SQL语言，精通Oracle或Mysql数据库开发；
3、熟悉ETL开发过程，掌握业务建模方法；?
4、能按照规范的开发流程完成编码，具有规范的开发文档编写能力；
5、有良好的业务学习和理解能力，能够独立完成项目设计开发任务；
6、接受一定出差（佛山）。"
"职位描述：
        
        岗位职责：
1. 负责部门数据仓库的维护、开发、优化；
2. 负责数据采集、分析、加工、清洗、输出过程的开发；
3. 负责数据处理流程的设计、优化、改造；?
4. 向产品团队、业务团队以及其他业务人员提供数据抽取相关技术支持。
5. 参与数据治理平台建设、协助数据标准和数据质量优化落地。

任职资格：
1. 全日制本科及以上学历，计算机、金融等相关专业；2年以上证券或相关金融项目经验；?
2. 2年以上数据仓库开发、ETL开发工作经验；精通MySQL、Oracle等数据库开发；?
3. 掌握主流的大数据技术，包括离线数据处理、流式处理技术和NoSQL技术；
4. 精通shell、pyhton脚本开发，有数据治理、数据测试经验者优先；
5. 有优良的Trouble Shooting能力；?
6. 有基于阿里云大数据平台开发经验者优先；
7. 具有金融行业数据仓库开发经验或具有征信、用户行为分析模型经验优先；
8. 工作踏实勤勉，主动积极，有较好的团队协作和沟通能力。"
"职位描述：
        
        工作职责: 1.负责数据采集与爬取、解析处理、入库及备份等数据日常工作； 2.参与实现分布式爬虫模块服务架构和数据存储架构的设计和研发；? 3.参与编写互联网内容的爬虫，制定反爬虫策略；?  任职要求：? 1.计算机相关专业本科以上学历； 2.熟悉常用网络协议，熟悉http代理、模拟登录，动态数据获取等，有扎实的数据结构基础和编码能力,熟悉爬虫、种子、去重、提取、过滤、分发、DNS?cache、异步处理等概念和过程； 3.熟练使用SQL/HQL,熟悉MongoDB、Mysql等主流数据库，有NoSql实际使用经验者优先；? 4.熟悉html和javascript，熟悉linux开发环境，有一定的开发经验，精通网页抓取原理及技术、正则表达式、xpath等；? 5.熟练使用Linux/Unix操作系统，熟悉常用的Shell/Python/Perl工具，熟悉常用linux命令，会在linux下安装部署各类环境需要的软件，会利用shell编写和开发自动化安装部署脚本；? 6.良好的沟通能力和团队精神，具备逻辑思维能力强，态度认真积极，责任心强，具备快速学习能力。"
"职位描述：
        
        1、负责数据仓库的功能模块开发，包括需求分析，系统设计和编码实现；
2、负责应用环境的搭建，部署和运行环境的监控工作；
3、重构现有系统，不断完善系统健壮性，代码质量和用户体验；
4、解决项目中存在的性能瓶颈及隐患漏洞。
?
任职要求：
1、熟悉主流关系型数据库 MySQL 或 PostgreSQL，及 Hbase 数据库原理理论架构；
2、熟悉数据仓库理论架构，包括但不限于数据调度、ETL、元数据管理、数据监控；
3、结合实际业务优化 SQL 及数据处理流程；
4、熟练掌握 Shell 及 Python 或 Java 程序开发语言；
5、熟悉大数据处理平台 Hadoop、Hive、MR，熟悉 Storm/Spark/Flink 其中一 种 Stream 处理技术；
6、了解缓存、队列等技术，熟悉 Redis、Kafka、RabbitMQ 等消息中间件。"
"职位描述：
        
        岗位职责：
1、负责系统设计和核心代码的编写；
2、负责协助项目经理完成技术评审和代码评审；
3、负责完成单元、联调等测试问题的修复；
4、负责协助测试人员和用户完成测试，并根据测试反馈进行问题修复；
5、完成项目经理交代的其它任务。

岗位要求：
1. 计算机及相关专业本科以上学历；
2. 至少3年以上Java开发经验，其中有1至2年大数据开发经验；
3. 熟悉大数据相关组件如：Hadoop/Spark/Hive/Kafka/Storm等；
4. 熟悉Linux操作系统；
5. 掌握常用的设计模式和架构模式，能够熟练使用建模工具进行系y设计；
6. 能够完成核心产品代码的研发工作，解决项目中关键问题和技术问题；
7. 工作责任心强，具备良好的团队合作精神，良好的沟通及协作能力。
8. 熟悉软件开发流程和配置库的使用，拥有良好的代码规范意识和文档编写能力"
"职位描述：
        
        岗位职责：
?-?参与大数据平台基础架构建设，优化和升级，负责关键问题的技术攻关和技术选型，制定解决方案
任职资格：
?1、具备系统级详细设计能力，亲身参与过相关平台的建设，并能输出规范的设计文档；
?2、精通Golang，有丰富的Golang实际项目开发经验；
?3、至少研究过一种Golang开源框架源码并理解其设计思路；
?4、精通关系型数据库MySQL或PostgreSQL，常用SQL优化方法，表优化；
?5、熟悉RPC、缓存、MQ等概念及相关技术；
6、了解非关系型nosql数据库，HDFS、HBase、Elasticsearch；
?7、熟练使用Linux操作系统；
?8、有良好的编程习惯和算法基础；
?9、精通算法与数据结构
?10、工作认真责任心强，善于沟通，具备良好的沟通和团队协作能力；
?11、熟练使用Python者优先。"
"职位描述：
        
        职位描述：1、以用户产生的海量行为日志为基础，进行个性化推荐；2、熟练掌握推荐算法模型，了解算法的核心内容，负责智能推荐相关算法的设计和优化；3、对推荐效果进行跟踪，对推荐策略持续优化。
职位资格1、3年以上工作经验，本科及本科以上学历；2、熟悉java后台程序设计，有实际系统的问题排查与调优经验；3、掌握hadoop、hbase、kafka、spark等分布式数据存储和分布式计算平台原理，具有相关系统的调优、 运维、开发经验；4、熟悉linux开发环境，熟悉python、shell、perl中的一种；5、对数据结构、算法有深刻理解，有hadoop等系统的源代码阅读经验者优先。"
"职位描述：
        
        岗位职责：
1.针对网站及多个APP的业务数据、用户数据、日志行为数据等构建数据中间层，为数据分析、数据挖掘、推荐等数据应用场景提供良好的基础数据 ；
2.深度挖掘数据价值，构建演出行为用户画像，挖掘用户流失行为、粘性用户行为，为业务、产品决策提供数据依据；
3.负责建立标准及推进日常数据报表和可视化需求的开发；
4.负责建立和优化推荐等多种算法模型应用到业务中创造价值；

岗位要求：
1.2年以上ETL、数据仓库开发经验；
2.较强的java或python编程能力；
3.熟悉Hadoop生态系统，有Hadoop，HBase，Hive，Strom，Spark等大规模数据日志处理技术经验；
4.熟悉常用数据结构，对特征选择，机器学习（Logstic聚类时间序列分类树SVM神经网络等）或推荐算法（Collaborative FilteringSVD等）有工程经验；
5.有个性化推荐，数据仓库等数据平台相关经验优先；
6.练掌握hadoop，storm，sparkFlink等分布式系统的开发和实施；
7.自驱力强，有良好的数据分析能力和逻辑思维能力，沟通协作能力强。

【加入我们】

我们提供竞争力的薪酬标准、年底双薪，贴心照顾你的钱包；

我们提供六险一金，福利齐全 ，让你工作后顾无忧；

我们提供周末双休、各类带薪假期，劳逸结合嗨翻天；

我们提供上班专车接送，零食饮料咖啡天天有；

我们提供贴心的加班餐补及车补,专业设备健身房，让你远离亚健康；

我们提供年度旅游，各种团建活动，work hard，play hard；

我们还提供生日礼品、婚育礼金、慰问礼金、传统节日礼品及健康体检等。"
"职位描述：
        
        岗位职责：
1.构建数据仓库，设计数据结构存储海量的产品数据，同时用技术手段解决灵活的，多层级的数据查询需求；
2.构建和优化数据处理流程，支撑处理海量数据规模；
3.利用机器学习技术，为业务部门建立数据分析和预测模型；
4.支持产品，运营、销售对业务上相关的数据需求，提供数据驱动和决策。

任职要求：
1.2年以上大数据处理、数据挖掘等领域开发经验，计算机相关专业本科及以上学历；?
2.熟悉MapReduce, Hadoop, Pig, Spark等分布式相关的技术及组件；?
3.极强的编程能力，熟练掌握Python，具备迅速处理复杂的数据和实现复杂算法的能力；
4.有机器学习相关方面的研发经验；?
5.熟练使用Linux或者类似POSIX系统；
6.很强的自我驱动力、结果导向并极具责任感，有良好沟通能力和团队协作精神。?

锦上添花：
1.数据可视化相关的技术；
2.有很强的数据结构和算法知识；?
3.熟悉Hadoop生态圈的各开源系统。"
"职位描述：
        
        岗位职责：
1、负责ROI模型建立和优化；
2、构建数据仓库，服务于用户画像、推荐等系统。
3、支持运营、产品对业务上相关的需求，提供数据驱动和决策的能力。
4、对用户数据进行高效的ETL，通过数据挖掘构建用户画像。
5、核心类数据的可视化展示。
6、客户端数据收集的相关工作。
?岗位要求：
1、?统计、计算机或相关专业的学士学位。
2、2年以上的大数据处理、数据挖掘等相关领域的科研/开发经验。
3、 熟练使用Linux或者类似POSIX系统。
4、熟悉MapReduce, Hadoop, Pig, Spark, HBase, Hive等分布式相关的技术及组件。
5、极强的编程能力：熟练掌握Python（Java或者Scala），具备迅速处理复杂的数据和实现复杂的算法的能力。
6、很强的自我驱动力、结果导向并极具责任感。
7、有激情、毅力，正能量。
8、有良好沟通能力和团队协作精神。"
"职位描述：
        
        岗位职责：
1、负责数据分析系统的设计和开发；
2、支持业务数据报告需求；
3、针对具体业务数据进行数据的离线计算或实时计算。
任职资格：
1、985、211本科以上学历计算机相关专业或知名互联网公司背景；三年以上大数据研发工作经验；
2、熟练掌握java基础知识，对数据结构和算法有深入的理解；
3、优秀的分析能力和数据敏感度，良好的解决问题能力；
4、熟练使用Shell/Python等脚本语言和工具；
5、有DMP数据平台开发经验，熟练使用mapreduce、hive、Hbase，spark进行离线和实时数据处理；
6、热爱技术，自我驱动，主动思考，忠于研究和使用新技术。"
"职位描述：
        
        岗位职责：
1、负责大数据流式数据处理的开发
2、负责大数据插件开发
3、负责基于大数据技术的监控调度系统开发
4、负责大数据平台基础设施建设
5、针对新人、普通开发人员进行有效辅导，帮助其快速成长
要求：
1、具备良好的java基础，并对java?web的各种开源框架如Spring、Spring?Boot等有深入的应用和优化经验
2、熟悉缓存、消息队列等至少一种技术原理及内部机制；
3、至少熟悉一种关系型数据库如Oracle、Mysql等，熟悉hbase/hive/hadoop/flink/hbase等大数据处理系统，熟悉其运行机制和体系结构
4、熟悉数据仓库领域知识和相关技能
5、有足够的代码质量意识，时间管理意识，团队协作意识
6、有Pentaho插件开发经验及大数据相关分布式系统（如Druid、Kylin、HBase、Spark等）的应用及定制优化经验优先"
"职位描述：
        
        职位描述：
1.参与客户需求调研，熟悉业务逻辑及数据源表结构等；
2.对源数据全量或增量进行抽取、清洗、转换、加载；
3.配置环境及安装数据库，搭建目标数据仓库，进行维度建模；
4.按照数据分析模型或可视化需求，编写存储过程对数据进行加工汇总等?
职位要求：
1.熟练使用hive数据仓库，熟悉数据仓库建模；
2.熟练使用spark进行开发，会python者优先；
3.熟练使用sqoop、Kettle等etl工具；
4.熟悉至少一种常见数据库及存储过程开发，会postgresql者优先；
5.熟悉异构数据库间的增量获取方式和数据同步方式；
6.熟悉linux系统者优先；具备良好的沟通能力，做事认真、仔细，具有团队协作能力；"
"职位描述：
        
        岗位职责：1、负责大数据基础平台、数据分析系统的建设与维护工作；2、协调配合数据分析工作，保障数据挖掘建模和工程化；3、大数据的ETL工作；4、大数据分析平台的开发、维护和优化；5、跨部门/团队协作，协同分析并解决各类大数据平台相关的运行或数据问题。
职位要求：1、计算机、数学相关专业本科以上学历；1年以上大数据相关经验；2、熟练SQL开发，至少掌握一种大数据存储相关数据库，如：MongoDB、Cassandra、hbase；3、有大数据分布式计算平台开发经验，熟悉Hadoop,?Spark，MapReduce，Hive等原理及应用；4、熟悉linux系统基本操作，能编写shell或python脚本；5、有数据仓库搭建项目经验者优先考虑；6、有开发过基于binlog和Spark/Storm的实时数据类项目者优先考虑；7、掌握Java/Scala/Python其中一种优先考虑；8、了解elasticsearch全文检索引擎的优先考虑；9、工作认真、负责、仔细，有良好的团队合作精神，良好的分析能力、沟通技巧。"
"职位描述：
        
        职位描述：
1.负责大数据平台软件需求分析、设计；
2.参与产品需求讨论、应用产品系统架构的设计、开发；
3.负责编写相应的需求、设计与技术文档；
4.参与线上系统环境的升级、运维监控、性能调优,向系统使用者提供技术支持服务。
?
任职资格：
1.本科及以上学历，3年以上大数据相关设计或研发经验；
2.熟悉分布式系统的架构，有分布式系统架构设计、大数据架构设计的经验，至少1个以上大型成熟项目的经验；
3.精通 Java、HFDS、MapReduce，并有相关的开发及优化经验；
4. 熟悉Spring、Spring Batch，Solr全文检索与推荐引擎开发；
5.熟悉MySql、SqlServer等数据库系统，有数据库编程经验、熟悉数据仓库的ETL的开发,有海量数据处理相关经验；
6.熟悉Hadoop、HBase、Hive、Spark、Storm等软件，至少精读过一个源码；
7.有电商大数据开发经验；
8.强烈的责任心，良好的沟通协调能力,较强的学习能力。"
"职位描述：
        
        IntroductionFor our Corporate Technology (CT) in Beijing, Siemens is looking for a ?Senior Industrial big data application Engineer at the earliest opportunity.What are my responsibilities?
Work with the architecture team and the requirements team to develop a product architecture and write detailed design documentation;
Build and implement relevant data analysis applications based on design documentation and technical architecture, design application architecture ?and setup distributed platform;
Technical research: to participate in project technology research, help to solve the technical problems;
Build and stabilize key modules of platforms with high quality;
What do I need to qualify for this job?
MS in Computer Science or a related field;
5+ years software development experience;
Familiar with Java related technologies;
Experienced in development framework of Spring/Springboot, AngularJS2, jQuery, etc.;
Experienced in JavaScript / HTML5 / CSS;
Experienced in dealing with massive amounts of data, such as above 10 million;
Experienced in Linux;
Fluent English speaking, reading and writing skills;
Priority condition
familiar with time-series database, Redis, MongoDB and other non-relational database, memory database;
Familiar with large distributed systems and typical large data application framework, Hadoop, Spark, Kafka, etc.; familiar with DFS, MapReduce and other large data processing technology;
Familiar with Storm, Hive;"
"职位描述：
        
        IntroductionFor our Corporate Technology (CT) in Beijing, Siemens is looking for a ?Senior Industrial big data application Engineer at the earliest opportunity.What are my responsibilities?
Work with the architecture team and the requirements team to develop a product architecture and write detailed design documentation;
Build and implement relevant data analysis applications based on design documentation and technical architecture, design application architecture ?and setup distributed platform;
Technical research: to participate in project technology research, help to solve the technical problems;
Build and stabilize key modules of platforms with high quality;
What do I need to qualify for this job?
MS in Computer Science or a related field;
5+ years software development experience;
Familiar with Java related technologies;
Experienced in development framework of Spring/Springboot, AngularJS2, jQuery, etc.;
Experienced in JavaScript / HTML5 / CSS;
Experienced in dealing with massive amounts of data, such as above 10 million;
Experienced in Linux;
Fluent English speaking, reading and writing skills;
Priority condition
familiar with time-series database, Redis, MongoDB and other non-relational database, memory database;
Familiar with large distributed systems and typical large data application framework, Hadoop, Spark, Kafka, etc.; familiar with DFS, MapReduce and other large data processing technology;
Familiar with Storm, Hive;"
"职位描述：
        
        岗位描述：
1.???? 参与数据产品的微服务和组件化设计和实现。
2.???? 编写产品相应模块的设计文档
3.???? 能够独立完成产品相应模块的设计、开发、单元测试；
4.???? 参与软件开发过程中的技术攻关，能够指导其它项目成员的开发工作。
5.??? 高质量完成编码工作，确保代码和组件的质量，具有高可维护性、可拓展及健壮性。
6.???? 参与数据仓库建设和规划，数仓模型设计和实现, 熟悉常用的指标分析方法、数据分析工具和平台，了解数据分析的基本方法和常见问题，能对项目开发工作提出建设性意见。
7.???? 参与数据产品、工具、平台规划和实现，基于传统数据仓库数据建模或 Hadoop体系架构的数据建模，构建可扩展的数据仓库，进行面向主题的数据集市的建设和规划，能支撑高速增长的业务；
8.???? 参与数据仓库ETL、存储过程、脚本等的开发，参与业务相关数据的指标计算和分析挖掘，参与数据仓库ETL流程的优化及ETL相关技术问题的解决；
9.???? 依据项目业务特点，进行数据存储、数据备份、数据迁移、数据归档设计，能够指导开发人员开发数据模型的访问服务及其API接口以供其它系统或组件调用；
10.? 参与数据质量问题的分析、跟进、解决，跟踪并分析公司相关数据产品，为产品创新、产品设计优化提供方案支持；
?
任职要求：
1.全日制本科及以上学历，计算机科学类或其他相关理工科专业，对数据仓库系统架构具有良好的认识； 2.精通Java语言（熟悉设计模式、多线程、网络通信、分布式编程技术），同时掌握python和scala语言者优先，熟悉Dubbo和Spring Cloud等常用技术框架; 3.有实际的数据仓库开发或数据建模经验，能根据项目要求构建数据存储、计算、分析模型，有解决大数据量的技术能力； 4.熟悉大数据生态系统组件，并有项目实战经验，如：Spark、MapReduce、HBase、Hive、ZooKeeper、YARN、HDFS等或流计算框架Spark Streaming、Storm等; 5.熟悉oracle关系数据库，熟悉Redis或MongoDB等至少一种NoSQL数据库; 6.熟悉Linux操作系统，对shell编程有一定了解; 7.有良好的数据分析意识和产品意识，能够从海量数据中发现有价值的规律; 8.具备良好沟通能力和团队合作精神，工作认真细致，责任心强，具有良好的编程基础及编程习惯; 9.积极主动,具备较强的分析解决问题的能力，以及优秀的逻辑思维能力，对有挑战的问题充满激情;"
"职位描述：
        
        岗位职责
1. 根据业务变化对数据进行采集、处理
2. 搭建和维护数据仓库，根据业务需求进行数据建模
3. 协助业务方，提供数据提取、报表等数据服务
4. 数据仓库的日常监控和运维

岗位要求
1. 精通至少一种关系型数据库，熟悉常见数据库性能优化和安全问题
2. 熟悉数据仓库建模理论
3. 能够熟练使用Python/Java进行复杂业务逻辑的数据处理
4. 具备web开发经验、前端开发经验者优先
5. 熟悉机器学习算法者优先
6. 有良好的沟通能力和业务理解能力
7. 持续学习者，不害怕没有接触过的技术和方法"
"职位描述：
        
        1) 基于工业数据分析业务需求，开展数据采集、存储、清洗、转化、建模分析、报表等数据处理和程序开发；
2) 熟悉机械过程信号处理方法和特征转换方法，如非平稳特征的特征提取，以及平稳特征的特征提取相关方法；
3) 对于小波变换、时域、频域转换等信号处理方法精通；
4) 对于电信号处理和模式识别精通，熟悉稳态和非稳态高频数据处理方式；
5) 基于业务需求，参与数据采集及相关指标梳理，表的搭建与连接，构建工业数据库及日常维护；
6) 熟悉数据分析十大建模模型，能够根据应用要求，组合完成新模型的迭代和开发；
7) 具备较强的探索性数据分析能力，能够基于业务理解，完成数据的可视化呈现、模型提炼、业务验证的全过程。

任职资格:
1) 硕士及以上学历，信号工程、应用数学、统计学、计算机、机械工程等相关专业；
2) 三年以上工作经验，博士及以上学历不限；
3) 掌握R/Python/C++/Matlab中至少1种开发语言；
4) 掌握SQL语句，会增删改查，熟悉MySQL/SQL Server/MongoDB/HBase等数据库, 有DBA经验优先；
5) 具有机器学习经验，并熟悉目前主流算法；
6) 能够承担一定的工作压力，有较好的自我驱动能力和责任感；
7) 具备优秀的逻辑思维能力、表达能力、沟通协调能力"
"职位描述：
        
        【工作职责】
1、负责产品需求分析、设计和文档编写
2、负责数据中心系统开发工作，例如BI系统、ETL系统
3、独立进行单元和功能测试，保证软件质量
4、协助架构师进行技术调研评估，试用新框架、新技术并撰写报告
?
【岗位要求】?
1、计算机、通信、电子、自动化等相关专业；
2、理论基础扎实，熟悉常用的数据结构及算法；
3、能够理解并实际运用面向对象思想解决实际问题
4、能熟练使用JAVA及JavaScript进行Web项目的开发，有Spring等框架使用经验的优先
5、对数据库有一定了解，熟悉ORALCE或者Mysql
6、大三以上，要求能够全职实习两个月以上"
"职位描述：
        
        数据工程师：
?
工作职责：
1、利用大数据相关组件实现海量的搜集和存储；
2、利用大数据相关组件实现数据清洗，转换等工作；
3、利用大数据相关组件实现数据可视化以及海量数据下的多维钻取分析；
4、整合大数据相关组件，构建数据沙盒，支撑多租户的数据分析；
5、组件性能调优；
?
任职资格：
1、3年以上相关工作经验，至少熟练掌握Java，Scala，Python中的一种或多种；
2、熟悉Spark，Flink，Mapreduce等分布式计算框架。
3、熟悉 Storm，SparkStreaming等流处理框架。
?4、熟悉MPP和搜索引擎，例如Impala，Presto，Elasticsearch等；
5、熟悉熟悉分布式存储系统，例如HDFS，Ceph等。
6、熟悉NoSQL存储，例如Hbase，MongoDB，CouchDB等；
7、了解PowerBI，Tableau等任一一款可视化工具优先考虑；
?8、有大数据相关组件性能调优经验或机器学习经验优先考虑；"
"职位描述：
        
        职位描述：
1.机器学习/数据挖掘等AI相关的算法研发；
2.负责位置、轨迹相关数据挖掘研究和开发；
3.AI相关算法的性能优化、工程环境部署；
4.参与搭建和实现分布式深度学习集群。
任职要求：
1.大数据/机器学习2两年工作经验；
2.熟练掌握机器学习相关的理论知识和实践技能；
3.熟悉CNN、RNN、LSTM等典型深度学习模型的使用场景和使用方法；
4.熟悉TensorFlow、Caffe、MXNet等主流深度学习框架中的一种或多种；
5.拥有扎实的数学和编程功力，有后台应用者优先。
6. 有关键点识别，活动识别经验者优先。"
"职位描述：
        
        岗位职责：1、设计和开发与云计算、云存储、分布式数据库、大数据挖掘相关的前后端软件；
2、云计算、云存储、分布式数据库、数据挖掘平台部署优化；3、承担大数据平台的研发，完成模块的开发、优化及验证工作（开发、测试、维护）；
4、指导和培训大数据运维、分析人员，提升大数据分析和处理技能，负责大数据核心技术的知识传递；5、负责基于数据分析平台的各种应用的开发、维护、推广培训工作；6、组织与业务部门的沟通讨论，确定分析课题及研究计划，牵头完成分析报告和分析模型，为业务发展提供决策支持。


任职要求：1、全日制本科，5年以上工作经验或者全日制硕士学历、2年以上工作经验；2、熟悉互联网、移动互联网相关业务，了解相应主流技术；3、熟悉开源软件，有开源项目经验者优先；4、熟练使用Python，并具备2年以上JavaEE开发经验，
5、有Hadoop，Spark，MapReduce，数据挖掘项经验者优先；6、熟悉Lucene、Solr、Elastic Search经验优先；7、熟悉MySQL、MongoDB、Redis，了解NoSQL相关技术；8、熟悉分布式文件系统和云存储技术，有Openstack、Hadoop、Spark等云计算和大数据相关经验优先；9、较好的英文技术文献阅读能力；"
"职位描述：
        
        开发人员?
1、Java开发经验3年及以上；
2、熟悉代码版本管理工具Git、持续集成Jenkins；
3、熟练掌握SpringMVC、MyBatis 等开源框架、深刻理解 SpringMVC 核心流程；
4、熟悉Tomcat、Apache、JBoss等服务器配置;?5、熟悉大数据平台各技术组件的开发和管理维护，包括HADOOP、HIVE、HBASE、ZOOKEEPER、FLUME、KAFKA、STORM、ES（Solr）等；
?
开发经理：
1.精通Java/J2EE；?2.熟悉Oracle/MySQL/Postgre/NoSQL数据库；?3.熟悉Linux开发环境；熟练掌握Python、Perl等脚本语言；?4.熟悉数据库调优方法，精通SQL，熟悉数据建模相关技术和工具。?5.熟悉大数据平台相关的Hbase、Hive以及Spark和Storm数据应用开发。?6.有开发经理相关经验，具备一定统筹能力、组织能力、执行力；"
"职位描述：
        
        岗位职责：
1、参与客户大数据项目的需求和设计讨论，解决客户的技术问题，编写相关技术文档
2、基于阿里云大数据平台，使用数据挖掘、数据分析、数学建模、算法等方法，开发/设计符合业务需求的数据处理功能；
3、维护客户的大数据项目，跟踪、定位/解决存在的问题或需求

岗位要求：
1、本科以上学历，3年以上数据开发工作经验
2、有丰富的维度模型设计经验，能够对复杂数据进行抽象和简化，有一定的产品思维和架构设计能力
3、较强的SQL语句编程能力，较强的数据开发编程能力
4、有过报表开发和使用经验，熟悉阿里巴巴数加产品、Tableau、帆软、永洪BI等报表开发
5、熟练Perl、Python、Linux Script脚本，有Java语言开发者优先
6、很强的学习能力及抗压能力
7、有阿里云大数据相关技术认证者优先
8、该岗位需要出差"
"职位描述：
        
        1、负责云日志产品系统架构设计，解决项目中的技术难点；
2、指导技术团队架构的实现，负责系统框架和核心代码的实现；
3、负责公司整体技术架构的规划，对开发团队进行技术指导和培训；

岗位要求

1、五年以上技术研发工作经验，1年以上架构规划经验。
2、精通Java和其他语言中的一种或多种。
3、熟悉分布式系统的设计和应用，熟悉分布式缓存、消息中间件等核心技术。
4、熟悉elk、kafka、flink等大数据系统经验者优先。
5、强的工作责任心和良好的沟通协调能力，能在压力下独立解决问题，有钻研精神，对云计算、大数据技术充满热情，有团队合作精神。
6、可以接受出差。"
"职位描述：
        
        岗位职责：
1、参与客户大数据项目的需求和设计讨论，解决客户的技术问题，编写相关技术文档
2、基于阿里云大数据平台，使用数据挖掘、数据分析、数学建模、算法等方法，开发/设计符合业务需求的数据处理功能；
3、维护客户的大数据项目，跟踪、定位/解决存在的问题或需求

岗位要求：
1、本科以上学历，3年以上数据开发工作经验
2、有丰富的维度模型设计经验，能够对复杂数据进行抽象和简化，有一定的产品思维和架构设计能力
3、较强的SQL语句编程能力，较强的数据开发编程能力
4、有过报表开发和使用经验，熟悉阿里巴巴数加产品、Tableau、帆软、永洪BI等报表开发
5、熟练Perl、Python、Linux Script脚本，有Java语言开发者优先
6、很强的学习能力及抗压能力
7、有阿里云大数据相关技术认证者优先
8、该岗位需要出差"
"职位描述：
        
        工作职责
1、负责制定数据仓库和数据分析平台的整体技术框架方案并根据业务扩展持续更新； 2、负责攻克技术难关，保证大数据系统的稳定运行； 3、负责数据模型离线系统数据ETL，建立数据抽取，清洗，校验，机器学习训练等数据加工流程； 4、负责协助业务完成部分数据分析工作。
任职资格
1、至少掌握python/java/c++等一种语言； 2、掌握大数据海量数据处理技术，有Hadoop/mr/Hive/HBase/Spark/等相关经验者； 3、深入理解map-reduce等计算逻辑原理与优化方法； 4、性格积极乐观，有良好的沟通能力，抗压能力，有强烈的学习/技术研究能力和良好的团队精神； 5、有大数据架构经验者优先，有图计算和图数据库相关经验者优先。"
"职位描述：
        
        岗位职责：??
1.负责数据平台建设。规范底层数据存储，结构化查询逻辑，方便快捷获取数据??
2.负责模型数据架构。让风控模型与数据架构解耦，实现模型快速迭代??
3.负责风控数据模型离线系统架构研发，建立数据抽取，清洗，校验，机器学习训练等数据加工流程 任职要求：??
1.有过大规模数据处理和开发的经验，对hive各种功能，特性比较熟悉；??
2.3年以上大数据架构设计、开发经验，熟悉常用编程语言，包括Python等；??
3.熟悉hadoop，spark，mongo，hive，hbase等大数据存储系统与技术；??
4.深入理解map-reduce等计算逻辑原理与优化方法；??
5.有较丰富的数据架构建设经验，并能跟进需求合理应用相关技术进行定制化开发；??
6.具有很强的技术研发和创新能力，能有效把握技术发展方向，有较强的执行能力、学习能力、沟通能力、适应能力，责任心强；"
"职位描述：
        
        岗位职责：
1、参与数据流程建设，数据仓库架构，包括源日志处理、ETL调度系统、数据集成系统、OLAP等子系统的设计和开发
2、解决业务人员在开发过程中遇到的工具使用、系统优化、数据处理技术等技术问题
3、负责用户数据仓库数据模型ETL开发和技术优化问题解决

职位要求：
1、计算机相关专业本科及以上学历（在校生）
2、掌握常用数据结构以及基本的算法,熟悉数据库原理,网络编程,多线程编程技术
3、熟悉Linux开发环境,熟练掌握SQL结构化查询语言,熟悉一种脚本语言(Shell、Python等)
4、熟悉Java/Python服务端系统开发，了解数据仓库架构系统
5、熟悉Hadoop/Spark/Hive/Hbase等组件使用场景，对相关源码有研究
6、具有良好的学习能力、时间和流程意识、沟通协作能力"
"职位描述：
        
        工作职责：
负责蜻蜓大数据平台的研发，包含数据基础平台的搭建，业务数据ETL处理，批量数据报表，实时数据的开发。

工作要求：
1、计算机或相关专业；
2、3年以上数据平台开发工作；
3、熟悉Hadoop、Spark、Storm等大数据平台相关技术；
4、熟练使用MapReduce、Hive、HDFS、Hbase、Redis、Kafka；
5、精通Java、Python、Scala。"
"职位描述：
        
        岗位职责：
1.参与蜻蜓个性化推荐系统、搜索系统的优化和开发。
2.参与系统设计，参与数据清洗、数据挖掘、特征提取、调参训练以及效果分析。
3.参与蜻蜓流量效率、业务指标的数据分析和报表处理。
4.应用算法和模型解决数据处理各个步骤中的问题。
5.参与项目讨论，提供实现文档。
6.调研和学习各类前沿算法、领域的最佳实践。
?
岗位要求：
1.国内外一流大学本科及以上学历，学习成绩优异，计算机相关专业。
2.2年以上大数据相关工作经验，技术能力强者不限。
3.熟悉基础算法和数据结构，有扎实的计算机知识及良好的代码习惯。
4.熟练掌握基于 Hadoop / Hive / Spark 的大数据计算框架，熟悉Scala或Python语言，Scala优先。熟悉Spark Streaming / Storm / Flink 等流式处理框架优先。
5.熟悉Linux操作系统，了解sqlmongoredis等常用数据库，掌握必要的服务端开发技术。熟悉数据可视化相关技术优先。
6.熟悉机器学习算法和推荐系统知识者优先。"
"职位描述：
        
        1. 负责公司的大数据平台的构建与开发；?
2. 负责公司大数据平台研发过程中的设计文档的撰写；?
3. 撰写规范专业的技术文档，研究行业前沿技术；
4. 参与小组的产品设计讨论，共同讨论和设计产品；
5. 大数据平台的新技术调研。??

1. 本科五年工作经验及以上，有至少一年的大数据技术实践经验；
2. 熟练使用hadoop及hadoop生态圈中的常用组件，如HBase、Hive、Pig、Kettle、zookeeper、Sqoop、Flume、Kafka、Storm、Redis、Spark、Yarn、Impala等全部或者部分组件；??
3. 深入理解Hadoop或Spark的原理和机制；
4. 熟练掌握Java，Shell 编程，具有一定JVM调优经验；? ?
5. 熟悉软件开发流程和配置库的使用，拥有软件开发流程中的代码规范意识、配置管理规范意识、文档撰写规范意识和团队合作沟通交流意识；
6. 对新生事物或者新技术有浓厚兴趣者优先，有较好的自主学习能力。"
"职位描述：
        
        岗位职责：1、完成公司大数据平台、数据仓库、数据集市的规划及实现；2、参与大数据平台相关业务产品需求调研，需求分析，并独立完成核心模块代码实现；3、参与现有大数据平台构架的改进，提质量及效率；4、协助测试人员进行软件的功能及性能测试。任职资格：1.?211、985院校本科以上学历，计算机相关专业；2.?6年研发以上相关工作经验，3年以上互联网大数据平台研发经验；3.?有项目管理经验，参与过过多个大型的数据仓库研发项目；4.?精通数据建模、数据标准管理、元数据管理、数据质量管理5.?精通大数据Hadoop体系的相关技术，具有大数据平台的架构实战经验。具备Flume/Kafka/Sqoop/Hive/Storm/Spark/Hbase/Elastic?Search等工具的实际开发经验；6.?良好的沟通表达（口头及书面）和文档交付能力、良好的团队合作精神压力承受能力。"
"职位描述：
        
        岗位职责：
1、完成公司大数据平台、数据仓库、数据集市的规划及实现；
2、参与大数据平台相关业务产品需求调研，需求分析，并独立完成核心模块代码实现；
3、参与现有大数据平台构架的改进，提质量及效率；
4、协助测试人员进行软件的功能及性能测试。


任职资格：
1. 211、985院校本科以上学历，计算机相关专业；?
2. 6年研发以上相关工作经验，3年以上互联网大数据平台研发经验；?
3. 有项目管理经验，参与过过多个大型的数据仓库研发项目；?
4. 精通数据建模、数据标准管理、元数据管理、数据质量管理?
5. 精通大数据Hadoop体系的相关技术，具有大数据平台的架构实战经验。具备Flume/Kafka/Sqoop/Hive/Storm/Spark/Hbase/Elastic Search等工具的实际开发经验；?
6. 良好的沟通表达（口头及书面）和文档交付能力、良好的团队合作精神压力承受能力。"
"职位描述：
        
        职位描述1、参与蚂蚁财富数据仓库架构设计与研发，建设公共数据平台和服务系统，实现高质量数据的互通与共享；2、参与蚂蚁财富数据产品与应用的数据研发，发掘数据商业价值，打造极致体验的数据产品；3、负责全链路离在线数据建模和生产、数据架构治理、和数据风险管理。职位要求1.从事数据仓库或挖掘领域至少2年以上，熟悉数据仓库模型设计与ETL开发经验 ，掌握维度建模设计方法，具备海量数据处理经验；2.熟悉数据仓库领域知识和技能者优先，包括但不局限于：元数据管理、数据开发测试工具与方法、数据质量、主数据管理；3.熟悉数据库技术，熟练运用SQL及其他Z言，能高效的与技术团队进行沟通；4.有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验着优先，如Hdfs、Mapreduce、Hive、Hbase、Spark、Storm；5.熟练掌握一门或多门编程语言，并有大型项目建设经验者优先，如Java、Python、Shell；6.良好的商业嗅觉，有丰富的数据分析经验，较强的数据、平台、技术理解能力；7.良好的语言沟通与表达能力，自我驱动；"
"职位描述：
        
        职位描述1、参与蚂蚁财富数据仓库架构设计与研发，建设公共数据平台和服务系统，实现高质量数据的互通与共享；2、参与蚂蚁财富数据产品与应用的数据研发，发掘数据商业价值，打造极致体验的数据产品；3、负责全链路离在线数据建模和生产、数据架构治理、和数据风险管理。职位要求1.从事数据仓库或挖掘领域至少2年以上，熟悉数据仓库模型设计与ETL开发经验 ，掌握维度建模设计方法，具备海量数据处理经验；2.熟悉数据仓库领域知识和技能者优先，包括但不局限于：元数据管理、数据开发测试工具与方法、数据质量、主数据管理；3.熟悉数据库技术，熟练运用SQL及其他Z言，能高效的与技术团队进行沟通；4.有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验着优先，如Hdfs、Mapreduce、Hive、Hbase、Spark、Storm；5.熟练掌握一门或多门编程语言，并有大型项目建设经验者优先，如Java、Python、Shell；6.良好的商业嗅觉，有丰富的数据分析经验，较强的数据、平台、技术理解能力；7.良好的语言沟通与表达能力，自我驱动；"
"职位描述：
        
        职位描述1、参与蚂蚁财富数据仓库架构设计与研发，建设公共数据平台和服务系统，实现高质量数据的互通与共享；2、参与蚂蚁财富数据产品与应用的数据研发，发掘数据商业价值，打造极致体验的数据产品；3、负责全链路离在线数据建模和生产、数据架构治理、和数据风险管理。职位要求1.从事数据仓库或挖掘领域至少2年以上，熟悉数据仓库模型设计与ETL开发经验 ，掌握维度建模设计方法，具备海量数据处理经验；2.熟悉数据仓库领域知识和技能者优先，包括但不局限于：元数据管理、数据开发测试工具与方法、数据质量、主数据管理；3.熟悉数据库技术，熟练运用SQL及其他Z言，能高效的与技术团队进行沟通；4.有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验着优先，如Hdfs、Mapreduce、Hive、Hbase、Spark、Storm；5.熟练掌握一门或多门编程语言，并有大型项目建设经验者优先，如Java、Python、Shell；6.良好的商业嗅觉，有丰富的数据分析经验，较强的数据、平台、技术理解能力；7.良好的语言沟通与表达能力，自我驱动；"
"职位描述：
        
        『蚂蚁金服小程序团队』求贤若渴!
北上广深成都，都在大力扩招中，机会错过不再来！

岗位描述:
1. 参与蚂蚁金服的产品平台、商户平台、开放平台的建设，每个平台支撑着支付宝、网商银行、蚂蚁财富、蚂蚁保险、蚂蚁开放平台等各个板块业务，需要具备领域建模能力，能看透业务本质化繁为简；
2. 根据业务需求，参与从业务分析、特征分析、模型建立、算法实现等过程，并逐步迭代算法效果；?
3. 需要耐得住寂寞，这里不一定能获取立竿见影的业务战果，但肯定有诸多考验业务洞察力、技术专精度等

岗位要求:
1. 三年以上Java开发及设计经验，优秀的编程能力及良好的开发习惯。具备独立沟通需求，设计，架构，开发的能力；
2. 具备良好的识别业务关键需求和设计领域模型的能力；
3. 具有良好的商业敏感度和优秀的数据分析技能，能够开发创新而实际的分析方法以解决复杂的商业问题；
4. 至少熟悉一种关系型数据库如Oracle、mysql等，熟练掌握Hive/SQL，熟悉Hadoop/Map-Reduce/MPI分布式计算框架，有海量数据处理经验者优先;?
5. 有大数据建模、大数据存储方面设计,并有大数据分析处理实际项目经验优先；
6. 有大型分布式、高并发、高负载、高可用性系统设计和稳定性经验优先；

部门定位:
开放与平台技术部致力于打造蚂蚁金服级的开放、产品、商户等通用业务平台，实现全局业务能力与商家资源的开放共享，对内助力于商家、用户、机构等服务体系构建，对外以小程序、生活号等为抓手激活支付+X的金融生活开放生态。"
"职位描述：
        
        职位描述
1、负责蚂蚁金服国际数据体系的建设，通过数据+算法+工程化能力，处理和萃取数据特征以及上层的数据运营、数据决策的体系建设；
2、参与大数据基础架构、产品技术的规划建设，包括数据采集平台、数据资产、数据产品、数据质量及稳定性保障体系建设。
任职要求
1、有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关开发经验，有Spark/Flink的开发经验尤佳；
2、较为丰富的数据平台的架构经验，精通数据建模理念和实战能力；有较为系统的海量数据性能处理经验，在数据产品和应用一定的成功经验；
3、具备较扎实的理论基础和工程能力，具备一定的JAVA、Python语言的开发能力，具备机器学习算法能力尤佳；
4、良好的思维逻辑性、语言表达能力；有较好英语口语能力尤佳。"
"职位描述：
        
        职位描述
1、负责蚂蚁金服国际数据体系的建设，通过数据+算法+工程化能力，处理和萃取数据特征以及上层的数据运营、数据决策的体系建设；
2、参与大数据基础架构、产品技术的规划建设，包括数据采集平台、数据资产、数据产品、数据质量及稳定性保障体系建设。

任职要求
1、有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关开发经验，有Spark/Flink的开发经验尤佳；
2、较为丰富的数据平台的架构经验，精通数据建模理念和实战能力；有较为系统的海量数据性能处理经验，在数据产品和应用一定的成功经验；
3、具备较扎实的理论基础和工程能力，具备一定的JAVA、Python语言的开发能力，具备机器学习算法能力尤佳；
4、良好的思维逻辑性、语言表达能力；有较好英语口语能力尤佳。"
"职位描述：
        
        我们作为蚂蚁数据技术平台部，需要面对全蚂蚁的数据问题，迎接每天P级别的数据处理；同时需要提供低延时，高可用的数据服务。

岗位描述：
1、负责系统实施，推进大数据数据处理和机器学习预测落地，用于保障蚂蚁全系统的资金安全和高可用等领域；?2、独立完成大型项目的系统分析设计，并负责核心模块研发； 负责完成系统Code Review的任务，确保相关代码的有效性和正确性，并能够通过Code Review提供相关性能以及安全的建议；?3、参与低延时大数据实时计算系统建设，提供工程保证，并可以对具体算法提供建议；?4、对业界在机器学习和数据挖掘等领域有一定预判，促进团队在数据收集的基础上，落实数据智能化分析。

岗位要求：
1、有强烈的技术热情，工作责任感；?2、有创新精神，乐于和热于技术钻研。思维严谨，逻辑清晰，具备批判性思维能力和习惯；?3、具备扎实的计算机专业基础，包括算法和数据结构、操作系统、计算机体系结构、计算机网络、数据库等；?4、扎实的Java/C/C++基础，良好的编程素养，对代码美感有追求，有一定的分布式开发调试经验；5、熟悉Hadoop/Map-Reduce/MPI/Spark分布式计算框架，熟悉spark streaming、sklearn、tensorflow等优先，对实时计算框架spark/flink有调优经验，且有海量数据处理经验优先；"
"职位描述：
        
        请留意：本次为上海专场，简历初筛通过之后，直接参加周末的专场面试，当天得到结果。专场具体时间未定，预计为四月中旬。

团队简介：
我们大部门的主要工作是负责蚂蚁全站系统的“高可用（从线程级到 IDC 级的故障自动定位和恢复决策）”和“资损防控（所有业务资金流的实时自动核对和止损）”这两大难题。 ?
? ??
在蚂蚁金服这样庞大的系统部署规模、频繁的变更频率、错综复杂的业务和资金流大背景下，可以预计这两项工作无法通过堆人的方式快速应对，即便是很有经验的专家。所以大方向是以数据驱动和智能化的思路来破局，一方面需要构建夯实的基础平台设施，支撑全站全量数据的高可靠近线传输、存储与计算。另一方面则需要结合场景去运用业界较为前沿的算法理论经验，实现问题域的智能分析，达到人工辅助甚至自动决策效果。
当下整个体系还有很大的探索空间和试错机会，如果：一.你本善于工程，对构建庞大实时高可靠的数据流感兴趣，同时又期望探索AI 的实际应用，二.你本善于算法，但苦于没有大体量的数据和足够复杂的场景去施展，我们觉得都是蛮匹配的方向。
工作职责包括但不限于：
1. 负责蚂蚁金服全站的“高可用”和“资损防控”这两大技术风险领域的基础平台建设；
2. 参与系统智能化建设，结合业务场景落地业界在机器学习和数据挖掘等领域的前沿理论经验；
3. 需要独立完成相关项目/关键模块的落地，包括核心模块的调研、设计、开发、测试、部署、优化等研发全流程，为系统质量和结果负责；（对，技术驱动下会有比较高的自由度，不会有太多人指手画脚，但自己要为结果负责）

职位要求：
1. 扎实的计算机专业基础，包括算法和数据结构，操作系统，计算机网络，计算机体系结构，数据库等；
2. 扎实的 Java 或相关编程语言基础（我们以 Java 为主），良好的编程素养，对代码有美感和极致的追求；
3. 理解实时流计算（ Spark/Storm/Flink ）或海量数据处理（ Hadoop/HBase/Hive ）相关经验优先考虑；
4. 掌握机器学习、数据挖掘或深度学习的原理和相关算法优先考虑；?
5. 强烈的技术热情和工作责任感，热衷于创新和分享，逻辑清晰并具备批判性思维能力和习惯；
6. 计算机软件或相关专业毕业，本科或以上学历，本次面向社招P6~P8；

备注：
1. Base地点可以选择北京、上海、杭州
2. 不同于业务团队，我们属于平台型研发"
"职位描述：
        
        职位描述：1.负责支付宝事业群数仓建设，包括：数据仓库（离线、实时）的数据架构、数据模型规划及实施、数据质量保障；
2.研究蚂蚁金服亿级用户及商户的相关行为及数据，并基于分类、标注、聚类等机器学习手段，挖掘不同业务场景的业务标签；任职要求：1.从事数据仓库或挖掘领域至少1年半以上，熟悉数据仓库模型设计与ETL开发经验 ，掌握维度建模设计方法，具备海量数据处理经验；
2.熟悉数据仓库领域知识和技能者优先，包括但不局限于：元数据管理、数据开发测试工具与方法、数据质量、主数据管理；
3.熟悉数据库技术，熟练运用SQL及其他Z言，能高效的与技术团队进行沟通；
4.有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验着优先，如Hdfs、Mapreduce、Hive、Hbase、Spark、Storm；
5. 对常规统计机器学习问题具有一定的理解，熟悉常用的模型；
6.熟练掌握一门或多门编程语言，并有大型项目建设经验者优先，如Java、Python、Shell；
7.良好的商业嗅觉，有丰富的数据分析经验，较强的数据、平台、技术理解能力；
8.良好的语言沟通与表达能力，自我驱动；"
"职位描述：
        
        我们的职责：

管理国民级App会员的账号、账户、证件、关系及资产等关键数据，为数据化智能提供基础的用户画像数据服务能力，助力会员在蚂蚁各类业务产品的数据分析及提升产品体验诉求。

我们的要求：

1.熟悉数据仓库模型设计，具备海量数据加工处理（ETL）相关经验；
2. 至少熟悉一种关系型数据库如Oracle、mysql等，熟练掌握Hive/SQL，熟悉Hadoop/Map-Reduce/MPI分布式计算框架，有海量数据处理经验者优先;
3. 熟悉回归分析模型、关联规则挖掘、分类和聚类算法、协同过滤算法等数据统计模型和挖掘算法，了解完整的数据挖掘过程方法论，并有独立完整的建模实践经验；
4. 具有良好的商业敏感度和优秀的数据分析技能，能够开发创新而实际的分析方法以解决复杂的商业问题；
5. 具有良好的沟通、团队协作、计划和创新的能力；
6. 有软件研发工程经验优先考虑。"
"职位描述：
        
        工作职责：1. 独立完成小型项目的系统分析. 设计，并主导完成详细设计和编码的任务，确保项目的进度和质量； ?2. 能够在团队中完成Code Review的任务，确保相关代码的有效性和正确性，并能够通过Code Review提供相关性能以及安全的建议； ?3. 深入理解数据业务，分析用户需求，能够从用户角度推动业务发展，提升公司数据应用能力； ?4. 能够有效地对新人或普通开发工程师进行辅导，帮助其快速成长。
任职资格：1. 三年以上Java开发及设计经验，优秀的编程能力及良好的开发习惯。具备独立沟通需求，设计，架构，开发的能力；或者，熟悉数据仓库模型设计，具备海量数据加工处理（ETL）相关经验； ?2. 至少熟悉一种关系型数据库如Oracle、mysql等，熟练掌握Hive/SQL，熟悉Hadoop/Map-Reduce/MPI分布式计算框架，有海量数据处理经验者优先; ?3. 熟悉回归分析模型、关联规则挖掘、分类和聚类算法、协同过滤算法等数据统计模型和挖掘算法，了解完整的数据挖掘过程方法论，并有独立完整的建模实践经验； ?4. 具有良好的商业敏感度和优秀的数据分析技能，能够开发创新而实际的分析方法以解决复杂的商业问题； ?5. 具有良好的沟通、团队协作、计划和创新的能力； ?6. 具有电子商务、金融行业背景的人优先。"
"职位描述：
        
        职位描述：
1、负责蚂蚁金服国际数据体系的建设，通过数据+算法+工程化能力，处理和萃取数据特征以及上层的数据运营、数据决策的体系建设；
2、参与大数据基础架构、产品技术的规划建设，包括数据采集平台、数据资产、数据产品、数据质量及稳定性保障体系建设。
职位要求：
1、有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关开发经验，有Spark/Flink的开发经验尤佳；
2、较为丰富的数据平台的架构经验，精通数据建模理念和实战能力；有较为系统的海量数据性能处理经验，在数据产品和应用一定的成功经验；
3、具备较扎实的理论基础和工程能力，具备一定的JAVA、Python语言的开发能力，具备机器学习算法能力尤佳；
4、良好的思维逻辑性、语言表达能力；有较好英语口语能力尤佳。"
"职位描述：
        
        职位描述：
1、负责蚂蚁金服国际数据体系的建设，通过数据+算法+工程化能力，处理和萃取数据特征以及上层的数据运营、数据决策的体系建设；
2、参与大数据基础架构、产品技术的规划建设，包括数据采集平台、数据资产、数据产品、数据质量及稳定性保障体系建设。
职位要求：
1、有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关开发经验，有Spark/Flink的开发经验尤佳；
2、较为丰富的数据平台的架构经验，精通数据建模理念和实战能力；有较为系统的海量数据性能处理经验，在数据产品和应用一定的成功经验；
3、具备较扎实的理论基础和工程能力，具备一定的JAVA、Python语言的开发能力，具备机器学习算法能力尤佳；
4、良好的思维逻辑性、语言表达能力；有较好英语口语能力尤佳。"
"职位描述：
        
        职位描述：

1、负责金融核心数据体系建设，通过专业的数据架构能力，服务于全面风险/企业经管/机构服务，支撑各BU（支付宝、蚂蚁财富、网商银行、微贷）业务健康发展；
2、基于业务需求，盘点规划数据资产，建设内部数据资产，引进外部数据资产，形成完整的数据资产大图；
3、参与大数据基础架构和技术体系的规划建设，整合与应用已有数据平台能力，解决实际业务问题；
4、负责数据质量体系建设，保障离线数据稳定性，以及架构升级过程中的数据治理工作；
5、以上工作职责有具体的细分，可以基于兴趣和爱好选择不同的方向发展。

职位要求：

1、计算机、数学、统计或相关专业本科及以上学历，较为丰富的数据仓库及数据平台的架构经验，精通数据仓库建模及ETL设计开发；
2、熟悉Oracle/Mysql/Hive/Hadoop/Map-Reduce/SPARK/STROM分布式计算框架中的一种，有海量数据处理和实时数据计算经验者优先；
3、有全面风险/企业经管/机构服务/账务系统大数据工作经验者优先；
4、具备python、grove、shell等脚本能力或机器学习算法能力尤佳；
5、良好的思维逻辑性、较强的沟通表达能力；
6、以上能力项不全部要求。"
"职位描述：
        
        职位描述：?
1.?负责蚂蚁金服基础数据平台的建设，包括基础的运维数据，资金数据，系统变更数据等。?
2. 对全链路数据质量负责，进行实时监控，分析，最终提供保障数据的质量，包括低延时，高可用等指标。?
3. 参与建设数据平台建设，满足实时数据流的上各种复杂计算需求，包括图计算，多流合并，以及各种常见Transform计算。?4. 对接数据平台上的各种业务方，满足不断发展的业务需求。?5. 对接各类数据源系统，包括蚂蚁平台内部的各种Queue，关系数据库，日志等系统。

职位要求：
?1. 较好的抗压能力，有Ownership意识，追求实现自我价值。?2. 有ETL，ELK类业务的实际项目经验，掌握实时计算技术体系包括数据采集、计算引擎Storm/Spark/Flink，对实时计算所涉及的事务、容错、可靠性有深入理解。了解背后的实现原理，并能够调优。?3. 对Hadoop/YARN/Hive等大数据工具有深入使用经验，熟悉大数据存储系统hbase/hdfs等，了解起背后的实现原理，并能够调优。?4. 精通Java，C/C++，Scala等其中一种，极佳的编程素养，有丰富的分布式开发经验。熟悉Linux系统，有一定的脚本开发能力。?5. 参与过超大规模数据项目，有百万级TPS数据处理经验者优先。

工作地点：

上海，上海中心大厦
杭州，黄龙国际大厦

公司福利：

????股票期权;?
????弹性工作;?
????绩效奖金;?
????年底双薪;?
????带薪年假;?
????定期体检;?
????专项奖金;?
????午餐补贴;?
????很多培训;"
"职位描述：
        
        职位描述1）建设金融监管、风险领域相关的数据体系；2）参与监管科技、业务风控离线／实时数据相关系统的ETL设计，开发；包括离线、实时数据加工，计算，ETL，管理，监控等模块等；3）有互联网前沿风控的业务洞见优先，并能出具风控的数据技术解决方案，并指导落地。4）有金融监管相关业务背景的优先。职位要求1）对金融监管业务经验，熟悉企业数据体系，具备优秀的设计及良好的开发习惯，具备独立沟通需求，设计，架构，开发的能力；2）对流式计算有实战经验、熟悉storm、spark等流式计算框架的运行机制和体系结构，熟悉实时数据技术体系；3）有良好的业务及产品感觉，可以站在使用者角度设计技术产品；可以主动并乐于了解日常业务，具备从日常业务中发现问题并解决问题的能力；4）熟悉各种NoSQL产品,对分布式架构熟悉者优先；具有图数据库开发经验者优先；5）对数据挖掘和机器学习有所了解，包括常用的机器学习算法和数据建模过程的优先。"
"职位描述：
        
        1.负责支付宝事业群数仓建设，包括：数据仓库（离线、实时）的数据架构、数据模型规划及实施、数据质量保障；
2.研究蚂蚁金服亿级用户及商户的相关行为及数据，并基于分类、标注、聚类等机器学习手段，挖掘不同业务场景的业务标签；

职位描述
1.从事数据仓库或挖掘领域至少3年以上，熟悉数据仓库模型设计与ETL开发经验 ，掌握维度建模设计方法，具备海量数据处理经验；
2.熟悉数据仓库领域知识和技能者优先，包括但不局限于：元数据管理、数据开发测试工具与方法、数据质量、主数据管理；
3.熟悉数据库技术，熟练运用SQL及其他Z言，能高效的与技术团队进行沟通；
4.有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验着优先，如Hdfs、Mapreduce、Hive、Hbase、Spark、Storm；
5. 对常规统计机器学习问题具有一定的理解，熟悉常用的模型；
6.熟练掌握一门或多门编程语言，并有大型项目建设经验者优先，如Java、Python、Shell；
7.良好的商业嗅觉，有丰富的数据分析经验，较强的数据、平台、技术理解能力；
8.良好的语言沟通与表达能力，自我驱动；"
"职位描述：
        
        1.负责支付宝事业群数仓建设，包括：数据仓库（离线、实时）的数据架构、数据模型规划及实施、数据质量保障；
2.研究蚂蚁金服亿级用户及商户的相关行为及数据，并基于分类、标注、聚类等机器学习手段，挖掘不同业务场景的业务标签；

职位描述
1.从事数据仓库或挖掘领域至少3年以上，熟悉数据仓库模型设计与ETL开发经验 ，掌握维度建模设计方法，具备海量数据处理经验；
2.熟悉数据仓库领域知识和技能者优先，包括但不局限于：元数据管理、数据开发测试工具与方法、数据质量、主数据管理；
3.熟悉数据库技术，熟练运用SQL及其他Z言，能高效的与技术团队进行沟通；
4.有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验着优先，如Hdfs、Mapreduce、Hive、Hbase、Spark、Storm；
5. 对常规统计机器学习问题具有一定的理解，熟悉常用的模型；
6.熟练掌握一门或多门编程语言，并有大型项目建设经验者优先，如Java、Python、Shell；
7.良好的商业嗅觉，有丰富的数据分析经验，较强的数据、平台、技术理解能力；
8.良好的语言沟通与表达能力，自我驱动；"
"职位描述：
        
        职位描述：
1、负责数据集市的规划、设计和实施，高效安排/规划计算资源；
2、负责业务数据报表需求的分析、设计和实现；
3、负责受理数据特征的挖掘和开发。
职位要求：
1、从事分布式数据存储与计算平台应用开发经验，如 Hadoop/Spark相关开发经验3年及以上；
2、具有数据平台经验，精通数据仓库建模及ETL设计开发 ；
3、具备一定的JAVA、Python语言的开发能力；
4、教育背景要求为数据库、信息学等相关领域，逻辑性、表达能力良好。"
"职位描述：
        
        职位描述： 工作职责 1. 基于 Kylin, Druid 等开源方案构建符合业务需求的平台； 2. 对来自 Kafka, CMQ, RMQ 的流数据，基于 Flink 等构建流计算引擎； 3. 对来自 Log, Mysql, Mongo, TiDB, ES 的数据源创建 cube，建立数据模型，对应用层需要大数据查询进行优化及统计； 4. 日常协助运维管理维护 Hadoop, Spark 集群； 职位要求 1、本科生及以上学历，3年及以上相关经验； 2、熟悉 Hadoop + Spark/Kylin，熟悉数据挖掘策略与算法； 3、善于发现问题、解决问题； 4、对新兴技术有好奇心，有利用技术解决实际问题的热情，开源社区积极参与者优先。"
"职位描述：
        
        岗位职责：1、基于海量的用户行为数据，优化用户画像标签体系，应用机器学习和数据挖掘算法，构建各类标签的算法策略；2、针对公司大数据产品的业务需求进行数据处理、数学建模、模型开发、模型优化、统计分析、挖掘及存储；3、针对业务问题，选择合适的挖掘算法对产品方案进行实施、验证和优化，任职资格1、具有统计和数据挖掘背景，熟悉常用数据库 ? 熟悉SQL查询 2、熟悉常用机器学习和数据挖掘算法，包括但不限于决策树、Kmeans、SVM、线性回归、逻辑回归以及神经网络等算法；3、至少掌握一门语言(Scala/Java/python/php/R)4、 熟悉 Hadoop/Storm/HIVE/Hbase 等产品5、 有机器学习、人工智能等实际工作经验"
"职位描述：
        
        岗位职责
1、 从事Hadoop、Spark、Storm等分布式大数据平台产品的设计和开发；
2、 针对部门大数据业务进行大数据分析、挖掘应用的开发；?
3、 为项目开发人员提供大数据技术指导及解决大数据平台应用中遇到的技术难题。
任职要求
1、 二年以上Java Web应用开发经验，本科及以上学历；?
2、 熟练掌握Java、Nodejs 中的至少一门语言，有Python、R语言开发经验优先；?
3、 熟悉Hadoop大数据生态圈技术 分布式存储Hdfs,Hbase等 资源调度Yarn,Kubernetes,Mesos等 计算框架 Spark,MR,Hive,Impala等 有相关源码研究优先。?
4、 熟悉Mysql、MongoDB等常用关系数据库，熟练编写SQL语句；有分布式nosql数据库应用经验优先；?
5、 熟悉Linux环境，能够熟悉使用shell脚本；?
6、 对大数据技术有强烈兴趣，有志于往大数据处理方向发展；工作认真踏实，动手和学习新技术能力强。?
7、熟练掌握实时数据处理常用技术工具Storm SparkStreaming等 8、熟练掌握常见数据流接入工具Flume kafka等?
9、熟悉离线和实时数据处理流程"
"职位描述：
        
        工作职责：
1. 智能客服、智能营销等AI项目核心服务研发工作
2. 人工智能系统的持续改进和迭代优化
3. 重点、难点技术攻关，持续探索前沿技术

任职要求：
1. 计算机及相关专业，本科及以上学历
2. 良好的编程基础，具备3年及以上Java或Python开发经验
3. 有推荐系统、问答系统等人工智能相关开发经验
4. 对AI算法有一定的了解"
"职位描述：
        
        【岗位职责】
?
(1)为大数据的全生命周期提供服务，覆盖数据产生，传输，建模，统计分析，实验评估，可视化的全流程；
(2)构建设计良好的数据流、数据仓库、调度系统、查询引擎，数据服务、分析系统、流程规范，数据工具/产品，降低数据的使用门槛，保证系统稳定高效运行，以实现数据的最大价值；
(3)核心用户行为数据流和相关数据服务，流式数据的实时传递，清洗，转换，计算，并对外提供查询服务；
(4)结合实际业务问题，运用数据挖掘、机器学习领域的前沿技术，给出解决方案；
(5)跟进开源社区的更新，阅读文档，验证feature，持续提升平台的性能与稳定性。

【任职要求】?

(1)统招本科或以上学历，计算机相关专业， 3年以上软件开发经验；
(2)熟练使用Java相关技术进行系统开发，有springboot,spring cloud相关技术开发经验者优先考虑；
(3)熟悉Hadoop，Map/Reduce，kafka，Spark，Hive，flume，sqoop等大数据相关技术，了解CDH或HDP框架；
(4)有大数据处理的实际开发经验，熟悉分布式计算相关技术；
(5)生产环境快速trouble-shooting能力，强悍的编码能力，对新技术有强烈的学习热情；
(6)网络基础扎实，熟悉TCP/IP协议，熟悉网络编程；
(7)熟悉互联网开源技术中的一种或几种以及类似的技术：redis，MongoDB, HDFS，HBase，ZooKeeper，Protocol Buffer；
(8)优秀的沟通和协作能力，有创新精神，乐于接受挑战，能承受工作压力。"
"职位描述：
        
        岗位职责：
1、参与大数据平台、工具平台的架构、设计以及实现；
2、参与对项目的开发需求进行评审，制定项目的设计文档、开发计划文档等；
3、负责公司各类数据产品数据抽取、清洗，以及数据算法与存储的设计和优化；
4、优化大数据平台的性能，提高稳定性；
5、负责大数据平台的组件升级与参数优化。

任职要求：
1、本科及以上学历，3年以上相关技术背景，具备扎实的数据结构和算法基础，扎实的工程实现能力；
2、熟悉hadoop大数据相关技术体系，包括但不限于Hbase、HDFS、Storm、Kafka、Spark、Hive、Flume等；?
3、精通Java或Python，能熟练编写规范代码，有较强的数据库及SQL开发调优能力；
4、熟悉自然语言处理/机器学习/数据挖掘领域，熟悉常用的机器学习算法优先考虑；
5、有大规模数据收集，日志处理经验，有电商数据分析背景优先考虑；
6、深入研究过大数据框架的运行机制、实现原理、源码者优先考虑。"
"职位描述：
        
        1、参与公司数据产品设计、研发与实施；
2、进行数据整理清洗和统计分析，刷选变量，提取特征，刻画数据特征；
3、数据表结构设计，数据库容量规划、架构设计，保证业务的高可用和高性能；
4、负责数据建模和日常报表的开发，并结合实际效果不断进行模型的训练和迭代，管理模型生命周期的全流程；
5、针对商业问题和实际业务，参与创新方法和应用的研发，充分挖掘数据的商业价值。

职位要求：
1、大学本科及以上学历，数学、统计、计算机等专业毕业；
2、三年以上数据管理、分析经验（有大数据分析经验，咨询、互联网公司数据管理分析经验者优先）；
3、掌握至少一种主流数据挖掘或数据分析工具，如Python、SAS、SPSS、SQL等；
4、熟悉主流数据库环境及开发，熟悉数据库性能调优，可熟练编写存储过程，能独立完成简单的ETL任务；
5、对大数据行业有热情，具备良好的学习能力、逻辑思维能力、沟通能力、团队协作能力和执行力。"
"职位描述：
        
        岗位职责：
1、负责公司BI项目开发和维护 ； ?????
2、负责数据分析与查询； ??
3、负责大数据项目开发及维护工作。

任职要求：
1、精通java语言，Java/Scala至少一种；
2、熟悉Hadoop/MapReduce/Hive之一，对ETL有一定了解；
3、了解flume、kafka、Hive、Spark等大数据开发工具；
4、有较强的业务理解认知能力和较好的逻辑思维能力。

此为校招职位，实习满三个月可免试用期。实习期福利待遇优厚哦，工作地点在北京望京，非北京地区的同学不用为住宿发愁啦~1、 实习期工资：140-180元/天；2、 公司提供实习期免费住宿；3、 培训制度完善，每位实习生都有导师带领。"
"职位描述：
        
        岗位要求：
1、本科3年以上；硕士及以上学历2年以上；基本素质较好者，工作经验要求可放宽。计算机或相关专业本科及以上。
2、熟悉Java、Scala，对Scala/java底层技术有一定研究；有一定的架构能力和良好的代码规范；
3、熟悉MySQL或其他主流数据库产品以及SQL语言；
4、对分布式系统原理有较深的理解，熟悉spark，hadoop，hbase，kafka，es，kudu，dubbo等技术；
5、熟悉scala，java，了解python优先；
岗位职责：
1、负责Hadoop平台数据仓库、数据集成、数据管理的设计、开发、迭代、优化和维护工作；
2、负责基于Spark平台的海量数据的处理、分析、统计、挖掘工作；
3、基于Hadoop生态圈进行扩展研发，根据公司业务构建统一的数据架构；
4、和业务团队深入合作，解决在业务发展中遇到的产品和平台架构问题；与团队一起进行新技术、新架构的可行性分析和研究。"
"职位描述：
        
        岗位职责：
1、负责公司大数据业务集群的运维工作, 参与数据治理、大数据集群的自动化运维和管理;
2、参与海量数据处理分布式平台及大数据分析系统的架构设计和搭建;
3、参与海量数据交互式查询引擎的研发与维护。
岗位要求：
1、3年及以上大数据相关开发经验，计算机、统计学、数学等相关专业本科及以上学历;
2、有扎实的编程能力,熟悉Java/Python/Scala其中的一种或几种编程语言;
3、掌握 canal/sqoop/Logstash、Kafka、Zookeeper、Hbase、Spark的等安装调试，性能优化；
4、对数据敏感，能熟练预估数据量，善于从数据中发现问题，有数据处理经验者优先;
5、熟悉大数据相关开源项目和社区，有深入阅读过源码的优先。"
"职位描述：
        
        职位描述：
1、负责大数据平台的规划和搭建、完成大数据平台的日常运营工作，为数据分析和展现提供支持；
2、通过深度挖掘用户的行为数据，从数据分析中发掘市场新动向、潜在客户分布、已有客户需求等信息；
3、参与基于大数据平台的创新业务场景进行数据产品的架构设计，负责数据产品的研发交付；
4、组织和主导大数据算法开发和工程化；
制订数据质量标准，管控数据变更流程，管理数据资产，确保数据安全；
5、及时跟进大数据领域新技术并分享，提升团队技术能力。

任职要求：
1、本科以上学历，计算机相关专业，三年以上互联网数据开发经验
2、精通 java，python，scala 等大数据开发语言，精通 hadoop，hive，kafka，storm，spark 等大数据平台和工具，有丰富的大数据项目的实践经验；
3、精通 ETL，数据仓库的设计和开发，对数据架构有深入的了解和具备相关的项目实践经验；
4、熟悉数据挖掘的相关理论和技术，了解机器学习相关算法，能从数据中挖掘和提升产品能力；
5、具备一年及以上团队管理经验优先"
"职位描述：
        
        工作职责
1.基于海量用户行为，开发用户画像数据挖掘模型； 2.负责用户画像数据准备、标签开发与标签评测。
任职资格
1.统招大学本科及以上学历； 2.掌握基于hadoop或hbase等大数据平台工具的开发与设计，熟悉Hive，map/reduce开发； 3.熟悉数据挖掘领域常用算法，如LR、关联规则、神经网络等，善于学习新东西； 4.参与过用户画像建模、用户画像系统或DMP系统的开发工作； 5.精通c/c++, Java或者python中一种编程语言，良好的代码习惯； 5.具有良好的沟通能力和团队协作精神，有较强的数据处理和分析能力。"
"职位描述：
        
        岗位职责：
1、负责广告大数据数据的处理，在分布式计算平台基础上建立高效、实时的数据?pipeline；
2、负责?Hadoop，Spark?等大数据基础设施和平台的改进，解决大规模生产环境集群可用性和性能优化问题；
3、负责广告大数据处理平台、数据仓库及BI系统的架构设计和研发工作。
任职要求：
1、计算机相关专业，本科及以上学历，4年以上Hadoop相关开发经验，2年以上Spark相关开发经验；
2、熟悉分布式的海量数据处理平台?，熟悉分布式系统思想，熟悉mapreduce原理，spark原理，特别是对spark的优化有实际经验。
3、有lowlatency（包括spark-streaming、flink、storm、kafka等）大数据处理经验者优先；
4、有大数据查询系统（包括ClickHouse、Phoenix、Presto、Impala、Druid、Kylin、Greenplum等）经验者优先
5、熟练使用java开发，擅长python，scala，shell中的一种或者多种；
6、具有大型互联网工作经验，具有较强的业务理解能力。"
"职位描述：
        
        岗位职责：
1. 独立完成小型项目的系统分析、设计，并主导完成详细设计和编码的任务，确保项目的进度和质量；?
2. 能够在团队中完成Code Review的任务，确保相关代码的有效性和正确性，并能够通过Code Review提供相关性能以及安全的建议；
3. 深入理解数据业务，分析用户需求，能够从用户角度推动业务发展，提升公司数据应用能力；?

岗位要求：?
1. 三年以上Java开发及设计经验，优秀的编程能力及良好的开发习惯。具备独立沟通需求，设计，架构，开发的能力；或者熟悉数据仓库模型设计，具备海量数据加工处理（ETL）相关经验；?
2. 至少熟悉一种关系型数据库如Oracle、mysql等，熟练掌握Hive/SQL，熟悉Hadoop/Map-Reduce/MPI分布式计算框架，有海量数据处理经验者优先;?
3. 具有良好的商业敏感度和优秀的数据分析技能，能够开发创新而实际的分析方法以解决复杂的商业问题；
4. 具有良好的沟通、团队协作、计划和创新的能力；"
"职位描述：
        
        岗位描述：
1、通过数据挖掘、大数据处理、数据分析等技术，对海量用户属性、行为数据和品牌运营数据进行挖掘与分析，包括但不限于用户画像、增长策略洞察、运营效果分析等方向；
2、与业务产品、运营深度配合，通过数据分析产品痛点，优化思路，并参与到产品策略调整的各环节，用数据帮助产品迭代；
3、与相关团队协作进行数据建模和推动部门的数据系统建设，包括但不限于海量用户行为日志设计、数据仓库设计、分析计算等相关工作

岗位要求：
1、本科及以上学历，计算机、数学、统计等相关专业；
2、4年及以上机器学习、大数据挖掘等相关领域经验，熟悉各类数据统计模型和挖掘算法，能够深入了解算法细节，主动优化获取最优结果；
3、对数据有敏感的分析能力，熟悉协同过滤、回归分析模型、关联规则挖掘、分类和聚类算法等数据统计模型和挖掘算法，有独立完整的建模实践经验优先；
4、熟悉Hadoop、Hive、Spark等一个或多个大数据计算框架和平台；
5、有个性化推荐、智能选品和搜索相关工作经验优先；?
6、责任心强，良好的沟通、团队协作和创新能力，能承受一定的工作压力"
"职位描述：
        
        岗位职责 ：?
大数据平台开发, 满足日益增长的数据计算需求, 提高小伙伴的工作效率；
离线计算/实时计算开发, 为线上业务提供数据支撑。?
任职条件：?
扎实的计算机基础, 至少一年大数据平台相关经验；
?熟练掌握如下最少一门语言: Java/Go/Python?；
熟练掌握如下最少一个组件: Hadoop/Spark/Kafka/Presto 等, 具备问题定位/解决能力, 有 HBase/Cassandra 等分布式存储相关经验加分, 有开源社区贡献的加分, 有 AWS 平台经验加分?
乐于沟通, 敢于担当, 具备良好的沟通和团队协作能力"
"职位描述：
        
        岗位职责：大数据平台开发, 满足日益增长的数据计算需求, 提高小伙伴的工作效率。离线计算/实时计算开发, 为线上业务提供数据支撑。任职条件：扎实的计算机基础, 至少一年大数据平台相关经验熟练掌握如下最少一门语言: Java/Go/Python熟练掌握如下最少一个组件: Hadoop/Spark/Kafka/Presto 等, 具备问题定位/解决能力, 有 HBase/Cassandra 等分布式存储相关经验加分, 有开源社区贡献的加分, 有 AWS 平台经验加分乐于沟通, 敢于担当, 具备良好的沟通和团队协作能力"
"职位描述：
        
        岗位职责
1、根据业务规划制定相应的技术规范，推动已有推荐系统的迭代，系统性能调优；
2、参与重点模块的设计，方案评审与技术支持，攻克项目中遇到的技术难题，把握系统的关键技术；
3、参与核心代码的编写，同团队成员review各个开发模块代码、优化业务代码；
4、参与技术选型和可行性评估；跟踪并研究关键技术和新技术并应用于现有业务当中。

职位要求
1、计算机相关专业、本科及以上学历；
2、3-5年相关java开发工作经验；
3、精通后端主流技术框架(spring cloud 优先)；掌握IntelliJ IDEA开发工具；
4、精通分布式、延展性、可扩展性架构设计，具备大流量、高容错性、高负载环境下的系统开发及优化；
5、具有大型分布式，高并发，高负载，高可用系统设计，开发和调优经验者优先；
6、具有新媒体推荐系统经验者优先。

公司福利
六险一金（一档/综合医疗）、免费早餐、弹性上班、杠杠的健身卡、女生每月带薪姨妈假、半入职周年假、年假、每月部门团建费"
"职位描述：
        
        1、 基于Hadoop/Spark的大数据处理和分析平台的架构和开发；
2、 负责分析新的数据需求, 完成数据处理的设计(文档、和实现）；
3、 负责数据处理程序设计框架改善, 数据处理性能优化, 系统数据处理的能力提高；?
任职要求：
1、 本科学历以上， 计算机软件及相关专业；
2、 有hadoop平台项目开发经验， 熟悉Hadoop、HBase、Hive、Spark、Mapreduce、Flume、Kafka、Storm、ETL等相关技术或者工具至少3个以上；
3、 有金融、游戏、推荐、人群画像等领域模型构建和调优工作经验者优先；
6、 学习能力强，喜欢研究新技术，有团队观念，具备独立解决问题的能力。"
"职位描述：
        
        岗位职责：
1、负责公司核心大数据组件的构造和开发；
2、负责公司大数据平台研发过程中的设计文档撰写；
3、与业务产品组共同讨论，合力对产品架构进行设计；
4、大数据平台新技术预研

任职要求：
1、具有4年以上软件开发经验， 至少1年大数据开发实践经验；
2、熟练掌握hadoop及hadoop体系内的常用组件；
3、拥有实际的Hadoop的项目经验优先，有Spark使用经验者优先；
4、熟练掌握Java语言及常用开源框架，如：MyBatis、Spring；
5、有较强的书面或口头沟通表达能力，有独立分析解决问题的能力；
6、对技术有浓厚兴趣者优先，有较好的自主学习能力。
Leader要求：
1、8年以上开发经验，其中3年以上大数据架构或相关工作经验；有零售大数据、电商平台系统设计和架构经验；
2、具有较强的数据挖掘、机器学习、语义分析的理论基础和实际项目经验，精通数据分析与各种算法与模型；构建用户画像体系，挖掘用户群体属性、行为偏好；
3、精通Hadoop/spark、hive、HBase等主流的大数据技术，至少3年以上产品/平台项目研发经验，具备大型复杂Hodoop数据平台的建设实施经验；精通java及python。

人工智能领域，行业前沿，前景好，公司大牛云集，公司地铁口附近，入职五险一金，下午茶，福利薪资优渥，该有的都有！"
"职位描述：
        
        职位描述：
1、基于海量数据，支持业务对数据的清洗、计算、分析和使用
2、支持业务处理数据的流式处理、分析用户行为等
3、通过海量数据，分析与挖掘各种潜在关联

职位要求?
1、计算机相关专业本科及以上学历?
2、精通至少一门编程语言(java/python/php)，熟练运用各种常用算法和数据结构，有独立的实现能力
3、熟悉常用的开源组件：Hadoop/Hive/HBase/Spark/Storm/Kafka/mysql，并了解其特性和使用场景优先
4、熟悉机器学习、数据挖掘、数据分析、分布式计算至少某一方面，有较深的理论研究和实践经验优先
5、优秀的沟通理解能力，能快速理解业务，用数据解读业务
6、数据分析、推荐、机器学习、数据挖掘相关的开发工作优先"
"职位描述：
        
        职位内容：
1、参与互联网数据、日志的数据清洗工作，参与数据仓库分层设计；
2、搭建数据处理相关的分布式计算调度系统，数据地图，算法平台，报表管理等；3、负责不同应用场景下的数据采集、解析、清理，为数据挖掘和机器学习提供支持；4、探索、开发并维护数据基础设施，提供各种高效数据访问和处理工具。

职位要求：
1、本科及以上学历，计算机、数学等相关专业优先；
2、熟悉常用的分布式计算工具，如Hadoop、Spark、Hive；
3、了解分布式计算的原理，有一定的debug能力；
4、能根据文档快速实施ETL方案；
5、工作积极主动、有责任心，具备良好的沟通能力和团队合作精神。

加分项：
1、有爬虫的使用和开发经验，对算法有了解和兴趣；
2、重视代码设计，能基于公司数据框架进行开发。"
"职位描述：
        
        职位内容：
1、参与互联网数据、日志的数据清洗工作，参与数据仓库分层设计；
2、搭建数据处理相关的分布式计算调度系统，数据地图，算法平台，报表管理等；
3、负责不同应用场景下的数据采集、解析、清理，为数据挖掘和机器学习提供支持；
4、探索、开发并维护数据基础设施，提供各种高效数据访问和处理工具。

职位要求：
1、本科及以上学历，计算机、数学等相关专业优先；
2、熟悉常用的分布式计算工具，如Hadoop、Spark、Hive；
3、了解分布式计算的原理，有一定的debug能力；
4、能根据文档快速实施ETL方案；
5、工作积极主动、有责任心，具备良好的沟通能力和团队合作精神。

加分项：
1、有爬虫的使用和开发经验，对算法有了解和兴趣；
2、重视代码设计，能基于公司数据框架进行开发。"
"职位描述：
        
        职位内容：
1、参与互联网数据、日志的数据清洗工作，参与数据仓库分层设计；
2、搭建数据处理相关的分布式计算调度系统，数据地图，算法平台，报表管理等；
3、负责不同应用场景下的数据采集、解析、清理，为数据挖掘和机器学习提供支持；
4、探索、开发并维护数据基础设施，提供各种高效数据访问和处理工具。

职位要求：
1、本科及以上学历，计算机、数学等相关专业优先；
2、熟悉常用的分布式计算工具，如Hadoop、Spark、Hive；
3、了解分布式计算的原理，有一定的debug能力；
4、能根据文档快速实施ETL方案；
5、工作积极主动、有责任心，具备良好的沟通能力和团队合作精神。

加分项：
1、有爬虫的使用和开发经验，对算法有了解和兴趣；
2、重视代码设计，能基于公司数据框架进行开发。"
"职位描述：
        
        职位描述：
1、搭建数据处理相关的分布式计算调度系统，数据地图，算法平台，报表管理等；
2、负责不同应用场景下的数据采集、解析、清理，为数据挖掘和机器学习提供支持；
3、探索、开发并维护数据基础设施，提供各种高效数据访问和处理工具；

职位要求：
1、985，211计算机相关专业本科以上学历，2年以上相关经验；
2、掌握计算机基础数据结构、操作系统原理、网络，理解算法的时间复杂度、空间复杂度等概念；
3、熟悉java，c++，mysql，能够了解一些nosql系统，比如redis，hbase等；
4、有英文文档的阅读能力；
5、热爱技术，动手能力强；
6、性格开朗，表达能力强；
Extra points：
1、对分布式计算有了解者优先；
2、对算法有了解和兴趣优先；
3、了解olap系统优先；
此岗位初、中、高级别都在看，如果有意向的同学可以把你的简历投递过来"
"职位描述：
        
        职位内容：
1、参与互联网数据、日志的数据清洗工作，参与数据仓库分层设计；
2、搭建数据处理相关的分布式计算调度系统，数据地图，算法平台，报表管理等；3、负责不同应用场景下的数据采集、解析、清理，为数据挖掘和机器学习提供支持；4、探索、开发并维护数据基础设施，提供各种高效数据访问和处理工具。

职位要求：
1、本科及以上学历，计算机、数学等相关专业优先；
2、熟悉常用的分布式计算工具，如Hadoop、Spark、Hive；
3、了解分布式计算的原理，有一定的debug能力；
4、能根据文档快速实施ETL方案；
5、工作积极主动、有责任心，具备良好的沟通能力和团队合作精神。

加分项：
1、有爬虫的使用和开发经验，对算法有了解和兴趣；
2、重视代码设计，能基于公司数据框架进行开发。"
"职位描述：
        
        岗位职责：
能独立参与数据仓库项目需求调研、分析、理解数据需求、完成数据模型设计；
任职要求：??
????1.熟悉数据仓库方法论，熟悉ETL架构搭建、调度控制，有搭建BI平台经验者优先；
??????2.精通关系型数据库理论，熟练掌握至少一种主流数据库系统，例如Oracle、MYSQL；
??????3.精通数据建模、数据挖掘预测、领域建模、数据仓库等，具备良好的数据分析技能，抽象汇总能力并精确的分析复杂业务问题；
??????4.善于理解客户需求，积极主动，行动力强，致力于数据仓库和治理；
??????5.有Power?Designer、Erwin等模型管理工具使用经验者优先；
??????三年及以上数据库开发工作经验；"
"职位描述：
        
        1）岗位要求：
1.计算机或者相关专业本科及以上学历，3年及以上相关工作经验；
2.熟悉Spark运行机制，研究Hadoop/Spark/Hbase/Hive等开源项目，对spark读取/写入各类数据源有经验，并开发通用组件；
3.具有spark自定义format的经验者优先
2）任职要求：
1.扎实的计算机系统和算法基础知识；良好的英文阅读能力；
2.扎实的Java、Scala语言基础，对JVM运行机制有深入了解；
3.熟悉Hadoop、Spark并有丰富的开发经验；
4.对常见开源框架代码有研究；
5.熟悉企业应用设计模式、面向对象的分析和设计技术，包括设计模式、UML建模等；
6.善于思考，能独立分析和解决问题，热衷于互联网技术的研究和创新；
7.责任心强，沟通能力好，具备良好的团队合作精神；
8.有深入研究过Hadoop/Spark源码者优先。"
"职位描述：
        
        工作职责:

 负责大数据的应用开发、研发族群文档编写 ；
 负责数据处理解决方案的设计与实施，以支持公司各部门的数据需求；
 参与数据挖掘工作，参与部门沟通，丰富技术实操能力。


任职资格:


 研一/研二在校生，实习三个月以上优先；
 熟悉 mysql语言、Linux操作系统及Hive的应用，了解python编程；
 熟悉数据库操作、维护和清理工作；
 有统计学数学知识，海量数据处理、数据分析和挖掘项目经验优先。"
"职位描述：
        
        职位描述：
1、大数据计算平台系统设计和开发；
2、数据分析应用功能设计与开发；
3、大数据计算平台自监控与维护能力设计与开发。
岗位要求：
1、 本科及以上学历，至少3年以上大数据平台设计与开发经验，Java、Python、Scala至少一种语言开发经验；
2、深入了解大数据计算平台常规架构和相关产品组件（Hadoop、Hive、Spark、Storm、Kafaka）原理、应用场景；
3、对数据处理、数据建模、数据分析、数据架构等有一定理解和认识；
4、极强的责任心、学习能力、沟通协作能力。

（可base深圳）"
"职位描述：
        
        职位描述：
1、大数据计算平台系统设计和开发；
2、数据分析应用功能设计与开发；
3、大数据计算平台自监控与维护能力设计与开发。
岗位要求：
1、 本科及以上学历，至少3年以上大数据平台设计与开发经验，Java、Python、Scala至少一种语言开发经验；
2、深入了解大数据计算平台常规架构和相关产品组件（Hadoop、Hive、Spark、Storm、Kafaka）原理、应用场景；
3、对数据处理、数据建模、数据分析、数据架构等有一定理解和认识；
4、极强的责任心、学习能力、沟通协作能力。

（可base深圳）"
"职位描述：
        
        岗位职责：
1、参与公司大型项目平台研发；
2、负责平台设计、研制及相关文档工作；
任职资格：
1、3年以上全职Java开发经验、精通Java语言、熟悉常用的开源应用框架；
2、熟悉面向对象的分析设计技术，具有Java项目的系统分析、设计和开发经验；
3、具备良好的编码习惯和协作意识以及文档编写能力；
4、熟悉linux下服务器环境部署和性能调优；
5、分布式数据存储和处理技术的实践者，包括但不限于Docker、Hadoop、Spark、Hbase、Kafka、Zookeeper等一种或几种；
6、有GIS、遥感、测绘等专业背景优先;
7、有气象、水利、环保、减灾、国土、等政府部门项目经验优先；
8、熟练使用Scala开发语言优先。"
"职位描述：
        
        1.负责大数据平台各个子系统的开发工作； 2.负责大数据基础技术的调研和选型； 3.结合需求设计高扩展、高性能、高可用的技术系统； 4.负责底层集群技术问题公关，集群调优； 5.海量数据处理或挖掘项目的开发和算法实现。任职要求：1.具有扎实的java功底，掌握分布式、多线程及高性能的设计与编码及性能调优，熟练使用常用关系型数据库，了解SQL优化方法；2.掌握大数据hadoop、flink、spark、hbase、kafaka、Hive、Impala、ELK者，熟悉主流大数据计算产品和数据分析技术并具有一定相关经验者优先； 6.对机器学习、数据挖掘、概率统计等相关算法的原理有一定了解，有实际算法改进经验者加分； 7.对数据仓库各类模型建模理论和分层架构有一定理解者加分； 8.数据敏感，逻辑清晰、严谨；"
"职位描述：
        
        职责：
1、负责大数据架构整体设计和实施，建立数据中台服务能力；
2、负责搭建数据采集系统、数据调度平台、数据可视化产品研发平台；
3、负责数据仓库整体的数据架构、数据建模构建；
4、负责数据质量、安全、元数据管理体系、数据血缘体系搭建和运营；
5、 负责策略算法团队的搭建和运营，建立数据挖掘应用平台。
?
岗位要求：
1、 硕士以上学历，计算机相关专业；
2、 6年以上分布式系统、大数据平台研发经历，3年以上团队管理经验；
3、 熟悉Hadoop、Hive、HBase等开源项目和社区，至少3年以上产品项目应用研发经验；
4、 熟悉Hadoop/Spark等系统，丰富的产品设计、性能调优、开发经验。有MongoDB、Hadoop/Hbase/Cassandra/Storm/Spark/Hive等多系统开发经验；
5、 精通数据库设计，熟悉Oracle/Mysql/Mysql集群等数据库，具有较好的Sql编写及优化能力，熟悉NoSQL；
6、 具有较强的数据挖掘、优化理论、机器学习的理论基础和实际项目经验，精通数据分析与各种算法与模型；
7、 极强的系统设计和系统架构能力，必要的产品管理意识；
8、 对分布式系统、云计算有深刻的理解和相关技术经验。"
"职位描述：
        
        岗位职责：
? ?负责腾讯云日志服务平台研发； ? ? ? ?大规模日志数据存储、分析与处理； ? ?

岗位要求：
? ?1. ?计算机专业本科及以上学历，3年以上互联网后台开发经验； ? ? ? ?2. 熟练掌握linux环境下c++/c/java/golang中的一种或几种； ? ? ? ?3. 熟练掌握常见的数据结构和算法； ? ? ? ?4. 熟悉网络的基本原理，如TCP/IP协议，HTTP协议等； ? ? ? ?5. 具有较好的团队合作和沟通能力； ? ? ? ?6. 有日志平台开发经验优先； ? ? ? ?7. 有检索系统开发经验（PB级）经验者优先考虑； ? ? ? ?8. 有大数据系统开发、OLAP系统开发经验优先； ? ? ? ?9. 熟悉zookeeper，etcd，consul等分布式协调程序中的一种或者几种者优先考虑； ? ? ? ?10. ?熟悉常见大数据基础组件的使用/原理/调优者优先，如Flume/Kafka/Hadoop/Hbase/Spark/Storm/ELK/ETL/kafka/Hive等；"
"职位描述：
        
        职位描述：
1. 负责平台数据分析相关功能和工具的架构和开发；
2. ?用机器?学习相关技术构建数据处理理平台和框架；
3. 理理解业务和?用户需求、业务数据的意义，收集客户/?用户需求；
4. 与产品一起推动相关功能落地，对数据进?行行挖掘和分析；
5. 设计和组建平台?大数据团队；
任职要求：
1. 统计学、计算机、数学等相关专业本科及以上学历；
2. 扎实的编程基础，了了解当前主流的数据处理理?方式和机器?学习框架?方
法；
3. 3年年以上研发工作经验，?至少2年年以上数据分析、数据产品、机器?学习
或人工智能相关项目工作经验；
4. 良好的沟通技巧和团队合作精神，有带领团队的意愿和经验。"
"职位描述：
        
        岗位职责： ? ?
根据产品需求进行方案设计、编码、部署、维护等工作 ; 承担大数据ETL、高效计算，即时查询等数据处理和分析工程开发 ; 负责BI/大数据产品架构设计与开发。
? ?

岗位要求： ? ?
3年以上TB级数据规模大型项目架构/开发/调优经验，具有行业数据平台数据架构和开发工作经验优先； 熟悉常见的算法和数据结构，熟练设计数据模型、ETL设计、Cube多维建模、OLAP开发、报表开发等 ; 熟练使用大数据处理框架（Hadoop/Hive/Spark/Impala/Kylin）相关技术； 熟悉流式计算引擎，对相关框架(Kafka/Storm/SparkStreaming/Flink)熟悉了解，有实际应用经验优先; 熟悉Linux/Unix系统，精通至少一门编程语言Go/Python/Java/C++等； 沟通主动，有较强的工作激情和抗压能力，能组织协同团队开发。"
"职位描述：
        
        岗位职责：
1、负责腾讯内部大数据计算平台的研发，解决用户问题
能在已有平台的基础上，进行二次开发和性能优化，增强其功能
2、对各种开源框架进行深入的代码剖析和优化，并贡献PR，反馈社区
3、参与新的大数据计算平台研发，进行架构设计和开发，达到业界领先的水平。
岗位要求：
1、本科以上学历，计算机或相关专业;?
2、3年以上Linux后台开发经验，有大规模系统开发经验;?
3、精通HTTP、TCP/IP协议，网络编程;?
4、熟悉Linux操作系统原理，常用工具;?
5、熟悉常用大数据开源组件;?
6、有高并发、大容量后台服务系统设计经验
7、对Hadoop、Flink、Spark、Lucene等开源项目有大规模应用经验，Contributor或者Committer优先；"
"职位描述：
        
        岗位职责： ? ?
参与地图数据全业务子系统的系统建设、架构设计、功能开发和优化等工作?
负责地图数据业务后台的系统架构设计和模块开发，为地图数据业务开发高性能、低延迟的数据存储、访问系统和数据流系统 负责道路数据和用户轨迹数据的挖掘体系和平台建设?
负责腾讯LBS数据生产平台后台研发，包括智能化调度平台，数据作业自动化，编辑母库管理等
? ?

岗位要求： ? ?
计算机或者gis相关专业毕业，熟悉常见的数据结构和算法设计，至少会c/c++、python、java中的一种编程语言
优秀的工程能力 对网络编程、数据库编程、数据库存储优化、操作系统、常见的分布化redis、postgres/mysql有较多的经验积累和理解
参与过大型业务系统的设计开发 具备较强的业务分析能力、业务抽强和学习能力，能够应用新技术、提出新想法解决业务问题?
有以下条件优先： 有微服务、缓存&数据库中间件、数据流系统等工作经验者优先 具备地图数据方向的相关后台研发经验优"
"职位描述：
        
        岗位职责?
负责Running数据采集平台的建设和研发工作，确保相关系统的稳定可靠运行；?
对图文数据进行按照产品要求进行分析处理并输出给业务； 参与系统的需求分析、评审；

岗位要求
?统招本科以上学历，计算机或相关专业；
?3年以上相关工作经验，掌握计算机基础知识，具备常规算法基础，熟悉常见的设计模式，有一定的架构能力和良好代码规范； 精通python/php/go任意一种语言,精通网络编程和多线程/多进程开发；
?参与过大型复杂分布式互联网系统的设计，熟悉常用的互联网技术，包括但不限于mysql、redis、rpc等；?
责任感强、有较强的逻辑思维能力、沟通能力和抗压能力强； 有大规模爬虫系统设计和spark大数据分析经验者优先。"
"职位描述：
        
        工作职责：
1、基于微信支付及相关的海量数据，通过各类算法构建风控相关模型，及时发现支付业务及相关金融业务的洗钱及欺诈风险，并进行定性定量分析；
2、构建 异常商户、异常团伙、异常用户的画像体系及感知模型，并不断优化发展模型使之能应对洗钱和欺诈方式的变异和升级；
?
工作要求：
1、有2年以上工作经验，熟悉Hadoop/spark等大数据计算平台；
2、有实际的有监督或无监督模型建模经验，精通一种或多种算法模型，如评分模型、聚类、社团挖掘、文本分析、深度学习等，熟悉python、R等某种编程语言；
3、有互联网/支付/金融方面的建模经验更佳；
4、有风控、业务安全方面的斗争经验更佳。"
"职位描述：
        
        岗位职责： ? ?
? 与产品团队充分沟通，驱动数据采集，构建数据指标体系，对QQ海量数据进行分析、提炼，为QQ大数据应用落地提供开发支持
?? 参与设计和开发QQ后台推荐系统，集成算法模型，实现在线算法
? ?

岗位要求： ? ?
? 对数据结构和算法设计有较为深刻的理解
?? 熟悉操作系统原理、数据库原理等计算机专业知识 ?
? 熟悉Linux、Shell/Python、SQL等，熟练掌握C/C++、Java、Go中至少一门编程语言 ?
? 熟悉大规模高并发处理、分布式存储等互联网后端开发技术者优先
?? 良好的团队合作精神，较强的沟通能力，很强的自我驱动力"
"职位描述：
        
        岗位职责： ? ?
负责POI数据业务后台的架构设计、开发与优化工作；?
对项目中现网问题跟进，疑难问题攻关及优化
? ?

岗位要求： ? ?
本科及以上学历，计算机相关专业，3年以上Linux后台服务器开发经验；?
熟悉python/node.js等开发语言，逻辑清晰，具备良好的分析解决问题能力；?
对后台开发有浓厚的激情，具备后台Server架构设计、开发以及性能调优能力，熟悉MYSQL/NoSQL的开发；?
责任心强，良好的对外沟通和团队协作及自我管理能力； 有LBS类平台开发经验者优先。"
"职位描述：
        
        职位描述：腾讯社交广告系统数据工程平台研发，偏重系统架构设计与实现，参加以下一到多项工作：?
1. 搭建数据仓库，存储并处理海量的实时、批量数据，满足广告业务的定向、分析和模型特征等业务需要
2. 建设数据发布系统，将数据仓库的数据应用到广告在线业务
3. 特征工程工程系统建设，为模型方提供特征数据流和特征离线调研、评估平台，并保证模型训练和预测阶段的特征线上与线下一致性；
4. 用户标识映射、画像数据在线服务的开发与维护；
5. 广告后台海量日志数据和广告主数据处理平台；
6. 报表和广告策略的统计数据生成和存储；
7. 多维透视业务索引和存储；
任职要求：重点大学本科以上学历，计算机相关专业；（说明：一定要985院校，最好是硕士）
具有扎实的数据结构和算法功底；
熟练使用 Java，Scala，C/C++， Python；
有海量数据处理经验，熟悉 Hadoop，Spark，HBase，Beam等开源框架 ；
有分布式系统，Tensorflow等机器学习系统等经验优先 ；
有较强学习能力和逻辑思维能力，具备良好的问题分析与解决能力；
善于沟通，工作积极主动，责任心强，具备良好的团队协作能力"
"职位描述：
        
        
工作职责：
1. 参与风控数据仓库、数据集市、风控大数据智能分析平台的开发和维护
2. 根据风控业务需求，从稳定性、功能、性能、可解释性等方面，参与设计、实现、改进数据平台的相关分析工具。
3. 开发ETL，数据库连接适配、数据同步等数据仓库配套工具。
4. 和技术架构师紧密合作，了解不同客户当前在分析技术上遇到的困难，设计分析类产品帮助业务方解决技术问题，用技术推动风控业务发展。
??


工作要求：
1、计算机相关专业，本科及以上学历，2年以上hadoop/spark/实时计算框架等的开发经验，有hadoop/spark/storm/hbase计算集群在实际项目上的开发和维护经验,对hadoop/spark/hbase等平台计算原理有深刻理解；
2、熟悉数据仓库、数据集市建模，了解业界通用的数仓建模方法。
3、熟悉linux/UNIX shell、熟悉(python/shell)任意一种脚本语言、熟悉Java/Scala等大数据开发语言。
4、熟练Mysql、oracle、redis等数据库，有过数据库调优和海量数据存储经验优先；
5、熟悉业界主流图数据库，有过实际项目经验者优先；
6、对新技术充满热情，具有良好的学习能力、团队协作能力和沟通能力；"
"职位描述：
        
        岗位职责： ? ?
风控风险大数据平台的建设以及数据和服务安全方面的建设； 负责海量大数据的清洗、特征挖掘工作。
? ?

岗位要求： ? ?
1、计算机相关专业，本科及以上学历，2年以上hadoop/spark/实时计算框架等的开发经验，有hadoop/spark/storm/hbase计算集群在实际项目上的开发和维护经验；?
2、对hadoop/spark/hbase等平台计算原理有深刻理解；?
3、熟悉spark流计算框架或其他开源实时计算框架；?
4、精通JAVA、Scala熟练掌握MapReduce、RDD原理及数据分析相关的二次开发；?
5、熟悉linux/UNIX shell、熟悉(python/shell)任意一种脚本语言；
6、有互联网爬虫开发、内容提取工作经验1年以上;?
7、熟练Mysql、oracle、redis等数据库，有过数据库调优和海量数据存储经验优先；?
8、对新技术充满热情，具有良好的学习能力、团队协作能力和沟通能力。"
"职位描述：
        
        岗位职责
分布式大数据计算平台开发；
数据计算性能调优；
高性能服务框架设计与开发；
大数据关联性分析与洞察。
岗位要求
全日制计算机相关专业本科及以上学历；
熟练掌握开源大数据处理技术栈，有Hadoop/storm/hive/spark等计算框架两年以上实际项目使用经验，深入阅读或修改过源码者优先；?
熟悉常用脚本语言(shell,perl,python)；?
熟练掌握数据仓库建模技术；
有过大数据系统架构经验或相关开源社区活跃者优先；
有互联网广告经验者优先。"
"职位描述：
        
        岗位职责： ? ?
? 与产品团队充分沟通，驱动数据采集，构建数据指标体系，对QQ海量数据进行分析、提炼，为QQ大数据应用落地提供开发支持 ? 参与设计和开发QQ后台推荐系统，集成算法模型，实现在线算法
? ?

岗位要求： ? ?
? 对数据结构和算法设计有较为深刻的理解 ? 熟悉操作系统原理、数据库原理等计算机专业知识 ? 熟悉Linux、Shell/Python、SQL等，熟练掌握C/C++、Java、Go中至少一门编程语言 ? 熟悉大规模高并发处理、分布式存储等互联网后端开发技术者优先 ? 良好的团队合作精神，较强的沟通能力，很强的自我驱动力"
"职位描述：
        
        岗位职责：
? ? 腾讯社交广告系统数据工程平台研发，偏重系统架构设计与实现，参加以下一到多项工作： ? ? ? ? ?1. 搭建数据仓库，存储并处理海量的实时、批量数据，满足广告业务的定向、分析和模型特征等业务需要 ? ? ? ?2. 建设数据发布系统，将数据仓库的数据应用到广告在线业务 ? ? ? ?3. 特征工程工程系统建设，为模型方提供特征数据流和特征离线调研、评估平台，并保证模型训练和预测阶段的特征线上与线下一致性； ? ? ? ?4. 用户标识映射、画像数据在线服务的开发与维护； ? ? ? ?5. 广告后台海量日志数据和广告主数据处理平台； ? ? ? ?6. 报表和广告策略的统计数据生成和存储； ? ? ? ?7. 多维透视业务索引和存储； ? ?
岗位要求：
? ?重点大学本科以上学历，计算机相关专业； ? ? ? ?具有扎实的数据结构和算法功底；  ? ? ? ?熟练使用 Java，Scala，C/C++， Python； ? ? ? ?有海量数据处理经验，熟悉 Hadoop，Spark，HBase，Beam等开源框架 ； ? ? ? ?有分布式系统，Tensorflow等机器学习系统等经验优先 ； ? ? ? ?有较强学习能力和逻辑思维能力，具备良好的问题分析与解决能力；  ? ? ? ?善于沟通，工作积极主动，责任心强，具备良好的团队协作能力；"
"职位描述：
        
        岗位职责：
1）负责AI平台和相关行业应用产品的后台研发。
岗位要求：
1）本科以上学历，计算机相关专业； ?
2）精通Linux和C++、GO等一种编程语言；?
3）热爱编程，能独立完成模块开发和交付工作；?
4）具备较广的技术视野和对技术有热情，能主动专研；?
5）具备良好的沟通表能力及团队协作精神、有较强的主动性、责任心与执行能力；?
6）有云计算、AI产品或SaaS服务开发交付经验者优先"
"职位描述：
        
        岗位职责：
负责广告后台海量日志数据和广告主数据处理平台；
负责报表和广告策略的统计数据生成和存储；
负责构建和维护稳定可靠的特征模型框架；
负责多维透视业务索引和存储。
任职要求：
大学本科以上学历，计算机相关专业；
两年以上相关工作经验，精通算法与数据结构，精通java/scala或c++编程语言；
有扎实的编程功底和编码习惯，以及良好的分析解决问题能力;
熟悉分布式计算和存储框架，熟悉hadoop, hbase, spark等分布式计算存储平台者优先;
积极主动，有责任心，勇于接受挑战。"
"职位描述：
        
        岗位职责：
腾讯社交广告系统数据工程平台研发，偏重系统架构设计与实现。
参加以下一到多项工作：?
1. 实时报表系统的设计与开发
2. DMP后台数据洞察与标签管理开发
3. 分布式查询系统元数据管理开发
任职要求：
本科以上学历，计算机相关专业；?
具有扎实的数据结构和算法功底；?
熟练使用 Java，Scala，C/C++， Python； 有海量数据处理经验，
熟悉 Hadoop，Spark，HBase，Beam等开源框架 ；
有较强学习能力和逻辑思维能力，具备良好的问题分析与解决能力；?
善于沟通，工作积极主动，责任心强，具备良好的团队协作能力。"
"职位描述：
        
        工作内容：
设计、实现云上大数据产品的架构，并且能持续优化系统架构，提高系统在高并发、大流量下的容灾容错能力，保证系统的高可用性（性能、安全、容量）； 2.通过梳理和抽象，沉淀通用性的平台或服务能力，发现和解决存在的技术问题，并在具体的业务场景中进行验证推广。

工作要求：
1. 扎实的java编程基础，熟悉Spring等开源框架，熟悉Java内存模型、多线程、NIO、类加载等。
2. 熟悉Linux、数据库、NoSQL、分布式存储，熟悉高并发、微服务、海量数据下的典型架构设计和性能优化之道。?
3. 精通常用架构原则、设计思想，熟悉微服务治理，能高度融入互联网研发节奏。?
4. 对数据敏感，有Hadoop、SparkMLib、Storm、Mahout、TensorFlow使用经验者优先，有大数据产品研发经验的优先。 5. 有SaaS平台、舆情、数据爬虫、分布式调度、搜索推荐、广告营销、LBS开发方面的从业经验优先。"
"职位描述：
        
        岗位职责：
1、负责腾讯财经大数据平台的建设和发展；
2、负责整体ETL设计和开发以及点问题处理、及核心复杂业务代码的设计和研发。

岗位要求： ? ?
1、计算机或金融/财经、数学相关专业，有5年以上的工作经验，熟悉数据仓库相关知识和理论，至少3年以上大型数据仓库开发经验；
2、精通Oracle数据库，精通PLSQL开发，熟悉sql的性能优化方法；
3、熟悉数据仓库ETL开发和流程，能根据业务需求设计整体的ETL方案和开发；
4、熟悉java或scala语言，对分布式、网络、高并发有自己的理解，对中型java项目有架构能力；?
5、深入大数据生态体系，对hadoop，spark，hive等分布式框架有深刻理解，通读主要源码，有大数据项目构建经验。"
"职位描述：
        
        岗位职责:

 负责看点及内容中台的整体数据体系架构设计及建设；
 负责数据实时检索分析平台的架构和建设;
 负责数据采集、数据分析及业务数据挖掘等；

岗位要求:

 3年以上软件开发经验，1年以上数据平台相关开发及架构设计经验；
 对大数据基础架构和平台有深刻理解，具备Hadoop生态圈核心组件（Hadoop, hive, Hbase等）项目应用研发经验;
 熟悉大数据相关基础组件如Spark, Kafka, Druid, ElasticSearch等，具备源代码级问题解决和集群优化改造能力者优先；
 熟悉分布式存储和NoSQL数据库技术，有实际生产项目应用经验；
 熟悉主流数据库技术（如GP, Mysql等），精通SQL，有一定SQL编码及调优经验；
 具备丰富的数据分析，挖掘和数据仓库建模的项目实践经验者优先"
"职位描述：
        
        
工作职责：
负责翻译训练语料的自动分析、筛选及评价；
负责用户数据的自动分析和管理；
负责翻译数据评测体系、数据分析处理平台等系统的开发；
? ?


工作要求：
计算机及相关专业本科及以上学历，3年以上从业经验；
有机器学习、文本挖掘两年以上经验优先；
熟悉NLP相关技术，熟悉文本挖掘、数据分类等任务的主要方法；
学习能力强，对新鲜事物充满浓厚的兴趣 ，有耐心；
熟练掌握C++/Java/scala/python等一种编程语言；"
"职位描述：
        
        
工作职责：
医疗数据的分析和处理：
实现影像和医技非结构化数据的处理应用，以及用户健康画像生成。
? ?


工作要求：
1. 计算机本科及以上学历，3年及以上Linux/Unix系统下数据相关开发经验。
2. 熟悉shell,python等脚本语言。熟悉MYSQL或其他大型数据库，有一定SQL编码及调优经验，熟悉java,Scala等语言更优。
3. 熟悉Hadoop，Spark，Storm等大数据计算框架以及TensorFlow，pytorch等深度学习平台，有海量数据处理经验。有用户画像和知识图谱相关积累。
4. 具备医疗行业信息化产品或者研发领域行业经验优先。
5. 自我驱动力强、有高度责任心和团队合作精神。"
"职位描述：
        
        
工作职责：
负责移动互联网产品的运营数据分析体系搭建；
负责事业群决策或市场数据模型、平台、产品的规划建设；
参与构建各种分析模型，跟踪和分析运营数据，发现潜在的缺陷与机会，为业务决策提供数据支撑，并推进落地。
? ?


工作要求：
熟悉数据仓库和数据建模的相关技术细节，熟悉SQL/Hadoop/Hive等大数据分析工具；
2年以上数据处理、分析相关项目经验；参与过完整的数据采集、数据清洗、分析和建模工作者优先；
有的Spark Storm等主流的大数据计算组件有开发和使用经验者优先；
良好的沟通能力、逻辑分析能力，善于总结，能抓住问题的重点；
良好的团队合作精神。"
"职位描述：
        
        岗位职责：负责腾讯游戏运营支撑数据平台的建设；负责海量数据的接入、计算、存储、查询和分析；参与数据平台自助化建设。
岗位要求：计算机相关专业，3年及以上相关工作经验，有扎实的计算机理论基础；精通Java/Scala/Python程序开发(至少一种)，熟悉Linux/Unix开发环境；?深入理解MapReduce，熟练使用Storm、Hadoop、Spark、Flink，并阅读部分源码；熟练使用HDFS、Hbase、Kafka、ElasticSearch、InfluxDB；具有高扩展性、高性能和分布式系统的实践经验；对分布式系统以及消息队列中间件有实践经验；具有Spark?Streaming、MLlib使用经验优先； 具有良好的沟通能力、学习能力、分析解决问题能力；具有高度的责任心和团队合作精神。"
"职位描述：
        
        岗位职责:
1：负责构建公司级内容平台的海量数据分析，挖掘工作；
2：跟进内容平台的数据梳理，各数据指标的计算和分析
3：参与海量数据的存储、查询和运营数据分析体系搭建
岗位要求:
1. 计算机相关专业，3年及以上相关工作经验,有扎实的计算机理论基础;
2. 熟悉hadoop、spark、ES等分布式计算和存储平台，研究过Hadoop或者Spark源代码的优先;
3. 熟悉Java/Python等编程语言，熟练使用SQL，有良好的编码习惯;  4. 技术视野开阔，有强烈的上进心和求知欲，善于学习和运用新知识；
5. 善于沟通和逻辑表达，良好的团队合作精神和积极主动的沟通意识；
6. 具备大数据云平台、计算存储平台、可视化开发平台经验优先；"
"职位描述：
        
        负责海量智能监控体系建设，调研业界优秀监控方案，深入理解用户需求，规划和实施监控体系升级和演进；
负责海量数据存储架构设计和建设。深入掌握当前监控海量存储架构，调研对比业界优秀存储方案后，对现有架构进行优化升级；
负责海量数据处理架构设计和建设。深入掌握当前监控海量数据处理架构，调研对比业界优秀数据处理框架，对现有架构进行优化升级；
负责监控功能开发，打造业界优秀的监控解决方案。"
"职位描述：
        
        
1.?基于大数据平台，负责BI、画像、数据仓库的开发和应用；2.?基于海量用户行为数据，建立、评估、持续优化数据模型，包括但不限于：用户价值评分、用户风险评分、用户偏好预测?、用户画像构建等等，产出用户标签；3.?结合公司的业务场景，进行数据产品设计，解决业务痛点，提升用户体验，探索新的商业模式；

任职资格

1.?本科及以上学历，计算机或数学相关专业，2.?思维清晰敏捷，逻辑分析能力强，具有良好的语言和书面表达能力；3.?精通hive?sql，有海量数据处理的调优经验；4.?熟悉spark优先；5.?用户画像构建和应用实战经验的优先；6.?有数据挖掘实践经验，擅长从海量数据中发现有价值的规律的优先；"
"职位描述：
        
        岗位职责：
数据接入DMP的清洗
大数据特征抽取、参数选择、算法实验、效果分析等
岗位要求：
至少3年工作经验
精通大数据采集、处理、存储、查询相关技术
熟练使用SQL，有一定的编码基础，并能使用Spark、Hive做数据清洗
具有高度的责任心和团队合作精神"
"职位描述：
        
        岗位职责：????????????????负责智慧零售大数据开发、数据挖掘、算法平台的技术架构及建设；??????????负责支持KA大数据实时检索分析平台的架构和建设；?????????负责智慧零售业务挖掘、算法应用的平台支持；岗位要求：?????????3年以上软件开发经验，2年以上数据平台相关开发及架构设计经验；??????????精通JAVA/C++开发语言，熟悉常用脚本语言(shell,perl,python)；?????????对大数据基础架构和平台有深刻理解，具备相关产品（Hadoop,hive,Hbase,pig等）项目应用研发经验；??????????精通大数据周边技术如Storm,Spark,Flume,Kafka等，具备源代码级问题解决和集群优化改造能力者优先；??????????精通主流数据库技术（如Oracle,SQLServer2000,GP,Mysql等），精通SQL，有一定SQL编码及调优经验；??????????具备丰富的数据分析，挖掘和数据仓库建模的项目实践经验?????????思路清晰，积极主动，具备良好的沟通能力和团队协作精神；?对智慧零售工作有持续的热忱和激情。"
"职位描述：
        
        岗位要求:
本科及以上学历，计算机相关专业，3年以上Linux后台服务器开发经验；
熟悉python/node.js等开发语言，逻辑清晰，具备良好的分析解决问题能力；对后台开发有浓厚的激情，具备后台Server架构设计、开发以及性能调优能力，熟悉MYSQL/NoSQL的开发；责任心强，良好的对外沟通和团队协作及自我管理能力；有LBS类平台开发经验者优先。 ? ?
岗位职责：
负责POI数据业务后台的架构设计、开发与优化工作；对项目中现网问题跟进，疑难问题攻关及优化"
"职位描述：
        
        【岗位职责】（1）负责内部数据提取、清洗；（2）对平台进行运营，满足用户需求。
【岗位要求】
（1）计算机相关专业本科及以上学历，半年以上工作经验；（2）了解Hadoop、Hive、Spark等大数据技术，具备一定的SQL和数据处理能力；?（3）具有良好的解决问题能力、学习能力、沟通表达能力；（4）工作细致，具有良好的团队合作精神，高度的责任感与抗压能力。"
"职位描述：
        
        职位描述：
【工作职责】
1. 负责数据分布式存储、计算系统；
2. 高水平团队，有 Ownership 的推动数据系统迭代；
3. 从架构到业务，支持公司快速发展；
4. 支持 CRM、搜索、机器学习平台等应用的底层数据架构。
?
【职位要求】
1. 掌握分布式系统原理，对存储、离线计算、实时计算中的一项或多项有深入的理解和认
识；
2. 很强的系统设计&编码能力，追求优雅的设计和优秀的代码质量，高标准，快速行动；
3. 思路清晰，具备生产系统快速 trouble-shooting 的经验和能力，擅长分析更深层次的原
因；
4. 对 HDFS, RocksDB, LevelDB, Memcache, Redis, MySQL, HBase, Kafka 的一项或多项有开发
经验；
5. 了解 Kafka、 MQ 等消息系统；
6. 对 Spark, Druid, Flink, OLAP 的一项或多项有经验者优先；
7. 拥抱新技术，有很强的学习能力。"
"职位描述：
        
        岗位职责：参与数据平台设计和架构；负责核心模块的开发；负责大数据系统的优化和监控运维；任职要求：具备扎实的计算机专业基本功；掌握Java开发语言；熟悉Linux操作系统；掌握常见的运维监控工具由一定的了解；熟悉大数据生态技术圈,?精通大数据生态架构,?有大数据平台的构建经验；熟悉Sql开发和Mysql等常见关系型数据库；熟悉Mysql，?Redis,?HBase等数据库的使用；熟悉Kafka，Storm，Hadoop等大数据工具相关的开发；熟悉Apache?Druid,?ElasticSearch等OLAP数据库；较强的学习能力和解决问题的能力,?能够阅读英文技术文档；"
"职位描述：
        
        岗位描述
1、负责在线/同步实时数据处理框架的设计、架构、开发。包括但不仅限于内核引擎，二级调度，统一编程语言，功能算子，开发平台，质量框架等等；?2、负责实时特征服务平台的建设，为蚂蚁智能决策建设特征体系，借助各个实时数据引擎，提供一站式的特征研发平台；?3、参与数据驱动业务的建设及发展，包括制定符合数据驱动特性的开发流程，搭建数据驱动相关技术生态，开发实时数据生态中间件等等；?4、保障和承担实时数据相关业务的稳定性，例如实时营销，线下支付，安全攻防等等。参与所有公司相关的大型技术活动（如双11，双12，新春红包），承担实时数据领域的大促值班，确保每一次活动的平稳顺利渡过。
岗位要求
1、熟悉至少一种开源流数据引擎，包括但不仅限于：Storm/Jstorm，Spark Streaming，Flink，Samza，Kafka，Puma，Esper等；有开发、设计、使用ETL，CEP相关框架者优先。?2、熟练掌握Java开发语言，具有优秀的架构设计能力，优秀的编程能力及优良的开发习惯。具备独立沟通需求，设计，架构，开发的能力；?3、有良好的业务及产品感觉，可以站在使用者角度设计技术产品。可以主动并乐于了解日常业务，具备从日常业务中发现问题并解决问题的能力；?4、具备强烈的进取心、求知欲及团队合作精神，具有良好的沟通能力。"
"职位描述：
        
        岗位描述
1、负责全域数据和应用产品的数据体系的建设，通过数据+算法+工程化能力，处理和萃取数据，让其成为应用和产品的能源；2、参与大数据基础架构和技术体系的规划建设，包括数据采集平台、数据资产管理与治理平台、数据质量及稳定性保障体系、数据处理智能化和自动化体系的建设。3、 以上工作职责有具体的细分，你可以基于你的兴趣和爱好选择不同的方向发展；
岗位要求
1、有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关开发经验，有Spark/Flink的开发经验尤佳；2、较为丰富的数据仓库及数据平台的架构经验，精通数据仓库建模及ETL设计开发；有较为系统的海量数据性能处理经验；在大数据资产管理与治理有一定成功产品化经验；3、具备丰富的大型互联网日志采集系统设计或架构经验，具备较扎实的理论基础和工程能力，熟悉HTTP、HTTPS等协议，有nginx、apache等web服务器上的模块开发或子系统的架构设计能力，有ios或android客户端SDK及服务端架构设计经验；4、具备一定的JAVA、Python语言的开发能力，具备机器学习算法能力尤佳；5、以上能力项不是全部要求，我们有多个细分岗位供您选择，如果您具备部分能力项，为何不创造一次选择的机会？ 欢迎聪明、自省、乐观、皮实的您！"
"职位描述：
        
        岗位职责：
1. 负责大数据平台查询优化器相关的设计，开发，文档撰写
2. 负责大数据平台 SQL 层的设计，开发和性能优化
3. 参与大数据平台底层系统存储系统的设计
4. 参与大数据平台AI部分设计，实现和应用
?
?
岗位要求：
1、全日制本科以上学历毕业生，计算机/软件工程/信息管理/数学与应用数学/自动化/通信工程/电子信息工程等理工科类专业。
2、熟悉Java技术规范。
3、精通Spark，有对于Spark二次开发经验，熟悉Spark架构设计及原理。
4、精通Spark Sql实现原理，熟悉Spark Catalyst过程，对于SparkSql 解析器 优化器有较深的理解。
5、熟悉Oracle或MySQL中的一种数据库，能熟练编写SQL语句；
6、拥有一定项目经验者、熟悉团队开发模式者优先；
7、数据结构和算法设计有较深的理解者优先。"
"职位描述：
        
        1、从事建设银行的数据加载，加工开发等工作；
2、涉及客户回馈、代理保险、代理银行、综合积分、企业现金、对公存款查询、电子不停车收费（ETC）、综合签约等业务的数据加载加工，转换等工作。"
"职位描述：
        
        联雅网络主要从事跨境独立站设计业务,办公地点在越秀区繁华地段，交通便利.

工作职责：
负责公司产品所有内部数据的数据接入、清洗、存储和展示；
负责公司产品研发过程中,智能数据部分的建设；

工作要求：
本科及以上，具备2年以上相关工作经验；
熟悉?Linux?操作系统和开发环境，熟练掌握SQL；
良好的统计分析基础，较高的数据敏感性；
具备海量数据处理相关经验优先；
对AB测试理论熟悉,有数据分析师工作背景优先；?
具备abtest实验系统建设经验优先；
具备同时上线上百个实验的经验优先

薪金待遇:
1.工资：基本工资+高提成
2.购买五险（医疗险、工伤险、养老险、生育险、失业险）
3.公众假期按照国家规定休息，春节休息十天；
4.平均每周工作时间5.5日
5.每年1-2次公司组织旅游；
6.提供健全的培训制度，良好的学习，晋升平台；
7.每月文娱活动，拓展培训。


欢迎有能力有经验的您加入到我们的年轻的团队共同发展。
官网：www.ueeshop.com
工作地址：广州市越秀区越秀南路185号创举商务大厦10楼整层"
"职位描述：
        
        联雅网络主要从事跨境独立站设计业务,办公地点在越秀区繁华地段，交通便利.

工作职责：
负责公司产品所有内部数据的数据接入、清洗、存储和展示；
负责公司产品研发过程中,智能数据部分的建设；

工作要求：
本科及以上，具备2年以上相关工作经验；
熟悉?Linux?操作系统和开发环境，熟练掌握SQL；
良好的统计分析基础，较高的数据敏感性；
具备海量数据处理相关经验优先；
对AB测试理论熟悉,有数据分析师工作背景优先；?
具备abtest实验系统建设经验优先；
具备同时上线上百个实验的经验优先

薪金待遇:
1.工资：基本工资+高提成
2.购买五险（医疗险、工伤险、养老险、生育险、失业险）
3.公众假期按照国家规定休息，春节休息十天；
4.平均每周工作时间5.5日
5.每年1-2次公司组织旅游；
6.提供健全的培训制度，良好的学习，晋升平台；
7.每月文娱活动，拓展培训。


欢迎有能力有经验的您加入到我们的年轻的团队共同发展。
官网：www.ueeshop.com
工作地址：广州市越秀区越秀南路185号创举商务大厦10楼整层"
"职位描述：
        
        职责描述：1、负责医疗数据集成平台产品的功能设计；2、负责医疗数据集成平台产品的功能模块开发；3、负责对ESB产品的二次封装开发；任职要求：1.学历：本科2.专业及行业经验：计算机相关专业；具有6年相关工作经验，对医疗信息软件有深刻的理解，熟悉医疗信息化相关标准与数据规范3.熟悉Java编程语言，有Shell或Ruby/PHP/Perl/Python等使用经验者优先；熟悉Linux操作系统，熟悉Oracle；熟悉主流java web框架；4.工作经验：具有2个及以上医疗信息化软件系统设计以及开发（集成平台、HIS、EMR）"
"职位描述：
        
        岗位职责:
1.负责公司安全攻防、安全渗透测试、安全应急响应和追踪溯源等安全技术工作
2.负责公司与国际、国家安全相关机构、安全研究机构等的安全技术交流和协作
3.负责公司安全评估、安全扫描、网络安全防护、Web安全防护、数据安全防护等安全技术工作；
4.负责公司的大数据安全数据分析工作；
5.负责公司大数据产品和方案中安全相关的技术支撑；
?
?
岗位要求：
1.计算机、软件工程、通信、信息安全相关专业全日制本科以上学历，具有信息安全工作经验2年及以上；
2.具备实际的安全攻防和安全维护经验，能够独立开展安全技术评估和防护工作，能够熟练使用各类扫描工具、弱口令探测工具、探工具、Web系统渗透工具、后门检测工具；
3.至少精通一门编程语言Java/C/C++/Perl/Python/PHP/Go等，有较强的独立编程能力；
4.具有良好的沟通能力，具备较强的新知识学习能力，具有强烈的进取意识及责任心，诚实敬业；
5.参加过国内外知名安全攻防竞赛并取得优异成绩者优先,取得ISO27001、CISSP、CISP证书者优先，具有主流安全厂商工作经验者优先。"
"职位描述：
        
        岗位职责：1.负责平台类和服务类大数据产品的规划、需求分析和架构设计；2.研究大数据平台的开放形态和生态，建立和维护大数据平台技术标准规范，推动业务领域内的数据产品的创新和设计；3.进行大数据的挖掘、存储、抽取、计算、应用、整合、可视化及API接口设计等研发工作，进行数据质量控制；4.负责新技术的调研和选型，设计和实现数据安全架构和数据权限控制；5.管理和指导大数据团队日常工作，选拔和培养合格的大数据人才，形成合理梯队；岗位要求：1.计算机、软件工程、通信相关专业全日制本科以上学历；? ? ? ??
2.精通Java、Python、Scala中至少一门开发语言，能熟练编写数据应用；3.精通Hadoop框架体系，能够熟练应用Hive、Hbase工具，精通Spark、SparkSQL、SparkStreaming，Storm等技术框架，具有项目经验；4.5年以上大数据相关工作经验，2年以上团队管理经验，分析能力、逻辑思维和沟通交流能力强，执着于技术未知领域的探索；5.熟悉Kafka、Redis、Memcache等消息或缓存框架和Sqoop、Flume、Spider等数据或日志采集技术优先；6.熟悉大数据的硬件基础设施(机器选型、网络架构)等主要设备的运行特点和性能指标优先；7.理解病掌握kubernetes、dcos等资源调度系统的工作原理和实现方式。"
"职位描述：
        
        岗位职责：
1、负责大数据应用功能开发；
2、负责编写数据ETL程序；
3、负责数据平台类相关模块的研制工作，包括采集，调度，任务，服务等；
4、负责数据平台产品化。
?
任职资格：
1、计算机或相关专业等相关专业本科及以上学历
2、基础扎实， 熟悉 linux 系统， 熟练使用 java,scala,python,shell 等至少一种以上语言
3、熟悉Hadoop、HBase、Hive、Storm、Spark、Mahout、NoSQL、ES中至少一种技术，阅读过源代码者优先；
4、充分理解大数据背景下的计算模型，熟悉MapReduce、Spark开发流程模型中任一，并具有分布式开发经验；
5、具备产品化思维，有相关平台开发运维经验优先；
6、具备较强的逻辑思维能力、学习创新能力、数据分析能力，以及良好的沟通技巧和团队合作能力。"
"职位描述：
        
        工作职责:1、基于hadoop、elasticsearch、flink、hbase等大数据组件进行大数据平台的搭建（安装、开发、部署、实施）2、基于java进行数据分布式处理的开发3、数据深度挖掘，发现潜在规则4、数据分布式处理优化任职资格:1、本科及以上学历，计算机等相关专业，211和985优先；2、有1-5年及以上大数据项目经验；3、精通Hadoop、Map-Reduce、Hbase、elasticsearch、消息中间件、Flink应用开发经验，熟悉Hive、Spark、Kylin等大数据开发工具者优先；4、精通SQL开发，精通Mysql、Oracle等关系型数据库中的一种；5、具备开发分布式系统能力，掌握大数据常见的java、python等语言的开发能力。6、具备数据深度挖掘能力，可发现潜在数据规则7、具备大数据平台搭建和优化能力
福利待遇：1、基本薪资（面议）+ 年终奖（2-4个月）2、补贴：餐补+高温补贴+过节费3、六险一金 + 商业保险4、每年定期的健康体检?5、丰富多彩的社团活动?7、每月按部门有活动经费8、5-15天带薪年假"
"职位描述：
        
        职位描述：
1. 参与大数据的采集、存储、处理，通过分布式大数据平台加工数据，支持业务管理决策;
2. 参与大数据体系的设计、开发、维护，通过数据仓库、元数据、质量体系有效的管理和组织几十PG的数据;
3. 参与大数据产品的研发，通过对数据的理解，发掘数据价值，探索大数据商业化;
任职要求：
1. 所学专业是计算机、数学、统计等相关专业皆可;
2. 有较强的动手能力和学习能力，熟悉SQL,熟悉JAVA、Python,Shell其中一种编程语言，熟悉unix或者linux操作;
3. 具备扎实的专业基础，良好的沟通能力和团队合作，主动积极、乐于面对挑战;
4. 有参与数据处理、分析、挖掘等相关项目优先 ;
5.对Hadoop、Hive、Spark、Hbase等分布式平台有一定的理解优先;"
"职位描述：
        
        岗位职责：
1.???? 负责分布式存储平台的设计及研发；
2.???? 负责大数据接入系统的设计和研发；
3.???? 持续对系统进行性能优化、功能改善以及稳定性提升；
岗位要求：
1.???? 计算机相关专业，硕士及以上学历；
2.???? 熟悉Java的基础技术体系，包括JVM、线程、并发、IO资源管理、网络等；
3.???? 熟悉HDFS、Hive、Kafka、Flink等开源存储系统中的至少一种，有源代码阅读及修改经验。
4.???? 熟悉分布式存储系统原理，有相关设计经验优先；
5.???? 对Paxos/Raft算法、高可用、高可靠架构等有深入理解，并有一定的实践经验。有压缩算法设计、存储结构设计等经验者优先考虑；"
"职位描述：
        
        岗位职责：
1.???? 负责分布式存储平台的设计及研发；
2.???? 负责大数据接入系统的设计和研发；
3.???? 持续对系统进行性能优化、功能改善以及稳定性提升；
岗位要求：
1.???? 计算机相关专业，硕士及以上学历；
2.???? 熟悉Java的基础技术体系，包括JVM、线程、并发、IO资源管理、网络等；
3.???? 熟悉HDFS、Hive、Kafka、Flink等开源存储系统中的至少一种，有源代码阅读及修改经验。
4.???? 熟悉分布式存储系统原理，有相关设计经验优先；
5.???? 对Paxos/Raft算法、高可用、高可靠架构等有深入理解，并有一定的实践经验。有压缩算法设计、存储结构设计等经验者优先考虑；"
"职位描述：
        
        岗位职责：
1.???? 负责大数据基础平台、数据分析产品的系统设计及开发；
2.???? 负责大数据平台的搭建、监控、性能调优；?
岗位要求：
1.???? 计算机相关专业，硕士及以上学历，3年左右大数据或者Java开发工作经验；
2.???? 有较强的开发能力，包括设计，编码，调试能力；
3.???? 熟悉主流的开源大数据技术，Hadoop、Spark、Kafka、Flink、hive等至少一种，在开源社区活跃者优先；
4.???? 对高稳定、高可用、高性能、大数据处理有过实际项目者优先考虑；"
"职位描述：
        
        工作职责:1. 参与大数据平台、金融相关数据处理业务的开发；2．参与细分领域的知识图谱的构建，复杂网络技术研发；3．利用机器学习、深度学习等前沿技术，提高知识抽取和信息抽取过程的自动化水平。任职资格:1．本科及以上学历，计算机等相关专业； 2．3年及以上相关经验，对大数据或算法有强烈兴趣；掌握复杂网络各个方向上的常用算法，有大规模计算经验优先；3.熟悉Hadoop生态系统内常见项目的使用（Hdfs、Hive、Hbase、Spark、Zookeeper、Yarn等），具有Map Reduce开发经验；4．熟悉知识图谱的构建，熟悉至少一种图数据库，如：Neo4j；熟悉自然语言处理方向常用技术，命名实体识别，关系抽取，句法分析等；5. 具有良好的沟通、组织、团队协作、分析和解决问题的能力。"
"职位描述：
        
        工作职责:1. 参与大数据平台设计和实施，负责基于Hadoop生态的大数据平台相关的应用开发；2. 进行大数据相关新技术的研究和落地；3. 完成上级交办的其他任务。任职资格:1. 本科及以上学历，计算机等相关专业；2. 具备3年以上大数据相关应用开发经验，熟练掌握Java语言，熟悉Hadoop、HBase、Hive等大数据相关技术；3. 熟悉Kafka消息框架，了解Flume、Logstash等日志收集系统；熟悉Spark流式计算框架、Shell、Python；4. 热爱技术，喜欢钻研，善于沟通，有团队合作精神。"
"职位描述：
        
        职位描述：
为服务供应链串联多渠道数据；对大数据进行管理、分析。
1、熟悉python爬虫，能自主做小程序
2、精通excel，能做report自动化3、做事积极主动，能够主动学习新知识，具有高度的责任感与团队合作精神"
"职位描述：
        
        岗位职责：
1、负责数据收集、清洗等工作；? 2、提供面向业务的数据服务，完成数据指标的统计、多维分析和展现；? 3、根据业务和产品情况，抽象业务逻辑，搭建和开发大数据平台。
4、实现端到端的自动化，配合各个部门完成无人供应链计划
?
职位要求：
1、统招本科或以上学历计算机相关专业在读学生，2020届，2021优先；
2、精通Python,Java等脚本语言的一种或多种，编码基本功扎实，有网页开发经验优先;
3、要求工程类背景，对PC有基本的认知和兴趣，有一定的英语听说读写能力，逻辑和沟通能力出众，有激情，有自信，有梦想
4、自我学习、驱动能力强，能够编写开发文档。一周可实习三天及以上。"
"职位描述：
        
        岗位职责：
1、保质保量完成自己每日或者阶段性的数据集成配置工作目标；?
2、完成流程配置过程文档编写；
3、做好工作周报、月报，季度工作总结；

任职要求：
1、本科以上学历，计算机、软件工程等相关专业；
2、一年以上相关数据处理工作经验；
3、熟悉掌握oracle,ServerSQL,MySql数据库其中一种；
4、具备一定的分析能力和解决问题的能力，积极主动、责任心强、善于沟通。
5、掌握ODI，ESB、OGG,Kettle等其中一种中间件优先"
"职位描述：
        
        一、任职资格：
1、年龄要求：22岁以上；
2、学历要求：大专以上学历；
3、专业要求：计算机、工程等相关学历；
4、经验要求：2-5年工作经验；
5、其他要求：
1） 具有基本的数据处理思维，了解数据处理的方式；
2） 掌握至少三种数据处理的设计与实现的理论与知识；
3） 熟悉unix或linux，熟悉开发必需的系统管理操作命令；
4） 精通Python/Java/Scala中任何一门开发语言；
5） 精通Shell、SQL语言，具有常用数据库系统(Oracle/DB2/MySQL)的开发实施经验
6） 熟悉Hadoop、Spark等大数据产品。
?
二、岗位职责：
1、 组织及实施数据处理设计与开发，包括数据接口设计，采集，整合，存储的开发；
2、 测试与部署；
3、 对已交付的系统与平台提供运维支持；"
"职位描述：
        
        岗位职责：
1、负责大数据平台软件环境搭建及维护；
2、负责大数据技术的研究及应用；
3、负责异构数据收集并加载到大数据平台；
4、负责网络数据抓取规划并提供网络信息提取解决方案。

任职要求：
1、熟悉Hadoop的体系架构和运行原理，有Hadoop方面项目经验；
2、对Hadoop的MapReduce原理有深入研究，有JAVA或Python语言环境下的MapReduce实际开发及部署、调优及维护经验；
3、具有构建及优化基于Hadoop/Hive/Hbase的海量存储产品设计及调优能力，具有数据分析、数据挖掘，文本挖掘、海量数据处理相关经验；
4、有Linux、Unix系统安装维护经验，熟悉常用Linux系统维护、监控工具，能快速定位系统瓶颈，具备Linux常用服务配置能力，会编写shell脚本；
5、有图片处理、视频分析、音频转换等方面的经验者优先；
6、熟悉网络爬虫原理，熟悉分词算法，熟悉至少一种网络爬虫工具，如nutch；
7、善于沟通、有良好的团队合作精神、高度的工作责任心和敬业精神。"
"职位描述：
        
        岗位职责：
1、与市场、业务等部门协作，必要时参与客户沟通，理解业务需求，界定问题，并制定数据方案；
2、响应前端分析师需要，从数据库或其他来源获取数据，并进行相应的数据处理准备；
3、与前端数据分析师配合，理解业务需求，进行数据探索、特征提取，选择分析方法或模型，并进行模型分析与评估，形成符合业务的分析结果；
4、响应来自业务、市场等部门的需求，进行特定场景的数据处理、挖掘、展示，提供数据集或轻型数据应用工具；
5、与数据工程师配合，完成模型部署后的业务验证、反馈。

任职要求：
1、本科毕业，统计学、数学、应用数学、计量经济学或其他量化分析相关专业；
2、熟悉数据清洗、降维、变量选择等数据准备过程；
3、熟悉回归、分类、聚类、关联规则、时间序列、神经网络、决策树及其他常用数据分析和挖掘技术，了解其算法原理和适用性，能够根据应用场景选择适当的方法，并通过数据分析工具进行必要的数据准备和算法实现；
4、能够熟练使用至少一种主流关系数据库及结构化查询语言，了解HIVE、Spark、Hadoop等大数据架构环境及数据仓库；
5、熟练掌握Python、R， JAVA中的至少一种；
6、责任心强、自我驱动、缜密的逻辑思维和结构化思维能力、问题抽象和问题分解能力、沟通能力、能承受较大的压力、在数据技术领域有持续学习的热情；
7、有一个以上独立的数据项目经验，有电力背景的优先。"
"职位描述：
        
        岗位职责：
1、与市场、业务等部门协作，必要时参与客户沟通，理解业务需求，界定问题，并制定数据方案；
2、响应前端分析师需要，从数据库或其他来源获取数据，并进行相应的数据处理准备；
3、与前端数据分析师配合，理解业务需求，进行数据探索、特征提取，选择分析方法或模型，并进行模型分析与评估，形成符合业务的分析结果；
4、响应来自业务、市场等部门的需求，进行特定场景的数据处理、挖掘、展示，提供数据集或轻型数据应用工具；
5、与数据工程师配合，完成模型部署后的业务验证、反馈。

任职要求：
1、本科毕业，统计学、数学、应用数学、计量经济学或其他量化分析相关专业；
2、熟悉数据清洗、降维、变量选择等数据准备过程；
3、熟悉回归、分类、聚类、关联规则、时间序列、神经网络、决策树及其他常用数据分析和挖掘技术，了解其算法原理和适用性，能够根据应用场景选择适当的方法，并通过数据分析工具进行必要的数据准备和算法实现；
4、能够熟练使用至少一种主流关系数据库及结构化查询语言，了解HIVE、Spark、Hadoop等大数据架构环境及数据仓库；
5、熟练掌握Python、R， JAVA中的至少一种；
6、责任心强、自我驱动、缜密的逻辑思维和结构化思维能力、问题抽象和问题分解能力、沟通能力、能承受较大的压力、在数据技术领域有持续学习的热情；
7、有一个以上独立的数据项目经验，有电力背景的优先。"
"职位描述：
        
        职责描述：
1、基于MySQL、Flume、Kafka、Hadoop、Hive、HBase、kylin等技术开发大数据分析平台的后台服务，支持部门的数据接入、落地，统计、分析、报告业务；
2、开发实时数据处理、统计功能，支撑上层业务，如：数据监控、统计分析、日报展现、业务方调用等。

任职要求：
1、精通SQL语言，5年以上数据库开发经验，本科以上学历；
2、熟悉数据仓库建模，熟悉海量数据处理及性能优化。
3、熟练掌握Java编程语言、有丰富的后台服务开发经验，对系统架构设计与性能调优有经验；
4、熟练掌握Hive、MapReduce、Spark、Storm、kylin等大数据技术，并有相关的使用、开发经验，熟悉源码者优先；
5、熟悉MySQL及NoSQL的原理，有相关使用、调优经验者优先；?
6、熟悉kettle、tableau优先"
"职位描述：
        
        ## 需要做 ##
* 参与数据仓库建设，搭建业务数据模型
* 负责数据的收集、清洗、分析，通过从不同的维度统计分析出数据，展现当前业务状况、帮助决策分析
* 配合各业务部门完成数据分析需求和数据产品开发，支撑公司各业务部门的日常运营需求
* 结合业务需求，为公司数据平台提供方案和建议

## 希望你 ##
* 有一年以上数据开发相关经验
* 熟悉Linux/UNIX系统，熟悉Python、Java或其它编程语言
* 了解数据仓库领域知识和数据分析相关技术，具备数据仓库模型设计和ETL开发经验
* 熟悉MySql，精通SQL，掌握SQL优化
* 了解Hive、Spark、Storm等大数据相关技术，了解MapReduce原理
* 有分析和解决问题的能力
* 热爱数据分析工作，较强的学习能力、责任心、逻辑思维能力、及沟通能力"
"职位描述：
        
        岗位职责：?
1、大数据开发，负责公司数据体系的搭建和工程开发、分布式数据存储及计算；?
2、参与公司的数据产品研发，大数据平台应用及规划，支撑业务需求增长;
3、调研新技术在业务中的可行性，参与数据基础架构规划和数据治理规范制定，并实施推广。?

技术要求：?
1、计算机、通信、数学相关专业本科及以上，211院校、三年及以上工作经验；?
2、熟悉java，python 有较强的工程能力；?
3、熟悉数据结构及算法；
4、熟悉Hadoop(HDFS/MapReduce/Hive)、Spark、HBase、Kafka、Flume等常见框架；
5、具有良好的逻辑分析能力、沟通能力和协调能力；
6、具有在线教育产品研发经验优先。"
"职位描述：
        
        工作职责：
1：根据业务需求，研发相关算法模型，进行算法验证；
2：配合程序员输出算法成果，完成算法产品化；
3：从业务和产品的角度出发，利用数据来发现产品、系统或者业务的问题，提出可以落地的改进措施和解决方案；
4：针对大数据建模，结合领域需要，创新产品和技术平台；
5：熟悉海关、港口物流运作等业务知识者为佳。
任职要求：
1.3-5年以上技术数据挖掘或算法实现类的技术开发经验；
2.专业：计算机，应用数学，金融数学，人工智能；本科或以上学历，硕士为佳
3.熟悉常用机器学习和数据挖掘算法；
4.熟练使用SQL、Marlab、Python/LinuxShell等脚本开发等；
5.至少精通一种编程语言。
6.逻辑性要好，善于沟通"
"职位描述：
        
        1.参与部门大数据平台的设计、建设与维护工作、数据支撑功能开发；
2.负责应用平台中报表相关功能的规划与设计，各业务线日志采集、清洗、整合、数据仓库建设等工作；
3.搭建运营数据平台，建立数据分析/数据挖掘模型，指导产品日常运营；
4.深度挖掘业务数据，通过用户行为分析、关联分析，搭建个性化的数据推荐系统，优化产品，并实现有价值的商业预测等；
岗位要求
1.本科以上学历，计算机相关专业，有操作系统、数据库等专业知识基础
2.3年以上分布式系统、大数据相关工作经验，至少2年服务器开发经验
3.需要有较强的学习能力和思考问题能力，责任心强，有良好的沟通适应能力
4.精通Java，熟悉IO、多线程,spring boot,spring mvc等基础技术
5.熟悉掌握一个以上大数据计算框架（Hadoop、Spark、Storm、Flink等）
6.熟悉掌握一个以上大数据数据库或查询引擎（HBase、Hive、ElasticSearch、Hue、Kudu等）
7.熟悉掌握Mysql、redis、MongoDB、Hive等常规的数据库调优手段
8.有超10TB大数据处理实战经验优先，熟悉整个大数据的完整处理流程，包括数据的采集、清洗、预处理、存储、任务调度、分析挖掘和数据可视化。
加分项：
1.有个性化推荐引擎的设计开发实践经验
2.有搜索引擎、rank模块设计开发的实践经验
3.熟悉逻辑回归、文本算法、排序、分类等机器学习的算法与运用"
"职位描述：
        
        工作职责:1、基于大数据平台，负责供应链管理相关的离线计算和实时计算的架构设计、功能实现；2、参与供应链管理相关的交互性系统设计和功能实现。任职资格:1、熟练使用kafka，Spark（SparkStreaming），HBase等完成海量数据的实时传输、计算和存储检索；2、熟练使用java/scala开发，熟悉使用Springmvc，mybatis等主流框架进行JavaWeb应用开发；3、熟悉mysql、redis的使用和优化，有海量数据处理经验者优先；4、扎实的数据结构和算法基础；5、具有良好的团队合作意识及表达沟通能力，有强烈的责任心和优秀的执行力；6、具有良好的自我驱动学习能力，善于思考、抽象、总结，对技术怀有浓厚兴趣并喜欢钻研。7、良好的逻辑思维；8、良好的责任心和执行力，能够承受一定的抗压力。"
"职位描述：
        
        工作职责:1、基于大数据平台，负责CRM相关的离线计算和实时计算的架构设计、功能实现；2、参与CRM相关的交互性系统设计和功能实现；任职资格:1、熟练使用kafka，Spark（SparkStreaming），HBase等完成海量数据的实时传输、计算和存储检索；2、熟练使用java/scala开发，熟悉使用Springmvc，mybatis等主流框架进行JavaWeb应用开发；3、熟悉mysql、redis的使用和优化，有海量数据处理经验者优先；4、扎实的数据结构和算法基础；5、良好的逻辑思维；良好的责任心和执行力，能够承受一定的抗压力；"
"职位描述：
        
        工作职责:1、负责梳理数据完整生命周期，评估各环节的安全风险并提出解决方案、推动实施；2、负责数据安全体系、访问权限体系的技术方向、实现思路、产品架构、功能设计、后端开发；3、推进数据安全风险量化标准、风险评估体系、风险响应机制；任职资格:1、熟悉闭环风险管理思路，针对数据风险有丰富的实践，对数据敏感，有落地实施数据安全项目工作经验；2、信息安全或计算机相关专业，两年以上数据安全工作经验；3、扎实的计算机编程基础，有Python或Java项目编程经验；"
"职位描述：
        
        工作职责:1、负责建设公司大数据平台，为公司用户提供稳定、易用的大数据平台工具和便捷、酷炫的数据产品； 2、参与并主导大数据平台工具链的设计、开发以及后续维护； 3、参与数据产品的研发，助力数据商业价值的发掘； 4、不断迭代优化已有平大数据台工具和数据产品，推动大数据平台的发展。任职资格:1.hadoop，mapreduce，spark，kafka2.pig，storm，spark streaming，flink，hbase，elasticsearch3.java4.集群搭建，维护5.kylin，clickhouse，impala"
"职位描述：
        
        工作职责:1、负责公司大数据平台建设,维护与优(Hadoop/ Hive/ Storm/ Spark/ flink/ hbase/ kafka/ impala等)2、负责开发大数据工具，如报表平台、多维度分析工具、ETL平台、调度平台的研发 任职资格:1、精通Java/Python/Scala至少一化种,熟悉shell,良好的代码编写素养，熟练掌握操作系统、网络原理、数据结构与算法2、精通Hadoop、Hive、Spark、Storm、HBase,flink等大数据技术的原理以及优化，并有一定的大数据平台建设调优经验3、在开源社群活跃并有积极贡献者优先4、思维敏捷，有较强的钻研学习能力,良好的沟通能力与团队合作5、有BAT工作经验者优先考虑6、有阿里odps经验者优先考虑7、对大数据源码有深入理解者优先考虑"
"职位描述：
        
        【岗位职责】
1、负责公司大数据平台建设,维护与优(Hadoop/ Hive/ Storm/ Spark/ flink/ hbase/ kafka/ impala等) 2、负责开发大数据工具，如报表平台、多维度分析工具、ETL平台、调度平台的研发
【任职资格】
1、精通Java/Python/Scala至少一化种,熟悉shell,良好的代码编写素养，熟练掌握操作系统、网络原理、数据结构与算法 2、精通Hadoop、Hive、Spark、Storm、HBase,flink等大数据技术的原理以及优化，并有一定的大数据平台建设调优经验 3、在开源社群活跃并有积极贡献者优先 4、思维敏捷，有较强的钻研学习能力,良好的沟通能力与团队合作 5、有BAT工作经验者优先考虑 6、有阿里odps经验者优先考虑 7、对大数据源码有深入理解者优先考虑"
"职位描述：
        
        工作职责:1、负责公司大数据离线、实时平台（如Hadoop/Hive/Storm/Spark）的建设、优化；2、负责开发大数据工具，如报表平台、多维度分析工具、ETL平台、调度平台的研发；任职资格:1、精通Java/Python/Scala至少一种，良好的代码编写素养，熟练掌握操作系统、网络原理、数据结构与算法；2、精通Hadoop、Hive、Spark、Storm、HBase等大数据技术的原理以及优化，并有一定的大数据平台建设调优经验; 3、在开源社群活跃并有积极贡献者优先；4、思维敏捷，有较强的钻研学习能力；5、较好的沟通能力、团队合作；"
"职位描述：
        
        岗位职责:
负责构建互联网企业级数据仓库，包括ETL、数据模型设计和开发、数据质量管控、BI等工作。
任职资格:
1、3年以上相关工作经验；
2、熟悉Linux/Unix开发环境，熟悉python/java/shell编程；
3、熟练掌握至少一种关系型数据库，如Oracle、Mysql等，精通SQL（mysql,hive），逻辑清晰，能应对复杂的业务逻辑分析；
4、熟悉数据仓库各类建模理论，以及数据仓库数据层级关系，精通多维数据模型设计；
5、有大数据分布式计算平台开发经验，了解hadoop相关原理,熟练使用mapreduce、hive、spark等进行数据加工；熟悉hive和spark的编写和性能调优；
6、熟悉至少一种数据ETL开发工具，如Airflow，Datastage,Kettle等
7、熟悉HBase、Redis、Elastic Search等开源大数据存储技术，并能结合不同的业务场景深入使用；
8、具备良好的沟通表达能力和跨部门协作能力，有良好的团队精神和合作意识，强烈的责任心，对工作有激情；"
"职位描述：
        
        职责描述：
1、负责大数据项目的ETL技术落地开发实施。
2、参与并理解大数据项目的整体设计思路和方案。
3、负责好数据的联调测试工作。
4、带领2个人以上独立开展工作。

任职要求：
1、至少5年及以上大数据相关工作经验。
2、能够熟练掌握ETL开发技术，熟练应用Kettle、Informatica、ODI等数据转换工具的开发技术。
3、能够熟练掌握及理解星形模型、雪花模型等基本数仓建设模型概念，理解ETL过程的各个数据层级关联和区别。
4、熟悉Hadoop框架体系，在Kylin/Presto/Druid(OLAP)、Spark/Storm/Flink(实时计算)、Hive/Kafka/HBase/Elasticsearch/Redis（其他大数据相关组件）的一项或多项有深入研究者优先。
5、拥有在大数据领域有一个以上项目经验，熟悉Hadoop Hive、Oracle等其他数仓建模的过程。
6、能够帮助团队成员解决开发过程中碰到的各种问题。
7、对大数据相关的前沿技术和知识感兴趣，善于学习。
8、具有较好的沟通能力及团队协作意识。
9、要有金融系统从业的背景。"
"职位描述：
        
        职责描述：
1、从事互联网领域金融产品中数据挖掘和数学建模的实施工作。
2、负责数据挖掘领域的分析研究，包括数据挖掘算法的分析研究，特定工程的数据挖掘模型的需求分析、建模、实验模拟。
3、负责指导软件开发工程师进行数据挖掘系统的开发，包括需求分析、系统设计、系统测试和优化。
4、负责研究成果在公司内的推广应用，以及对外对内合作交流，不断提升公司的业务绩效能力。?
5、针对营销理论、消费者的消费行为数据结合数据挖掘领域的特点进行综合全面的业务逻辑架构及系统架构设计。

任职要求：
1、计算机科学、软件工程、自动化、电信等相关信息专业，硕士或者博士以上学历；
2、有数据分析研究经验，并深入理解常见的数据挖掘、机器学习、深度学习算法原理；
3、能熟练使用至少一款（如：Python、R、java、C++、Scala等）常见的编程语言；
4、理解常用数据结构和算法，能根据具体情况灵活应用，了解海量数据处理，有使用Hive/Spark SQL分析海量数据的能力和经验；
5、具有强烈的好奇心和自学能力，优秀的分析和解决问题的能力，对于创新技术或挑战性课题有强烈的探索意愿和深入研究热情；
6、有扎实的统计分析基础，有数学竞赛经验，有互联网和金融企业大数据实践经验。
7、具备较好的沟通能力及团队协作的能力。"
"职位描述：
        
        工作职责：
1、协助需求人员及产品经理，完成技术方案制定、数据模型设计、kettle作业及调度设计，按要求输出设计文档；
2、带领小组开发成员完成实时计算、离线分析等开发，并对交付质量负责；
3、负责已上线数据应用开发运维，并定期对程序运行情况进行分析调优；
4、参与系统运营及用户体验提升。

岗位要求：
1、本科及以上学历，3年以上工作经验，1年以上大数据开发经验；
2、熟悉hadoop/HBase/Spark/Storm/Redis/Kafka/ES技术及其生态圈，有实时计算项目经验优先。
3、熟练掌握SQL，熟悉至少一种ETL开发工具，有kettle开发经验者优先；
4、熟悉java/python编程，有数据挖掘、机器学习经验优先;
5、了解数据仓库基本原理，有传统数据仓库建设经验者优先；
6、英语四级以上或具备英语沟通能力(TOEFL/TOEIC/IELTS）。"
"职位描述：
        
        【工作职责】
1、协助需求人员及产品经理，完成技术方案制定、数据模型设计、kettle作业及调度设计，按要求输出设计文档；
2、带领小组开发成员完成实时计算、离线分析等开发，并对交付质量负责；
3、负责已上线数据应用开发运维，并定期对程序运行情况进行分析调优；
4、参与系统运营及用户体验提升；


岗位要求】
1、熟悉hadoop/HBase/Spark/Storm/Redis/Kafka/ES技术及其生态圈,有实时计算项目经验优先。
2、熟练掌握SQL，熟悉至少一种ETL开发工具，有kettle开发经验者优先；
3、熟悉java/python编程，有数据挖掘、机器学习经验优先;
4、了解数据仓库基本原理，有传统数据仓库建设经验者优先；
5、985或211院校本科及以上学历，3年以上工作经验，1年以上大数据开发经验；
6、英语四级以上或具备英语沟通能力（TOEFL/TOEIC/IELTS）；"
"职位描述：
        
        职位描述：
工作职责：?-对海量业务数据进行分析挖掘，产出有效的可视的模型供业务部门数据化运营使用;?-根据对市场环境的了解，独自承担复杂分析任务，并形成分析报告;?-相关分析方向包括：重要产品相关、用户行为相关，业务逻辑相关;?-大规模用户日志分析、统计和建模.?任职要求：?-本科及以上，数学、统计学和计算机相关专业优先;?-3年以上数据分析和挖掘领域相关工作经验;?-熟悉数据仓库和数据挖掘的相关技术, 能够够熟练使用SQL;?-有移动互联网产品的数据分析经验，游戏行业数据分析经验者优先;?-熟练掌握大数据分析工具HadoopMapReduce、Spark、Hive、Sqoop等
-具有良好的分析报告撰写能力，能制作专业的可视化分析报告;?-思维敏捷，良好的逻辑分析能力、良好的沟通能力，能在一定压力下工作."
"职位描述：
        
        岗位职责： 1、负责大数据平台系统设计和开发； 2、负责数据平台的监控、维护及优化； 3、参与大数据机器学习算法研究和开发；??

任职资格：
1、3年以上中等规模集群环境下的Hadoop/Impala/Hive/Spark集群相关运维经验；
2、精通Hadoop、Hbase、Hive、Spark集群搭建维护、优化及异常问题解决；
3、熟练Java/Scala/Python编程语言至少一种；
4、具有优秀的开发规范意识，对大数据技术和开发有热情，工作认真负责，有较强的学习能力和团队合作意识；
5、有机器学习算法经验优先
6、有大中型互联网公司工作经验者优先。"
"职位描述：
        
        职位描述：1、为美柚亿级用户的海量数据和大规模推荐系统提供可靠的基础设施；2、优秀的数据挖掘分析处理能力；3、参与数据接入、集成、优化等处理流程；4、参与大规模分布式机器学习系统化服务建设，满足业务的数据诉求；职位要求：1、本科以上学历，2年以上工作经验（能力及其突出者可放宽要求）。2、掌握分布式系统原理，对存储、计算、消息队列、集群管理中的一项或多项有深入的理解和认识；2、自我驱动型，乐于挑战没有明显答案的问题，能快速理解业务场景，从具体问题中抽象出通用的解决方案；3、熟悉多项大数据处理/分析相关的工具/框架，e.g. Hadoop, Mapreduce, Hive, Storm, Spark, kafka；4、熟悉Python和Java优先；5、有ACMICPC/数学建模/Kaggle竞赛经历优先；"
"职位描述：
        
        职位描述：1、为美柚亿级用户的海量数据和大规模推荐系统提供可靠的基础设施；2、优秀的数据挖掘分析处理能力；3、参与数据接入、集成、优化等处理流程；4、参与大规模分布式机器学习系统化服务建设，满足业务的数据诉求；职位要求：1、本科以上学历，1年以上工作经验（能力及其突出者可放宽要求）。2、掌握分布式系统原理，对存储、计算、消息队列、集群管理中的一项或多项有深入的理解和认识；2、自我驱动型，乐于挑战没有明显答案的问题，能快速理解业务场景，从具体问题中抽象出通用的解决方案；3、熟悉多项大数据处理/分析相关的工具/框架，e.g. Hadoop, Mapreduce, Hive, Storm, Spark, kafka；4、熟悉Python和Java优先；5、有ACMICPC/数学建模/Kaggle竞赛经历优先；"
"职位描述：
        
        岗位职责：
负责大算法计算相关分布式平台开发与架构设计。
参与公司搜索引擎框架设计与体系化开发，为公司海量数据提供稳定的数据检索服务。


岗位要求：
1.熟悉搜索引擎体系与原理，有solr/elasticsearch等索引平台开发经验，对相关技术原理有较深入的了解。
2.参与过大规模分布式系统的设计及研发工作，能够承担一线的架构设计或研发工作。
3.有丰富的java工程开发经验，熟练掌握mysql、redis等开源工具，有大数据相关平台开发经验者优先。
4.有良好的沟通与团队合作能力，具有开放，求进的互联网精神。
5.本科及以上学历，三年及以上工作经验。"
"职位描述：
        
        职位描述
1. 负责项目中数据处理工作(数据采集、清洗、汇总、集成等),保证数据的准确性和稳定性；
2. 负责协助完成应用系统中数据上下层衔接处理工作；
3. 对用户数据进行分析和挖掘，提供决策支持；
4. 大数据数据产品策划，对数据库信息的深度挖掘，充分体现数据的商业价值职位要求；
任职要求:
1. 大学本科及以上学历，精通java；
2. 精通shell脚本编程，至少熟悉Python或perl等一门语言;
3. 熟悉HTTP协议;
4. 熟悉Hadoop/Hive/Hbase/Spark/Storm等分布式计算环境进行海量数据分析与计算经验者优先;
5. 做过数据仓库,对数据治理、数据标准及元数据有很好理念及实施经验的优先;
6. 良好的沟通能力和团队精神,具备创新意识；
7. 以结果为导向,具有强烈的责任心、钻研精神和良好的团队沟通能力"
"职位描述：
        
        【工作职责】
1.保障整个数据平台的安全、稳定和数据的准确性；
2.大数据集群架构和资源使用优化，提高整个平台工作效率；
3.关注hadoop、spark等大数据技术生态发展动态，及时关注已用产品的新特性，并规划升级计划，及时关注新技术、新产品，并测试调研后选择性应用到生产环境中；
4.从数据角度出发制定并推进各业务系统的数据接入与流转的流程规范和方案；
【岗位要求】
1.有2年以上数据平台建设经验，对数据平台建设有较为深刻的理解；
2.至少主导过一个规模较大的大数据平台项目的成功经验；
3.对基于Hadoop的大数据体系有深入认识，具备相关产品（Hadoop、Hive、HBase、Spark、Storm、 Flume、Kafka、ES等）项目应用研发经验，有Hadoop集群搭建和管理经验;
4.熟悉java/python语言；"
"职位描述：
        
        岗位职责：?
1 负责公司级基础数据仓库的建模及开发；
2 理解业务的本质需求，构建结构层次合理、灵活可扩展的数据集市
3 分析挖掘用户行为数据，构建公司级用户画像
?
任职要求：
?
1. 有3年以上工作经验，数学、统计、计算机相关专业优先；
2、具备较强的开发能力，具备数据仓库模型设计，ETL优化经验，有互联网用户画像实践经验优先；
3、熟悉Hadoop生态，hive/kafka/hbase/spark/kylin/flink/presto/elasticsearch等；
4、熟练掌握至少一种编程语言:Java/Python，熟悉Linux系统及常用Shell命令；
5、有较好的逻辑思维和清晰的表达能力，具备团队协作意识，较好的抗压能力和自驱能力，有带人经验优先"
"职位描述：
        
        岗位职责:1、负责美图用户画像数据平台开发：开发画像数据剖析平台，画像数据挖掘评测平台2、负责美图画像元数据管理、数据监测平台开发3、负责美图画像数据服务开发：开发高可用、高并发画像查询服务
任职资格:1、两年以上工作经验，全日制大专及以上学历，计算机/软件工程相关专业优先2、必须熟练掌握Spring、SpringBoot、MySQL、Maven、Git等基础web开发技能3、熟悉linux 及shell脚本使用；熟悉容器化部署、服务运维监控4、熟悉redis使用、高并发服务开发；熟悉netty、Google库使用优先5、熟悉Hive、Kylin、Hbase、Elasticsearch使用优先6、熟悉数据仓库类型应用、数据挖掘相关知识优先欢迎具有良好职业素养、对技术范、工程型人才！"
"职位描述：
        
        工作内容:?
1、负责公司内部大数据组件的优化工作。
2、参与整体系统架构的规划，参与PB级别计算存储系统，优化系统性能。
3、对开源组件进行二次开发，并协助其他业务人员开发与优化出高效的计算程序。
工作职责：
1、Hadoop Spark技术栈的开发和管理，解决实际业务挑战，YARN, HDFS, MapReduce, Spark, Hive, kafka etc；?
2、与开源社区保持交流，发现对业务场景有帮助的特性并引入生产环境，或将经内部验证的特性贡献到社区；?
3、承担千台规模Hadoop集群的管理工作，与业务一起解决性能优化、容量规划，保障集群高效稳定经济运行。?
任职资格：
1、两年以上工作经验，本科以上学历
2、熟悉linux编程环境，有较强的开发能力（java/scala/python/shell等 );
3、思维活跃，熟悉 Hadoop Spark 及相关基础设施；?
4、优秀的设计和编码能力，针对具体的业务场景问题，快速设计和实现解决方案，对工程质量有较高的自我要求；
5、对YARN, HDFS, MapReduce, Spark, Hbase, kafka 的一项或多项有经验者优先
6、有修改Hadoop Spark Hive源码者优先
7、思维清晰敏捷，逻辑分析能力强，有独立设计和解决问题者可培养"
"职位描述：
        
        1、负责美图用户画像数据平台开发：开发画像数据剖析平台，画像数据挖掘评测平台2、负责美图画像元数据管理、数据监测平台开发3、负责美图画像数据服务开发：开发高可用、高并发画像查询服务任职资格：1、两年以上工作经验，全日制大专及以上学历，计算机/软件工程相关专业优先2、必须熟练掌握Spring、SpringBoot、MySQL、Maven、Git等基础web开发技能3、熟悉linux?及shell脚本使用；熟悉容器化部署、服务运维监控4、熟悉redis使用、高并发服务开发；熟悉netty、Google库使用优先5、熟悉Hive、Kylin、Hbase、Elasticsearch使用优先6、熟悉数据仓库类型应用、数据挖掘相关知识优先欢迎具有良好职业素养、对技术范、工程型人才！"
"职位描述：
        
        岗位职责:1、负责公司相关产品的设计与研发；2、参与产品需求及技术方案的讨论与设计；3、负责解决开发过程中的技术问题，对性能进行优化；4、保证服务的安全性与稳定性；
任职资格:1、计算机相关专业本科及以上，两年以上软件开发工作经验； 2、熟悉系统架构、数据库结构设计、业务逻辑抽象、组件封装等编码工作；3、JAVA基础扎实，理解io、多线程、集合等基础框架，对JVM原理有一定的了解；4、掌握Spring、MyBatis、MySQL、Netty等技术；熟悉Git、Jenkins、Maven、Docker等工具基本使用；4、有Hadoop, Spark，Kafka等大数据框架和信息流的使用经验优先；5、较好的沟通能力，适应能力好。"
"职位描述：
        
        岗位职责：
1、参与公司大数据平台相关架构设计；
2、带领大数据组成员完成相关工作内容；
3、参与对项目的开发需求进行评审，制定项目的设计文档、开发计划文档等；
4、基于Spark平台处理、分析数据。
任职要求：
1、3年以上大数据开发经验；
2、了解数据仓库建设基本思路，有数据仓库建设项目经验；
3、较强的数据库及SQL能力，有较强的开发调优能力；
4、熟悉Java/Scala开发，扎实的数据结构，算法功底；
5、熟悉Linux下开发，熟练使用Shell/Python其中一种；
6、熟悉Hdfs、Hbase、Hive等Hadoop/Spark家族产品；
7、熟练ELK、Kafka等常用日志数据处理方案组件，需有实际开发经验；
8、针对业务系统数据需求，能够提出合理的数据收集、处理方案；
9、严谨的逻辑思维，强烈的技术热情善于合作，喜欢有挑战性的工作；
10、对大数据技术有热情者、有团队管理经验优先考虑；
11、有大规模数据收集，日志处理经验，有电商数据背景优先考虑；
12、深入研究过大数据框架的运行机制、实现原理、源码者优先考虑。
13、?全日制统招本科以上学历，985/211院校优先"
"职位描述：
        
        作为未来Yamibuy数据平台工程师团队的成员，成功的候选人将在具有协作团队精神的快速开发环境中致力于高水平的数据平台的研发，同时和其他团队成员一起提供设计来维优化现有的数据平台，并为解决复杂业务问题的方案提供数据服务
主要职责：
在日常工作中监控数据平台性能并维护数据质量
设计处理多渠道数据的收集，处理和存储系统的解决方案
实施数据平台的持续性开发
设计开发数据展现系统和服务系统，支持应用程序工程师实施基于数据的推荐系统
设计数据仓库并实施
根据数据分析模型和解决方案来帮助业务部门解决实际运维问题
为各业务部门提供数据使用和解释的快速技术支持
对业务部门的数据和报表的日常和随机需求提供快速支持
利用分析工具和方法帮助业务部门对信息系统中的数据进行挖掘，深度学习
对现有数据平台实施持续改进和升级
基本要求：
必须有团队协作精神，能自我激励，注重细节，提供高质量的数据和分析结果
需要有坚实的问题分析能力
在日常工作中，需要有坚实的发现问题，解决问题能力
具有善于学习，快速掌握新技术，并能快速在实际项目中实施的能力
能够完成文档并在敏捷的开发环境中快速工作
有SQL，Linux脚本，Java或Python的坚实工程技术背景和编程能力
熟悉Hadoop，Spark等大数据平台技术和云平台
熟悉并能灵活使用关系型数据库和NoSQL数据库
对处理大数据工作和数据处理充满热情
对具有数据挖掘和机器学习技术的背景优先考虑
对具有数学统计技能的良好背景优先考虑
教育背景：
计算机科学或工程背景的本科或硕士学位
全日制统招本科以上学历，985/211院校优先"
"职位描述：
        
        职位职责：?1、基于海量数据，支持业务对数据的分析和使用；?2、支持业务处理数据的流式处理、分析客户行为等。?职位要求：?1、精通至少一门编程语言，熟练运用各种常用算法和数据结构，有独立的实现能力 ；?2、熟悉常用的开源组件：Hadoop/Hive/Spark/Storm，并了解其特性和使用场景优先；?3、熟悉机器学习、数据挖掘、数据分析、分布式计算至少某一方面，有较深的理论研究和实践经验优先；?4、数据分析、推荐、机器学习、数据挖掘相关的开发工作优先。"
"职位描述：
        
        工作职责：
-构建美团点评金融数据仓库（分层建设、主题模型、元数据管理、性能和效率优化）；
-金融相关BI系统建设，规划并带领小伙伴试错、成长，做离业务最近的数据BI系统；
-金融数据仓库OLAP体系搭建，建设TB级高效在线分析应用；
-金融数据日常需求开发，与分析师、PM、OP一起感知变化，实现高效的数据运营；
-调研和实践热门数据仓库组件和技术（kylin、spark、storm、实时数仓......）；
-指导初级数据工程师的工作。
职位要求：
-计算机相关专业本科以上学历；
-熟悉数据仓库建设方法论，包括但不限于：
-分层（ODS、base、fact、topic、cube）建设方法；
-主题建设方法，能独立抽象主题、建设模型、物理化并调整效率和性能；
-常用的BI系统建设方法，熟练使用主流BI工具，理解其实现原理、使用什么技术解决什么问题；
-熟练掌握 SQL，理解 Hive/MySQL/Oracle 原理和调优方法，有独立处理大规模数据/日志的经历；
-有两年以上数据仓库(DW) / 商业智能(BI) / 数据统计相关工作经验；
-熟练掌握 Java / Python / PHP 中至少一种编程语言；
-优先：有支付系统、财务系统、金融系统、风控安全研发经验者；
-优先：有新人导师、团队管理经验者。"
"职位描述：
        
        岗位职责：
1、HR领域的数据仓库设计与实现，构建丰富，准确的HR数据体系；
2、HR管理的数据化赋能，抽象和归纳业务需求，开发HR管理报表及应用；
3、与BI分析，HR研发团队一起配合，致力于打造HR领域的数据解决方案。

岗位要求：
1、全日制统招本科及以上学历；3年以上数据仓库，数据开发相关工作经验；
2、具备计算机科学基础知识，掌握数据库基本原理；
3、深入理解数据仓库领域的业务理解，主题划分，模型设计，架构分层等专业技能；
4、掌握大数据生态技术栈，精通hive编程，SQL基本功，优秀的问题解决能力；
5、善于交流，良好的团队合作与协调沟通能力，与产品，系统，BI等等多方密切配合的经验和意识；
6、熟悉互联网大数据体系，有相关工作经验者优先；
7、从事过企业管理，HR领域，或者类似CRM项目优先；
8、熟悉相关大数据分析和展示的开源工具的使用优先。

岗位亮点：
1、从0到1参与专业领域的数据体系搭建，从底层数据建设到数据应用，端到端的技术解决方案；
2、如何从复杂的业务逻辑中抽象解决问题的方法，过程中的挑战和历练，提升个人思维能力；
3、多元化背景的团队技术大牛一起，共同学习和成长。"
"职位描述：
        
        岗位职责：1、HR领域的数据仓库设计与实现，构建丰富，准确的HR数据体系；2、HR管理的数据化赋能，抽象和归纳业务需求，开发HR管理报表及应用；3、与BI分析，HR研发团队一起配合，致力于打造HR领域的数据解决方案。岗位要求：1、全日制统招本科及以上学历；3年以上数据仓库，数据开发相关工作经验；2、具备计算机科学基础知识，掌握数据库基本原理；3、深入理解数据仓库领域的业务理解，主题划分，模型设计，架构分层等专业技能；4、掌握大数据生态技术栈，精通hive编程，SQL基本功，优秀的问题解决能力；5、善于交流，良好的团队合作与协调沟通能力，与产品，系统，BI等等多方密切配合的经验和意识；6、熟悉互联网大数据体系，有相关工作经验者优先；7、从事过企业管理，HR领域，或者类似CRM项目优先；8、熟悉相关大数据分析和展示的开源工具的使用优先。岗位亮点：1、从0到1参与专业领域的数据体系搭建，从底层数据建设到数据应用，端到端的技术解决方案；2、如何从复杂的业务逻辑中抽象解决问题的方法，过程中的挑战和历练，提升个人思维能力；3、多元化背景的团队技术大牛一起，共同学习和成长。"
"职位描述：
        
        岗位职责：
1、负责HR领域的数据仓库设计与实现，构建丰富，准确的HR数据体系；
2、HR管理的数据化赋能，抽象和归纳业务需求，开发HR管理报表及应用；
3、与BI分析，HR研发团队一起配合，致力于打造HR领域的数据解决方案；
4、培养团队成员，组织技术分享，促进团队成员进步。

岗位要求：
1、全日制统招本科及以上学历；4年以上数据仓库，数据开发相关工作经验；
2、具备计算机科学基础知识，掌握数据库基本原理；
3、深入理解数据仓库领域的业务理解，主题划分，模型设计，架构分层等专业技能；
4、掌握大数据生态技术栈，精通hive编程，SQL基本功，优秀的问题解决能力；
5、善于交流，良好的团队合作与协调沟通能力，与产品，系统，BI等等多方密切配合的经验和意识；
6、熟悉互联网大数据体系，有相关工作经验者优先；
7、从事过企业管理，HR领域，或者类似CRM项目优先；
8、熟悉相关大数据分析和展示的开源工具的使用优先。

岗位亮点：
1、从0到1参与专业领域的数据体系搭建，从底层数据建设到数据应用，端到端的技术解决方案；
2、如何从复杂的业务逻辑中抽象解决问题的方法，过程中的挑战和历练，提升个人思维能力；
3、多元化背景的团队技术大牛一起，共同学习和成长。"
"职位描述：
        
        美团的使命是“帮大家吃得更好，生活更好”。作为中国领先的生活服务电子商务平台，公司拥有美团、大众点评、美团外卖、美团打车、摩拜单车等消费者熟知的App，服务涵盖餐饮、外卖、打车、共享单车、酒店旅游、电影、休闲娱乐等200多个品类，业务覆盖全国2800个县区市。2018年Q3,美团的总交易金额达1457亿元人民币，同比增加40%。截至2018年9月30日止过去十二个月，美团年度交易用户总数达3.8亿，平台活跃商家总数达550万。

2018年9月20日，美团点评（股票代码：3690.HK）正式在港交所挂牌上市。

当前，美团战略聚焦 Food +Platform，正以“吃”为核心，建设生活服务业从需求侧到供给侧的多层次科技服务平台。与此同时，美团正着力将自己建设成为一家社会企业，希望通过和党政部门、高校及研究院所、主流媒体、公益组织、生态伙伴等的深入合作，构建智慧城市，共创美好生活。

资深大数据开发工程师
岗位职责：
1.负责兴趣点多源大数据的接入、评估、清洗、判重融合、存储管理及发布等数据处理工作；
2.负责兴趣点数据生产链路搭建开发，不断完善流程建设；
3.基于公司数据仓库，持续优化生产流程效率；
4.负责相关领域相关专利的撰写发表。

岗位要求：
1.计算机、数学或统计学等相关专业本科及以上学历，3年以上互联网研发工作经验；
2.精通Unix/Linux操作系统下Java或Scala开发，了解Python、C/C++；
3.熟练掌握大数据处理技术栈，有丰富的Hadoop、Spark、Hive 等大数据处理技术的实际项目使用经验；
4.具有扎实的计算机科学功底，扎实的编程基础和数据结构算法基础，极强的编程能力和问题解决能力；
5.有大规模分布式系统开发经验，有扎实的系统工程化架构能力；
6.有开发高品质产品、编写高质量代码的自我要求；
7.具备强烈的进取心、求知欲及团队合作精神，热衷于追求技术极致与创新。"
"职位描述：
        
        工作内容：1、负责公司财务分析相关数据仓库的架构、设计； 2、完成财务数据统计与分析任务，对业务组提供数据支持服务； 3、对数据仓库建模、大数据计算技术等提出架构规划和思路； 4、负责大数据清洗、存储、处理、分析等场景的架构设计和开发?。任职资格：1、本科及以上学历，六年及以上数据仓库及数据开发相关工作经验 ；2、较强的数据库及SQL能力，谙熟MYSQL等开源数据库，并对Hadoop技术体系有所了解和研究； 3、熟练数仓工具的使用和调优； 4、对数据敏感，有较强的逻辑分析能力，对(大)数据处理和分析技术有强烈热情； 5、有互联网数据分析背景优先 。"
"职位描述：
        
        大数据开发&架构&技术专家
岗位职责：

1.负责美团外卖配送数据系统以及大数据处理平台，实时计算平台建设
2.以快速解决业务需求为第一要义，用技术提高生产力，持续优化系统架构；
3.能够快速融入团队，组织团队技术分享，提升团队的战斗力

任职要求

-?本科及以上学历，扎实的计算机专业基本功；
-至少2年以上Java开发经验，精通Java及面向对象设计开发，对部分Java技术有深入研究，研究过优秀开源软件的源码并有心得者优先;
-?熟悉常见设计模式，精通Spring，MyBatis等流行开源框架；
-?具备良好的互联网产品和技术视野
-?精通MySQL应用开发，熟悉数据库原理和常用性能优化技术，以及NoSQL、Queue?的原理、使用场景以及限制；
-?能够独立或协同，高质量按期完成项目；
-?有较强的逻辑思维能力，善于分析、归纳、解决问题，持续学习和总结，自我迭代。"
"职位描述：
        
        岗位职责：
1 与公司业务线各数据团队紧密合作、 和业务互动、深入理解用户对数据使用的需求；?
2 参与数据平台建设系统建设，架构迭代，解决业务问题；?
3 面向数据开发者，开发、迭代高效易用的数据开发、管理、运维工具。?
岗位要求：?
岗位基本要求：?
1 4年以上后台系统相关研发经历；熟悉linux操作系统；熟练使用Git等版本控制工具；
2 熟练使用Python或Java等至少一种开发语言，了解服务器架构体系、数据库以及中间件技术，如：MySQL，ORM，Web Framework，MQ 等;?
3 有良好的软件工程知识和编码规范意识，对代码和设计质量有严格要求，重视Code Review?
具备以下者优先：
1 具备一定系统的架构设计、开发和调优能力者优先；?
2 在BI分析、数据仓库建摸相关领域从业经验者优先，
3 具备较好的跨团队沟通、合作能力，良好的用户意识。"
"职位描述：
        
        工作职责：
- 金融数据仓库和业务数据集市建设；
- 业务模型抽象、数据模型设计开发；
- 支持业务的数据需求，跟PM一起完善业务的数据分析体系和工具；
- ETL、数据应用和服务的设计开发；
- 积累数据生产、分析工具，不断提高数据生产效率；
- 实时数据仓库设计、开发与服务。
职位要求:
- 快速的业务学习和理解能力，有良好的自驱能力，对工作充满热情；
- 熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，熟悉3NF和多维数据模型设计；
- 具备大型数据仓库架构设计、模型设计、ETL设计的相关经验；
- 熟悉MySQL、DB2、Oracle、Teradata、Greenplum等主流数据库技术，有较好的SQL能力；
- 具备Hadoop、Hive、HBase，Spark，Kylin等大数据技术背景，并具有开发经验者优先；
- 具备金融业务背景知识优先。"
"职位描述：
        
        关于快驴进货：
快驴进货是美团公司在“帮大家吃得更好、生活更好”的使命驱动下，深入餐饮产业链上游，推出的一站式餐饮供应链平台。快驴进货致力于通过缩短流通环节，降低流通成本，构建专业、短链、高效的餐饮供应链；协助餐饮商户以更低成本，更高效率的方式来获取安全可靠的食材供应，让餐饮采购更简单。
快驴使命：“让餐饮采购更简单”。
快驴愿景：“餐饮供应链服务实现标准化、信息化、智能化”。

岗位职责:
● 建设快驴数据仓库，开发优化数据模型，支持业务方的数据需求；
● 梳理业务系统和操作流程，提高数据生产质量；
● 建设数据服务，支持业务系统的数据需求；
● 数据治理、保证数据准确性、一致性；
● 数据分析与挖掘，发现数据中的价值；
● 指导团队新同学。

岗位要求:
● 3年以上数据开发经验，精通SQL、了解数据仓库建模理论；
● 熟悉大数据生态技术，如Hadoop/Hive/Spark等，了解大数据下的性能优化；
● 对数据敏感，有较强数据分析和解决问题能力；
● 积极沟通，工作主动，愿意尝试新的技术、业务领域。

加分项：
● 有多主题域数据建模经验；
● 熟悉统计原理，有数据挖掘经验；
● 有团队管理经验；
● 了解数据治理和多维数据分析；
● 有供应链、仓配方向的数据建模经验。

岗位亮点：
● 有机会全身心地参与新零售业态，体验并掌握各个环节的核心技术要素，和团队一起对供应链、采销、仓配等行业技能进行全新的升级、再造；
● 能在急速发展的B端业务当中，从0到1地建立对B端业务和产品技术的认知，构建完整的宏观图景；
● 能和电商、O2O、物流、零售、人工智能等多元化背景的团队技术大牛一起，综合学习，共同进步。"
"职位描述：
        
        工作职责：
-构建美团点评金融数据仓库（分层建设、主题模型、元数据管理、性能和效率优化）；
-金融相关BI系统建设，规划并带领小伙伴试错、成长，做离业务最近的数据BI系统；
-金融数据仓库OLAP体系搭建，建设TB级高效在线分析应用；
-金融数据日常需求开发，与分析师、PM、OP一起感知变化，实现高效的数据运营；
-调研和实践热门数据仓库组件和技术（kylin、spark、storm、实时数仓......）；
-指导初级数据工程师的工作。
职位要求：
-计算机相关专业本科以上学历；
-熟悉数据仓库建设方法论，包括但不限于：
-分层（ODS、base、fact、topic、cube）建设方法；
-主题建设方法，能独立抽象主题、建设模型、物理化并调整效率和性能；
-常用的BI系统建设方法，熟练使用主流BI工具，理解其实现原理、使用什么技术解决什么问题；
-熟练掌握 SQL，理解 Hive/MySQL/Oracle 原理和调优方法，有独立处理大规模数据/日志的经历；
-有两年以上数据仓库(DW) / 商业智能(BI) / 数据统计相关工作经验；
-熟练掌握 Java / Python / PHP 中至少一种编程语言；
-优先：有支付系统、财务系统、金融系统、风控安全研发经验者；
-优先：有新人导师、团队管理经验者。"
"职位描述：
        
        美团的使命是“帮大家吃得更好，生活更好”。作为中国领先的生活服务电子商务平台，公司拥有美团、大众点评、美团外卖、美团打车、摩拜单车等消费者熟知的 App，服务涵盖餐饮、外卖、打车、共享单车、酒店旅游、电影、休闲娱乐等 200 多个品类，业务覆盖全国 2800 个县区市。
2018 年 9 月 20 日，美团点评（股票代码：3690.HK）正式在港交所挂牌上市。
当前，美团战略聚焦 Food +Platform，正以“吃”为核心，建设生活服务业从需求侧到供给侧的多层次科技服务平台。与此同时，美团正着力将自己建设成为一家社会企业，希望通过和党政部门、高校及研究院所、主流媒体、公益组织、生态伙伴等的深入合作，构建智慧城市，共创美好生活。

工作职责：
1.负责无人车数据的收集、清洗、存储等数据处理工作，参与高性能数据服务平台的设计与开发；
2.负责并发大数据计算处理、实时计算处理等相关开发工作，支撑自动驾驶算法训练测试、地图生产、仿真回放等；
3.通过技术提升无人车数据平台的可靠性、稳定性、易用性，完善数据平台工具链的建设。

任职要求：
1.精通Unix/Linux操作系统下Java或Scala开发，了解Python、C/C++或Go等，有良好的编码习惯，有扎实的计算机理论基础；
2.熟练掌握大数据处理技术栈，有丰富的Hadoop/Spark/SparkStreaming/Storm/Flink的实际项目使用经验；
3.熟练掌握HDFS/HBase/Hive/S3等分布式大数据存储技术；
4.有大规模高并发分布式系统开发经验，有良好的系统工程化能力；
5.具备良好的逻辑思维和学习能力，有分析解决实际问题的能力;
6.具备强烈的进取心、求知欲及团队合作精神，热衷于追求技术极致与创新。

具有以下条件者优先考虑：
1.有Web标注或WebGL可视化平台开发经验者优先考虑；
2.有大规模激光3D点云数据处理，视频处理等工作经验者优先；
3.有一定Ros相关项目经验者优先考虑；
4.有无人车、自动驾驶相关背景和经验者优先考虑；
5.有3年以上互联网产品开发经验者优先考虑；
6.有丰富数据库使用经验者优先考虑；
7.计算机领域相关的编程大赛获奖、专业期刊发表文章或者有发明专利等。"
"职位描述：
        
        工作职责：
1.? ?搭建并优化金服数据体系，负责数据仓库方向、数据应用方向开发和管理工作
2.? ?构建金融及其各个业务线数据仓库（分层建设、主题模型、元数据管理、性能和效率优化）
3.? ?参与/负责相关BI系统建设及其解决方案落地，规划并带领小伙伴试错、成长，做离业务最近的数据系统
4.? ?负责数据仓库体系搭建，建设PB级高效、灵活的在线分析应用
5.? ?受理数据日常需求开发，与分析师、PM、OP一起感知变化，实现高效的数据运营
6.? ? 与小伙伴一起调研和实践热门数据仓库组件和技术
职位要求：?
1、 4年以上数据仓库(DW) / 商业智能(BI) / 数据统计相关工作经验者
2.? ? 熟悉数据仓库建设方法论?
3.? ? 熟练掌握 SQL，理解 Hive/MySQL/Oracle 原理和调优方法，有独立处理大规模数据/日志的经历
4.? ? 熟练掌握至少一种编程语言"
"职位描述：
        
        关于美团：
 美团的使命是“帮大家吃得更好，生活更好”。作为中国领先的生活服务电子商务平台，公司拥 有美团、大众点评、美团外卖、美团打车、摩拜单车等消费者熟知的 App，服务涵盖餐饮、外卖、 打车、共享单车、酒店旅游、电影、休闲娱乐等 200 多个品类，业务覆盖全国 2800 个县区市。 
 2018 年 9 月 20 日，美团点评(股票代码:3690.HK)正式在港交所挂牌上市。 
 当前，美团战略聚焦 Food+Platform，正以“吃”为核心，建设生活服务业从需求侧到供给侧的 多层次科技服务平台。与此同时，美团正着力将自己建设成为一家社会企业，希望通过和党政部 门、高校及研究院所、主流媒体、公益组织、生态伙伴等的深入合作，构建智慧城市，共创美好 生活。

岗位职责：
1、搜索数据仓库的架构、设计相关开发建设；
2、完成项目数据统计与分析任务，对业务组提供数据支持服务，ETL实施、ETL优化、报表等；
3、配合产品经理完成数据梳理和技术分析。

岗位要求：
1、较强的数据库及SQL以及SQL优化能力，Mysql、Hive、Hbase等开源数据库，并对Hadoop技术体系有所了解和研究；
2、三年以上HIVE数据仓库项目经历，有较强的调优能力(hive调优)；
3、熟悉使用druid等数据相关系统；
4、有数据分析相关工作经验者优先；
5、了解persto、spark等数据引擎及其原理；
6、了解Linux脚本编程，有java、python等编程经验或编程能力加分；
7、对数据敏感，有较强的逻辑分析能力，对大数据处理和分析技术有强烈热情；
8、有互联网数据分析背景，特别是O2O项目经验者优先。"
"职位描述：
        
        岗位职责：
1.负责兴趣点多源大数据的接入、评估、清洗、判重融合、存储管理及发布等数据处理工作；
2.负责兴趣点数据生产链路搭建开发，不断完善流程建设；
3.基于公司数据仓库，持续优化生产流程效率；
4.负责相关领域专利的撰写发表。
岗位要求：
1.计算机、数学或统计学等相关专业本科及以上学历，5年以上互联网研发工作经验；
2.精通Unix/Linux操作系统下Java或Scala开发，了解Python、C/C++；
3.熟练掌握大数据处理技术栈，有丰富的Hadoop、Spark、Hive 等大数据处理技术的实际项目使用经验；
4.具有扎实的计算机科学功底，扎实的编程基础和数据结构算法基础，极强的编程能力和问题解决能力；
5.有大规模分布式系统开发经验，有扎实的系统工程化架构能力；
6.有开发高品质产品、编写高质量代码的自我要求；
7.具备强烈的进取心、求知欲及团队合作精神，热衷于追求技术极致与创新。"
"职位描述：
        
        美团的使命是“帮大家吃得更好，生活更好”。作为中国领先的生活服务电子商务平台，公司拥有美团、大众点评、美团外卖、美团打车、摩拜单车等消费者熟知的 App，服务涵盖餐饮、外卖、打车、共享单车、酒店旅游、电影、休闲娱乐等 200 多个品类，业务覆盖全国 2800 个县区市。
2018 年 9 月 20 日，美团点评（股票代码：3690.HK）正式在港交所挂牌上市。
当前，美团战略聚焦 Food +Platform，正以“吃”为核心，建设生活服务业从需求侧到供给侧的多层次科技服务平台。与此同时，美团正着力将自己建设成为一家社会企业，希望通过和党政部门、高校及研究院所、主流媒体、公益组织、生态伙伴等的深入合作，构建智慧城市，共创美好生活。

工作职责：
1.负责无人车数据的收集、清洗、存储等数据处理工作，参与高性能数据服务平台的设计与开发；
2.负责并发大数据计算处理、实时计算处理等相关开发工作，支撑自动驾驶算法训练测试、地图生产、仿真回放等；
3.通过技术提升无人车数据平台的可靠性、稳定性、易用性，完善数据平台工具链的建设。

任职要求：
1.精通Unix/Linux操作系统下Java或Scala开发，了解Python、C/C++或Go等，有良好的编码习惯，有扎实的计算机理论基础；
2.熟练掌握大数据处理技术栈，有丰富的Hadoop/Spark/SparkStreaming/Storm/Flink的实际项目使用经验；
3.熟练掌握HDFS/HBase/Hive/S3等分布式大数据存储技术；
4.有大规模高并发分布式系统开发经验，有良好的系统工程化能力；
5.具备良好的逻辑思维和学习能力，有分析解决实际问题的能力;
6.具备强烈的进取心、求知欲及团队合作精神，热衷于追求技术极致与创新。

具有以下条件者优先考虑：
1.有Web标注或WebGL可视化平台开发经验者优先考虑；
2.有大规模激光3D点云数据处理，视频处理等工作经验者优先；
3.有一定Ros相关项目经验者优先考虑；
4.有无人车、自动驾驶相关背景和经验者优先考虑；
5.有3年以上互联网产品开发经验者优先考虑；
6.有丰富数据库使用经验者优先考虑；
7.计算机领域相关的编程大赛获奖、专业期刊发表文章或者有发明专利等。"
"职位描述：
        
        美团的使命是“帮大家吃得更好，生活更好”。作为中国领先的生活服务电子商务平台，公司拥有美团、大众点评、美团外卖、美团打车、摩拜单车等消费者熟知的 App，服务涵盖餐饮、外卖、打车、共享单车、酒店旅游、电影、休闲娱乐等 200 多个品类，业务覆盖全国 2800 个县区市。
2018 年 9 月 20 日，美团点评（股票代码：3690.HK）正式在港交所挂牌上市。
当前，美团战略聚焦 Food +Platform，正以“吃”为核心，建设生活服务业从需求侧到供给侧的多层次科技服务平台。与此同时，美团正着力将自己建设成为一家社会企业，希望通过和党政部门、高校及研究院所、主流媒体、公益组织、生态伙伴等的深入合作，构建智慧城市，共创美好生活。

工作职责：
1.负责无人车数据的收集、清洗、存储等数据处理工作，参与高性能数据服务平台的设计与开发；
2.负责并发大数据计算处理、实时计算处理等相关开发工作，支撑自动驾驶算法训练测试、地图生产、仿真回放等；
3.通过技术提升无人车数据平台的可靠性、稳定性、易用性，完善数据平台工具链的建设。

任职要求：
1.精通Unix/Linux操作系统下Java或Scala开发，了解Python、C/C++或Go等，有良好的编码习惯，有扎实的计算机理论基础；
2.熟练掌握大数据处理技术栈，有丰富的Hadoop/Spark/SparkStreaming/Storm/Flink的实际项目使用经验；
3.熟练掌握HDFS/HBase/Hive/S3等分布式大数据存储技术；
4.有大规模高并发分布式系统开发经验，有良好的系统工程化能力；
5.具备良好的逻辑思维和学习能力，有分析解决实际问题的能力;
6.具备强烈的进取心、求知欲及团队合作精神，热衷于追求技术极致与创新。

具有以下条件者优先考虑：
1.有Web标注或WebGL可视化平台开发经验者优先考虑；
2.有大规模激光3D点云数据处理，视频处理等工作经验者优先；
3.有一定Ros相关项目经验者优先考虑；
4.有无人车、自动驾驶相关背景和经验者优先考虑；
5.有3年以上互联网产品开发经验者优先考虑；
6.有丰富数据库使用经验者优先考虑；
7.计算机领域相关的编程大赛获奖、专业期刊发表文章或者有发明专利等。"
"职位描述：
        
        高级大数据开发工程师
岗位职责1，基于地理大数据的矢量地图数据处理工具研发；2，基于大数据平台的矢量瓦片数据质检平台研发。任职要求1，计算机相关专业，工作经验5年及以上，3年以上大数据相关开发经验；2，熟悉Linux，精通Java/Scala语言中的一种或多种，熟悉Java技术栈；3，熟悉分布式系统；4，熟悉大数据领域的技术栈，如Spark/Hadoop/Hive；5，具有数据平台/数据产品的完整搭建经验，实时大数据经验，大规模并发请求经验；6，较强的组织能力、团队合作精神、良好语言表达及沟通能力。"
"职位描述：
        
        岗位职责：
1 承担数据BP中心的数仓设计和开发工作?
2 承担业务方应用层数据的搭建和开发工作?
3 优化数据模型和ETL性能，参与数据治理，确保数据质量?
4 业务方数据问题的统一接口人与综合解决方案提供方，对外提供一站式服务?
5 跨团队沟通、推动数据生产链路上的问题改进?
岗位要求：?
1）岗位基本要求：?
1 具有扎实的计算机专业知识，极强的问题解决能力?
2 掌握数据仓库的经典建模方法，熟悉不同建模方法的优劣，三年以上的数仓开发经验?
3 掌握大数据生态技术栈，具备较丰富的Hadoop、Hive、HBase等大数据工具应用和开发经验?
4 扎实的SQL功底，了解不同框架下SQL执行的原理，有过性能优化的实际经验?
5 优秀的业务理解能力和良好的沟通协调能力?
2）具备以下者优先：
1 了解或有一定系统开发经验，能够使用java、python等语言进行编程?
2 有数据敏感度、能够从数据分析的视角看待问题或有一定数据分析经验?
3 了解或参与过数据挖掘项目"
"职位描述：
        
        【职位描述】
引入适用大数据分析技术, 可根据需求实践多维度分析的解决方案
带领数据分析技术小组攻克技术难点, 解除大数据的性能瓶颈

【岗位要求】
有7年以上大数据工作经验
对月数据达亿级别以上数据量有实际接触,对这样数据量做多维度分析的实践能力
对OLAP/OLTP深刻了解差异, 具有大型数据仓库架构设计、模型设计、ETL设计的相关经验
具备带领研发/重构/优化新一代大数据应用的能力, 能对既有ElasticSearch(ES)提出更完善的方案
若具备Hadoop、Hive、HBase，Spark，Kylin等大数据技术背景，并具有开发经验者优先"
"职位描述：
        
        【职位描述】
引入适用大数据分析技术, 可根据需求实践多维度分析的解决方案
带领数据分析技术小组攻克技术难点, 解除大数据的性能瓶颈

【岗位要求】
有7年以上大数据工作经验
对月数据达亿级别以上数据量有实际接触,对这样数据量做多维度分析的实践能力
对OLAP/OLTP深刻了解差异, 具有大型数据仓库架构设计、模型设计、ETL设计的相关经验
具备带领研发/重构/优化新一代大数据应用的能力, 能对既有ElasticSearch(ES)提出更完善的方案
若具备Hadoop、Hive、HBase，Spark，Kylin等大数据技术背景，并具有开发经验者优先"
"职位描述：
        
        团队介绍： 
美团用户平台-搜索与NLP部-NLP中心是负责美团人工智能技术研发的核心团队，使命是打造领先的自然语言处理核心技术和服务能力，依托NLP（自然语言处理）、Deep Learning（深度学习）、Knowledge Graph（知识图谱）等技术，处理美团海量文本数据，打通餐饮、旅行、休闲娱乐等各个场景数据，构建美团知识图谱，搭建通用NLP Service，为美团各项业务提供智能的文本语义理解服务。 我们的团队既注重AI技术的落地，也开展中长期的NLP及知识图谱基础研究。目前项目及业务包括美团知识图谱、智能客服、语音语义搜索、文章评论语义理解、美团智能助理等。

岗位描述： 
1、参与构建大规模知识图谱构建、Ontology设计，将海量数据结构化、图谱化
2、深入算法团队，为人工智能产品提供数据支持和数据分析
3、深入业务，形成对业务价值有影响力的数据支撑

岗位要求： 
1、3年以上的数据、工程开发经验
2、熟悉数据仓库产品、图数据库，对数据处理、维度建模、数据分析等有深刻认识和实战经验，如Hadoop/Hive/Spark等的数据应用开发
3、对大数据平台的构建和实现机制有深刻的理解，有大数据平台运维和开发经验
4、有较强的编程能力和编程经验，至少熟悉Java/python/C++其中一门编程语言，有较强算法工程能力
5、具备较好沟通协调能力，主动建立与业务的紧密合作，推动业务升级

加分项：
参与并主导过大型知识图谱构建优先

岗位亮点：
1、团队牛人云集，来自Facebook、MSRA、阿里达摩院、微信、中科院、阿里云、百度NLP&KG等优质平台，业务环境复杂、挑战性大（优化和整合的环境）
2、与优质行业AI机构合作，投入资源，培养和孵化优质项目
3、有特色工作机制，包括Mentor机制、Paper Readig机制、Deep Dive/Brain Storming机制、学术论文、专利机制等
4、有行业影响力的培训和学习交流机会、参加国际优质学术会议等
5、公司级项目，具有挑战性"
"职位描述：
        
        关于快驴进货*：
快驴进货是美团公司在“帮大家吃得更好、生活更好”的使命驱动下，深入餐饮产业链上游，推出的一站式餐饮供应链平台。快驴进货致力于通过缩短流通环节，降低流通成本，构建专业、短链、高效的餐饮供应链；协助餐饮商户以更低成本，更高效率的方式来获取安全可靠的食材供应，让餐饮采购更简单。
快驴使命：“让餐饮采购更简单”。
快驴愿景：“餐饮供应链服务实现标准化、信息化、智能化”。
?
岗位职责*：
●?建设数据平台服务，利用数据为快驴商城创造价值；
●?优化系统架构，提高服务稳定性和性能；
●?服务治理，保证数据准确，提高开发效率；
●?及时解决线上问题；
●?指导团队新同学。
?
岗位要求*：
1）岗位基本要求：
●?3年以上研发工作经验，精通Java、thrift、spring boot、mybatis、SQL；
●?熟悉Hadoop/Kafka等大数据生态技术；
●?对数据敏感，有较强数据分析和解决问题能力；
●?积极沟通，工作主动，愿意尝试新的技术领域；
●?有良好编程习惯，有代码洁癖。
2）具备以下者优先：
●?有数据平台、数据仓库研发经验；
●?有数据挖掘、机器学习基础；
●?有团队管理经验。
?
岗位亮点*：
●?有机会全身心地参与新零售业态，体验并掌握各个环节的核心技术要素，和团队一起对供应链、采销、仓配等行业技能进行全新的升级、再造；
●?能在急速发展的B端业务当中，从0到1地建立对B端业务和产品技术的认知，构建完整的宏观图景；
●?能和电商、O2O、物流、零售、人工智能等多元化背景的团队技术大牛一起，综合学习，共同进步。"
"职位描述：
        
        岗位职责
1. 闪购业务的数据仓库的架构、设计、开发；
2. 完成项目数据统计与分析任务，对业务组提供数据支持服务；
3. 配合产品经理完成数据需求梳理，技术分析和方案设计，团队内沟通协调，推动项目落地；

任职要求
1. 对数据敏感，有较强的逻辑分析能力，对(大)数据处理和分析技术有强烈热情；
2. 较强的数据库及SQL能力，谙熟MYSQL等开源数据库，并对Hadoop技术体系有所了解和研究；

3. 3年HIVE数据仓库项目经历，有较强的开发调优能力；

4. 全日制本科及以上学历，计算机/数学/统计学/金融等相关专业；
5. 了解LINUX脚本编程，有PYTHON等脚本编程能力加分；
6. 有电商/新零售/互联网数据分析背景，特别是O2O项目经历者优先；
7. 有数据分析/数据挖掘/商业分析项目经验优先；"
"职位描述：
        
        工作职责:1 研发数据管理系统，数据仓库，指标系统用以提升数据管理和业务可视化水平。2 积极响应各事业部的数据需求3完成常规hadoop监控，运维工作任职资格:1.3年及以上的数据仓库建设经验;2.熟悉数据仓库各类建模理论，以及数据仓库数据层级关系，具备大型数据仓库逻辑模型和物理模型设计经验；3.有元数据管理、数据质量管控、数据管理经验者优先；4.有Hadoop、Hive等分布式计算平台使用经验者优先；5.有互联网支付、餐饮、金融等行业应用经验者优先；6.具备良好的团队合作精神，良好的分析能力与沟通技巧;公司吸引点：1、 除滴滴外唯一获得 BAT 共同投资的互联网公司，成立 5 年，员工 1600 余人，占领相关 细分市场 90%以上份额，D 轮融资即将 close。 2、 一年 14-16 薪，2 次加薪晋升机会，全额社保公积金； 免费健身房游泳池、下午茶，零食畅吃； 公司年度两次旅游、部门每月团建； 弹性工作制；"
"职位描述：
        
        工作职责:1、负责美味大数据平台架构的设计与实施；2、参与建设、维护、优化基于实时技术的数据平台，为业务提供易用的数据工具和平台；3、关注开源技术动态；4、通过大数据平台和工具，支撑海量数据分析、数据挖掘、机器学习工作，提升美味线上产品效果。
任职资格:1、丰富的Java研发经验，精通Java，熟悉python/java/scala中的一种；2、熟悉Mysql等常见数据库技术，熟悉网络编程及并发技术；3、有丰富后端服务系统的设计和实现经验，有独立的系统级设计能力；4、扎实的计算机基础，熟悉常用的数据结构和算法，熟悉Linux系统环境；5、熟悉大数据技术栈，对Hadoop、Hive、Presto、Spark、Hbase、Kafka、ELK，flink等开源组件有使用及优化经验者优先；6、有互联网公司中大型分布式系统经验优先；公司吸引点：1、 除滴滴外唯一获得 BAT 共同投资的互联网公司，成立 5 年，员工 1600 余人，占领相关 细分市场 90%以上份额，D 轮融资即将 close。 2、 一年 14-16 薪，2 次加薪晋升机会，全额社保公积金； 免费健身房游泳池、下午茶，零食畅吃； 公司年度两次旅游、部门每月团建； 弹性工作制；"
"职位描述：
        
        岗位职责：
1、梳理分析公司业务，盘点整合公司数据资产。
2、规划落地面向医美行业、产业互联网、大数据营销等要素的企业级数仓。
3、完成数仓分层和主题建模设计实现。
4、快速响应数据接入、报表平台、业务和产品、自助分析等等环节的数据需求。
5、Coach业务和产品部门使用报表平台和自助分析工具。
岗位要求：
1、敏锐的业务分析和数据整合能力。
2、精通数据仓库主题建模、ER模型、分层设计和数据仓库建设方法论。
3、熟练使用SQL、Python等脚本语言。
4、熟练使用Dataworks、MaxCompute 、Ozzie、Tez、Hue、Azkanban、Hive、Spark等工具。"
"职位描述：
        
        岗位职责：1， 互联网金融数据处理与分析2， 大数据平台的ETL工具开发与优化3， 大数据平台的调度系统开发与优化4， 实时数据处理系统的开发与设计任职资格：1，全日制统招本科，三年以上工作经验；2，Java基础知识扎实，熟悉常用的框架3，了解大数据常用开源组件，如hadoop,hbase ,spark优先4，了解大数据开源调度系统，熟悉azkaban的优先5，了解大数据实时流处理，熟悉tidb,kudu优先"
"职位描述：
        
        工作职责:1、大数据及其它应用软件开发； 2、负责JSP系统的模块开发，负责页面、后台代码、数据库等开发； 3、根据开发规范与流程独立完成模块的设计、编码、测试以及相关文档； 4、完成领导交办的其它事情。任职资格:1、本科及以上学历，计算机、软件工程相关专业； 2、2年及以上JAVA开发相关经验； 3、熟悉MapReduce，Hadoop等技术，框架者优先； 4、掌握Java编程、Eclipse开发工具； 5、掌握STRUTS，SPRING,HIBERNATE 主流J2EE框架； 6、熟练使用JSP、WebService、JavaScript、Ajax、Html、Jquery等技术进行Web开发； 7、熟悉Hbase、Oracle、MySql等数据库开发与应用； 8、具有良好的自我管理能力和沟通能力及快速学习能力，工作积极主动，有较强的团队协作精神，对技术具有执著的钻研精神，吃苦耐劳，能长期从事软件开发工作； 9、具备良好的代码编程习惯和较好的文档编写能力。"
"职位描述：
        
        工作职责:1、负责大数据应用体系搭建与运维，参与新技术选型和调研，解决不断增长的海量数据带来的存储和计算挑战；2、根据开发规范与流程独立完成模块的设计、编码、测试以及相关文档；3、上级领导临时交办事宜；任职资格:1、本科及以上学历，计算机软件相关专业毕业，3年及以上JAVA开发相关经验；2、具有基于Hadoop/Hive/HBase/Storm/Spark/Kafka等大数据技术的开发经验，对大数据基础架构和平台有深刻理解；3、熟悉Linux环境，熟悉Linux?shell/python任一脚本；4、主导过运用Hadoop及相关产品对海量数据处理优先考虑；5、精通JAVA编程语言，同时熟悉C++语言优先考虑；6、熟悉MySQL、ElasticSearch、Mongodb、Redis等技术者优先考虑；7、工作积极主动，有较强的团队协作精神，对技术具有执著的钻研精神，能独立解决问题；"
"职位描述：
        
        工作职责：
1、负责大数据基础平台的整体规划和架构设计，参与需求分析、建模、架构设计、技术决策以及详细设计；2、优化、维护、升级现有大数据平台，解决系统中的关键问题和技术难题，不断提升系统的稳定性和效率，为公司的业务提供大数据底层平台的支持和保证；3、设计并实现对BI分析、数据产品开发、算法开发的系统性支持；4、持续挑战新的技术方向，攻克大数据量，高并发，高稳定性，易用性等各种技术难点；5、领导交办的其他工作。
任职资格：
1、本科及以上学历，计算机等相关专业毕业；?2、2年及以上开发相关经验；3、熟练使用Linux操作系统的配置，管理、优化以及各种常用命令；4、熟练使用Java、Python、Perl、Shell、Scala、Go等语言进行程序开发(Java优先考虑)，有海量数据处理和并行计算开发的热衷；5、了解Hadoop、Storm、Spark、Kafka这些组件的原理并具备部署、实施、维护相关组件的能力；6、熟悉云架构、云计算、云存储技术；7、学习能力强、团队协作、踏实稳重、吃苦耐劳"
"职位描述：
        
        职位描述：
1、对业务迅速深入理解，并熟悉业务功能、策略；2、基础数据抽取及临时查询SQL支撑；3、数据仓库的完善，优化和拓展兼容性；4、对数据工具的并发需求完善支撑和必要优化，要求稳定性，维护和问题修复；5、嵌套较多的基础数据抓取，和临时任务数据的抓取；6、历史数据及查询任务数据校验及数据清洗。

职位技能： ?1、全日制大学本科以上学历，数学、统计、计算机、运筹学等相关专业；2、3年及以上数据抽取经验，有互联网产品、运营数据需求查询经验，具有数据分析和数据仓库建模的项目实践经验优先；3、熟练掌握SQL，Mysql，excel，mongodb；掌握R，Spark，python，Js；熟练掌握ETL，存储过程；熟练掌握数据校验、清洗技能；4、责任心强，保密意识好；逻辑思维严谨，专注、具有数据敏感度；反应迅速，能够良好沟通；5、有数据分析方面相关培训更佳。"
"职位描述：
        
        职位职责：
1：参与得到大数据平台建设，包括技术选型，工程开发和集群运维等；
2：支撑OLAP/OLTP数据产品研发，提升数据产品性能和稳定性
3：夯实数据层基础，跨团队协作，解决各类大数据平台相关问题，为上层应用和产品决策提供持续、高效、稳定的数据支撑
职位要求：
1：3年以上大数据工程开发经验，深入理解数据工程全生命周期，对OLAP/OLTP任一方向有独到见解加分；
2：掌握大数据生态圈主流技术，包括HDFS、YARN、HBase、Hive、Impala、Spark、Kafka、Zookeeper、Azkaban、ES等；
3：掌握Spark Streaming，对Flink有深入理解的优先考虑；
4：对使用过的分布式计算技术有原理上的深度理解，对性能优化和稳定性提升有一线实战经验；
5：具有扎实的Java基础，熟悉常用设计模式，掌握J2EE体系结构，熟练使用SpringBoot、SSM框架、Mysql、redis、docker等进行服务端开发；
6：思维清晰，性格open，自我驱动。"
"职位描述：
        
        职位描述：
1. 负责网易私有云和公有云实时计算产品研发
2. 深入理解实时计算场景，结合实际需求完成实时计算平台架构设计、开发工作。
3. 负责线上系统的技术支持工作，保障系统稳定运行。
职位要求：
1. 5年以上平台设计和开发经验，具备优秀的编程能力和良好的开发习惯。
2. 具备独立沟通需求、设计、架构、开发、测试、运维的能力，有过大规模系统设计和工程实现的经验。
3. 熟悉至少一种大数据处理引擎，例如Hadoop、Storm、Spark、Flink等。
4. 熟悉Linux平台上的Java、Scala编程。
5. 优先考虑在开源社群活跃并有积极贡献者。
6. 具有认真的技术态度，积极沟通，懂得团队协作。"
"职位描述：
        
        岗位职责：1、 负责数据中心的大数据组管理工作。 2、 负责公司级BI、数据仓库等数据产品设计和研发； 3、 规划和设计整体数据平台，包括：数据归集、数据仓库数据服务、数据产品； 4、 与公司各条业务线沟通协调，充分合作，协助运营部门做好良好的数据分析产品； 5、 负责公司数据团队的建设，使得数据团队整体能力适应公司发展和不断提升；
岗位要求：1. 本科或以上学历，6年数据相关经验，包含至少2年团队管理经验。团队管理规模大于10人。 2. 熟练掌握数据仓库设计，开发工作。能够根据业务设计并开发数据仓；掌握 Java 编程语言，并熟悉 Shell，Python 等一门以上脚本语言；熟悉 Linux/Unix 环境，有 Hadoop 框架开发经验 3.了解 Hive，Hbase，Spark，Storm 等一种以上大数据处理工具和技术； 4.逻辑思维能力强，对数据敏感，有较强的学习能力和创新思维； 5.具备较强的沟通能力和文字表达能力，有较强的团队管理能力； 6. 必须有大型互联网行业背景"
"职位描述：
        
        职位描述：
1.负责建设数据对外能力开放平台。2.参与数据仓库架构设计与数据开发。

资格要求：
1. 掌握Hadoop/Spark生态圈的主流技术及产品，深入了解Hadoop/Spark生态圈产品的工作原理及应用场景。2. 熟悉数仓体系和大数据处理平台相关子系统功能，如ETL、数据报表、监控、数据质量等。3. 有数据开放平台开发经验者优先。4. 开源社群活跃并有积极贡献者优先。?5. 具备强烈的进取心、求知欲及团队合作精神，具有良好的沟通能力。"
"职位描述：
        
        职位描述：
1. 负责电商数据仓库搭建、ETL开发与维护；2. 完成数据统计、编写计算任务、接口开发；3. 参于数据规范制定、文档编写。

资格要求：
1.本科以上学历，软件工程/计算机/通信/数学等相关专业；2.熟悉Hive SQL语言，熟悉shell, python等至少一种脚本语言；3.有hadoop、spark、flink等至少一种大数据平台的使用经验；4.理解能力强，善于沟通，有责任心和团队精神；5.有数据仓库建设、商业数据分析、增长项目经验者优先。"
"职位描述：
        
        职位描述：
1、负责离线计算平台的开发和维护工作；2、负责HBase/TiDB的开发与维护工作；3、负责Alluxio/Arrow等开发与维护工作。
资格要求：
1、5年以上相关领域开发经验，熟悉Java/Go/C++的一种；2、对数据库系统或分布式系统的原理和架构有较好的了解；3、优秀的发现和解决问题能力，良好的沟通能力和团队意识。加分项：1、熟悉Hadoop生态，参加过开源项目；2、熟悉Hive、Spark、HDFS、HBase、TiDB中至少一种产品的实现细节；3、有数据库/数据治理产品的开发和运维经验。"
"职位描述：
        
        职位描述：
1.参与实时数据平台的设计开发，满足业务方对于实时数据的需求。?2.深入理解数据业务，分析用户需求，能够从用户角度推动业务发展，提升公司数据应用能力。

资格要求：
1. 计算机、统计、数学等相关专业本科以上学历，从事流计算/实时开发工作2年以上。2. 精通spark,storm,kafka,hbase,hadoop等大数据相关工具的使用,有部署生产环境的流计算集群,底层架构&性能优化经验。3. 熟悉flink,有实际开发经验者优先。?4. 开源社群活跃并有积极贡献者优先。?5. 具备强烈的进取心、求知欲及团队合作精神，具有良好的沟通能力。"
"职位描述：
        
        岗位描述
1.负责跨境电商业务的供应链数据平台开发，并将算法策略落地到业务场景中；?
2.利用各类业务数据建立数据模型，开发高性能的供应链数据分析系统；
3.对海量电商数据进行数据挖掘与分析，实现实时效果反馈和数据闭环；
4.搭建数据仓库，并提升数据采集，传输，处理，存储的性能或效率；
5.你会和最有潜力的跨境电商技术团队一起成长。
岗位要求
1.计算机，软件等相关专业；具有较强的编程能力（Java/Python）；
2.参与或负责过电商系统数据的研发和运维；
3.具有海量数据计算，实时流式计算等相关项目经验；
4.了解Hadoop、Hive、Spark，Storm等大数据相关技术者优先；?
5.优秀的分析问题和解决问题的能力，能够把理论成功应用于实践；
5.有极强的责任心和工作主动性；
7.有供应链相关背景者优先。"
"职位描述：
        
        职位描述：
1.负责跨境电商业务的供应链数据平台开发，并将算法策略落地到业务场景中；?2.利用各类业务数据建立数据模型，开发高性能的供应链数据分析系统；3.对海量电商数据进行数据挖掘与分析，实现实时效果反馈和数据闭环；4.搭建数据仓库，并提升数据采集，传输，处理，存储的性能或效率；5.你会和最有潜力的跨境电商技术团队一起成长。
资格要求：
1.计算机，软件等相关专业；具有较强的编程能力（Java/Python）；2.参与或负责过电商系统数据的研发和运维；3.具有海量数据计算，实时流式计算等相关项目经验；4.了解Hadoop、Hive、Spark，Storm等大数据相关技术者优先；?5.优秀的分析问题和解决问题的能力，能够把理论成功应用于实践；5.有极强的责任心和工作主动性；7.有供应链相关背景者优先。"
"职位描述：
        
        1.负责跨境电商业务的营销平台开发，并将算法策略落地到业务场景中； 2.利用各类业务数据建立用户，商品模型，开发高性能的用户画像分析系统；3.对海量电商数据进行数据挖掘与分析，实现实时效果反馈和数据闭环；4.搭建数据仓库，并提升数据采集，传输，处理，存储的性能或效率；5.你会和最有潜力的跨境电商技术团队一起成长。
职位要求
1.计算机，软件等相关专业；具有较强的编程能力（Java/Python）；2.参与或负责过大型互联网广告营销系统的研发和运维；3.具有海量数据计算，实时流式计算等相关项目经验；4.了解Hadoop、Hive、Spark，Storm等大数据相关技术者优先； 5.优秀的分析问题和解决问题的能力，能够把理论成功应用于实践；5.有极强的责任心和工作主动性；7.有互联网广告相关背景者优先。"
"职位描述：
        
        岗位描述：1. 根据业务状况构建数据仓库体系和数据指标体系，为信贷风控业务提供数据和框架支持

2. 沉淀算法和数据分析思路， 提炼数据产品需求， 协作并推动数据产品的落地?
3. 与相关团队协作进行数据建模工作，推动业务部门的数据化运营
岗位要求
1.熟练掌握SQL，掌握python/java/scala至少一门编程语言，熟练掌握hive、spark等大数据工具，有数据仓库、数据分析的工作经验；
2.熟悉数据仓库模型设计 ，掌握常用数据建模方法，具备海量数据加工处理（ETL）相关经验；
3.较好的业务理解能力，良好的语言沟通与表达能力
4.热爱技术，勤于钻研，追求极致；
5.良好的技术视野，能适应新业务新技术快速的发展变更，对新业务/新技术有持续学习的热情；?
6.优秀的分析问题解决问题能力，喜欢挑战自己，良好的沟通能力。"
"职位描述：
        
        职位描述：
1. 负责用户增长转化大数据平台的架构和开发2. 负责大数据基础标签体系建设3. 负责模型训练模块工具化以及工程化搭建
资格要求：
1. 大学本科以上学历?2. 熟悉Hadoop、Hive、HBase等当前主流的开源数据平台；?3. 熟悉大数据处理相关技术，包括但不限于Hadoop、Hive、Hbase、Impala、Spark，Kafka、Flume、Sqoop、Storm、Redis等；4. 熟悉常见的数据埋点、收集、数据ETL处理方法和流程，在用户行为日志采集、海量数据处理、数据建模、业务理解方面有丰富经验5. 熟悉推荐系统和数据挖掘算法者优先。6. 熟练掌握Java，Shell 编程，具有一定调优经验；?7. 良好的逻辑思维能力；做事积极主动；有较强的执行能和和较好的沟通能力。"
"职位描述：
        
        岗位描述
。负责公司端游和手游等游戏项目的数据中心的建设，和数据报表的开发；
。参与部门大数据平台的搭建工作及实时处理流程的设计；
。负责实时开发相关组件的维护及优化；
。完成多渠道流式数据的接入及业务方实时计算指标的开发需求；
。参与公司其他大数据类研发项目，结合大数据平台探索应用场景并参与实施。
?
岗位要求：
。本科及以上学历，3年及以上大数据开发工作经验；
。熟悉SQL编程及性能调优，熟悉Linux常用命令，以及Python、Shell等脚本语言；
。精通Java/Scala，对JVM运行机制有深入了解；
。熟悉Hadoop/Spark生态圈相关技术，并了解底层框架 (如：HDFS，MR / Spark 等) 机理；
。熟悉 Kafka 等至少一种消息中间件，掌握 Storm / Flink / Spark Streaming 等至少一种流式数据处理框架，至少1年实时计算的实际开发经验；
。具备较高的程序开发及调试能力；具备一定的系统设计能力；
。具有强烈的责任心和充分的主动性，能够积极主动的推进项目的进展；
。具有较强的抗压能力和学习能力，能够独立、高效地发现和解决或推动解决各种疑难问题；
。具有良好的沟通能力和团队合作能力；
。有底层框架二次开发经验或深入了解底层源码者优先。"
"职位描述：
        
        1. 3年以上工作经验，熟练运用数据库开发工具(postgres、mysql、oracle)。
2. 有大数据平台（HIVE/Spark/Scala/Java）开发经验优先;
3. 具备丰富的金融行业数据仓库基础数据模型设计和开发经验；
4.善于表达、乐于学习、理解能力较好"
"职位描述：
        
        ?应聘要求：1、工作经验：1年以上Hive,Spark的应用开发经验，有流式计算经验更佳，至少一个企业级数据仓库项目开发经验或者大数据处理项目经验；2、专业技能：良好的编程习惯和开发能力，Java、python、scala必须精通其中一种；3、基本能力：熟悉常用开源分布式系统，Hadoop/Hive/Spark/Yarn，精通源代码尤佳；4、其他：2年以上mysql,?oracle等数据库经验，具备优秀的SQL编写和调优能力。
外包岗位 ?介意者勿扰。"
"职位描述：
        
        岗位职责：
1.集成大数据组件，搭建大数据平台，支持数据分析业务应用。
2.构建、调试、优化数据平台的数据接入、计算、索引、服务等全流程。对大数据平台的系统集成进行功能测试，性能测试，组件联调，架构选型。
3.大数据技术组件的技术研究.
4.设计研发数据平台工具。

岗位要求：
1.计算机相关本科及以上学历，有强烈的责任心和团队合作精神、具备良好的沟通能力以及快速学习的能力，有独立项目开发经验。
2.熟悉Java、Python、Sql、Shell语言开发。
3.熟悉Linux，熟悉数据库操作，熟悉大数据常用组件的集成和应用。
4.精通hdfs、hadoop、spark、hive、yarn、hbase架构和原理。
5.熟悉常用大数据组件工具（如nifi、kafka、flume、azkaban等），具备安装、调试、应用、维护、优化的能力。
6.熟悉ES架构、原理。能够规划设计ES集群支撑业务应用。
7.了解docker技术优先。有分布式开发经验者优先。
8.综合素质佳，经验欠缺者，可由公司提供大数据实验环境培养。"
"职位描述：
        
        【岗位职责】
1. 大数据系统和产品的架构设计、研发、自动化、智能化工作
2. 结合业务需求，打造相应的数据产品
3. 深入渗透业务，负责数据分析挖掘工作，建立数据体系，以数据驱动业务发展决策
4. 业务数据报表、报告、API的实现和运营
5. 探索研究新颖的技术，提升大数据服务能力和质量

【任职要求】
1. 具备大数据研发、调优、运营经验
2. 熟悉大数据生态架构和基本原理，有相关使用和开发经验，包括但不限于：Flume，Kafka，HDFS，Kudu，Hive，Impala，Spark，Flink等
3. 技术栈要求，包括但不限于：Java，Scala，Python，SQL等
4. 有很好的数据敏感度和数理逻辑思维，善于分析和解决问题
5. 有很好的自驱力，沟通和团队协作能力
6. 有很强的学习能力和钻研精神，热衷于新技术的探索和实践
7. 有海量互联网大数据相关经验者优先"
"职位描述：
        
        职位描述： 1、负责业务数据的ETL处理工具开发； 2、负责数据计算作业的开发与优化,为公司数据业务计算提供支持； 3、基于hadoop、hbase、spark、storm等项目进行二次封装开发，为外部业务系统实现上层接入平台； 4、负责大数据集群的线上运营及部署系统开发； 职位要求: 1、计算机及相关专业本科及以上学历； 2、精通Java语言，有分布式系统开发和设计经验； 3、熟悉linux,掌握shell/python/perl任意一种脚本语言，能够用脚本完成数据采集及处理； 4、具备良好的主动工作意识和能力，能主动承担工作压力和自我挑战； 5、喜欢钻研技术，善于学习和运用新知识，具备良好的分析能力及问题处理能力。"
"职位描述：
        
        岗位职责：1. 大数据应用项目的设计开发;2. 大数据平台的持续改进优化; ? ?
任职要求： ? ?
1.精通Java语言，有分布式系统开发和设计经验；2.具有一年以上分布式存储和计算的开发经验；3.喜欢钻研技术，善于学习和运用新知识，具备良好的分析能力及问题处理能力； ? ?
4.参与过数据存储方案设计或数据库优化，具备一定实践经验者优先；5.有hadoop、hbase、solr、spark等项目应用及部署操作经验者优先。"
"职位描述：
        
        负责大数据平台的业务开发及数据处理支持
岗位职责：
1.负责业务数据的ETL处理工具开发；
2.负责数据计算作业的开发与优化,为公司数据业务计算提供支持；
3.基于hadoop、hbase、spark、storm等项目进行二次封装开发，为外部业务系统实现上层接入平台；
4.负责大数据集群的线上运营及部署系统开发
任职资格：
1.计算机及相关专业本科以上学历；
2.具有两年以上工作经验，经验丰富者尤佳；
3.精通Java语言，有分布式系统开发和设计经验；
4.熟悉linux, 掌握shell/python/perl任意一种脚本语言，能够用脚本完成数据采集及处理；
5.具有一年以上的数据库或分布式缓存的应用经验；
5.具备良好的主动工作意识和能力，能主动承担工作压力和自我挑战；
6.喜欢钻研技术，善于学习和运用新知识，具备良好的分析能力及问题处理能力；
7.参与过数据存储方案设计或数据库优化,具备一定实践经验者优先；
8.有hadoop、hbase、storm、spark、yarn等项目应用及部署操作经验者优先"
"职位描述：
        
        岗位职责
1.负责数据库中间件，存储引擎的研发工作;
2.研究学习海量规模数据库领域的前沿技术，并投入生产使用;
3.与业务系统对接，完成业务方对存储的需求.
任职要求：
1.计算机相关专业本科以上学历，3年以上大数据存储领域项目经验;
2.熟悉常用的数据结构和算法，熟练linux环境;
3.熟悉hadoop/hbase/hive等大数据相关开源工具中的一门或几门;
4.精通c/c++/java/php里的一门或几门，具有扎实的面向对象开发经验;
5.乐于解决具有挑战性的问题，具备优秀的分析问题，解决问题能力;
6.思维灵活，对数据敏感，擅长与产品经理，数据挖掘工程师等进行交流沟通及合作;
7.有团队管理工作经验者优先;
8.有数据挖掘，机器学习工作经验者优先。"
"职位描述：
        
        岗位职责
1、负责大规模数据存储，高性能离线计算平台的研发与维护
2、理解和分析数据挖掘的需求和数据特点，开发中间数据层及策略中间件
3、用户行为分析，核心指标制定与相关性分析，竞争产品跟踪等大数据需求
任职要求
1、计算机相关专业本科以上学历，2年以上大数据领域项目经验
2、熟悉常用的数据结构和算法，熟练linux环境
3、熟悉hadoop/hbase/spark/kylin等大数据相关开源工具中的一门或几门
4、精通c/c++/java/php里的一门或几门，具有扎实的面向对象开发经验
5、乐于解决具有挑战性的问题，具备优秀的分析问题，解决问题能力
6、思维灵活，对数据敏感，擅长与产品经理，数据挖掘工程师等进行交流沟通及合作
7、有数据挖掘，机器学习工作经验者优先"
"职位描述：
        
        岗位职责：
1、负责大规模数据存储，高性能离线/实时计算平台的研发与维护；
2、理解和分析数据挖掘需求和数据特点，开发中间数据层及策略中间件；
3、用户行为分析、核心指标制定与相关性分析、竞争产品跟踪等大数据需求。
岗位要求：
1、计算机相关专业硕士以上学历，2年以上大数据领域项目经验，如果经验足够，可放宽到本科；
2、熟悉常用数据结构和算法, 熟练Linux环境及shell脚本；
3、熟悉hadoop/hbase/spark等大数据相关开源工具中一门或几门；
4、熟悉C++/java里的一门或几门，具有扎实的面向对象开发经验；
5、乐于解决具有挑战性的问题, 具备优秀的分析问题、解决问题能力；
6、思维灵活，对数据敏感，擅长与产品经理、数据挖掘工程师等进行交流沟通及合作；
7、有数据挖掘、机器学习工作经验者优先。"
"职位描述：
        
        职位描述：
????1、负责大数据平台开发实现；
????2、各种算法实现落地。
职位要求：
????1、精通Hadoop/Spark/Storm/Kafka/Redis/Hbase/Hive 等技术；
????2、熟悉数据挖掘，AI算法，精通典型大数据算法和策略，精通推荐系统、广告系统；
????3、具备Java语言开发经验，精通关系型数据库及SQL语言，熟悉NoSQL/JSON/XML；
????4、有数据仓库经验者优先，有集群性能调优经验者优先；
? ? 5、985、211院校毕业优先，计算机专业、软件专业优先。"
"职位描述：
        
        岗位职责：
1.参与公司大型信息系统数据库设计和研发；
2.优化数据库结构和性能，并进行数据分析。
3.具有良好的业务分析和数据分析能力，能独立解决数据业务问题
任职要求：
1.本科及以上学历，计算机、通信等相关专业，具有扎实的计算机技术理论知识；
2.精通PL/SQL语言，熟练掌握存储过程的编写和调试；
3.熟悉Oracle数据库的运行机制及日常管理，熟悉关系数据库原理，能进行性能调优及维护工作；
4.有良好的沟通、协调和表达能力，有较强的独立工作能力和解决问题的能力；
5.热爱Oracle开发工作，责任心强，工作严谨，有较强的团队合作精神和抗压能力。"
"职位描述：
        
        任职要求1、2019年本科应届生，就读计算机、大数据相关专业；
2、有参与数据处理开发项目实习，熟悉数据仓库/大数据概念和数据处理项目的实施流程更佳；
3、有一个以上基于j2ee架构下SpringMVC(SSM架构)开发项目经验; 4、熟悉 python/js前端开发，具备一定的审美能力更佳；  5、熟悉 Greenplum/Oracle/db2数据库，能够 PSQL开发 ETL，熟悉海量数据处理性能优化；  6、有踏实的态度、能吃苦耐劳、良好的沟通能力、团队精神、有一定的承压能力; 7、欢迎想从事大数据方向的毕业生投递。"
"职位描述：
        
        岗位职责：
1、进行业务系统数据库的规划、设计、实施，设计并优化数据库物理建设方案;
2、负责产品软件的数据库字典脚本的编写，保障产品升级版代码中数据库脚本无障碍运行。
3、负责产品软件中复杂业务的SQL语句及存储过程开发；
3、负责各项目SQL评审，提出SQL改进意见；

技能要求
1.有3年以上Oralce,MySQL数据库相关开发、优化经验，有其他No SQL数据库的开发经验。
2.熟悉数据库原理特别是执行计划、数据分区、索引等工作机制，具备基本的sql优化经验，能够定位SQL效率问题并根据业务需求进行优化。
3.理解系统需求，编写PL/SQL、SQL代码实现，并对编写的代码进行优化；
4.有ETL开发经验，熟悉kettle，DataStage等ETL工具
5. 拥有oracle ocp 证书优先"
"职位描述：
        
        各位拉勾网的应聘者，你们好。

关于鱼池
中国最早的比特币矿池，全球最大的综合性矿池，业务遍布中国、美国、加拿大、新加坡、俄罗斯等全球多个国家。创始人及团队都在区块链行业深耕多年，拥有丰富的行业经验及资源。
鱼池是一家充满朝气并对区块链有深刻理解及经验的公司，我们站在区块链技术的最前沿，在经历了行业17年的动荡起伏后，我们依旧保持着初心，为区块链技术的发展贡献绵薄之力。

关于岗位
现寻找一位数据研发工程师。希望你能在数据建模、数据开发、数据生产流程优化等方面给予公司帮助与支持，于鱼池一同成长。
我们希望你能够对互联网公司有极大的工作热情，英语也会是你很大的加分项。

岗位职责：

 负责数据建模、数据开发、数据生产流程优化及相关技术问题的解决；
 深入理解公司业务，负责业务相关各数据统计平台、日常报表及数据可视化的设计开发工作。


岗位要求：

 本科以上学历，有1-3年数据相关开发经验；?
 精通SQL，有较好的SQL性能调优经验，理解Hive/Mysql 基本原理和调优策略；?
 熟悉类UNIX系统环境下的开发，掌握Python、Shell等脚本语言至少一种；?
 了解大数据常用技术，Hadoop/HBase/调度系统/Kylin等；?
 对数据和业务敏感，有良好的逻辑和沟通能力；?
 有数据仓库相关经验优先；
 具有海量数据处理、互联网从业背景者优先。


公司福利

 一周做五休二，弹性工作，不打卡。
 望京现代化超赞写字楼工作环境。
 免费午餐，公司每日安排阿姨制定工作餐。
 丰富的公司团建活动、贴心的公司人文关怀。
 高于市场水平的薪酬及福利。
 租房补助（限居住公司附近）。
 齐全的入职大礼包（电脑等办公用品）。
 其他硅谷、互联网式企业福利（无限量小吃饮料）。"
"职位描述：
        
        岗位职责：
负责ETL设计、模型设计、开发、技术支持等工作，并保证数据安全、及时、稳定、可恢复
?
任职要求：
1、3年及以上数据处理（ETL）开发经验，能独立完成数据处理开发工作
2、熟悉mysql/oracle等标准数据库，熟练上述数据库的开发
3、有hadoop和hiveSql的使用经验
4、熟悉ETL设计，熟悉数据仓库的架构、开发规范和流程
5、熟悉至少一种ETL开发工具，如Datastage，Informatica,?kettle等
6、具备数据仓库实施经验者优先"
"职位描述：
        
        岗位职责：
举例：大数据开发经理
目标：完成数据部底层架构包含Hadoop集群和实时集群的运维和性能的提升，MR所有任务监控和处理，部分任务的开发等。
主要成果：
a）负责数据部底层架构的稳定和调优（Hadoop，Storm），核心技术问题攻关；
b）负责数据部业务系统相关具体应用算法的设计，开发；负责数据相互流转；
c）根据公司产品和业务发展特点，负责研究相关大数据产品和技术发展方向。
d）负责调度平台的研发与运维；负责实时任务，推荐引擎的开发；

任职资格：
1. 计算机、信息系统相关专业本科以上学历，4年以上相关工作经验；
2. 扎实的Java编程基础，熟悉Linux/Unix开发环境，了解基础的服务器运维经验;
3.对Hadoop相关的技术和组件(HDFS, MR, Hbase, Hive, Spark, Storm, Kafka等）有全面了解，能够熟练安装，配置，部署和优化Hadoop 或Storm集群系统；?
4. 有大数据处理实战经验，熟悉整个大数据的完整处理流程，包括数据的采集，清洗，预处理，存储； 有爬虫编写经验优先；有分布式java系统,web系统开发经验优先；
5. 有丰富的数据库使用或设计经验，熟悉Mysql、Oracle或MongoDB、Redis，Cassandra等；
6. 有上进心，思维活跃，有良好的沟通能力，逻辑思维能力和团队协作能力。"
"职位描述：
        
        岗位职责：
1、独立完成中大型项目的系统分析、设计，并能够完成核心代码的编写，确保技术方案能够按计划要求，高质量的完成
2、参与相关产品需求讨论与产品系统架构的设计优化工作
3、负责相关系统的技术运营，确保系统的性能及稳定
4、对技术有较强的钻研及学习精神，能够深入了解开源技术、现有系统技术等相关技术原理，出现问题时能够通过较强的技术手段较好的解决问题

任职资格：
1、4年以上Java开发经验，有扎实的java编程基础，有完整web项目开发经验者优先。
2、对各种开源框架如SpringBoot、SpringMVC、Hibernate等有深入了解和编程经验。
3、了解MySQL/Sql Server/HBase、Cache(Redis/Memcached)、NoSQL、MQ等知识。
4、熟悉linux操作系统和基础命令，对大数据应用组件有了解或者感兴趣的优先。
5、具备较好的沟通表达能力、较强的团队精神，工作积极、勇于创新，对技术有激情，有较强的主动学习能力。
6、有大数据分析工具，营销工具的开发经验优先；有web系统经验的优先；"
"职位描述：
        
        岗位职责：
1、配合研发经理进行的系统分析、设计，并能够完成核心代码的编写，确保技术方案能够按计划要求，高质量的完成
2、参与相关产品系统的研发和优化工作
3、负责相关系统的技术运营，确保系统的性能及稳定
4、对技术有较强的钻研及学习精神，能够深入了解开源技术、现有系统技术等相关技术原理，出现问题时能够通过较强的技术手段较好的解决问题

任职资格：
1、2年以上Java开发经验，有扎实的java编程基础，有完整web项目开发经验者优先。
2、对各种开源框架如SpringBoot、SpringMVC、Hibernate等有深入了解和编程经验。
3、了解MySQL/Sql Server/HBase、Cache(Redis/Memcached)、NoSQL、MQ等知识。
4、熟悉linux操作系统和基础命令，对大数据应用组件（hadoop，storm，spark）有了解或者感兴趣的优先。
5、具备较好的沟通表达能力、较强的团队精神，工作积极、勇于创新，对技术有激情，有较强的主动学习能力"
"职位描述：
        
        岗位目标：
1、负责智慧商场，智慧大屏，虚拟逛店项目数据分析；
2、为业务优化提供决策方向；
3、对应用效果指标进行监控。

岗位职责：
1、负责智慧商场（可以完整跟踪顾客逛店路径）相关数据的分析，不定期产出分析报告，指导智慧商场运营优化；
2、负责APP相关数据的分析，指导APP运营团队运营优化；
3、负责相关分析报表体系设计，给业务部门的日常运营提供支持；
4、负责相关数据项目规划和执行。

任职资格：
1、全日制本科学历或以上，3年以上相关工作经验；
2、具备数据收集、甄别和分析能力，能够独立指定数据分析方案并产出报告；
4、学习能力强，具备良好的数据敏感度，能够结合业务场景，敏锐的捕获数据价值和产品机会
5、精通SQL、EXCEL、PPT。熟悉R，Python的优先，有建模经验优先。
6、工作认真负责，细心，有较强的沟通能力、逻辑思维能力和总结归纳能力，具备团队合作精神。"
"职位描述：
        
        1、岗位工作职责
负责项目部分模块的设计开发工作；
对系统出现的数据问题能快速定位解决；
严格执行工作计划，主动汇报并高效完成任务保证部门及个人工作目标实现；
2、任职要求
熟练使用Storm/Spark Streaming，并具有实时计算项目经验；
熟练使用Java、sql 编程，有良好的编码习惯；?
能独立梳理业务逻辑，完成业务需求；
?熟悉大数据处理相关产品架构和技能（如：Storm/Hadoop/Hive/HBase/Spark/Kafka/Flume/zookeeper/Redis等）；
具备一定离线报表开发能力；
熟练使用linux开发环境和命令；
具备良好的学习能力，分析解决问题和沟通表达能力；"
"职位描述：
        
        岗位职责：
1、深入理解业务需求，抽象系统数据模型，对数据进行清洗、分析、统计及接口开发；
2、按时按质完成项目分配的任务开发、系统评测等工作任务；
3、定期维护系统程序，快速处理反馈回来的系统bug；
4、负责构建数据仓库（设计、开发、维护），大数据处理架构；
5、负责基于Hadoop、Spark等技术的海量数据自动化分析处理和统计工作。
任职资格：
1.熟悉Hadoop、Hive、Hbase、Spark、Flume、Kafka、Spark Streaming等大数据相关技术；
2.熟悉Java和Python，掌握基本算法和数据结构；
3.掌握至少一种主流关系数据库（Oracle/MySql/SqlServer），有一定的SQL功底；
4.要求两年以上工作经验；
5.有较强的沟通能力，有一定的团队领导能力；
6.专科以上学历，计算机、软件相关专业"
"职位描述：
        
        工作职责：
? ? ? ?负责技术规划部大数据相关的技术预研开发
岗位要求：
1） 有视频监控相关的开发背景
2） 精通C/C++、JAVA、Python等一门及以上的编程语言；
3） 精通大数据相关技术（Hbase/MPP/Spark/Hadoop）
3） 有知识图谱, 图数据库，数据挖掘相关的技术背景及开发经验者优先
4） 5年工作经验及以上,本科及以上学历"
"职位描述：
        
        工作职责：
? ? ? ?负责技术规划部大数据相关的技术预研开发
岗位要求：
1） 有视频监控相关的开发背景
2） 精通C/C++、JAVA、Python等一门及以上的编程语言；
3） 精通大数据相关技术（Hbase/MPP/Spark/Hadoop）
3） 有知识图谱, 图数据库，数据挖掘相关的技术背景及开发经验者优先
4） 5年工作经验及以上,本科及以上学历"
"职位描述：
        
        岗位职责：?
1、参与数据服务平台的设计及开发工作；?
2、负责数据服务平台数据检索，索引、关系建模及计算、任务调度相关开发工作；?
3、跟进大数据前沿技术的发展，适时引入合适的技术支撑业务场景；?


岗位要求?
1、统招本科及以上学历，计算机相关专业，2年以上大数据相关工作经验；?
2、熟悉Hadoop/Hive/Spark的体系结构、原理和特性，对Hadoop生态系统有一定的了解；?
3、熟悉Java，有丰富的并发编程经验，可以熟练使用Python/Shell等脚本语言，熟悉Linux操作系统；?
4、有海量数据分析、处理的相关系统的开发及优化经验；?
5、有推荐、搜索等相关系统开发经验者优先；?
6、有良好的数学基础，了解机器学习常用算法，具备自然语言处理、特征分析等方面知识及应用经验者优先；?
7、责任心强，良好的沟通能力和团队协作精神。 """
"职位描述：
        
        岗位职责：
（1）参与数据平台设计以及实现；
（2）多来源结构与非结构数据的清洗、整理和加工；
（3）算法模型设计及开发?任职要求：
（1）?对Linux操作系统熟练掌握，熟悉shell等脚本编程；
（2）?具备java实际开发经验，并对java虚拟机有较深刻的理解，掌握常用java开源框架；
（3）熟悉Maven的使用，理解Maven的原理与使用技巧，?熟练用Git进行代码版本控制；
（4）参与过分布式高性能服务的设计开发过程，有大规模分布式系统的实践经验；
（5）熟悉常见NoSQL数据库，如Redis、Memcached,MongoDB等?；
（6）熟悉分布式系统原理及以面向数据的建模方法；
（7）熟悉hadoop集群的搭建、管理及优化；
（8）熟悉HDFS/HBase/Hive/MapReduce/Storm/Spark等相关技术,有?MapReduce?程序的实战开发经验；
（9）有大数据量处理经验，能进行SQL优化和调优，有数据建模经验，熟悉数据库设计，能建立合理高效的数据模型；
（10）熟悉scala语言优先。
（11）全日制本科以上学历，计算机及相关专业毕业；
（12）三年以上工作经验，有金融、大数据等行业经验者优先；
（13）良好的沟通能力、团队协作能力，及执行力。"
"职位描述：
        
        1.负责整合公司内部各种数据源2.搭建一个高效实时的数据分析平台3.能够有效支撑业务部门的各种数据报表需求任职要求： ?1.具备扎实的数据结构、算法等计算机基础知识。2.深入理解python编程语言。3.熟练运用python进行数据分析，熟悉Pandas、Numpy等数据相关python库。4.精通Hadoop、Hive、HBase、Kylin、Spark等各类数据存储及计算框架，能够根据业务场景选用不同的技术和框架搭建多层级的数据中心。5.熟悉Saiku、OLAP计算及建模者优先。6.工作认真负责，沟通、合作能力强。"
"职位描述：
        
        一、岗位要求
1.计算机相关专业本科及以上学历；
2.3年以上大数据产品或项目开发经验，精通Hadoop生态圈，精通一种流式计算框架（storm或sparkstreaming或flink），熟练使用Spark，HBase、Hive、Kafka、Redis等；
3.精通SQL，熟练使用HSQL实现复杂数据处理逻辑，并具备数据处理调优的能力；
4.熟悉Linux开发环境，熟悉Linux的shell命令。
5.具有良好的逻辑思维能力和严谨的程序开发思想，具备独立问题排查与处理的能力；
6.良好的团队精神和合作意识，强烈的责任心，对工作有激情，良好的沟通能力，能吃苦耐劳；
7.有大数据项目或产品背景者优先；
8.有使用Spark SQL进行数据处理，并具有Spark SQL优化经验者优先。


二、职位描述
1.负责大数据平台的设计与应用功能开发；
2.根据项目或产品的需要，负责离线/实时的数据存储、加工和处理；
3.结合项目或产品涉及的具体业务场景，对数据进行清洗、计算与加工；
4.思路清晰，可快速响应数据处理的需求，评估并给出合理的解决方案，并采用合理的方式处理需求；
5.积极主动，能够与团队成员进行有效沟通，并完成数据处理结果的核对与对接；
6.负责前沿或关键技术的研究，完成服务性能优化；
7.完成上级交办的工作或任务。"
"职位描述：
        
        职位要求：1.?熟悉SQL语句编写，熟悉MySql及其他常用数据库工具的安装及配置；2.?熟悉LINUX操作系统常用命令；3.?熟悉常用的测试方法及理论，有相关测试经验；
4.?两年以上软件项目（实施/运维/测试）工作经验；
5.?具备较强的语言表达能力，能与客户顺畅沟通或产品介绍；6.?具备较强的学习与动手能力；7.?熟悉大数据相关技术的优先；8.?有一定的软件开发能力的优先。工作内容：1、负责项目与甲方沟通协调及需求编写工作；2、负责项目的数据处理、测试工作；
3、协调配合项目的环境安装工作；4、完成领导交待的其他工作。"
"职位描述：
        
        工作职责

1、负责公司内部数据平台的设计和开发
2、负责关键业务数据的实时化可视化展现
3、参与智能推荐系统的架构设计、开发、部署和数据分析等工作

技能要求

1、至少精通一门服务器端编程语言，Python、Java、Scala或Go
2、精通Spring的各种组件
3、熟悉Hadoop生态圈（Spark, Hive, Pig, Oozie, Impala, MapReduce, Kafka, Elasticsearch）
4、至少精通一个NoSQL数据库
5、精通SQL
6、有高并发系统处理能力者优先
7、有良好的沟通能力，能够理解业务部门、产品部门以及研发工程师的不同角度的需求
8、有良好的学习能力，关注业界最新技术和动态
9、计算机专业，本科及以上学历"
"职位描述：
        
        岗位描述
1. 负责大数据计算平台开发、机器学习算法开发、计算性能和算法调优、高性能服务框架设计与开发2. 负责提升各个平台的易用性，进行DAG相关逻辑开发，远期朝向AutoML发展3. 负责设计与开发相关后台基础设施，并辅助线上服务稳定运行岗位要求1. 计算机相关专业本科及以上学历，一年以上开发工作经验，有扎实的计算机理论基础；2. 精通C/C++、Java或Python等服务端编程，有良好的编码习惯；3. 熟悉Unix/Linux操作系统；4. 熟悉传统机器学习算法（例如LR、GBDT等）者优先；5. 熟练掌握开源大数据处理技术栈，有Hadoop/Spark/Storm等框架，深入阅读或修改过源码者优先。6. 熟悉后台RPC框架，熟悉GRPC/Thrift/TARS/BRPC的其中一种，深入阅读或修改过源码者优先。7. 熟悉存储基础设施，熟悉Redis/HBase/Ceph的其中一种以上，深入阅读或修改过源码者优先。


团队背景：
1. 团队主要由来自腾讯、百度、华为等公司的资深研究员、架构师构成，拥有世界尖端的NLP与信息分发的经验；2. 团队成员来自于985/211院校、顶级海外院校，包括牛津、帝国理工、UCL、亚琛工业、港中文、港科、北大、北邮、厦大等院校，水平杰出；3. 目前方向包括NLP、画像、推荐、搜索、知识图谱等业界核心方向，远期还会有对话机器人等前沿方向；4. 工业、学术上我们会要求大家保持敏捷，一方面要在工业上做到业界顶尖水准；另一方面要在学术上对SotA有所追求，我们会有定期的工业、学术的文章研讨，一同学习进步。"
"职位描述：
        
        岗位描述
1. 负责大数据计算平台开发、机器学习算法开发、计算性能和算法调优、高性能服务框架设计与开发2. 负责提升各个平台的易用性，进行DAG相关逻辑开发，远期朝向AutoML发展3. 负责设计与开发相关后台基础设施，并辅助线上服务稳定运行岗位要求1. 计算机相关专业本科及以上学历，一年以上开发工作经验，有扎实的计算机理论基础；2. 精通C/C++、Java或Python等服务端编程，有良好的编码习惯；3. 熟悉Unix/Linux操作系统；4. 熟悉传统机器学习算法（例如LR、GBDT等）者优先；5. 熟练掌握开源大数据处理技术栈，有Hadoop/Spark/Storm等框架，深入阅读或修改过源码者优先。6. 熟悉后台RPC框架，熟悉GRPC/Thrift/TARS/BRPC的其中一种，深入阅读或修改过源码者优先。7. 熟悉存储基础设施，熟悉Redis/HBase/Ceph的其中一种以上，深入阅读或修改过源码者优先。


团队背景：
1. 团队主要由来自腾讯、百度、华为等公司的资深研究员、架构师构成，拥有世界尖端的NLP与信息分发的经验；2. 团队成员来自于985/211院校、顶级海外院校，包括牛津、帝国理工、UCL、亚琛工业、港中文、港科、北大、北邮、厦大等院校，水平杰出；3. 目前方向包括NLP、画像、推荐、搜索、知识图谱等业界核心方向，远期还会有对话机器人等前沿方向；4. 工业、学术上我们会要求大家保持敏捷，一方面要在工业上做到业界顶尖水准；另一方面要在学术上对SotA有所追求，我们会有定期的工业、学术的文章研讨，一同学习进步。"
"职位描述：
        
        岗位描述
1. 负责大数据计算平台开发、机器学习算法开发、计算性能和算法调优、高性能服务框架设计与开发2. 负责提升各个平台的易用性，进行DAG相关逻辑开发，远期朝向AutoML发展3. 负责设计与开发相关后台基础设施，并辅助线上服务稳定运行岗位要求1. 计算机相关专业本科及以上学历，一年以上开发工作经验，有扎实的计算机理论基础；2. 精通C/C++、Java或Python等服务端编程，有良好的编码习惯；3. 熟悉Unix/Linux操作系统；4. 熟悉传统机器学习算法（例如LR、GBDT等）者优先；5. 熟练掌握开源大数据处理技术栈，有Hadoop/Spark/Storm等框架，深入阅读或修改过源码者优先。6. 熟悉后台RPC框架，熟悉GRPC/Thrift/TARS/BRPC的其中一种，深入阅读或修改过源码者优先。7. 熟悉存储基础设施，熟悉Redis/HBase/Ceph的其中一种以上，深入阅读或修改过源码者优先。


团队背景：
1. 团队主要由来自腾讯、百度、华为等公司的资深研究员、架构师构成，拥有世界尖端的NLP与信息分发的经验；2. 团队成员来自于985/211院校、顶级海外院校，包括牛津、帝国理工、UCL、亚琛工业、港中文、港科、北大、北邮、厦大等院校，水平杰出；3. 目前方向包括NLP、画像、推荐、搜索、知识图谱等业界核心方向，远期还会有对话机器人等前沿方向；4. 工业、学术上我们会要求大家保持敏捷，一方面要在工业上做到业界顶尖水准；另一方面要在学术上对SotA有所追求，我们会有定期的工业、学术的文章研讨，一同学习进步。"
"职位描述：
        
        【职位描述】
根据业务场景，建立数据模型，开发数据指标；

建立数据集规范，数据采集/数据服务API规范；

负责数据仓库设计，开发；

根据业务场景，建立领域数据模型；

研究算法，开发数据指标。

【职位要求】

三年以上具有数据开发、数据建模相关经验，能熟练使用python,java；

熟悉主流数据库，熟练运用SQL，并熟练运用Python进行ETL开发；

了解数据仓库OLAP，熟悉多维分析优先，及了解数据分析、数据挖掘常用算法；

熟悉Hadoop生态体系，熟练使用Hadoop、Spark、Kafka、HBase等大数据体系相关系统；

参与过大数据平台搭建，开发或运维实践经验优先；


如有，加分项

1、对新兴技术有好奇心，有利用技术解决实际问题的热情，开源社区积极参与者优先；

2、有Low latency（包括Spark-streaming、Flink、Storm、Kafka等）大数据处理经验者优先；

3、有存储系统（包括Hbase、Cassandra、Redis、Mongodb等）经验者优先；

4、有大数据查询系统（包括ClickHouse、Phoenix、Presto、Impala、Druid、Kylin、Greenplum等）经验者优先；

5、有海量数据下图计算、关系挖掘、推荐预测实践经验者优先。"
"职位描述：
        
        岗位职责:

1、协助完成BI项目的需求分析，整体评估，方案设计，架构部署等工作；2、负责大数据关键技术的预研，协助团队解决开发过程中的技术难点； 3、承担基于大数据平台应用的开发和维护工作以及爬虫系统的后期开发和维护；4、协助完成数据产品的概要设计以及数据仓库的建模。 
任职资格:

1、要求计算机，软件工程相关专业，两年以上大数据开发经验最佳；2、具备python爬虫经验，熟悉flask框架；3、熟悉使用hive数据仓库，数据仓库建模，对hadoop生态中的mapreduce/hdfs/spark/kafka/flume/hbase/sqoop等相关技术和工具要具备部署，开发和调优经验，对最新的hadoop前沿技术保持着学习和研究的热情；4、要求掌握shell,python,sql，熟悉linux系统，了解redis，elasticsearch，kettle；5、优秀的数据思维和强烈的数据决策意识，良好的数据敏感度，能从海量数据中提炼核心结果，善于用简单语言表述复杂结论；6、清晰、严密的逻辑思维能力和分析能力，良好的需求理解能力，对项目风险能提前预判；7、思路严谨，具有良好的心理素质及能承受较大的心理压力，能独当一面。"
"职位描述：
        
        岗位职责：
1、负责用户标签、用户画像、精细化运营系统的构建、机器学习、AI在线服务平台的构建及其优化；
2、负责业务需求的数据加工和数据服务的系统开发；
任职要求：
1.?本科3年以上工作经验，从事过用户画像、用户标签相关数据服务的设计与开发经验者优先。
2.?精通SQL、Python，至少掌握一种编译型开发语言，Java/Golang等，具有高并发服务优先。
3.?具有大数据开发组件Hive、Impala、Spark、HBase使用及调优经验.
4.?具有基于流式数据服务框架（Flink、Spark?Streaming）的数据处理、指标统计、模型开发经验。
5.?掌握数据加工、处理的常用工具及方法，熟悉数据仓库设计及其优化。
6.?具有独立的数据加工等服务抽象设计能力，具有良好的编程风格，可以根据设计方案按时完成定制化软件编码和单元测试工作。
7.?掌握常用数据挖掘算法，具有机器学习、深度学习工程开发经验者优先。?
8.?具备良好的学习能力、分析解决问题的能力和沟通协调能力，高度责任心和团队合作精神，关注前沿新技术。"
"职位描述：
        
        ? 亿企赢拥有600万的企业用户和可触及上亿个人。在如此庞大的业务背后，产生了海量的自有数据。如何将这庞大的数据管理妥善和合理利用，是摆在我们面前的一个难题。? 做为大数据基础平台研发团队，主要任务是搭建我们自己的大数据基础平台，包括大数据存储（文件和数据库）、数据批处理、流处理框架和信息流框架等，以及设计和开发管理这些框架的工具，包括用户管理、监控管理和配置管理等。 使得其他研发团队，通过这些工具，可以高效的开发大数据应用。
职责：
1.?? 搭建和维护PB级别的大数据基础平台。
2.?? 搭建和维护多PB数据的大数据框架，例如Hadoop，Spark，Hive，Kafka，Hbase，Impala等。
3.?? 设计和开发大数据框架开源项目对应的管理工具、例如用户管理、监控、配置管理等。
4.?? 与数据仓库组、基础架构团队、业务研发团队等紧密合作。
5.?? 探索和研究新的大数据处理技术（例如新的大数据处理框架，开源项目等）
 任职要求：
1.?? 拥有计算机相关专业本科及以上学历。
2.????????5年以上的大数据相关研发经验。
3.???????? 熟悉java语言，有hadoop,?Spark，Kafka等大数据框架和信息流的使用经验。
4.???????? 熟练运用spring,mybatis等主流的开发框架；熟练使用Oracle、MySql数据库；熟悉Git、Junit、Maven等工具应用。
5.???????? 有Java?web全栈开发经验者优先。
6.?? 有大数据用户权限(Kerberos等)控制、监控管理、配置管理等使用或者研发经验者优先。"
"职位描述：
        
        职责：
1. 搭建和维护PB级别的大数据基础平台。
2. 搭建和维护多PB数据的大数据框架，例如Hadoop，Spark，Hive，Kafka，Hbase，Impala等。
3. 设计和开发大数据框架开源项目对应的管理工具、例如用户管理、监控、配置管理等。
4. 与数据仓库组、基础架构团队、业务研发团队等紧密合作。
5. 探索和研究新的大数据处理技术（例如新的大数据处理框架，开源项目等）

任职要求：
1. 拥有计算机相关专业本科及以上学历。
2. 2年以上的大数据相关研发经验。
3. 熟悉java语言，有hadoop, Spark，Kafka等大数据框架和信息流的使用经验。
4. 熟练运用spring,mybatis等主流的开发框架；熟练使用Oracle、MySql数据库；熟悉Git、Junit、Maven等工具应用。
5. 有Java web全栈开发经验者优先。
6. 有大数据用户权限(Kerberos等)控制、监控管理、配置管理等使用或者研发经验者优先。"
"职位描述：
        
        ? ?亿企赢拥有600万的企业用户和可触及上亿个人。在如此庞大的业务背后，产生了海量的自有数据。如何将这庞大的数据管理妥善和合理利用，是摆在我们面前的一个难题。? ?做为数据仓库研发团队，主要任务是在自建的大数据基础平台之上，搭建一套健全的数据仓库，包括ETL工具、任务调度工具、标准数据仓库、批处理分析工具、实时和准实时分析工具、数据接口等。? ?使得业务研发团队，通过这些工具，可以安全高效的访问数据以及构建在此之上的应用，附能客户。? ?做为团队的一员，你将参与到平台的设计、研发及推广中，成为核心团队的中坚力量。
?
职责：
1.?? 设计和构建PB级别的数据仓库平台。
2.?? 管理和使用各类多PB分析堆栈。
3.?? 设计和开发数据标准工具（作业调度程序，ETL，数据可视化，查询编辑器等）。
4.?? 与基础架构团队、业务研发团队等紧密合作。
5.?? 探索和研究新的大数据处理技术（例如新的大数据处理框架，开源项目等）
任职要求：?
1.?? 拥有计算机相关专业本科及以上学历。
2.? ?3年以上的大数据ETL(kettle，sqoop等)、任务调度(Oozie, airflow等)、分析工具（Impala,Hive等）等研发经验。
3.? 熟悉java语言，有hadoop,?spark等大数据框架的使用经验。
4.? ?熟练运用spring,mybatis等主流的开发框架；熟练使用Oracle、MySql数据库；熟悉Git、Junit、Maven等工具应用。
5.? 有Java?web全栈开发经验者优先。"
"职位描述：
        
        工作职责
1、负责大数据平台架构的规划、设计与实施；
2、参与建设、维护、优化基于实时技术的数据平台，为业务提供易用的数据工具和平台；
3、关注开源技术动态；
4、通过大数据平台和工具，支撑海量数据分析、数据挖掘、机器学习工作
任职要求
1、丰富的Java研发经验，精通Java，熟悉Python；
2、熟悉Mysql，熟悉网络编程及并发技术，熟悉安全解决方案；
3、有丰富后端服务系统的设计和实现经验，有独立的系统级设计能力；
4、扎实的计算机基础，熟悉常用的数据结构和算法，熟悉Linux系统环境；
5、熟悉大数据技术栈，对Hadoop、Hive、Spark、Hbase、Kafka、ELK等开源组件有使用及优化经验者优先；
6、有互联网公司中大型分布式系统经验优先；"
"职位描述：
        
        岗位职责：
1、负责大数据架构的搭建和开发引导?
2、负责大数据模型的设计?
3、参与数据源的调研分析?
4、参与数据仓库产品设计与数据建模?
5、Hadoop集群的管理、维护和调优?
6、Hadoop平台的数据接入，数据治理和数据优化?
7、解决海量数据分析和挖掘方面的业务需求

岗位要求：
1、计算机相关专业本科以上学历，1年以上大数据处理相关工作经验；?
2、精通大数据处理技术（如 Hadoop、Spark等）；精通 Java编程；?
3、有分布式计算相关开发经验，有Hadoop、Hive、Spark等相关开发经验优先；?
4、熟悉HDFS、Hbase、Hive的原理、特性和常用配置且有实战开发经验；
?5、熟悉常用的数据挖掘模型，例如分类、聚类、回归分析等；"
"职位描述：
        
        岗位职责：
1、根据业务和产品情况对数据模型进行设计和优化；
2、完成数据模型的ETL开发、实施，ETL流程优化以及相关技术问题的解决；
3、根据业务需求的理解，开发数据，提供面向业务的数据服务；
岗位要求：
1、统招本科及以上学历，计算机相关专业；
2、熟悉数据仓库建模理论，了解数据仓库数据分层架构、多维数据模型设计，有1年以上的实际工作经验；
3、在用户行为日志采集、处理、建模方面有丰富经验；
4、熟悉Hadoop / Spark / Hive ，熟练掌握SQL，有HIVE、Spark Sql使用经验者优先；
5、熟悉Linux开发环境，熟悉至少一种开发语言（Python / Java）；
6、优秀的逻辑思维能力、业务需求分析能力和执行力，较好的沟通能力；"
"职位描述：
        
        岗位职责：?
1、从事大数据平台建设开发，数据治理，分析，编码的工作。?

任职要求：?
1、数学、统计、计算机等相关专业，大学本科及以上学历，985，211学校；?
2、了解统计学、数学、人工智能和数据挖掘理论基础，了解数据仓库、数据挖掘与分析的相关知识，具有良好的数据模型设计能力，熟悉常用统计分析方法、数据挖掘基本算法；?
3、熟悉java，python，scala开发语言，并具有实际开发经验；?
4、了解hadoop技术生态圈相关知识，有过hadoop生态圈部署，开发经验；?
5、了解Oracle、MySQL、SQL Server、DB2至少一种数据库软件，熟练使用SQL完成常规取数，使用Linux Shell、Python脚本初步处理数据；?
6、熟悉联机分析处理(OLAP) 理论与工具，掌握OLAP数据平台，熟悉大数据结构化及非结构化分析工具；?
7、熟悉Sqoop，Hive，Impala，spark，Drill，kylin以及BI工具者优先；?

其他要求：?
1、 学习能力强，适应能力好，主动性强，抗压能力强，团队协作意识强，能适应一定程度的加班；?
2、 具备良好的沟通能力和表达能力，有较强的数据敏感度，良好的沟通协调能力，能承受一定的工作压力；"
"职位描述：
        
        工作职责：
1、负责企业级大数据产品核心功能的设计和开发
2、保证代码质量、效率和可靠性，编写产品技术文档，按时完成开发目标
3、配合测试组完成项目测试工作、系统交付工作
4、对项目交付和客户提供技术支持
?
任职要求：
1、Linux操作经验（Linux都不熟悉，大数据经验肯定不行）
2、MySQL/SQL关系型数据库使用经历
3、Maven，Java/scala开发调试能力（会写代码及简单的数据结构算法题，底线是二分查找）、JVM基础（堆内存、GC）
-大数据基础
1、熟悉HDFS&Yarn，MapReduce原理 或 Spark执行原理
2、熟悉Hbase存储和查询原理，对Hbase适用场景和关键问题（比如rowkey热点）有认识
-大数据开发项目
1、面向大数据平台组件做过相关开发工作，比如
a）数据接入治理：flume, kafka, hive, spark streaming等
b)? 数据存储和查询：hbase，sparksql等"
"职位描述：
        
        岗位职责：
1. 参与数据中台的设计和数据建模。
2. 解决客户现场大数据方面的问题，bug修复。
 任职资格： 1. 全日制统招本科以上学历，计算机、软件等相关专业。2年以上数据建模/运维经验。 2. 熟悉Linux系统，能够熟练使用shell/python脚本处理工具，熟练排查linux常见问题和故障 3. 深入理解Hdfs/Hive/Spark/HBase/Yarn/Kafka/其中的一个或者两个的内部运行机制。 4. 熟练使用sql进行数据的开发和建模。 5. 有相关数据治理经验是一个加分项。
6. 熟悉druid，elasticsearch，Kylin等OLAP数据库是一个加分项。"
"职位描述：
        
        岗位职责：
1. 负责项目数据标准的制定的收集、整理、分析工作?
2. 负责数据结构的详细设计工作?
3. 负责大数据批量转换、处理工作?
4. 负责项目中程序员的技术支持工作，包括简单sql语句、数据库相关对象的创建、相关服务的发布等?
5. 负责客户现场数据的部署、发布、测试等工作?
6. 积极完成项目团队中的其他技术支持工作。?
7. 1-2年的gis数据处理工作经验优先。

任职要求：
1. 测绘、地理信息系统、城市规划相关专业毕业.。
2. 熟悉国内外gis平台，如arcgis、skyline、mapgis、cad、mapinfo等 ，熟悉silverlight。
3. 熟悉关系型数据库的操作，如access、oracle、sqlserver等，有基本sql语句编写能力?
4. 有一定的数据标准文档编写能力，能完成数据说明书、数据处理报告等文档的编写?
5. 具有良好的沟通能力、学习能力和团队合作意识、良好的职业素养和责任心，工作严谨?
6. 能适应短期出差?
7. 具有地理信息系统从业经验或有规划、国土、水利、管线行业从业经验者优先。"
"职位描述：
        
        工作职责:1. ? ?负责相关开源系统/组件的性能、稳定性、可靠性等方面的深度优化；2. ? ?负责解决产品生产环境下各种实际问题，保障大数据平台在生产环境下的高可用性；3. ? ?带领团队进行技术设计工作和疑难技术的攻关任职资格:1. ? 熟悉linux、JVM底层原理，3年以上的后台开发经验,能作为技术担当，解决核心技术问题2、掌握基础网络协议（TCP、HTTP等）知识，熟悉网络编程和网络服务框架等3、具有扎实的编程基础，熟练掌握至少一门语言c/c++/java/go/python4、熟悉多线程并发编程技术；熟练掌握各种数据结构和算法5、追求高品质代码，对工程质量有深刻认识， 注重模块化、单元测试、异常测试6、性格开朗、善于沟通，有极强的技术敏感性和自我驱动学习能力，注重团队意识满足以下之一条件者优先：1、有大规模分布式对象、文件、块存储或分布式数据库等项目相关开发经验2、有以下任一开源存储系统开发经验：HBASE/HDFS、Elasticsearch、LevelDB/RocksDB，MongoDB,Redis， Ceph，Clickhouse, Etcd，Openresty等3、熟悉Linux下 I/O协议栈"
"职位描述：
        
        职位描述：
1、负责搭建hadoop/spark集群，并维护与管理；
2、负责hadoop平台上的数据存储，数据维护和优化；
3、利用hadoop、hive、spark平台、Nosql数据库、redis内存数据库、实时分析平台，进行数据统计、分析、挖掘，处理等作；
4、负责大数据应用平台核心模块的详细设计和开发工作；
5、使用java进行程序开发
任职资格：
1、计算机相关专业本科及以上学历；3年以上大数据处理经验
2、精通关系型数据库（mysql,oracle）和非关系型数据库；
3、熟悉linux操作系统，熟练编写shell脚本；
4、具备较强的逻辑思维能力，能快速分析并解决出现的问题,具有较强的沟通能力；
5、熟悉面向对象的设计和开发过程，能熟练使用 Scala ?、java 、 Python等开发语言；
6、熟悉Hadoop、hive、HBase、Zookeeper 、Storm 、Spark等分布式框架，对hadoop源码有深入研究和工作经验者优先；
7、精通hadoop,spark的基本原理,并能够熟练编写spark程序；
8、具有hadoop cluster部署、优化、排错的能力；
9、熟练使用hive，并能够编写hiveQL,及sparksql"
"职位描述：
        
        岗位职责：
1、负责公司项目大数据平台的构建与开发；
2、负责公司项目大数据平台研发过程中的设计文档的撰写；
3、撰写规范专业的技术文档，研究行业前沿技术；
4、大数据平台的新技术调研。

任职要求：
1、信息类或计算机类相关专业本科以上学历，掌握扎实的IT基础知识。
2、熟练掌握Java、scala编程语言，具有两年以上JavaEE开发经验。
3、熟悉面向对象编程、主流Java框架，熟练使用eclipse等IDE。
5、熟悉Linux/Unix的基本使用, 能独立搭建Linux/Unix应用部署。
6、具有较强的逻辑思维、学习能力和解决问题的能力，能够独立承担任务。
7、具有良好的团队协作精神和沟通能力，能够承担较大工作压力。
8、较强的自我驱动能力，结果导向并极具责任感。
9、有大数据应用、大型互联网应用项目经验者优先。"
"职位描述：
        
        岗位职责：
1、负责数据接入、数据清洗、底层重构，业务主题建模等工作；
2、负责大数据整体平台的架构与方案编写。
?
任职要求：
1、计算机、软件工程等相关专业，本科及以上学历，具有3年及以上大数据开发与架构分析经验优先考虑；??
2、?熟悉Hadoop或Spark生态相关技术，包括MapReduce、hdfs、Hive、Spark等，1个以上大数据平台项目实施经验；?熟悉Oracle或MySQL数据库技术；
3、熟悉数据仓库和数据建模的相关技术细节，精通JAVA语言；熟悉SQL/Hadoop/Hive/Hbase/Spark等大数据工具。?
4、具有海量数据处理经验，或有互联网行业数据挖掘工作经验者优先。"
"职位描述：
        
        职位描述 : 1. 参与公司 BI 和 数据仓库的搭建 2. 参与数据质量、数据安全方面的管理和稽查 3. 基于数据驱动构建企业的数据模型EDW以及面向应用产品与分析的应用层模型设计开发 4. 参与数据平台的研发，发掘数据商业价值，打造极致用户体验的票务平台。 职位要求 :  1. 熟悉大数据框架并拥有实际开发和调优经验(Hadoop,MapReduce,Spark,Storm,Flink 等); 2. 拥有分布式存储及优化经验(ELK, Redis, Hbase, HDFS); 3. 了解日志系统、监控告警系统、自动化技术平台，有相关开发经验优先; 4、熟悉并掌握一门或多门语言（Python、Java、PHP、Go、C&C++、shell）的使用，有Python、java开发经验优先; 5、具备数据分析能力，熟练掌握SQL语言; 6、有较强的思考能力和创新能力，具有踏实的工作心态，具有良好的团队协作能力和沟通、学习能力。"
"职位描述：
        
        工作职责：
1、参与数据仓库和大数据平台的环境搭建、架构设计和程序开发；
2、参与分布式结构化数据的数模设计；
3、主要负责大数据实时计算的新技术落地及平台提升；
4、负责分布式批量计算、分布式内存计算、数据仓库类SQL查询统计等离线计算。

职位要求：
1、本科及以上学历，计算机、软件工程或相关专业出身，4年以上工作经验，具有Hadoop、Spark、Spark Streaming、Flink开发与应用经验；
2、 熟悉Flume与Kafka等数据采集和消息通道技术，熟练掌握HDFS、Hbase、Hive、Spark、Flink等大数据技能，熟练掌握Spark Streaming、Flink等流计算技术；
3、有较好的Java或Scala基础；
4、熟悉Linux环境及脚本开发（Python/Perl/Shell等）；
5、熟悉MySQL，Redis，Druid，能够快速的理解业务模型及数据模型；
6、理解ETL过程，拥有DW项目开发经验，熟练掌握SQL/HQL；
7、积极主动参与讨论、发现并解决问题；
8、学习能力强，拥有优秀的逻辑思维能力、良好的理解和表达能力、较强的抗压能力；
9、能迅速融入团队，与其他团队成员保持良好的合作。

加分项：
1、有大型互联网公司流量项目开发经验；
2、有Linux操作系统及Tomcat中间件运维经验；
3、熟悉CDH集群管理并有kerberos及sentry权限管理经验；
4、有过Hadoop开源项目经历。"
"职位描述：
        
        工作职责：
1、参与数据仓库和大数据平台的环境搭建、架构设计和程序开发；
2、参与分布式结构化数据的数模设计；
3、主要负责大数据实时计算的新技术落地及平台提升；
4、负责分布式批量计算、分布式内存计算、数据仓库类SQL查询统计等离线计算。

职位要求：
1、本科及以上学历，计算机、软件工程或相关专业出身，4年以上工作经验，具有Hadoop、Spark、Spark Streaming、Flink开发与应用经验；
2、 熟悉Flume与Kafka等数据采集和消息通道技术，熟练掌握HDFS、Hbase、Hive、Spark、Flink等大数据技能，熟练掌握Spark Streaming、Flink等流计算技术；
3、有较好的Java或Scala基础；
4、熟悉Linux环境及脚本开发（Python/Perl/Shell等）；
5、熟悉MySQL，Redis，Druid，能够快速的理解业务模型及数据模型；
6、理解ETL过程，拥有DW项目开发经验，熟练掌握SQL/HQL；
7、积极主动参与讨论、发现并解决问题；
8、学习能力强，拥有优秀的逻辑思维能力、良好的理解和表达能力、较强的抗压能力；
9、能迅速融入团队，与其他团队成员保持良好的合作。

加分项：
1、有大型互联网公司流量项目开发经验；
2、有Linux操作系统及Tomcat中间件运维经验；
3、熟悉CDH集群管理并有kerberos及sentry权限管理经验；
4、有过Hadoop开源项目经历。"
"职位描述：
        
        工作职责：
1、负责推荐系统架构服务开发及优化；
2、优化推荐系统性能、稳定性、可扩展性，保障算法策略模块快速迭代；
3、分析用户行为数据、产品和服务等内容数据，增加有效的用户特征和内容数据特征，改进模型和召回、排序策略，提升推荐效果；?
4、提升用户获取知识和产品资讯等的效率，改善用户体验。

任职资格：
1、熟悉linux平台，熟练使用java/python，熟悉常用的数据结构，具有良好的编程习惯；
2、熟悉Hadoop、spark等大数据处理工具；
3、有用户画像、标签系统、推荐系统等相关开发经验，熟悉常用的搜索或推荐算法，理解算法思想；
4、在个性化推荐、知识推理、智能问答方面有研发和应用经验者优先；
5、掌握机器学习相关知识，有深度学习在推荐系统中应用经验者优先；
6、有海量数据机器学习/数据挖掘/计算广告/搜索引擎相关经验者优先；
7、有较强的学习能力，逻辑思维能力强，责任感强，工作积极主动，有良好的团队协作意识。"
"职位描述：
        
        工作职责：
1、HDFS/HBase/Ceph等分布式存储系统的性能改进、功能扩展、故障处理；
2、不断解决规模增长带来的技术和业务问题，确保大数据存储系统的稳定、高效、易用。

职位要求：
1、2年以上Hadoop生产环境或其他分布式存储系统工作经验；
2、对技术有着永无止境的追求，自认为是技术Geek，具备很强的问题解决能力；
3、熟悉Hadoop生态系统或其他开源存储项目源码，至少精读过其中某一个的源码，对大规模数据处理具有独到的理解，有patch或源代码经验者优先。"
"职位描述：
        
        工作职责：
1、HDFS/HBase/Ceph等分布式存储系统的性能改进、功能扩展、故障处理；
2、不断解决规模增长带来的技术和业务问题，确保大数据存储系统的稳定、高效、易用。

职位要求：
1、2年以上Hadoop生产环境或其他分布式存储系统工作经验；
2、对技术有着永无止境的追求，自认为是技术Geek，具备很强的问题解决能力；
3、熟悉Hadoop生态系统或其他开源存储项目源码，至少精读过其中某一个的源码，对大规模数据处理具有独到的理解，有patch或源代码经验者优先。"
"职位描述：
        
        岗位职责：
1. 研究智能运维（AIOPS）场景下的AI应用?
2. 基于IT监控大数据，在时序数据异常检测、事件处理，告警根源分析、智能决策支持等方面探索优化产品功能；
3. 负责AIOPS系统的算法和模型的实现，丰富算法库；
4. 参与AIOPS系统设计与研发，探索人工智能在IT领域的创新应用，驱动公司业务的发展。

岗位要求:?
1. 计算机、数学、自动化等相关专业，本科及以上学历，3-5年软件开发相关工作经验；
2. 2年以上大数据或AI相关经验者优先；
3. 有AI应用开发或者AI平台架构经验，精通TensorFlow/Caffe等人工智能技术框架者优先；
4. 熟练使用以下编程语言中的至少一种： Java，C++，Python，GO语言，优秀的开发、调试能力，有大规模4. 高并发、高性能应用架构设计和开发经验者优先；
5. 掌握AI基础概念，理解机器学习基本算法的设计思想和求解手段，熟悉时间序列处理，熟悉机器学习常用算法：决策树，随机森林，协同过滤，SVM, 回归算法等
6. 熟悉机器学习常用类库（如：Numpy，Pandas, Scikit-Learn, Tensorflow，Keras等）, 熟悉神经网络理论，熟悉CNNRNNLSTM原理；
7. 对新技术钻研有强烈兴趣，对挑战性问题充满激情，有良好的学习能力和强烈的进取心；
8. 具备优秀的逻辑思维能力，快速分析和解决问题的能力，有良好的沟通和团队协作能力，对业务有较好的理解能力和敏锐度，注重理论与实际。"
"职位描述：
        
        职责描述：1. 基于Hadoop与Spark，进行海量数据模型设计、数据ETL开发；2. 负责基于开源框架的大数据的数据开发，包括数据提取、分析与结果整理；3. 负责分布式数据平台框架下的数据架构设计与开发，以及数据产品开发；4. 参与公安大数数据模型体系构建及算法模型的设计和开发；5. 开发大数据自动化运维、监控、故障处理工具，监控所有基础设施组件、应用程序，提供紧急应急措施。
任职要求：1. 计算机、数学、统计或相关专业本科及以上学历，三年以上软件开发工作经验，数据挖掘和BI分析领域优先；2. 至少熟悉一种关系型数据库如Oracle、mysql等，熟练掌握Hive/SQL，熟悉Spark/Map-Reduce/MPI分布式计算框架，进行海量数据模型设计、数据ETL开发；熟悉实时数据处理者优先； 3. 熟练使用Java，熟悉常用的java类库以及框架； 4. 熟练使用Python/Shell/Perl/R语言等其中一种语言优先； 5. 熟悉回归分析模型、关联规则挖掘、分类和聚类算法、协同过滤算法等数据统计模型和挖掘算法，了解完整的数据挖掘过程方法论，并有独立完整的建模实践经验，优先；6.有轨迹分析算法、推荐算法相关的实际项目经验，优先考虑；7. 具有良好的沟通、团队协作、解决问题和创新的能力；8.有CCA开发员认证者优先。"
"职位描述：
        
        职责描述：1. 基于Hadoop与Spark，进行海量数据模型设计、数据ETL开发；2. 负责基于开源框架的大数据的数据开发，包括数据提取、分析与结果整理；3. 负责分布式数据平台框架下的数据架构设计与开发，以及数据产品开发；4. 参与公安大数数据模型体系构建及算法模型的设计和开发；5. 开发大数据自动化运维、监控、故障处理工具，监控所有基础设施组件、应用程序，提供紧急应急措施。
任职要求：1. 计算机、数学、统计或相关专业本科及以上学历，三年以上软件开发工作经验，数据挖掘和BI分析领域优先；2. 至少熟悉一种关系型数据库如Oracle、mysql等，熟练掌握Hive/SQL，熟悉Spark/Map-Reduce/MPI分布式计算框架，进行海量数据模型设计、数据ETL开发；熟悉实时数据处理者优先； 3. 熟练使用Java，熟悉常用的java类库以及框架； 4. 熟练使用Python/Shell/Perl/R语言等其中一种语言优先； 5. 熟悉回归分析模型、关联规则挖掘、分类和聚类算法、协同过滤算法等数据统计模型和挖掘算法，了解完整的数据挖掘过程方法论，并有独立完整的建模实践经验，优先；6.有轨迹分析算法、推荐算法相关的实际项目经验，优先考虑；7. 具有良好的沟通、团队协作、解决问题和创新的能力；8.有CCA开发员认证者优先。"
"职位描述：
        
        工作职责：?
1.?公司数据体系的完善和把控，数据报表相关开发
2.?对海量业务数据进行处理、整合、分析，为运营及决策提供业务分析及数据支持；
3.?跟踪数据异常的原因，为业务和技术系统的优化，提出解决方案
4.?参与大数据系统的构架和二次开发，包括但不局限于BI系统、实时计算系统
5.?参与用户画像、知识图谱，以及其他数据挖掘相关的工作
任职要求：
1.?计算机、数学统计类相关专业，正规院校本科及以上学历；
2. 有数据挖掘分析相关经验，熟悉 storm，kafka等框架
3.?熟练使用hive，熟悉Linux操作系统，熟悉Python语言；
4.?熟悉Hadoop工作流程，熟悉MR执行流程，能够编写MapReduce/Spark程序
5. 优秀的学习能力，分析和解决问题的能力
6. 富有挑战精神和强烈的进取心
7. 诚恳、踏实，敢于承担责任，对技术和工作充满热情"
"职位描述：
        
        工作职责：?
1. 公司数据体系的完善和把控，数据报表相关开发?
2. 对海量业务数据进行处理、整合、分析，为运营及决策提供业务分析及数据支持；?
3. 跟踪数据异常的原因，为业务和技术系统的优化，提出解决方案?
4. 参与大数据系统的构架和二次开发，包括但不局限于BI系统、实时计算系统?
5. 参与用户画像、知识图谱，以及其他数据挖掘相关的工作?
任职要求：?
1.?计算机、数学统计类相关专业，正规院校本科及以上学历；?
2.?1年以上数据挖掘分析相关经验，了解?storm，kafka等框架?
3.?熟练使用hive，熟悉Linux操作系统，了解Python语言；?
4.?熟悉Hadoop工作流程，熟悉MR执行流程，能够编写MapReduce/Spark程序优先?
5.?优秀的学习能力，分析和解决问题的能力?
6.?富有挑战精神和强烈的进取心?
7.?诚恳、踏实，敢于承担责任，对技术和工作充满热情"
"职位描述：
        
        岗位职责：
1.负责游戏统计相关的技术选型、设计以及开发，包括数据采集、存储、分析、挖掘、与BI对接等，利用数据驱动游戏用户的增长和产品功能迭代，并形成工具化产品便于游戏接入；
2.负责游戏统计相关流程的优化，产出处理亿级别增量数据的能力，包括性能、稳定性等方面，确保产品稳定运行
3.参与数据底层的工具、平台、部署流程等技术体系建设的工作，提升技术池深度及广度；

任职要求：
1.熟练掌握Hadoop生态中各组件的功能，有解决集群环境中各种问题的经历，能够对技术团队中遇到的Hadoop或Spark相关技术栈的问题予以有力的支持；
2.强悍的编码能力，生产环境快速 troubleshooting能力，对新技术有强烈的学习热情；；
3.具有3年以上的实际工作经验，有海量数据的数仓设计和ETL开发的项目实践；
4.优秀的逻辑思维能力和业务需求分析能力，良好的沟通交流能力，善于主动思考和自我驱动；"
"职位描述：
        
        工作职责
参与大数据产品平台架构设计和研发；
负责大数据模块详细设计和实现；
参与大数据平台优化和产品性能优化；
负责大数据平台代码实现、单元测试、代码修改和维护等工作。

职位要求
2年以上大数据相关产品开发经验，本科以上学历；
较强英语阅读能力，可以熟练检索和查阅英文文档和文献；
扎实的计算机编程能力和良好的编程习惯，熟悉Linux环境下编程，至少精通Java/Scala/Python语言其中的一种，熟悉常用的shell命令工具，熟悉Git源代码版本控制工具；
有分布式系统的设计、开发、调优实战经验，熟练掌握Hadoop、Spark、MongoDB、HBase、Hive、ElasticSearch、Redis、Storm等技术；
对大规模分布式系统有深入研究者优先，有开源代码贡献经历优先；
熟悉基于图数据库（Neo4j、Titan/JanusGraph）的系统开发者优先；
具有数据挖掘和带团队工作经验优先，具有在科研单位、事业单位的研发工作经验者优先；
具备强烈的进取心、严格的逻辑思维分析解决问题能力，有良好的沟通表达能力和团队合作精神。"
"职位描述：
        
        工作职责

参与大数据产品平台架构设计和研发；

负责大数据模块详细设计和实现；

参与大数据平台优化和产品性能优化；

负责大数据平台代码实现、单元测试、代码修改和维护等工作。

职位要求

2年以上大数据相关产品开发经验，本科以上学历；

较强英语阅读能力，可以熟练检索和查阅英文文档和文献；

扎实的计算机编程能力和良好的编程习惯，熟悉Linux环境下编程，至少精通Java/Scala/Python语言其中的一种，熟悉常用的shell命令工具，熟悉Git源代码版本控制工具；

有分布式系统的设计、开发、调优实战经验，熟练掌握Hadoop、Spark、MongoDB、HBase、Hive、ElasticSearch、Redis、Storm等技术；

对大规模分布式系统有深入研究者优先，有开源代码贡献经历优先；

熟悉基于图数据库（Neo4j、Titan/JanusGraph）的系统开发者优先；

具有数据挖掘和带团队工作经验优先，具有在科研单位、事业单位的研发工作经验者优先；

具备强烈的进取心、严格的逻辑思维分析解决问题能力，有良好的沟通表达能力和团队合作精神。"
"职位描述：
        
        工作职责
参与大数据产品平台架构设计和研发；
负责大数据模块详细设计和实现；
参与大数据平台优化和产品性能优化；
负责大数据平台代码实现、单元测试、代码修改和维护等工作。
职位要求
2年以上大数据相关产品开发经验，本科以上学历；
较强英语阅读能力，可以熟练检索和查阅英文文档和文献；
扎实的计算机编程能力和良好的编程习惯，熟悉Linux环境下编程，至少精通Java/Scala/Python语言其中的一种，熟悉常用的shell命令工具，熟悉Git源代码版本控制工具；
有分布式系统的设计、开发、调优实战经验，熟练掌握Hadoop、Spark、MongoDB、HBase、Hive、ElasticSearch、Redis、Storm等技术；
对大规模分布式系统有深入研究者优先，有开源代码贡献经历优先；
熟悉基于图数据库（Neo4j、Titan/JanusGraph）的系统开发者优先；
具有数据挖掘和带团队工作经验优先，具有在科研单位、事业单位的研发工作经验者优先；
具备强烈的进取心、严格的逻辑思维分析解决问题能力，有良好的沟通表达能力和团队合作精神。"
"职位描述：
        
        岗位职责：1. 负责大数据平台（Hadoop/Hbase/Hive/Spark）的自动部署、自动化维护和性能调优；2. 负责大数据平台的用户管理和任务调度功能开发，以及整体平台解决方案的产品化输出；3. 负责业务相关的数据存储、算法分析与统计等API接口设计与开发；4. 负责大数据具体应用算法的设计，以及大规模数据的深度关联分析和实时统计分析；5. 负责基于大数据平台的可视化框架产品开发；职位要求：* 具有计算机、应用数学、模式识别、人工智能、统计等专业背景知识，具备研究、钻研精神，不断追求超越和创新；* 对机器学习、数据挖掘算法及其在互联网行业的应用，有比较深入的认识和理解；* 熟悉Hadoop、HBase、Hive/Pig、Storm、Spark、Mahout、NoSQL、ES中至少一种技术，阅读过源代码者优先；* 充分理解大数据背景下的计算模型，熟悉MapReduce、Spark开发流程模型中任一，并具有分布式开发经验；* 了解Docker、Mesos等技术，有实际经验者优先；* 熟悉NLP等技术，有实际经验者优先；* 熟悉大数据存储和计算模块的性能优化；* 具备较强的逻辑思维能力、学习创新能力、数据分析能力，以及良好的沟通技巧和团队合作能力；开发语言要求：* 熟练掌握Python，Java，Scala中至少2种语言* 熟练Bash脚本其它要求：* 具有网络安全行业背景优先"
"职位描述：
        
        工作职责:【工作职责】1. 负责大数据产品平台架构设计和研发；2. 负责大数据产品模块详细设计和开发；3. 负责大数据平台优化和产品性能优化；4. 参与大数据平台代码实现、单元测试、代码修改和维护等工作;5. 领导相关大数据产品的技术攻关。任职资格:【职位要求】1. 3～5年以上大数据开发经验，本科以上学历；2. 扎实的计算机编程能力和良好的编程习惯，熟悉linux环境下编程，精通java/scala/python语言，熟悉常用的shell命令工具，熟悉Git源代码版本控制工具；3. 有分布式系统的设计、开发、调优实战经验，熟练掌握Hadoop、Spark、MongoDB、Hbase、Hive、ElasticSearch、Redis、Storm等技术；4. 具有数据挖掘和带团队工作经验优先；5. 具备强烈的进取心、严格的逻辑思维分析解决问题能力，有良好的沟通表达能力和团队合作精神。6. 对大规模分布式系统有深入研究者优先，有开源代码贡献经历优先"
"职位描述：
        
        岗位职责：

1、支持业务需求，基于海量数据实现数据采集、清洗入库、统计计算，包括运营报表/仪表盘开发；
2、协助策略落地实现，提供高可靠数据服务；
3、对业务和数据进行梳理，设计大数据模型，构建相关应用，用数据推动业务发展；
4、主要负责流式实时计算分析和离线数据统计分析。

任职要求：

1、本科及以上学历，3年及以上大数据相关工作经验；
2、具备成熟的系统设计架构能力，丰富的高并发、分布式的系统设计经验；
3、熟悉业界先进的大数据生态组件（MR/Spark/HBase/ElasticSearch/ClickHouse/Hadoop/Hive），有成熟的系统设计应用经验；
4、熟悉Mysql/Redis/MongDB等系统原理机制以及线上应用经验原则；
5、对新技术保持求知欲，熟悉数据采集、清洗入库、统计计算、Web展示核心要点，可实现指标计算需求；
6、具有优秀的代码治理经验，良好的表达能力和团队协作精神；
7、具有顽强的拼搏精神、奉献精神、敬业精神,有英文读写和交流能力者优先。"
"职位描述：
        
        工作职责：
负责通用大数据平台工具的架构和开发，包括，调度系统，开发平台，多维分析平台，可视化系统以及 AB 实验平台等
负责公司大数据体系的标准制定以及建设落地，包括，数据采集规范，数仓建设规范，权限资源规范等
主导公司数据治理工作，提升数据易用性，保证数据质量以及管控数据成本
负责对业务提供数据能力输出，建设各类附能业务分析的数据产品，包括，用户和内容画像等
负责数据平台团队的人才结构建设和内外协作管理，提升团队的技术实力和服务能力
任职资格：
五年以上数据架构或者数据平台工作经验，有 PB 级大数据处理实战经验
深刻理解 Hadoop、Spark、Hive、Kafka 和 Flink 等技术体系
代码开发能力强悍，至少熟练使用 Java、Scala、Go、Python 其中一种
具备强烈的理解业务、服务业务和驱动业务的意识
具备出色的逻辑思维能力、组织协调能力、沟通交流能力

加分项：
熟悉 Druid，Kudu、HBase、ClickHouse 等 OLAP 存储系统底层架构
有数据开发和数据治理相关经验
熟悉数据挖掘和数据算法，并有一定的实践"
"职位描述：
        
        工作职责：
负责通用大数据平台工具的架构和开发，包括，调度系统，开发平台，多维分析平台，可视化系统以及 AB 实验平台等
负责公司大数据体系的标准制定以及建设落地，包括，数据采集规范，数仓建设规范，权限资源规范等
主导公司数据治理工作，提升数据易用性，保证数据质量以及管控数据成本
负责对业务提供数据能力输出，建设各类附能业务分析的数据产品，包括，用户和内容画像等
负责数据平台团队的人才结构建设和内外协作管理，提升团队的技术实力和服务能力
任职资格：
五年以上数据架构或者数据平台工作经验，有 PB 级大数据处理实战经验
深刻理解 Hadoop、Spark、Hive、Kafka 和 Flink 等技术体系
代码开发能力强悍，至少熟练使用 Java、Scala、Go、Python 其中一种
具备强烈的理解业务、服务业务和驱动业务的意识
具备出色的逻辑思维能力、组织协调能力、沟通交流能力

加分项：
熟悉 Druid，Kudu、HBase、ClickHouse 等 OLAP 存储系统底层架构
有数据开发和数据治理相关经验
熟悉数据挖掘和数据算法，并有一定的实践"
"职位描述：
        
        大数据开发工程师

工作职责：负责知乎信息流业务的业务日志生成、业务数据处理、报表开发、实时数据处理等功能和相关模块的开发及优化，为业务决策提供依据，保证数据的稳定性和准确性，为线上服务提供优质数据；

任职资格：
1）有大数据系统开发经验，熟悉 Hadoop 技术栈，掌握 MapReduce、Spark、Hive 等数据处理工具；
2）掌握 HBase、Redis 等海量分布式数据存储及访问框架；
3）熟练掌握 Java/Scala，Python 等高级编程语言中的一种或几种；熟悉 IO、并发等编程框架；
4）良好的业务理解能力，能够和团队成员进行有效的沟通和协作；

加分项：
1）有过数据仓库、大数据平台、BI 系统开发经验者优先；
2）有推荐、搜索、广告等相关领域工作经验者优先；"
"职位描述：
        
        数据平台开发工程师

职位描述
1. 公司数据集成服务模块的开发，负责数据的落地和交换
2. 数据开发、元信息管理和任务调度平台模块开发
3. AB Testing 实验平台功能开发


职位要求
1. 5年以上工作经验，有数据开发经验或者 AB Testing 开发经验优先
2. 精通 Java 语言，熟悉 Java Spring 开发框架
3. 对 AB Testing 或者用户画像有开发经验者优先
4. 编码能力强悍，熟悉 Hadoop，Spark，Hive，Druid，HBase 等应用开发经验优先
5. 善于沟通，具备优秀的产品嗅觉，优秀的技术与业务结合能力"
"职位描述：
        
        

 负责公司大数据平台建设，设计有层次、灵活可扩展的平台架构
 负责数据可视化平台的设计与优化，满足灵活的多维分析需求和稳定的报表需求
 搭建公司统一的数据服务层，高效开放数仓生产的数据
 设计和搭建公司通用数据集成服务建设，负责数据的落地和交换


职位要求


 有数据服务或者数据集成经验者优先
 精通 Java 语言，熟悉 Java Web 开发框架
 有至少 TB 以上级大数据处理经验，支撑过实际业务场景
 编码能力强悍，熟悉 Flume，Spark，Kylin，Druid，Storm，Flink 等应用开发经验优先
 善于沟通，具备优秀的产品嗅觉，优秀的技术与业务结合能力
 3年以上相关工作经验"
"职位描述：
        
        职位描述：
负责数据仓库架构设计与开发
负责大数据建模、ETL、数据产品的设计开发
满足业务线数据需求，设计面向业务的数据集市模型
需求的沟通与数据开发项目管理

职位要求

编码能力强悍，Java / Scala / Python 其中一种深入掌握。具备 Hadoop，Spark，Hive，Druid，Storm，Flink 等大数据开发经验优先
对数据敏感，逻辑清晰、严谨，数据仓库实施经验优先
熟练使用 SQL，有一定的 HQL 或 SQL 性能调优经验优先
善于沟通，具备优秀的产品嗅觉，优秀的技术与业务结合能力"
"职位描述：
        
        负责数据仓库架构设计与开发
负责大数据建模、ETL、数据产品的设计开发
满足业务线数据需求，设计面向业务的数据集市模型
需求的沟通与数据开发项目管理

职位要求

编码能力强悍，Java / Scala / Python 其中一种深入掌握。具备 Hadoop，Spark，Hive，Druid，Storm，Flink 等大数据开发经验优先
对数据敏感，逻辑清晰、严谨，数据仓库实施经验优先
熟练使用 SQL，有一定的 HQL 或 SQL 性能调优经验优先
善于沟通，具备优秀的产品嗅觉，优秀的技术与业务结合能力"
"职位描述：
        
        工作职责:
* 负责知乎大数据计算引擎方向技术规划和开发落地
* 业界新技术跟踪调研及对外技术交流
任职资格：
* 熟悉 SQL 解析及逻辑物理计划机制
* 熟悉常见的 OLAP 计算引擎（如 hive，spark，impala，presto，clickhouse，hawq，druid，kylin 等）架构和实现，对源码有深入研究者优先
* 熟悉 Linux 系统下软件性能监控和调优技术
* 熟悉 Devops 思想，具备大数据计算引擎平台化的产品功能设计能力
* 强烈的工作责任心和对技术的热情"
"职位描述：
        
        工作职责:
* 负责知乎大数据计算引擎方向技术规划和开发落地
* 业界新技术跟踪调研及对外技术交流
任职资格：
* 熟悉 SQL 解析及逻辑物理计划机制
* 熟悉常见的 OLAP 计算引擎（如 hive，spark，impala，presto，clickhouse，hawq，druid，kylin 等）架构和实现，对源码有深入研究者优先
* 熟悉 Linux 系统下软件性能监控和调优技术
* 熟悉 Devops 思想，具备大数据计算引擎平台化的产品功能设计能力
* 强烈的工作责任心和对技术的热情"
"职位描述：
        
        

 构建分布式大数据服务平台，参与构建公司海量数据存储、实时查询系统
 负责知乎内部 HBase 集群的规划，维护和调优, 为业务应用提供平台级支持和服务
 深入 HBase 源码内核改进优化项目，解决各类 HBase 线上问题


岗位要求

 2年以上java经验，了解JVM调优，熟练使用 shell 以及 python, 熟悉 Go 以及 Ruby 语言优先；
 熟悉Hadoop生态，理解 HBase/HDFS/Zookeeper架构和工作原理；
 了解至少一种主流分布式存储系统的架构和实现细节；
 极强的责任心和快速解决问题的能力；?
 有大规模 HBase 集群运维经验或对 HBase 存储原理熟悉者优先。"
"职位描述：
        
        搭建公司级可视化分析系统和数据服务
维护全端数据的采集和集成，对接数仓
管理数据生命周期，提供一站式的数据开发、元信息管理和任务调度平台


职位要求

精通 Java 语言，熟悉 Java Web 开发框架
至少 3 年以上工作经验，有至少 TB 以上级大数据处理经验，支撑过实际业务场景
编码能力强悍，熟悉 Hadoop，Spark，Hive，Druid，Storm，Flink 等应用开发经验优先
善于沟通，具备优秀的产品嗅觉，优秀的技术与业务结合能力"
"职位描述：
        
        
 搭建公司级可视化分析系统和数据服务
 维护全端数据的采集和集成，对接数仓
 管理数据生命周期，提供一站式的数据开发、元信息管理和任务调度平台
 提供 AB Testing 实验平台，系统化集成实验分析框架，推动业务增长



职位要求


 精通 Java 语言，熟悉 Java Web 开发框架
 至少 3 年以上工作经验，有至少 TB 以上级大数据处理经验，支撑过实际业务场景
 编码能力强悍，熟悉 Hadoop，Spark，Hive，Druid，Storm，Flink 等应用开发经验优先
 善于沟通，具备优秀的产品嗅觉，优秀的技术与业务结合能力"
"职位描述：
        
        职位描述：
构建分布式大数据服务平台，参与构建公司海量数据存储、实时查询系统
负责知乎内部 HBase 集群的规划，维护和调优, 为业务应用提供平台级支持和服务
深入 HBase 源码内核改进优化项目，解决各类 HBase 线上问题

岗位要求：
1年以上java经验，了解JVM调优，熟练使用 shell 以及 python, 熟悉 Go 以及 Ruby 语言优先；
熟悉Hadoop生态，理解 HBase/HDFS/Zookeeper架构和工作原理；
了解至少一种主流分布式存储系统的架构和实现细节；
极强的责任心和快速解决问题的能力；?
有大规模 HBase 集群运维经验或对 HBase 存储原理熟悉者优先。"
"职位描述：
        
        工作内容：
1. 分析,测试和优化Spark SQL
2. 开发自动化测试框架
?
Skill要求：
1. 有java基础
2. 熟悉SQL
2. 有数据库或者数据仓库开发经验优先"
"职位描述：
        
        工作内容：
1. 分析和解决用户在使用hadoop/spark系统中遇到的问题
2. 搭建SOP流程
3. 开发和使用大数据支持系统
4. 构建完善服务体系
?
Skill要求：
1. 有java基础
2. Hadoop/Spark有经验者优先
3. 有数据库或者数据仓库管理经验优先"
"职位描述：
        
        2019届的优秀毕业生
学历要求：本科以上；
专业要求：计算机/软件工程/信息/数学/物理等相关专业优先。
能力要求：1） 扎实的计算机/信息基本功，有一定的编程能力，熟悉Java/SQL，了解Linux或Unix系统；2）基本英语听说读写能力；3）良好的学习能力及团队合作。?
工作职责：敏捷开发流程下的研发工作。
可签署三方协议。"
"职位描述：
        
        我们使用的技术：
开发语言：scala、java、python、shell数据(仓)库：hive、impala、mysql、mongodb、redis监控工具：cloudera-sever、zabbix大数据存储引擎：hdfs、kudu大数据计算引擎：spark、spark-sream、mapreduce2、impala、flink采集工具：streamsets、sqoop、flume开发工具：gitlab、confluence、禅道、jenkins云服务器：阿里云、百度云

我们需要您：
1、整理并维护公司当前的大数据应用系统得维护和升级改造2、负责参与数据网关、大数据用户画像和风控等系统得研发3、根据业务需要，实现实时和离线数据得采集和清洗，并协助数据仓库工程师做好数据得入库4、负责业务需要得实时计算应用，并和公司其他应用系统做对接开发4、根据业务需要，协助开发看板报表、用户个性化报表对您的期望：
1、计算机相关专业，本科及以上学历，3年以上开发相关经验，2年以上大数据开发工作经验，学习能力突出2、扎实的Scala语言基础；熟练hadoop生态系统内常见项目的使用（hdfs、hive、Sqoop、hbase、spark、zookeeper,yarn等），有实际大数据项目经验优先3、数据库要求：熟悉Oracle或MySql、postgresql数据库中得一种4、开发框架要求：熟练运用Flume, Kafka, Spark Streaming/Storm等，并有实际项目运用经验；5、熟悉Linux/Unix环境及脚本开发（shell/python等）6、熟悉JAVA开发，了解基于J2EE的WEB架构设计，了解Web开发流程，有Web MVC（Struts、Spring，Hibernate等）开发经验； 熟悉scala语言更佳7、具有良好的沟通能力、组织能力及团队协作精神，有较强的分析和解决问题的能力加分项：1. 有Hadoop、Spark、HBase深入源代码分析经验 2. 熟悉机器学习、数据挖掘、分布式计算 3. 基础能力+学习能力特别优秀者"
"职位描述：
        
        我们使用的技术：
开发语言：scala、java、python、shell数据(仓)库：hive、impala、mysql、mongodb、redis监控工具：cloudera-sever、zabbix大数据存储引擎：hdfs、kudu大数据计算引擎：spark、spark-sream、mapreduce2、impala、flink采集工具：streamsets、sqoop、flume开发工具：gitlab、confluence、禅道、jenkins云服务器：阿里云、百度云

我们需要您：
1、整理并维护公司当前的大数据应用系统得维护和升级改造
2、负责参与数据网关、大数据用户画像和风控等系统得研发
3、根据业务需要，实现实时和离线数据得采集和清洗，并协助数据仓库工程师做好数据得入库
4、负责业务需要得实时计算应用，并和公司其他应用系统做对接开发
5、根据业务需要，协助开发看板报表、用户个性化报表对您的期望：
1、计算机相关专业，本科及以上学历，3年以上开发相关经验，2年以上大数据开发工作经验，学习能力突出
2、扎实的Scala语言基础；熟练hadoop生态系统内常见项目的使用（hdfs、hive、Sqoop、hbase、spark、zookeeper,yarn等），有实际大数据项目经验优先
3、数据库要求：熟悉Oracle或MySql、postgresql数据库中得一种
4、开发框架要求：熟练运用Flume, Kafka, Spark Streaming/Storm等，并有实际项目运用经验；
5、熟悉Linux/Unix环境及脚本开发（shell/python等）
6、熟悉JAVA开发，了解基于J2EE的WEB架构设计，了解Web开发流程，有Web MVC（Struts、Spring，Hibernate等）开发经验； 熟悉scala语言更佳
7、具有良好的沟通能力、组织能力及团队协作精神，有较强的分析和解决问题的能力加分项：
1、有Hadoop、Spark、HBase深入源代码分析经验
2、 熟悉机器学习、数据挖掘、分布式计算 3、 基础能力+学习能力特别优秀者"
"职位描述：
        
        岗位职责:
1． 参与金融大数据研发；
2． 参与数据仓库ETL流程的优化及解决ETL相关技术问题；
3． 负责数据基础架构的升级和优化，不断提升系统的稳定性和效率；
4． 设计并实现对机器学习、数据挖掘的系统性支持；

岗位要求：
1． 计算机相关专业，本科及以上学历；
2． 具备良好的编程习惯，熟悉常用的数据结构和算法；
3． 熟练掌握PHP/Python/java任一语言；
4． 具备良好的数据库理论基础知识，较强的sql书写能力，熟练使用MySQL/postgres等数据库；
5． 有数据处理，ETL流程优化实战经验,熟悉kettle/informatica等抽取工具；
6. ? 有使用 kafka，storm，spark streaming 实时数据处理系统建设经验优先。"
"职位描述：
        
        职位描述:
1、 负责公司数据平台架构设计、开发；
2、参与公司大数据产品（OLAP、AdHoc、实时指标）等可视化分析系统的设计和开发；
3、 保障和持续提升数据平台业务运营能力、支撑公司业务发展；
4、 参与大数据生态系统相关技术的使用、封装和优化等研发工作。

岗位要求:
1、 善于沟通、编码能力强悍；
2、 3年以上大数据相关工作经验，熟练掌握Java/scala开发语言；
3、 理解大数据生态技术的特性、原理、以及使用场景；
4、 至少读过一种源码，包括不限于（Hadoop、Hive、Spark、ElasticSearch、Hbase、Kafka）；
5、 有大数据平台、开发相关经验优先；
6、 有Druid、Kylin项目使用经验优先。"
"职位描述：
        
        岗位职责：1. 负责大数据平台技术框架的选型与集成；2. 基于大数据平台的数据产品与服务的规划、设计与开发；3. 负责应用数据采集、清洗、分析、展现；4、大规模数据挖掘和机器学习算法的实现；5、在线和离线海量数据分析平台的开发；6、研究大数据前沿技术，提升系统的运维效率；7、实现大数据基础架构平台的自动化运维。任职资格：1、计算机相关专业,具有1年以上大数据开发经验，熟悉Java,Linux；2、熟悉Hadoop大数据处理系统的开发,搭建及部署者优先；3、熟练地处理数据模型、数据ETL以及存储管理；4、熟悉Hadoop(HDFS/MapReduce/Hive)、Spark、HBase、Storm、Kafka、Flume等类框架技术，具备相关项目应用研发经验者优先考虑；5、熟悉分布式系统概念、架构，有大规模分布式系统设计、实现、部署等经验；6、有较强的书面与口头沟通表达能力，独立分析、解决问题的能力。


省广集团-大平台：
l? 我国最具规模的整合营销传播集团，中国广告业的扛旗者。
l? 中国服务业500强公司。
l? 上市集团。
大数据中心-核心部门：
l? 集团“大数据，全营销”战略的牵头及驱动部门；
l? 负责集团旗下公司数据整合及数据产品搭建、运营推广；
l? 负责大数据联盟搭建与运营，为内外部客户提供专业、全面的大数据技术支持和营销服务指导。
待遇：
l? 薪酬待遇：薪酬优厚，入职即买五险一金，工资+奖金+交通补贴+通讯补贴+餐补；
l? 福利完善：弹性工作、国外旅游、下午茶、零食、各类团建；
l? 员工提升：提供各类培训，有完整的员工晋升机制；
l? 互联网氛围：扁平化管理，同事领导均为大牛，并且非常nice；
l? 办公环境：办公环境优越，咖啡厅、健身房、电影院、食堂。"
"职位描述：
        
        岗位职责：
1. 3年以上工作经验，熟练运用数据库开发工具(postgres、mysql、oracle)。
2. 有Spark/Scala/Java开发经验
3. 具备丰富的金融行业数据仓库基础数据模型设计和开发经验；
4. 善于表达、乐于学习、理解能力较好
技术技能必备要求?
1. 有大数据平台（HIVE/Spark/Scala/Java）开发经验优先;
2. 工作细心，耐心，有较强责任心，有较强的沟通能力和团队协作精神。
3. 有较强积极主动能力，能主动接受工作安排，主动分析需求，主动提供开发建议
4. 性格开朗活泼
5. 本科及以上学历"
"职位描述：
        
        岗位职责：
1、负责基于Hadoop/Spark平台架构的开发、设计和布局?
2、完成系统框架的设计和核心代码的编写；?
3、针对海量的用户行为数据进行统计、分析与挖掘，不断提高系统运行效率。?
4、负责对数据进行分析，为项目组提供大数据技术指导及分析手段支撑，?
5、负责大数据平台的性能监控和持续优化；针对需求提供大数据分析技术解决方案?
6、大数据平台的运维工作，持续完善大数据平台，保证稳定性、安全性。?
任职资格：?
1、3年互联网行业开发经验，计算机或相关专业本科以上学历。?
2、精通Hadoop大数据平台架构，具有扎实的Java/Python等开发语言；并可以开发高效可靠的代码。
3、具有较强的数据分析、数据挖掘的能力。?
4、熟悉spark、Hive、storm等计算框架者优先，对分布式存储和计算原理有较深的理解。?
5、严密的数学思维、突出的分析和归纳能力、优秀的沟通表达能；?
6、个性开朗，对技术钻研好学、逻辑思维能力强，沟通能力优秀，有团队合作精神。"
"职位描述：
        
        岗位职责：
1、负责基于Hadoop/Spark平台架构的开发、设计和布局?
2、完成系统框架的设计和核心代码的编写；?
3、针对海量的用户行为数据进行统计、分析与挖掘，不断提高系统运行效率。?
4、负责对数据进行分析，为项目组提供大数据技术指导及分析手段支撑，?
5、负责大数据平台的性能监控和持续优化；针对需求提供大数据分析技术解决方案?
6、大数据平台的运维工作，持续完善大数据平台，保证稳定性、安全性。?
任职资格：?
1、3年互联网行业开发经验，计算机或相关专业本科以上学历。?
2、精通Hadoop大数据平台架构，具有扎实的Java/Python等开发语言；并可以开发高效可靠的代码。
3、具有较强的数据分析、数据挖掘的能力。?
4、熟悉spark、Hive、storm等计算框架者优先，对分布式存储和计算原理有较深的理解。?
5、严密的数学思维、突出的分析和归纳能力、优秀的沟通表达能；?
6、个性开朗，对技术钻研好学、逻辑思维能力强，沟通能力优秀，有团队合作精神。"
"职位描述：
        
        岗位职责：
负责开发内部深度学习专用数据分布式存储和处理平台。
任职资格：
1. 具有数据平台相关开发经验，熟练掌握分布式系统理论。
2. 熟练掌握 C++ 和 Go 语言。
3. 参与过开源分布式数据存储系统（如 HDFS, HBase）开发优先。
4. 参与过开源分布式数据处理系统（如 MapReduce, Spark, Ray）优先。"
"职位描述：
        
        岗位职责:
1、负责数据基础平台组件的开发；
2、负责支持大规模数据处理的实时、离线平台建设。

任职要求:
1、熟练掌握golang，至少一年Linux环境下golang实际项目开发经验；
2、熟悉常用数据结构与算法；掌握TCP/IP和常用的网络协议，开发过基于tcp、udp、http等高并发传输数据经验者优先；
3、熟悉mysql、mongodb、redis等常用数据库，能够独立设计数据库表格并优化数据库语句；
4、具有良好的沟通能力和团队合作能力，对技术有激情、有追求，开源社区活跃加分；
5、对高并发、异步有深刻理解，有高并发同/异步后端服务设计经验及分布式系统设计开发经验者优先。"
"职位描述：
        
        岗位要求：1、针对业务问题进行分析，深入了解业务需求和痛点，为业务部门提供数据支持；2、通过日常工作，搭建业务分析模型或业务分析指标体系，统一数据指标分析口径；3、有专业的数据分析能力，能独立负责某一模块的系统性分析；4、数据仓库需求调研和需求分析;5、参与数据仓库，报表，业务分析系统的开发工作；6、制定ETL相关的设计方案和开发计划；7、数据标准及数据清洗。任职资格：1、精通PGSQL/mysql等数据库、精通sql语言，对数据库优化、sql优化等有相关经验；2、熟悉数据仓库的理论和数据库建模；3、精通常用的开源ETL工具如：KETTLT等；4、熟悉电商和数据挖掘优先；5、熟悉python优先。"
"职位描述：
        
        【岗位职责】
负责ETL开发，数仓架构设计，建模数据支撑，数据整合，数据监控；
负责业务逻辑抽象等编码工作；
按需求进行风控模型的线上部署，确保模型的正常运营；
负责风险控制报表的制作和维护，并对风险指标进行监控，给出风险预警和改进建议；

【岗位要求】
985、211院校毕业，统招本科及以上学历，统计学、数学、计算机等相关专业优先；有银行、金融背景优先；
熟练掌握python及相关的库包，1年以上python实际开发经验；熟悉linux开发环境，掌握基本的shell，熟悉awk常用命令；
熟悉数据仓库的设计和建设，?熟练使用hive及Hbase，熟悉SQL；熟悉Hadoop、Hive等分布式计算平台的使用；
有django、flask等框架开发经验者优先；
有良好的编码习惯，编写的代码健壮，可快速定位到抛异常的代码；
良好的沟通能力和团队合作能力，工作积极主动，学习能力强，具有较强的抗压能力。"
"职位描述：
        
        岗位描述1、你需要参与相关产品数据仓库搭建、数据分析平台的设计和开发；2、你需要完成相关产品的海量数据处理、分析和挖掘工作；3、你需要协助完成实时处理系统的设计和开发工作。岗位要求我们希望你：1、学的是计算机或电信、网络等相关专业，本科以上的学历。2、熟练掌握Java编程语言，并熟悉Shell，Python等一门以上脚本语言；3、熟悉Linux／Unix环境，有Hadoop框架开发经验者优先；4、了解Hive/Hbase/Spark/Storm等一种以上大数据处理工具和技术者帅气值加五分；5、抗压能力强，责任心又重，遇到难题冲上去就是干，关键还能和团队打得一手好配合"
"职位描述：
        
        岗位职责：1、负责对网络应用数据的信息分类、关联、提取挖掘等分析工作；2、负责DPI功能模块的设计和开发。3、负责核心产品设备反欺诈的数据采集工作。岗位要求：1、本科及以上学历，通信类、信息类、电子类、计算机类相关专业；2、2年以上Linux?开发经验，精通TCP/IP、HTTP等基本网络协议；3、具有防火墙、IDS/IPS、抗攻击、入侵检测、流量监控系统/上网行为管理系统开发经验者优先；4、了解正则匹配、加解密算法、数据挖掘、逆向分析等技术，熟悉深度包检测(DPI)等网络安全产品开发经验者优先；5、熟练使用wireshark、tcpdump等工具者优先6、有大数据处理经验优先、网络安全产品研发经验者优先"
"职位描述：
        
        岗位职责：
1、负责核心产品设备反欺诈的数据分析、处理、加工工作。
2、配合产品快速迭代反欺诈相关功能。

岗位要求：
1、3年以上java开发经验，1-3 年大数据相关工作经验 ；
2、了解TCP/IP、HTTP、FTP等基本网络协议；
3、精通Storm或Spark，熟悉大数据相关技术如HADOOP、HIVE、HBASE、Kafka，redis等
4、工作认真细心，对数据敏感，有较强的逻辑分析能力
5、有银行反欺诈相关工作经验优先"
"职位描述：
        
        工作职责：1、熟悉并使用过各种大数据相关框架或组件优先Hadoop、Spark、Storm、Hive等，熟练使用Hive sql进行数据开发；2、熟悉并使用过mysql等关系型数据库进行数据开发；3、熟练掌握ETL工具的使用和编写，如Kettle、Apache Camel等；4、熟悉数据仓库建模，并使用过Erwin、PowerDesigner等数据建模工具进行设计。任职资格：1、本科及以上学历，3年以上数据仓库BI大数据工作经验；2、有互联网领域工作经验，熟悉电商业务；3、有Linux下的开发或运行环境操作经验，有shell、perl、Python开发经验优先；4、具有良好的沟通、团队协作、计划和主动性思考的能力。"
"职位描述：
        
        1. 熟悉数据治理、数据标准、数据建模、主数据、元数据管理方法论，并有丰富的项目经验；2. 熟悉linux/Java，以及Hadoop生态圈的组件框架，具备在组件框架基础上开发的丰富经验；3. 能从项目管理的角度，运用数据治理的相关理论和方法，来统筹和协调各部门推进项目的落地；4. 熟悉关系型数据库、NoSQL数据库、HBase，Hive、Hadoop等；5. 有信息模型设计、用户行为分析、用户标签画像、运营数据分析工作经验者优先；6. 有CDH集群管理以及大数据平台运维经验者优先；"
"职位描述：
        
        岗位职责：
1、承担建设基于Hadoop/Spark生态的大数据离线/实时处理平台；
2、日常ETL脚本开发与维护
3、参与业务数据、生产日志的抽取、转储、检索等相关工作； 4、跟进大数据前沿技术的发展，将合适的技术方案适时引入业务场景；
?
任职资格：
1、2-3年互联网大数据处理经验；有实时处理工作经历并有一定解决方案者优先； 2、熟悉大数据开源技术，包含（不限于）Hadoop/Spark/Hive/Hbase/Impala /Flume/Kafka/Solr/Es分布式框架/计算/存储/检索等相关技术,并有一定的Hadoop生态系统运维经验； 3、掌握Python或Java一种开发语言； 4、掌握SQL，HQL进行数据开发；较好的SQL性能调优经验； 5、优秀的分析、解决问题能力，充分的数据敏感度；有一定的高性能支撑经验和故障排除能力； 6、具备强烈的工作责任感，喜欢钻研，态度乐观，团队意识强。
ps：有以下经验者优先。
1.熟悉深度学习、数据挖掘和NLP技术，有自然语言理解等应用经验者优先；
2.悉常用数据结构和算法，有较强的实现能力
3.熟悉深度学习开源框架（如TensorFlow等）者优先。
4、有推荐系统、推荐算法经验优先考虑。"
"职位描述：
        
        岗位职责：?1、对百度云CDN PB级别数据进行实时统计及离线处理分析；?2、开发和维护百度云CDN超大规模数据服务后台?3、参与大规模数据服务平台架构的系统设计、开发和优化，不断提高系统的稳定性、性能。
4、参与数据方向团队管理和建设

任职资格：?1、5年以上工作经验，3年以上大数据相关项目实际开发经验。有带5人以上团队经验者优先。2、具备扎实的开发功底，熟练掌握一门以上编程语言(Go/Java/Python)，熟悉Linux开发环境；?3、熟悉分布式开发、多线程及并发技术，熟悉网络编程；?4、熟悉主流分布式处理框架，熟练掌握MapReduce、Storm、Spark一种以上开发；有海量数据处理系统优化和性能调优者优先?5、有系统性分析和解决问题的能力，能将复杂的业务问题转化为数据/数学模型；?6、有持续学习能力和意愿，具有较强领悟力，优秀的团队合作意识，性格乐观，态度踏实。"
"职位描述：
        
        工作职责
-负责大数据平台前端技术topic调研和产品需求研发工作
-负责大数据平台前端技术基础框架和平台的研发工作
-负责大数据平台前端易用性优化
-前端技术研究和新技术调研
任职资格
-精通前端技术，熟悉至少一种前端开发框架和前端工程构建工具，熟悉业界主流框架、工具的使用及原理
-精通html/css/JavaScript等前端相关技术
-有vue、nodejs、PHP等开发经验者优先
-有数据统计分析经验者优先"
"职位描述：
        
        工作职责：
-负责手百/feed/百家号/视频 OLAP分析平台的设计、研发及应用
-负责手百/feed/百家号/视频相关产品用户、运营数据的统计分析支持

任职资格：
-计算机或相关专业本科及以上学历
-具有良好的编程能力，熟悉Java/Python等编程语言
-有大型OLAP系统开发和应用经验优先，例如Druid/Kylin/Pinot
-精通hadoop/hive开发，熟悉数据仓库理论
-有大型java项目经验优先"
"职位描述：
        
        岗位职责：?1、对百度云CDN PB级别数据进行实时统计及离线处理分析；?2、开发和维护百度云CDN超大规模数据服务后台?3、参与大规模数据服务平台架构的系统设计、开发和优化，不断提高系统的稳定性、性能。

任职资格：?1、两年以上工作经验，一年以上大数据相关项目实际开发经验?2、具备扎实的开发功底，熟练掌握一门以上编程语言(Go/Java/Python)，熟悉Linux开发环境；?3、熟悉分布式开发、多线程及并发技术，熟悉网络编程；?4、熟悉主流分布式处理框架，熟练掌握MapReduce、Storm、Spark一种以上开发；有海量数据处理系统优化和性能调优者优先?5、有系统性分析和解决问题的能力，能将复杂的业务问题转化为数据/数学模型；?6、有持续学习能力和意愿，具有较强领悟力，优秀的团队合作意识，性格乐观，态度踏实。"
"职位描述：
        
        工作描述：
-负责手百/feed/百家号/视频数据仓库、数据集市的建设.?-负责手百/feed/百家号/视频相关产品用户、运营数据的统计分析支持?-负责手百/feed/百家号/视频数据分析平台的设计、研发及应用.?-负责数据建模并利用模型进行产品的评测、数据评估、数据挖掘

任职资格：
-计算机或相关专业本科及以上学历?-掌握数据仓库基本理论，精通hadoop/hive开发等?-具有良好的编程能力，熟悉Java/Python/php等编程语言?-仓库方向需熟悉SQL和建模，有较好的SQL性能调优经验?-平台方向有大型php或者java项目经验优先?-有数据挖掘经验者优先"
"职位描述：
        
        工作职责:
-负责地图数据仓库、数据集市的建设
-跟踪业务线数据需求，对用户、运营等数据的统计分析支持
-负责数据分析平台的设计、研发及应用.
-优化产品数据指标体系，开发通用数据产品
职责要求:
-计算机专业，本科及以上学历
-3年以上互联网大数据工作经验者优先，有较好的HQL性能调优经验
-熟悉Hadoop生态，有扎实的数据仓库理论基础，熟悉数据仓库模型设计，精通hadoop/hive开发等
-具有良好的编程能力，精通Shell/Java/Python等编程语言
-有Spark streamng开发经验者优先
-具备良好的学习能力和沟通交流能力，有强烈的责任心，能够迅速熟悉业务，融入团队
-有数据挖掘经验者优先"
"职位描述：
        
        工作职责:
- 负责百度智能云AI应用相关产品的架构设计与研发
- 结合实际业务问题，运用数据挖掘、机器学习领域的前沿技术，给出解决方案
职位要求:
- 计算机或相关专业本科及以上学历
- 精通Linux/Unix平台上的C/C++/Java/Python/Scala/Go编程（精通其一即可），对数据结构和算法有较为深刻的理解
- 精通大数据计算、存储相关技术，如Spark/Hadoop/HBase/Cassandra/Elasticsearch等
- 有强烈的上进心和求知欲，善于学习新事物，渴望用技术改变未来
- 具备优秀的逻辑思维能力，对解决挑战性问题充满热情，善于解决问题和分析问题
- 具有良好的沟通能力和团队合作精神,出色的推动能力、执行力
有下列经验之一者优先：
- 有机器学习/数据挖掘理论和技术基础"
"职位描述：
        
        -负责百度搜索用户行为大数据平台和架构建设?
-负责流式数据架构和算子开发?
-负责业务理解和技术实现满足业务需求?
-负责海量用户行为数据的数据仓库建设和研究
任职资格
-对流式计算storm,flink,spark streaming有了解与开发经验?
-熟练使用 c/c++,python，有scala经验加分?
-对数据仓库，尤其是大数据数据仓库、流式数据采集有架构经验优先?
-本科必须是计算机、软件工程等相关方向?
-工作踏实，积极认真负责、乐于沟通"
"职位描述：
        
        岗位职责：

-负责利用海量工业数据挖掘数据的内在关系，提升工业效率；工作包括但不限于：负责工业数据的清洗去噪、基于数据特性应用合适算法解决实际问题（例如质检预警、成因分析）；?
-负责探索最新的机器学习（包括深度学习、增强学习、结构化学习）在实际项目中的落地；任职要求：
-快速的学习能力，能够快速理解业务场景，快速实验算法原型在业务场景的效果，给出合理的技术方案；
-具备扎实的数据结构和计算机理论知识，较强的 c/c++/python 编；?
-理解深度学习的基本原理以及相关的模型训练和调优经验；理解主流的深度网络结构设计方法和原理；
-具备良好的沟通能力，团队合作能力和问题抽象能力；
加分项：
-深入研究过时序分析、关联分析等技术并有实际项目经验者优先；
-对样本数据异常检测，监控系统预警分析等实际项目经验者优先；
-有半监督模型、弱监督模型、稀疏样本机器学习应用实践经验者优先；
-一年以上人工智能领域公司研究和项目落地经验这优先；
-有高水平论文者优先，包括但不限于CVPR、NIPS、WWW、AAAI、WSDM、KDD等；"
"职位描述：
        
        岗位职责：?
-建设搜索流量、用户数据仓库，负责核心报表及数据流的ETL工作
-负责数据质量监控和异常分析，确保数据准时、准确产出
-建设数据分析平台，为其他部门/系统提供数据支持
-负责构建数据分析模型，挖掘用户需求，研究互联网产品及用户变化，以支持各项决策
?
任职资格：?
-计算机或相关专业，本科及以上学历；
-2年以上数据开发经验，精通SQL或hive编程； ?
-熟悉Hadoop生态，有Hadoop streamng开发经验；
-熟悉Linux，熟练掌握shell、Python等脚本语言；
-有互联网大数据工作经验者优先；
-有数据仓库项目开发经验者优先；
-有很强的分析问题和解决问题的能力，有强烈的责任心；"
"职位描述：
        
        工作职责
-负责百度搜索大数据系统架构设计和研发 
-负责流式数据架构设计和算子开发 
-负责spark引擎优化与计算任务开发 
-负责流式数据建设的日常维护工作

任职资格
-计算机相关专业本科及以上学历，2年以上流式系统或spark架构开发经验 
-熟练使用 c/c++、spark-sql、scala等语言 
-对流式数据仓库建设，数据统计性能优化等有一定项目经验 
-较强的逻辑思维能力，有大型互联网公司相关经验者优先"
"职位描述：
        
        工作职责： -负责搜索公司商业运营运营分析中台的设计、研发及应用.? -负责搜索公司商业运营相关运营数据的统计分析支持?
-负责数据建模并利用模型进行产品的评测、数据评估、数据挖掘
-负责搜索公司商业运营数据仓库、数据集市的建设协同

职位要求：
-计算机或相关专业本科及以上学历? -掌握数据仓库基本理论，精通hadoop/hive开发等? -具有良好的编程能力，熟悉Java/Python/php等编程语言? -仓库方向需熟悉SQL和建模，有较好的SQL性能调优经验? -平台方向有大型php或者java项目经验优先? -有数据挖掘或数据分析经验者优先"
"职位描述：
        
        工作职责
-负责百度集团级用户行为数据仓库的建设，提升数据仓库性能 
-支持业务团队对日志和数据指标的需求，提升数据获取效率 
-通过对数据的分析和挖掘，产出有价值的产品改进建议 
-持续关注行业动态，产出业务决策报告

任职资格
-计算机相关专业本科及以上学历，2年以上数据开发工作经验 
-熟悉hadoop，spark等分布式计算框架，熟练使用HIVE、scala等进行大数据处理 
-理解数据仓库的概念和原理，熟悉数据建模方法 
-具备一定的数据分析能力，有较好的数据敏感度和较强的逻辑思维能力 -有大型互联网公司相关经验者优先"
"职位描述：
        
        岗位职责：?1、负责数据仓库的架构设计,?开发和实施；2、负责数据ETL流程的建设，优化以及解决ETL相关技术问题；3、负责机器学习流水线的架构设计,?开发和实施；4、负责数据任务调度系统、数据监控系统的设计，开发和实施；5、负责数据schema管理系统的设计，开发和实施。任职要求：1、本科及以上学历，计算机相关专业;两年以上互联网行业大数据相关工作经验；2、了解并行和分布式计算的基本原理；熟练掌握Hadoop,hdfs,?hive,?Spark,Storm,flink，cassandra,?hbase、ElasticSearch等常用的大数据系统或式计算框架；熟悉MySQL,?postgres,?MongoDB等数据库；3、具备优秀的数据敏感性；4、优秀的分析问题和解决问题的能力，勇于解决难题；强烈的上进心和求知欲，较强的沟通表达能力与协作推进能力；?5、热爱互联网，对互联网产品和技术有浓厚的兴趣，热衷于追求技术极致与创新；6、有开源社区贡献经验的开发者优先考虑。"
"职位描述：
        
        岗位职责：
-?负责百姓网大数据平台的可用性、稳定性、健壮性，包括各软件模块、各硬件和网络设备、数据安全性和权限控制等方面； -?通过持续不断的技术进化和机制建设，推进大数据平台运维自动化，流程标准化； -?关注大数据领域的新技术，尝试和引进新技术，以持续进化大数据平台的技术架构； -?在百姓网大数据平台上开发数据应用；
?
任职要求：
-?本科以上学历，3 年以上的大数据平台相关工作经验； -?精通 Hadoop（HDFS 和 Yarn）、Hive、Spark 等大数据平台的基础组件；熟悉大数据平台 ETL 流程相关概念和工具；具备丰富的?Spark Streaming 实时数据流方面的实践经验，熟悉 Presto 并具有相关经验； -?熟悉大数据平台在操作系统、服务器硬件、网络等方面的部署方案； -?在自动化运维方面有丰富经验，思路清晰，具有冷静判定问题的决断力，具备自驱力，能够持续推进大数据平台在运维方面的自动化，提升平台可用性、稳定性和健壮性； -?精通 Linux Shell，具备 Java?程序开发能力；
?
加分项：
-?熟练使用 Airflow；
-?熟悉神策、ReDash、Tableau 等数据分析展示工具；
-?开发过实际用于生产环境的 Presto Connector 或扩展插件；
-?熟悉青云、阿里云、腾讯云等主流云服务的大数据模块并有过实践经验；
?
岗位亮点：
- 这是一个不设限的综合技能型岗位，以运维为本，延伸到大数据平台应用开发；
-?我们不堆人，我们更主张用技术的手段实现自动化，让人去做机器做不了的事情；"
"职位描述：
        
        岗位职责：
- 负责百姓网大数据平台的可用性、稳定性、健壮性，包括各软件模块、各硬件和网络设备、数据安全性和权限控制等方面；
- 通过持续不断的技术进化和机制建设，推进大数据平台运维自动化，流程标准化；
- 关注大数据领域的新技术，尝试和引进新技术，以持续进化大数据平台的技术架构；
- 在百姓网大数据平台上开发数据应用；
?
任职要求：
- 本科以上学历，3 年以上的大数据平台相关工作经验；
- 精通 Hadoop（HDFS 和 Yarn）、Hive、Spark 等大数据平台的基础组件；熟悉大数据平台 ETL 流程相关概念和工具；具备丰富的 Spark Streaming/Flink 实时数据流方面的实践经验；
- 熟悉大数据平台在操作系统、服务器硬件、网络等方面的部署方案；
- 在自动化运维方面有丰富经验，思路清晰，具有冷静判定问题的决断力，具备自驱力，能够持续推进大数据平台在运维方面的自动化，提升平台可用性、稳定性和健壮性；
- 精通 Linux Shell，具备 Java 程序开发能力；
?
加分项：
- 熟练使用 Airflow?/?Zeus等调度工具；
- 熟练使用 CDH平台；
- 熟悉神策、ReDash、Tableau 等数据分析展示工具；
- 熟悉青云、阿里云、腾讯云等主流云服务的大数据模块并有过实践经验；
?
岗位亮点：
- 这是一个不设限的综合技能型岗位，以运维为本，延伸到大数据平台应用开发；
- 我们不堆人，我们更主张用技术的手段实现自动化，让人去做机器做不了的事情；"
"职位描述：
        
        工作职责:1、 负责Hadoop大数据平台架构分析、构建；2、 负责基于Hadoop生态系统的研发。任职资格:1、 大学本科及以上学历，计算机相关专业；2、 三年以上工作经验；3、 熟悉Hadoop生态系统组件，如：Hadoop、Storm、Spark、Flume、Kafka、HBase、Hive、Pig、ZooKeeper；4、 熟悉Linux开发环境；5、 熟悉ElasticSearch、Storm、Spark优先；6、 能够读懂及书写英文文档；7、 有Storm、Spark调优、统计学知识的优先考虑；8、 有机器学习经验者优先考虑。"
"职位描述：
        
        工作职责:1.根据业务需求，进行数据项目的需求分析、模型设计、ETL设计开发；2.负责把业务数据接入、处理、存储到数据库；3.搭建数据集成平台，实现数据采集自动化；4.负责ETL的性能、存储、调试等。任职资格:1、有Hadoop、Hive等大数据开发实在经验；2、了解/熟悉银行业务或信托业务或零售等业务，有1年以上数据类项目设计与开发经验；3、2年以上工作经验，其中至少有1年以上ETL相关工作经验；4、要求熟练使用主流数据库 Oracle、Mysql、DB2等；5、熟悉一种或多种ETL工具优先考虑，Informatica, kettle等；6、熟悉 Linux开发环境,有Java后台开发经验；掌握R，Spark，python，Js更佳；8、了解关系数据库理论、数据仓库架构及原理、数据仓库实施方法论；9、自我学习能力强，拥有优秀的逻辑思维能力，具有一定沟通交流能力，强烈的责任心和团队合作精神；10、抗压性强，可接受随项目出差及加班。"
"职位描述：
        
        1.??? 熟悉Java开发；
2.??? 了解Hive、spark等框架具备hive sql编写能力；
3.??? 了解SSH开发框架，熟练使用SpringSecurity+SpringJPA；
4.??? 了解Mysql,SqlServer等数据库优化及应用设计；
5.??? 了解Javascript,XML,Ajax,Jquery等Web2、0技术；
6.??? 逻辑思维严密；
7.??? 全日制普通高等院校本科及以上学历，大三、大四、研一、研二在校大学生或海外留学生；
8.??? 专业不限，IT/DT类专业、理工类、金融类专业优先考虑；
9.??? 每周至少工作3天；"
"职位描述：
        
        岗位职责:

1、参与大数据开放平台基础能力建设，承担系统架构、组件开发、方案验证等工作；

2、参与构建大数据系列产品，包括但不限于用户画像、用户增长与用户经营、数据分析挖掘、实时计算、数据分发、机器学习平台、风控反欺诈等产品线；

任职要求：

1、 统招本科或以上学历，5年以上大数据开发工作经验；

2、扎实的JAVA基础，能熟练使用JAVA进行软件功能开发；

3、熟练掌握基于hadoop生态的大数据开发工具，包括HIVE、Spark、HBase、Sqoop、ES、Impala、Flink、Storm等，有实时系统开发经验优先；

4、熟悉常用的数据挖掘算法，例如聚类、回归、决策树等，有过NLP项目经验优先；

5、有过互联网公司数据仓库、分析系统、用户画像、广告平台等产品开发经验者优先；

6、工作积极主动，善于合作，敏而好学；"
"职位描述：
        
        大数据开发工程师

职责描述：
1. 负责数据分析、加工、清理、处理程序的开发 ；
2. 从事海量数据分析、挖掘相关工作；
3. 参与大数据应用项目的核心部分的设计和开发。

任职要求：
1.本科及以上学历，计算机、通信等相关专业至少3年以上Java开发工作经验；
2.熟悉hadoop生态系统内常见项目的使用（hdfs、hive、hbase、spark、zookeeper,yarn等），具有MapReduce开发经验，有实际大数据项目经验优先；
3.熟练掌握Oracle、MySql等主流数据库；
4.熟悉JAVA，熟悉基于J2EE的WEB架构设计，熟悉Web开发流程，有丰富的Web MVC（Struts、Spring，Hibernate等）开发经验；
5.熟悉Linux/Unix系统环境下的操作；熟悉Tomcat等应用服务器的配置和优化；
6.具有良好的沟通能力、组织能力及团队协作精神，有较强的分析和解决问题的能力。
具有机器学习工程经验的优先考虑"
"职位描述：
        
        岗位职责:
1、参与大数据开放平台基础能力建设，承担系统架构、组件开发、方案验证等工作；
2、参与构建大数据系列产品，包括但不限于用户画像、用户增长与用户经营、数据分析挖掘、实时计算、数据分发、机器学习平台、风控反欺诈等产品线。

任职要求：
1、 统招本科或以上学历，2年以上大数据开发工作经验；
2、扎实的JAVA基础，能熟练使用JAVA进行软件功能开发；
3、熟练掌握基于hadoop生态的大数据开发工具，包括HIVE、Spark、HBase、Sqoop、ES、Impala、Flink、Storm等，有实时系统开发经验优先；
4、熟悉常用的数据挖掘算法，例如聚类、回归、决策树等，有过NLP项目经验优先；
5、有过互联网公司数据仓库、分析系统、用户画像、广告平台等产品开发经验者优先；
6、工作积极主动，善于合作，敏而好学。"
"职位描述：
        
        岗位职责：
? ? 1、参与公司实时数据总线平台的设计与开发；
? ? 2、参与公司实时计算平台的设计与开发；
? ? 3、参与平台现有功能的改造与优化；


任职要求：
? ? 1、统招本科以上学历，计算机或相关专业，3年以上Java/scala开发经验；
? ? 2、熟悉storm/jstorm/flink的流计算引擎框架,精通flink框架者优先；
? ? 3、具备大数据相关组件的使用经验，熟悉hbase、yarn、kafka、zookeeper、elasticsearch等组件；
? ? 4、较强的学习能力，沟通协调能力及团队合作精神；"
"职位描述：
        
        岗位职责:

1、参与大数据开放平台基础能力建设，承担系统架构、组件开发、方案验证等工作；

2、参与构建大数据系列产品，包括但不限于用户画像、用户增长与用户经营、数据分析挖掘、实时计算、数据分发、机器学习平台、风控反欺诈等产品线；

任职要求：

1、 统招本科或以上学历，2年以上大数据开发工作经验；

2、扎实的JAVA基础，能熟练使用JAVA进行软件功能开发；

3、熟练掌握基于hadoop生态的大数据开发工具，包括HIVE、Spark、HBase、Sqoop、ES、Impala、Flink、Storm等，有实时系统开发经验优先；

4、熟悉常用的数据挖掘算法，例如聚类、回归、决策树等，有过NLP项目经验优先；

5、有过互联网公司数据仓库、分析系统、用户画像、广告平台等产品开发经验者优先；

6、工作积极主动，善于合作，敏而好学；"
"职位描述：
        
        岗位职责:

1、参与大数据开放平台基础能力建设，承担系统架构、组件开发、方案验证等工作；

2、参与构建大数据系列产品，包括但不限于用户画像、用户增长与用户经营、数据分析挖掘、实时计算、数据分发、机器学习平台、风控反欺诈等产品线；

任职要求：

1、 统招本科或以上学历，2年以上大数据开发工作经验；

2、扎实的JAVA基础，能熟练使用JAVA进行软件功能开发；

3、熟练掌握基于hadoop生态的大数据开发工具，包括HIVE、Spark、HBase、Sqoop、ES、Impala、Flink、Storm等，有实时系统开发经验优先；

4、熟悉常用的数据挖掘算法，例如聚类、回归、决策树等，有过NLP项目经验优先；

5、有过互联网公司数据仓库、分析系统、用户画像、广告平台等产品开发经验者优先；

6、工作积极主动，善于合作，敏而好学；"
"职位描述：
        
        岗位职责：?

 参与大数据分析平台和数据仓库设计、建模、研发
 对各源数据进行ETL与标准化
 根据业务需求，开发相应数据产品

任职要求：
1、具备较强的数据分析，问题分析，逻辑思维能力，良好的沟通，团队协作能力。
2、计算机或相关专业本科及以上学历；
3、熟悉Hadoop生态，精通Spark RDD运算模型，熟练开发Spark Job、Spark Streaming应用程序；"
"职位描述：
        
        职责描述：1、面向轨道交通数据分析、自动部署的数据分析软件平台实现；2、负责大数据分析平台前后端系统架构的设计与实现3、负责数据分析平台系统分析与设计、代码重构、结合需求设计高扩展性、高性能、安全、稳定任职要求：1、硕士学历，计算机或相关专业2、3年以上前后端开发经验，熟练掌握一种主流前端开发框架，如VUE/React/Angularjs，能独立构建大型前端应用3、精通java企业级开发，掌握Spring /Spring MVC/Spring Boot、Mybatis/Hibernate、Shiro等框架的使用4、精通主流数据库的应用，有大数据开发经验"
"职位描述：
        
        职责描述：1、面向轨道交通数据分析、自动部署的数据分析软件平台实现；2、负责大数据分析平台前后端系统架构的设计与实现3、负责数据分析平台系统分析与设计、代码重构、结合需求设计高扩展性、高性能、安全、稳定任职要求：1、硕士学历，计算机或相关专业2、3年以上前后端开发经验，熟练掌握一种主流前端开发框架，如VUE/React/Angularjs，能独立构建大型前端应用3、精通java企业级开发，掌握Spring /Spring MVC/Spring Boot、Mybatis/Hibernate、Shiro等框架的使用4、精通主流数据库的应用，有大数据开发经验"
"职位描述：
        
        任职资格
1. Java基础扎实，3年以上Java使用经验：熟练掌握数据结构、多线程编程，掌握常用的设计模式；熟悉JVM，包括内存模型、类加载机制以及性能优化，熟悉J2EE开源框架，如spring/spring mvc,mybatis，熟悉Python、Shell；
2. 深入了解高性能中间件Kafka, Netty, Redis,Protocal Buffer, docker和dubbo（或类似rpc框架）等；?
3.? 具有很强数据库设计经验和SQL优化功底；
4.? 具备良好的面向对象编程经验，深入理解OO、AOP思想，具有很强的分析设计能力，熟悉常用设计模式；?
5.? 具有Hadoop&Flink开发、HBase，Phoenix，Spark，ElasticSearch，Tensorflow等相关项目实践，有独立系统的架构设计经验优先。?
6. 内核或系统层调优经验优先，熟悉linux，熟悉LINUX常用命令?
7.? 具备良好的沟通能力，工作积极认真，具有创新精神。"
"职位描述：
        
        【岗位职责】1.?负责公司基于Hadoop、hive、MySQL的大数据系统的开发?2.?根据游戏数据模型，完成日常运营数据处理?3.?游戏海量数据仓库建设?【任职要求】1.?有?JAVA、Python?相关开发经验?2.?有?Hadoop、Hive、MySQL?的使用经验?3.?有游戏行业数据开发、数据仓库开发、BOSS系统开发经验优先?4.?对开源大数据相关系统研究有较高热情?5.?有较好的数学、统计学基础?6.?有数据挖掘经验或者是互联网及游戏行业从业经验优先"
"职位描述：
        
        ?岗位职责：1， 参与项目技术总体设计，技术问题处理2， 负责项目数据开发，数据架构优化，数据库优化3， 负责项目数据字典，标准开发文档，数据接口文档，开发架构文档等的编写及维护任职资格：1. 本科及以上学历，计算机相关专业，3年以上相关工作经验2. 熟悉ORCLE/MYSQL等至少一种大型数据库的数据开发经验，精通SQL开发技术及性能优化3. 具备海量数据处理，整体设计工作经验4. 有物流行业相关项目经验优先5. 有较强的逻辑思维，良好的沟通能力及团队协作能力"
"职位描述：
        
        1、? 熟练掌握HIVESQL开发语言，精通HIVESQL优化，并能结合数据仓库的最佳实践不断调整、优化仓库设计。
2、? 善于主动思考和行动,? 有承压能力和良好的结构化问题解决能力。?
3、有大数开发经验"
"职位描述：
        
        1、? 熟练掌握HIVESQL开发语言，精通HIVESQL优化，并能结合数据仓库的最佳实践不断调整、优化仓库设计。
2、熟悉数据库oracle；对大数据的组件要熟悉比如hive? spark hbase
3、善于主动思考和行动,? 有承压能力和良好的结构化问题解决能力。
4、有大数开发经验"
"职位描述：
        
        1、? 熟练掌握HIVESQL开发语言，精通HIVESQL优化，并能结合数据仓库的最佳实践和前沿理论，不断调整、优化仓库设计。
2、? ?优秀的职业素养，善于主动思考和行动。
3、? 有承压能力和良好的结构化问题解决能力。
4、? 互联网、银行、信用卡、保险等金融机构或主流金融公司工作经验优先考虑。"
"职位描述：
        
        工作职责：? ?参与公司大数据平台及相关应用的研发工作
?职位要求：?
1.全日制本科及以上学历，计算机、数学等相关专业
2.熟悉大数据生态组件，如Hadoop,Spark等?
3.了解Java及相关的技术体系，能编写高质量的代码。
?4.爱好编程，且有很强的自我驱动力及自我学习能力。
?有以下经验者优先:
大数据相关开源项目的committer"
"职位描述：
        
        工作职责：? ?参与公司大数据平台及相关应用的研发工作? ? ? ?
职位要求：?
1.全日制本科及以上学历，计算机、数学等相关专业
2.熟悉大数据生态组件，如Hadoop,Spark等?
3.了解Java及相关的技术体系，能编写高质量的代码。
?4.爱好编程，且有很强的自我驱动力及自我学习能力。
?有以下经验者优先:?大数据相关开源项目的committer"
"职位描述：
        
        工作职责：? ?参与公司大数据平台及相关应用的研发工作?
?职位要求：
?1.全日制本科及以上学历，计算机、数学等相关专业
2.熟悉大数据生态组件，如Hadoop,Spark等?
3.了解Java及相关的技术体系，能编写高质量的代码。?
4.爱好编程，且有很强的自我驱动力及自我学习能力。?有以下经验者优先:?1.大数据相关开源项目的committer"
"职位描述：
        
        岗位职责：

1、负责大数据平台的设计和开发；2、负责海量数据的处理、分析、挖掘；3、负责高并发、大存储的数据系统，实时计算处理系统的研发。

任职要求：

1.本科或以上学历，计算机软件相关专业优先；2.2年以上大数据处理，大规模的数据分析和算法实践；3.精通hadoop / Spark编程，或者具有其他并行计算的实践经验；4.熟悉Mysql/Redis 等常用SQL和NoSQL数据库；5.至少熟练掌握Java、Python等两种以上语言；6.熟悉Hadoop、Spark生态圈，能运用其解决问题；7.有丰富的大数据集群部署和维护管理经验；8.良好的沟通，团队合作意识，非常强的学习能力。

福利待遇：

1.超出行业平均水平的薪资，多少全凭能力决定； 2.享受五险一金，并提供餐补、交通补贴等； 3.公司发展离不开员工的努力，员工重大事件公司将慰问及关怀； 4.弹性工作制，全天7H工作时间，完美避开上下班高峰时段； 5.享受国家法定假日及周末双休，享有带薪年假、病假、调休假等； 6.每月举行一次Birthday Party，日常工作日茶餐厅提供饮料、零食、水果等； 7.传统佳节会有高标准的节日礼金或礼品； 8.每年将进行豪华套餐的健康体检； 9.在超过2000平舒适的工作区域工作，保证最佳工作状态。



工作地址：成都市高新区天府软件园E区E3-1-3F"
"职位描述：
        
        岗位职责：
1、负责大数据平台的设计和开发；
2、负责海量数据的处理、分析、挖掘；
3、负责高并发、大存储的数据系统，实时计算处理系统的研发。

任职要求：
1.本科或以上学历，计算机软件相关专业优先；
2.3年以上大数据处理，大规模的数据分析和算法实践；
3.精通hadoop / Spark编程，或者具有其他并行计算的实践经验；
4.熟悉Mysql/Redis 等常用SQL和NoSQL数据库；
5.至少熟练掌握Java、Python等两种以上语言；
6.熟悉Hadoop、Spark生态圈，能运用其解决问题；
7.有丰富的大数据集群部署和维护管理经验；
8.良好的沟通，团队合作意识，非常强的学习能力。

福利待遇：
1.超出行业平均水平的薪资，多少全凭能力决定；
2.享受五险一金，并提供餐补、交通补贴等；
3.公司发展离不开员工的努力，员工重大事件公司将慰问及关怀；
4.弹性工作制，全天7H工作时间，完美避开上下班高峰时段；
5.享受国家法定假日及周末双休，享有带薪年假、病假、调休假等；
6.每月举行一次Birthday Party，日常工作日茶餐厅提供饮料、零食、水果等；
7.传统佳节会有高标准的节日礼金或礼品；
8.每年将进行豪华套餐的健康体检；
9.在超过2000平舒适的工作区域工作，保证最佳工作状态。"
"职位描述：
        
        岗位职责：
1. 负责临床医疗大数据平台ETL、存储、云计算平台开发；
2、离线海量数据分析平台的开发；
3、大数据前沿技术调研；

职位要求：
1、计算机专业，本科以上学历，硕士优先；
2、熟悉java、python等一种或多种开发语言，熟悉多线程、多进程模型,熟悉Linux
3、熟悉Hadoop(HDFS/MapReduce/Hive)、Spark、HBase、Kafka、Flume等类框架技术，具备相关项目应用研发经验；或者有搜索引擎开发经验，熟悉luncene/ES、倒排索引、ranking、索引更新等技术者优先；
4、熟悉分布式系统概念、架构，有大规模分布式系统设计、实现、部署等经验优先；
5、良好的学习能力、沟通能力和团队合作精神。"
"职位描述：
        
        岗位职责：
1. 负责临床医疗大数据平台ETL、存储、云计算平台开发；
2、离线海量数据分析平台的开发；
3、大数据前沿技术调研；

职位要求：
1、计算机专业，本科以上学历，硕士优先；
2、熟悉java、python等一种或多种开发语言，熟悉多线程、多进程模型,熟悉Linux
3、熟悉Hadoop(HDFS/MapReduce/Hive)、Spark、HBase、Kafka、Flume等类框架技术，具备相关项目应用研发经验；或者有搜索引擎开发经验，熟悉luncene/ES、倒排索引、ranking、索引更新等技术者优先；
4、熟悉分布式系统概念、架构，有大规模分布式系统设计、实现、部署等经验优先；
5、良好的学习能力、沟通能力和团队合作精神。"
"职位描述：
        
        职位描述：
1、基于Hadoop生态，搭建并维护大数据平台；
2、负责分布式数据平台下的各数据应用架构设计、开发、调优、维护；
3、基于业务模型，负责大数据平台数据模型的ETL设计、开发及自动化工作；
4、能够与产品经理、业务团队进行良好的沟通合作，按时保质完成数据开发任务；
?
岗位要求：
1、985本科以上学历，计算机科学或相关技术专业，2年以上互联网数据从业经验；
2、熟练掌握开源的分布式大数据处理技术，包括但不限于：hadoop/hive/flume/azkaban/kafka/storm等，能独立搭建稳健可靠的大数据集群平台；
3、熟练掌握Linux、Java、python等大数据常用编程语言，有相关开发经验；
4、对新技术有很高的好奇心，学习能力强，能探索各种技术解决实际问题；"
"职位描述：
        
        主要职责：

 ????基于Hadoop生态，搭建并维护大数据平台；
 ????负责分布式数据平台下的各数据应用架构设计、开发、调优、维护；
 ????基于业务模型，负责大数据平台数据模型的ETL设计、开发及自动化工作；
 ????能够与产品经理、业务团队进行良好的沟通合作，按时保质完成数据开发任务；

?
任职要求：

 ???985本科以上学历，计算机科学或相关技术专业，2年以上互联网数据从业经验；
 ????熟练掌握开源的分布式大数据处理技术，包括但不限于：hadoop/hive/flume/azkaban/kafka/storm等，能独立搭建稳健可靠的大数据集群平台；
 ????熟练掌握Linux、Java、python等大数据常用编程语言，有相关开发经验；
 ????对新技术有很高的好奇心，学习能力强，能探索各种技术解决实际问题；"
"职位描述：
        
        主要职责：

 ?根据业务需要，进行基于Hadoop集群进行数据表的开发工作；
 ?进行数据仓库的模型设计，进行大数据的采集、清洗和加工计算工作；
 负责数据平台日常报表的数据开发、维护、监控；
 ?严谨认真，保证数据质量；

任职要求：

 ?本科以上学历，计算机科学或相关技术专业，有互联网数据开发经验；
 ?熟悉开源的分布式大数据处理技术，包括但不限于：hadoop/Hive/Sqoop等；
 ?熟练掌握Linux、Java、python等大数据常用编程语言，有相关开发经验；
 ?认真谨慎的精神，独立分析和解决问题的能力；"
"职位描述：
        
        岗位职责：
1、hadoop大规模集群优化；2、各种分布式存储方案构建；3、集群数据安全相关体系建设；4、hbase集群整体优化和功能开发；5、hive集群性能优化；6、Spark／Storm等相关应用，平台开发；

任职要求：
1、 本科及以上学历，计算机及相关专业；2、 具有至少3年以上Java开发经验，熟悉python/shell等脚本语言，熟悉tcp/ip网络协议，熟悉基本存储原理；3、 熟悉hadoop、spark相关各种开源项目，Hive/Hbase等有实际应用开发经验，具有一定独立解决问题的能力；4、 熟悉多进程、多线程、数据库、IO、内存管理等方面编程者优先；5、 相关具体技术方向1年以上项目经验；6、 熟悉软件开发过程、相关规范和开发工具，能独立完成软件模块的详细设计；7、逻辑思维清晰，沟通能力良好，大型互联网公司相关从业经验优先。"
"职位描述：
        
        岗位职责：1. 负责大数据应用开发(如实时监控/BI/DMP/CRM/推荐系统/数据资产等)，包括数据采集、提取、分析与数据产品化；2. 负责大数据平台的设计和开发，以及Spark、Storm、Hive、Yarn等计算组件的开发与性能优化；3. 负责大数据基础设施建设与维护，包括Hadoop集群、调度系统、数据开发工具以及可视化工具；4. 负责大数据平台上的模型构建和数据挖掘算法的实现；5. 开发规范等文档的编写与维护，以及其他与项目相关的研发工作；岗位要求：1. 计算机专业本科以上学历，扎实的java基础，至少3年大数据开发经验；2. 具备丰富的数据处理经验，对数据处理、数据清洗、数据建模、数据分析等有深刻认识和实战开发经验；3. 熟悉常用开源分布式系统，对HBase/Hive/Spark/Storm/Flink/Kafka中的一项或多项深度掌握,具备海量数据处理以及性能优化的能力；4. 清晰的逻辑思维和表达能力，热爱技术、乐于分享，沟通能力强；5. 良好的团队精神和合作意识，强烈的责任心，对工作有激情，抗压能力强；加分项：1.有支付行业、互联网金融行业的背景优先；2.有用户画像、推荐系统和机器学习方面经验优先；"
"职位描述：
        
        岗位职责：
1、 基于hadoop的大数据集群维护；
2、 负责大数据集群组件的升级调优，以及新组件的调研；
3、 负责集群数据安全管理；
4、 负责大数据集群的使用情况监控分析。?

岗位要求：
1、 本科学历须211院校以上，硕士及以上学历不限院校， 计算机软件及相关专业；
2、 三年以上大数据集群维护经验,掌握java,python,scala中至少一种开发语言；
3、 有基于hadoop的开发经验者优先， 熟悉Hdfs、Yarn、HBase、Hive、Spark、Mapreduce、Flume、Kafka、Storm、ETL等相关技术或者工具至少3个以上；
4、 学习能力强，喜欢研究新技术，有团队观念，具备独立解决问题的能力。"
"职位描述：
        
        岗位职责1、负责海量数据的分析处理和数据统计系统的研发；2、根据相关业务需求，进行数据处理、分析及统计；3、Hadoop，Spark，Kafka，ELK等软件的配置和系统优化；4、分布式网络爬虫的设计与开发；5、数据仓库的研发、设计与维护。岗位要求1、精通Java，熟悉Linux开发环境，熟悉R、Python、C、C++至少一种编程语言；2、熟练Hadoop大数据平台的核心框架，能够使用Hadoop提供的通用算法，熟练掌握Hadoop整个生态系统的组件如：Yarn，HBase、Hive、Pig等重要组件，能够实现对平台监控、辅助运营系统的开发；3、熟悉决策树、聚类、逻辑回归，关联分析、SVM，贝叶斯等数据挖掘算法优先，有海量时间序列数据挖掘经验优先；4、有文本挖掘、用户画像、自然语言处理、推荐系统、机器学习等研究经历或工作经历优先；5、对商业和业务逻辑敏感，具有较强的逻辑思维能力，能够参与团队合作，积极进取，踏实勤奋；6、本科学历须211院校以上，硕士及以上学历不限院校。公司介绍：苏州瑞翼信息技术有限公司，是一家专注于移动互联网商务服务和大数据资源整合、应用、开发、服务和运营的高新技术企业，专业提供搭建大数据应用与服务平台，公司未来五年计划规模营收突破十亿，利润率50%，实现数据挖掘、数据整理、大数据分析、精准营销、跨领域数据融合、供应链重组与整合等各方面应用。是苏州市认定的大数据企业。企业荣誉：2012 年 8 月公司首次被认定为高新技术企业与江苏省民营科技企业。2017年 3 月经苏州市经信委评定为""苏州市平台重点示范企业""；7 月经科信局推荐进入""2016 年苏南国家自主创新示范区瞪羚企业名录""；8 月入选苏州市发改委第一批""大数据企业库""。企业价值：长期以来，瑞翼专注服务于三大运营商。凭借专业且富有经验的研发团队，以移动互联网为载体，利用开放平台资源，实现了基于运营商的资源整合平台。全面提升资源利用效率，让数据产生价值。公司秉承将员工长期利益与公司利益保持一致的经营理念，坚持学习、成长、分享的价值观，常年定期给予核心员工股份激励。"
"职位描述：
        
        岗位职责
1、负责海量数据的分析处理和数据统计系统的研发；
2、根据相关业务需求，进行数据处理、分析及统计；
3、Hadoop，Spark，Kafka，ELK等软件的配置和系统优化；
4、分布式网络爬虫的设计与开发；
5、数据仓库的研发、设计与维护。
岗位要求
1、精通Java，熟悉Linux开发环境，熟悉R、Python、C、C++至少一种编程语言；
2、熟练Hadoop大数据平台的核心框架，能够使用Hadoop提供的通用算法，熟练掌握Hadoop整个生态系统的组件如：Yarn，HBase、Hive、Pig等重要组件，能够实现对平台监控、辅助运营系统的开发；
3、熟悉决策树、聚类、逻辑回归，关联分析、SVM，贝叶斯等数据挖掘算法优先，有海量时间序列数据挖掘经验优先；
4、有文本挖掘、用户画像、自然语言处理、推荐系统、机器学习等研究经历或工作经历优先；
5、对商业和业务逻辑敏感，具有较强的逻辑思维能力，能够参与团队合作，积极进取，踏实勤奋；
6、本科学历须211院校及以上，硕士及以上学历不限院校。"
"职位描述：
        
        公司介绍：斐波那契信息技术有限公司是面向企业的大数据智能技术服务商，我们的宗旨是： 为企业唤醒数据价值。斐波那契致力于为客户提供智能的大数据分析和营销平台及产品， 帮助客户挖掘潜在客户，精准营销，把控风险。 斐波那契以“数据中台”为核心战略，将建成以数据科学家，数据产品专家、数据处理专家为核心的技术团队。核心团队成员来自IBM、eBay等大型to-B 和互联网企业，拥有大数据和技术多年实战经验。职位职责：1.?在规定日程内完成开发智能大数据平台2.?定义、设计、实现和维护多层级的分布式软件系统，并完成相关文档3.?确保系统满足功能、性能、可扩展性、和可靠性4.?评估模块的开发工作量，规划实现工作，发布系统变更5.?积极维护团队在质量方面的标准，推广最佳实践6.?理解业务问题，并能提出解决方案职位要求： 1.?计算机相关专业，本科以上学历，需211院校及以上学历，硕士以上不限院校，2年以上相关研发经验2.?良好的解决问题能力，能独立解决问题3.?有面向对象设计方法， ，2年以上java 开发经验4.?熟悉linux开发环境5.?有大型可扩展分布式系统设计或者大数据处理系统设计经验更加6.?了解大数据相关技术如hadoop/hbase/spark/elasticsearch, etc.7.?有推荐系统或者用户画像系统开发经验更佳"
"职位描述：
        
        岗位职责
1、负责海量数据的分析处理和数据统计系统的研发；
2、根据相关业务需求，进行数据处理、分析及统计；
3、Hadoop，Spark，Kafka，ELK等软件的配置和系统优化；
4、分布式网络爬虫的设计与开发；
5、数据仓库的研发、设计与维护。
岗位要求
1、精通Java，熟悉Linux开发环境，熟悉R、Python、C、C++至少一种编程语言；
2、熟练Hadoop大数据平台的核心框架，能够使用Hadoop提供的通用算法，熟练掌握Hadoop整个生态系统的组件如：Yarn，HBase、Hive、Pig等重要组件，能够实现对平台监控、辅助运营系统的开发；
3、熟悉决策树、聚类、逻辑回归，关联分析、SVM，贝叶斯等数据挖掘算法优先，有海量时间序列数据挖掘经验优先；
4、有文本挖掘、用户画像、自然语言处理、推荐系统、机器学习等研究经历或工作经历优先；
5、对商业和业务逻辑敏感，具有较强的逻辑思维能力，能够参与团队合作，积极进取，踏实勤奋；
6、本科学历须211院校及以上，硕士及以上学历不限院校。"
"职位描述：
        
        岗位职责1、负责海量数据的分析处理和数据统计系统的研发；2、根据相关业务需求，进行数据处理、分析及统计；3、Hadoop，Spark，Kafka，ELK等软件的配置和系统优化；4、分布式网络爬虫的设计与开发；5、数据仓库的研发、设计与维护。岗位要求1、精通Java，熟悉Linux开发环境，熟悉R、Python、C、C++至少一种编程语言；2、熟练Hadoop大数据平台的核心框架，能够使用Hadoop提供的通用算法，熟练掌握Hadoop整个生态系统的组件如：Yarn，HBase、Hive、Pig等重要组件，能够实现对平台监控、辅助运营系统的开发；3、熟悉决策树、聚类、逻辑回归，关联分析、SVM，贝叶斯等数据挖掘算法优先，有海量时间序列数据挖掘经验优先；4、有文本挖掘、用户画像、自然语言处理、推荐系统、机器学习等研究经历或工作经历优先；5、对商业和业务逻辑敏感，具有较强的逻辑思维能力，能够参与团队合作，积极进取，踏实勤奋；6、本科学历须211院校及以上，硕士及以上学历不限院校。"
"职位描述：
        
        岗位职责：
1、 基于CDH的大数据集群维护；
2、 负责大数据集群组件的升级调优，以及新组件的调研；
3、 负责大数据集群的使用情况监控分析。?
岗位要求：
1、 本科学历须211院校以上，硕士及以上学历不限院校， 计算机软件及相关专业；
2、 三年以上大数据集群维护经验,掌握java,python,scala中至少一种开发语言；
3、 有基于hadoop的开发经验者优先， 熟悉Hdfs、Yarn、HBase、Hive、Spark、Mapreduce、Flume、Kafka、Storm、ETL等相关技术或者工具至少3个以上；
4、 学习能力强，喜欢研究新技术，有团队观念，具备独立解决问题的能力。"
"职位描述：
        
        职位描述：任职要求：1、?本科学历须211院校以上，硕士及以上学历不限院校,?计算机软件及相关专业；2、?熟练掌握Java/Scala编程,?可以熟练使用Linux操作系统，了解Linux集群技术者优先；3、?两年以上?MR/Spark?开发经验，有网站/数据平台架构经验尤佳；4、?有hadoop平台项目开发经验，?熟悉Hadoop、HBase、Hive、Spark、Mapreduce、Flume、Kafka、Storm、ETL等相关技术或者工具至少3个以上；5、?有风控、推荐、人群画像等领域模型构建和调优工作经验者优先；6、?学习能力强，喜欢研究新技术，有团队观念，具备独立解决问题的能力。"
"职位描述：
        
        职责：
1、参与大数据架构和大数据产品研发。?
2、和产品、测试、算法团队充分沟通，保证具体功能的正常研发。
3、协助大数据架构师，对大数据架构做优化。

任职要求：
1、全日制重点院校本科及以上学历，计算机、数学及相关专业。
2、熟悉大数据开发语言如Java或scala，熟悉SQL、MDX查询语言。
3、熟悉计算机理论，对网络 数据库 软件模型有较好的基础。
4、需要较强的学习能力，对技术有钻研精神，并有较高的热情，热衷于新技术学习和实践。
加分项：熟悉Hadoop、Hive、HBase、Spark、ElasticSearch等。"
"职位描述：
        
        2020届实习岗位（提供转正）职责：1、参与大数据架构和大数据产品研发。 2、和产品、测试、算法团队充分沟通，保证具体功能的正常研发。3、协助大数据架构师，对大数据架构做优化。任职要求：1、全日制985院校本科及以上学历，计算机、软件、数学及相关专业。2、熟悉大数据开发语言如Java或scala，熟悉SQL、MDX查询语言。3、熟悉计算机理论，对网络 数据库 软件模型有较好的基础。4、需要较强的学习能力，对技术有钻研精神，并有较高的热情，热衷于新技术学习和实践。5、全职实习，实习期2个月以上加分项：熟悉Hadoop、Hive、HBase、Spark、ElasticSearch等。

薪资：100元/天"
"职位描述：
        
        职位描述：
1. 设计大数据相关产品的前端架构，参与产品的技术选型和调研；
2. 参与公司数据产品如数据分析、数据可视化等方面的前端开发工作，并优化前端性能；
?
职位要求：
1. 全日制本科及以上学历，计算机相关专业；
2. 熟练掌握前端的基本技术如：HTML、CSS、JavaScript、HTTP协议；
3. 熟悉并且能够熟练使用常用的前端开发框架，如：jQuery、Vue、React、AngularJS；
4. 至少熟悉Gulp、Webpack、Grunt等构建工具中的一种；
5. 有多浏览器兼容经验，熟悉移动端、PC端web开发及多设备兼容调试等方面经验；
6. 熟练使用Node.js, Python, Ruby等任一脚本语言者优先；
7. 对数据敏感，善于发现数据中的潜在规律，善于分析问题，有很强的逻辑思维能力和推理能力；
8. 具备优秀的沟通协调能力和团队合作精神，有高度的责任感，有上进心和主动性，有owner意识；"
"职位描述：
        
        职位描述：
1. 设计大数据相关产品的前端架构，参与产品的技术选型和调研；
2. 参与公司数据产品如数据分析、数据可视化等方面的前端开发工作，并优化前端性能；
?
职位要求：
1. 全日制本科及以上学历，计算机相关专业；
2. 熟练掌握前端的基本技术如：HTML、CSS、JavaScript、HTTP协议；
3. 熟悉并且能够熟练使用常用的前端开发框架，如：jQuery、Vue、React、AngularJS；
4. 至少熟悉Gulp、Webpack、Grunt等构建工具中的一种；
5. 有多浏览器兼容经验，熟悉移动端、PC端web开发及多设备兼容调试等方面经验；
6. 熟练使用Node.js, Python, Ruby等任一脚本语言者优先；
7. 对数据敏感，善于发现数据中的潜在规律，善于分析问题，有很强的逻辑思维能力和推理能力；
8. 具备优秀的沟通协调能力和团队合作精神，有高度的责任感，有上进心和主动性，有owner意识；"
"职位描述：
        
        职位描述：
1. 参与大数据处理、日志收集处理、分布式系统等的开发；
2. 负责统计、数据分析等相关的各类算法的开发；
3. 搭建高扩展高性能的日志处理系统。
职位要求：
1. 全日制本科及以上学历，计算机相关专业；
2. 3年以上java语言编程经验，对JVM原理有一定了解，熟悉Linux及Shell编程；
3. 有大数据相关组件的开发与应用经验，熟悉分布式计算、存储、调度等原理，并有相关的分布式系统的开发经验；
4. 熟练掌握主流大数据基础组件的技术原理及技术，如：Hadoop、Storm、Spark、Flink、HBase、Hive、ElasticSearch、Kafka、Flume、Scribe等，并有相关的源码阅读经验；
5. 具有良好的语言表达和文档撰写能力，能够熟练阅读英文文档和论文；
6. 具备优秀的沟通协调能力和团队合作精神，有高度的责任感，有上进心和主动性，有owner意识；"
"职位描述：
        
        岗位职责：
-参与大数据架构和大数据产品研发；?
-和产品、测试、算法团队充分沟通，保证具体功能的正常研发；
-协助大数据架构师，对大数据架构做优化。
任职要求：
-统招本科计算机相关专业或以上学历；
-具有3年以上开发经验，1年以上大数据开发经验；
-JAVA基础扎实，熟悉Spring、SpringMvc、Mybatis等开源框架；
-熟悉Redis、mq等分布式系统常见的中间件，并有实际使用经验；
-熟悉Hadoop/Hive/Spark，有一定的使用经验。"
"职位描述：
        
        岗位要求：
1.?负责各种网络资源数据的采集、清洗、整合和大数据的分布式存储；
2.?负责大数据类产品的系统分析与架构设计，配合产品经理完成产品的快速研发与交付；
3.?负责大数据平台各组件的性能优化工作和部分设计、开发文档的编写工作；
4.?负责大数据项目的开发、维护等工作；
5.?负责大数据相关数据架构规划、数据建模、数据库设计以及大数据产品研发工作，并为应用开发团队提供技术支持、模型分析；
6.?熟悉Hadoop、Hive 、Spark、Hbase 、Storm、Flume、ElasticSearch、Neo4J、Kafka等框架组件，深刻理解分布式数据处理技术原理；
7.?熟练掌握Java、Python、Scala等语言中的一种；
?
岗位职责：
1.?参与大数据分布式应用系统服务器端或客户端软件开发工作（需求开发、故障解决和性能优化等）；
2.?承担建设基于Hadoop/Spark生态的大数据离线/实时处理平台；
3.?参与业务数据、生产日志的抽取、转储、检索等相关工作；
4.?跟进大数据前沿技术的发展，将合适的技术方案适时引入业务场景；"
"职位描述：
        
        岗位职责：
1、在项目负责人或项目经理的安排下开展工作；
2、承担地图数据项目生产作业；
3、承担数据建库工作；
?
任职要求：
1、测绘、地理信息系统等相关专业；
2、熟练使用ArcGIS、AutoCAD、CASS等相关数据编辑软件；
3、有二调、三调、国情普查、农经权等项目经验的优先。

待遇：3000-5000/月"
"职位描述：
        
        岗位职责:
1、负责大数据平台开发实现；?2、各种算法实现落地。
任职资格:
1、精通Hadoop/Spark/Storm/Kafka/Redis/Hbase/Hive 等技术；2、熟悉数据挖掘，AI算法，精通典型大数据算法和策略，精通推荐系统、广告系统；3、具备Java语言开发经验，精通关系型数据库及SQL语言，熟悉NoSQL/JSON/XML；4、有DSP项目经验者优先, 有数据仓库经验者优先，有集群性能调优经验者优先。"
"职位描述：
        
        岗位职责:1.负责大数据平台/推荐系统/等产品的架构、研发和持续优化 2.和业务团队深入合作，解决在业务发展中遇到的产品和平台架构问题；具备一定的前瞻性； 3.具体领域包括但不限于推荐算法开发、分布式存储、大规模分布式计算、实时计算、跨平台资源调度、大规模分布式算法平台等；4.负责搭建效果监控平台，数据质量监控平台，数据中心建设，算法模型平台化建设；5.基于Hadoop生态圈进行扩展研发，构建统一的Data Infrastructure，在开源的基础上研发统一支持Batch和Streaming的计算引擎，SQL、NoSQL、Queue和Cache等分布式存储系统，以及自动化运维平台管理超大规模集群。 6. 根据公司的搜索和推荐业务需求，基于上述Data Infrastructure，开发海量电商数据处理和机器学习流程，为搜索和推荐引擎输送实时数据更新，直接影响在线排序，提升成交转化。
任职资格:1.3年以上，对Linux操作系统熟练掌握，熟悉shell脚本编程；2.深入理解 Hadoop/Hive/Oracle 等数据管理系统的原理、运维、性能调优方法；3.深刻理解hadoop相关技术的原理和开发方法，熟练hadoop平台的搭建部署、调优、故障诊断、运行维护的方法和工具；4.精通storm及其开发5.熟练掌握Map/Reduce、HBASE、HIVE、PIG、Mahout中两种以上开发技术，并有实际产品的上线应用；6.对集群有着深刻的了解，能深入的了解hadoop集群及其周边常用各个模块；7.搭建维护hadoop集群并进行必要的troubleshooting, 保障系统正常运行；8.能利用集群实现对数据的分析和处理。"
"职位描述：
        
        【职责描述】 1、负责大数据平台的架构设计和开发，包括平台组件选型及搭建；
2、负责大数据平台的数据接入、处理、查询相关的开发工作；
3、负责大数据相关的应用系统开发，与业务系统的接口设计与开发；
4、负责离线/实时的数据存储和加工处理，保证数据质量，负责数据监控体系的建立和维护。
?
【任职要求】 1、计算机或数学相关专业大学本科及以上学历；?
2、1年以上大数据开发经验，3年左右Java开发经验；
3、熟悉Spark/Hadoop，Hbase，Storm，Kafka等大数据处理框架；
4、熟练掌握Oracle、MySQL数据库技术；
5、有责任心，勤恳踏实，具备良好的沟通能力和承压能力。"
"职位描述：
        
        岗位职责：
1、负责公司大数据基础服务系统研发设计工作；
2、参与应用选型研究、系统架构设计、软件开发工作；
3、负责数据基础结构的规划和设计；
4、用户行为、日志等数据的处理、分析、挖掘和存储。
?
任职要求：
1、统招本科及以上学历，计算机相关专业，3年以上开发经验，良好的理工科背景、扎实的数理功底优先；
2、精通Java开发，熟悉IO机制、网络通讯、多线程等基础知识框架，熟悉缓存、消息队列、索引查询等机制；
3、熟练掌握Hadoop的MapReduce应用的开发以及部署，熟悉分布式计算系统理念，熟悉Hive、Pig等大数据开发工具，熟悉mahout?、mlab；
4、熟练掌握?linux、python?，熟悉spark框架、storm流式计算
5、对数据库有一定了解，熟悉ETL流程；
6、熟悉推荐系统，掌握各种数据挖掘算法者优先；
7、有爬虫、网页正文提取、分词和特征提取等相关经验优先；
8、熟悉junit、sonar等代码质量保障工具；
9、具有良好的团队协作精神，对互联网主流的研发流程、质量控制方式、项目管理方式有充分的了解有责任感、可承受多任务并行的工作压力，重视沟通，具备自主的学习能力和追求卓越的态度。"
"职位描述：
        
        岗位职责：
1、打造领先互联网金融数据平台，包括数据采集、实时数据流、数据仓库、调度系统、查询引擎等，降低数据的使用门槛，实现数据最大价值；
2、打造业界领先的采集、存储、计算等分布式系统，为海量数据和大规模业务系统提供可靠的基础设施；
3. 负责爱财数据平台的建设，包括风控系统运行所需的内外部数据的采集、加工和计算、数仓周边配套设置建设等；
4. 对全链路数据质量负责，进行实时监控，分析，最终提供低延时，高可用等指标；
5. 对接数据平台上的各种业务方，满足不断发展的业务系统建设需求；
6. 对接各类数据源系统，包括集团内部的各种queue，关系数据库，非关系型数据库，日志等系统。

岗位要求:
1、计算机、数学相关专业本科及以上学历，5年以上开发经验；
2、扎实的Java开发功底，理解IO、多线程、集合、并发包，对JVM原理有较好的了解；
3、存储方向：对 HDFS、Hive、Redis、MySQL、HBase、Kafka的一项或多项有经验者优先；
4、计算方向：对 Spark、Storm、Flink、Hive、Druid的一项或多项有经验者优先；
5、资源管理方向：对 YARN、Mesos 的一项或多项有经验者优先；
6、追求优雅的设计和优秀的代码质量，高标准，强悍的编码和trouble-shooting能力，优秀的团队沟通与协作能力；
7、向开源社区贡献过 patch 者优先，请在简历上说明。"
"职位描述：
        
        工作职责：
1、负责各业务大数据平台建设开发;
2、参与数据平台数据挖掘项目;

任职资格：
1、本科以上学历,计算机、数学、统计学等相关专业；
2、熟悉java/python等至少一种语言，熟悉shell,linux系统,Mysql数据库,有较好的SQL性能调优经验;
3、具备hadoop、spark等常见的大数据框架开发经验,3年以上相关经验；
4、具备良好的沟通能力和团队合作能力,有进取心。"
"职位描述：
        
        工作职责：
1. 负责大数据平台的维护与开发，包括ETL开发、数仓建模等等；
2. 与采集组、业务研发组相互协作，共同完成任务；
3. 参与需求的确认、方案的研讨以及落地实施；
4. 研究新技术，为大数据平台提供更好的解决方案。
?
职位要求：
1. 具有扎实的数仓基础理论知识，以及数据库优化、查询优化等；
2. 具有一定的大数据运维经验，解决大数据在实际使用中常见的问题；
3. 掌握大数据平台常用组件的原理，可熟练运用：Hadoop，Hive，HDFS，Oozie，Kafka，Flume，Hbase，Impala等等；
4. 具有一定的Java、Python、Golang等编程基础，可以完成一些组件二次开发或者其他相关需求的开发；
5. 具有团队协作意识，责任心强，可以独立，快速高效得完成分配的工作；
4. 了解一些常见的关系型数据库或NoSQL数据库，比如：MySQL，PostgreSQL等
6. 了解数据挖掘、机器学习等知识，有项目经验更佳；
7. 大数据经验 5年+"
"职位描述：
        
        我们希望您是：
? ? ? ?靠谱的工程师：较好的服务意识，极强的执行力和沟通力，极强的工作责任心；
? ? ? ?有创业者基因：你渴望一个能够共同成长的团队，而不是找一份养家糊口工作；

? ? ?我们会让你做：? ? ? 1.数据处理后台开发；? ? ? 2.hadoop相关开发；? ? ? 3.分布式计算相关开发；? ? ? 您必须要自带的技能：? ? ? 1.java基础较好，熟悉多线程、设计模式等；
? ? ? 2.熟悉Mysql数据库,linux操作系统，熟悉shell编程，具备开源框架使用经验；
? ? ? 3.熟悉hadoop/hive/hbase／kafka／zookeeper优先；
? ? ? 4.熟悉数据storm/samza优先；
? ? ? 5.能够吃苦耐劳，工作积极主动，具备较宽知识面，具备web开发能力；
? ? ? 6.从事过大数据相关项目实践优先。
? ? ? 7.熟练掌握Java语言
? ? ? ?如果您还具备这些：? ? ? ?有个人技术博客，或定期参与业内交流；? ? ? ?有优秀个人作品，或带领过知名应用开发；? ? ? ?长期混开源社区，参与知名项目；? ? ? ?是猴子派来的逗比；? ? ? ?以及其它任何你觉得独特的技能或经验。"
"职位描述：
        
        实习职责：?

 负责爱奇艺基础数据平台的多个内部系统前端 WEB 开发，支持数据展现、排序、编辑、报警，以及数据统计与可视化；
 支持产品、技术同学提出的数据分析、统计、报表需求；
 负责部分后台数据同步、清洗、转换逻辑的开发。 ?


实习要求：?

 国家统招本科学历以上，计算机、软件相关专业，毕业时间2020年或以后；
 编程基础扎实，熟练使用 Java，对基本数据结构和常用开发工具/环境（Linux、IDEA、Git、maven、MySQL 等）熟练使用；
 熟练使用一种以上的 Web 前端框架（如 jQuery、React），熟悉 JavaScript、CSS；
 了解大数据常用工具和知识（如 Hadoop、Hive、NoSQL）；
 热爱钻研，有较强的学习能力，具备强烈的责任心，良好的沟通协作能力，能够与产品经理、后台开发同学协同工作
 每周出勤不低于4个工作日，实习期不低于3个月。 ?


加分项：?

 有网页交互设计经验，熟练掌握一种以上的前端框架的；
 对数据统计、分析感兴趣，并熟练掌握大数据工具和原理的。"
"职位描述：
        
        工作内容/职位描述： 1、参与爱奇艺财务大数据平台的架构设计和开发； 2、基于业务需求和应用场景，设计和实现爱奇艺财务大数据相关产品； 3、为爱奇艺提供财务相关数据支持和服务。
任职资格： 1、本科或以上学历，计算机专业，5年以上大数据项目开发经验； 2、具有Hadoop/Spark开发与应用经验，有较大规模的项目经历并应用在生产环境； 3、熟悉hbase、hive、YARN、Storm、Pig、zookeeper等大数据相关工具，并有处理TB级以上数据的项目经验； 4、具有独立完成从方案选型设计到原型系统开发实现的能力； 5、具有Java后端开发经验，熟悉ssm（spring+spring MVC+MyBatis）开发框架； 6、熟悉spring cloud等微服务框架； 7、熟悉docker/impala/elasticsearch/mongodb/mysql等； 8、有较强的沟通表达能力，善于学习，能迅速理解产品需求；有较强的责任心和事业心，能够自我驱动； 9、有财务大数据相关项目开发经验的优先考虑。

温馨提醒：
如果 7 天内您没有收到爱奇艺的面试邀请，那么目前我们不会安排您参加后续的面试环节，感谢您的理解和对爱奇艺的关注与认可。"
"职位描述：
        
        团队介绍：我们是一支信仰技术的团队，带着这份对技术的偏执，目前爱奇艺全网搜索已经是全球最大的中文视频搜索平台。在这里，你的任何改进，都可能提升数亿用户的用户体验；你的任何想法和意见，都会受到尊重，都会影响数亿用户的搜索体验。
?
薪资：年薪35w+，能力优秀者不受限
?
工作职责：
负责爱奇艺全网搜索数据的分析、挖掘等工作
负责爱奇艺全网搜索用户画像
负责数据的可视化工作，以及商业智能，为提升用户体验提供数据支持
职位要求：
熟练掌握JAVA开发，熟悉掌握分布式应用开发原理，熟练掌握多线程开发，熟练掌握设计模式
熟悉jvm，有线上调优经验
熟悉常用的大数据分析框架，如hive、spark、flink、Impala等，并熟悉运行原理
良好的计算机编程素养
熟悉机器学习算法加分
以上框架深入原理加分"
"职位描述：
        
        工作内容：?1. 海量广告日志数据的收集、处理、报表计算及自动化任务管理及监控平台开发2. 广告数据实时/流计算平台设计、开发与调优，要求低延迟，高并发，精确一次，支持品牌，效果，RTB等多种业务?3. 负责实时/流计算平台线上运维、保障系统稳定和高可用，解决大并发下的各种问题??职位要求：??1. 较强的学习和动手能力，对大数据领域有兴趣2. 两年流计算应用开发或流计算平台开发相关经验3. 精通Flink、Spark Streaming任一一项，熟悉Kafka、kudu底层机制4. 精通Java，熟悉Scala语言5. 本科或本科以上学历，计算机/电子／通信／统计／数学相关专业优先，有广告相关背景优先
温馨提醒： 如果 7 天内您没有收到爱奇艺的面试邀请，那么目前我们不会安排您参加后续的面试环节，感谢您的理解和对爱奇艺的关注与认可"
"职位描述：
        
        岗位职责: 
1、参与爱奇艺智能大数据平台的架构设计和开发； 
2、基于业务需求和应用场景，设计和实现爱奇艺大数据相关产品； 
3、为爱奇艺所有业务线提供数据支持和服务。 
任职要求: 
1、本科或以上学历，计算机专业，3年以上大数据项目开发经验； 
2、具有Hadoop/Spark开发与应用经验，有较大规模的项目经历并应用在生产环境； 
3、熟悉hbase、hive、YARN、Storm、Pig、zookeeper等大数据相关工具，并有处理TB级以上数据的项目经验； 
4、具有独立完成从方案选型设计到原型系统开发实现的能力； 
5、有较强的沟通表达能力，善于学习，能迅速理解产品需求；有较强的责任心和事业心?，能够自我驱动； 
6、熟悉docker/impala/elasticsearch/mongodb等技术的优先。
?
温馨提示：
如果7天内您没有收到爱奇艺的面试邀请，那么目前我们不会安排您参加后续的面试环节，感谢您的理解和对爱奇艺的关注与认可。"
"职位描述：
        
        岗位职责：1、负责大数据项目实施以及部分设计开发；2、负责大数据环境的部署、调优以及日常运维；3、负责大数据环境下的数据清洗、转换、建模、分析以及部分开发工作；4、参与数据挖掘业务体系的架构设计、规划及实施。岗位要求：1、熟悉主流关系型数据库系统(Oracle、MySQL等),?并熟练运用SQL进行数据查询管理操作；2、熟悉Hadoop、Spark等大数据平台架构，有实际的项目实施运维经验；3、熟练使用Hive、HBase、Impala等大数据处理系统,了解其内部工作机制,熟悉其系统结构,有排查和解决相关技术问题的经验；4、熟悉Storm、Flink、Spark?Streaming等流式数据处理框架，有一定的实施运维能力；5、熟悉ElasticSearch、Solr等分布式搜索引擎，有一定的实施运维能力；6、熟练掌握Linux操作系统，能够熟练使用Linux系统命令，熟悉Shell等脚本编程；7、熟悉Java、Python等编程语言，具备基本的程序设计开发能力；8、掌握非结构化数据的保存、分析、访问、调优，掌握或使用过至少一种Nosql的开源产品，如HBase、Redis等；9、有海量数据的分析能力和处理经验、对数据分析和数据挖掘有浓厚兴趣者优先考虑；10、强烈的责任心和团队合作能力，良好的学习能力，严密的逻辑思维能力并且敢于创新和接受挑战，能够在一定压力下工作。"
"职位描述：
        
        岗位职责：1、负责大数据项目实施以及部分设计开发；2、负责大数据环境的部署、调优以及日常运维；3、负责大数据环境下的数据清洗、转换、建模、分析以及部分开发工作；4、参与数据挖掘业务体系的架构设计、规划及实施。岗位要求：1、熟悉主流关系型数据库系统(Oracle、MySQL等),?并熟练运用SQL进行数据查询管理操作；2、熟悉Hadoop、Spark等大数据平台架构，有实际的项目实施运维经验；3、熟练使用Hive、HBase、Impala等大数据处理系统,了解其内部工作机制,熟悉其系统结构,有排查和解决相关技术问题的经验；4、熟悉Storm、Flink、Spark?Streaming等流式数据处理框架，有一定的实施运维能力；5、熟悉ElasticSearch、Solr等分布式搜索引擎，有一定的实施运维能力；6、熟练掌握Linux操作系统，能够熟练使用Linux系统命令，熟悉Shell等脚本编程；7、熟悉Java、Python等编程语言，具备基本的程序设计开发能力；8、掌握非结构化数据的保存、分析、访问、调优，掌握或使用过至少一种Nosql的开源产品，如HBase、Redis等；9、有海量数据的分析能力和处理经验、对数据分析和数据挖掘有浓厚兴趣者优先考虑；10、强烈的责任心和团队合作能力，良好的学习能力，严密的逻辑思维能力并且敢于创新和接受挑战，能够在一定压力下工作。"
"职位描述：
        
        工作职责：
1、协助构建数据分析和监控体系，为产品和市场提供数据支持和决策依据；
2、负责数据分析系统部分设计和开发工作；
3、根据业务需求和目标，将数据模型转化为实际应用；
4、提升系统和集群性能，优化代码和数据结构；

任职资格：
1、本科及以上学历，计算机专业背景，有独立分析问题和解决问题的能力；
2、具有良好的数据结构/算法、网络、操作系统等计算机基础知识；
3、具有良好的沟通能力和责任心；
4、具有缜密的思维逻辑和快速定位问题的能力，具备对技术挖掘、更新的热情；
5、熟悉ElasticSearch，hadoop生态，spark生态，熟悉其原理、常用方法和源代码者优先。"
"职位描述：
        
        工作职责：
1、协助构建数据分析和监控体系，为产品和市场提供数据支持和决策依据；
2、负责数据分析系统部分设计和开发工作；
3、根据业务需求和目标，将数据模型转化为实际应用；
4、提升系统和集群性能，优化代码和数据结构；

技能及资质要求：
1、本科及以上学历，计算机专业背景，有独立分析问题和解决问题的能力；
2、具有良好的数据结构/算法、网络、操作系统等计算机基础知识；
3、具有良好的沟通能力和责任心；
4、具有缜密的思维逻辑和快速定位问题的能力，具备对技术挖掘、更新的热情；
5、熟悉ElasticSearch，hadoop生态，spark生态，熟悉其原理、常用方法和源代码者优先。"
"职位描述：
        
        公司描述：
熵简科技是一家专注于智能投研辅助决策工具的研发机构，致力于使用智能化的方式简化投资研究的复杂度。
我们有神秘大客户，闷声大发财。
了解各行各业的数据，天空是你的极限！

刚结束新一轮融资，准备大展身手。

职位愿景：
DT数据时代正在到来，现在上车还来得及！
这是一家快速成长的公司，因此也需要能够快速成长的你。

希望在大数据、机器学习、人工智能领域有所建树的你，是否深陷“大数据第22条军规”之苦？
没经验所以不能参与大项目、没项目所以没有经验的困局？
做了WordCount之后不知如何继续精深？
在一个业务驱动的公司里无所适从？
在一个默默无闻的小公司里浪费青春？
在一个名声在外的大公司里混吃等死？

……

来这里！熵简科技是一家技术驱动、精英文化、结果导向的研发公司！

在这里我们信仰弹性工作和结果驱动，相信严酷的技术挑战是你最好的老师；
这里有来自清北复交、海外名校，曾任职于一线互联网公司的精英团队，是你未来的良师益友；
这里有来自顶尖网络课程的专业知识，“动物书”的海洋，是你未来的大学城；
还有天马行空的知识沙龙，终身学习，生活是诗和远方；

更有做不完的需求，踩不完的坑，需要你来攻克（当然，是和团队一起）！

熵简科技需要技术过硬、迎难而上的你，而你――需要这个机会！

岗位职责：
1) 负责海量数据整体架构设计与数据架构管控，根据具体业务和产品对数据模型进行统一分析和规划
2) 负责部门业务需求调研和数据开发
3) 配合后端工程师和算法工程师实现数据流转

任职资格：
1、本科及以上学历
2、2年及以上数据开发经验，精通SQL，有分布式计算平台（Spark、Hive）数据开发经验；?
3、熟悉数据仓库各类建模理论，以及数据仓库层级体系；?
4、熟练使用scala、java者优先
5、有数据治理相关项目的工作经验，对数据质量管理有深入见解；?
6、有特征工程和算法相关经验优先。"
"职位描述：
        
        岗位职责：
负责公司大数据产品核心功能的设计和开发。

任职资格：
1. 熟练掌握JAVA语言；
2. 熟练使用MySQL、Oracle、PostgreSQL等数据库，并具有较强的SQL优化能力；
3. 熟悉Hadoop、Hive、HBase、Spark等相关开源项目；
4. 熟悉linux操作系统，包括Shell/Python等脚本编码和软件开发等；
5. 熟练使用ETL工具，如Kettle，会使用JAVA进行调用；
6. 熟悉Redis等常用NoSQL解决方案、了解各自的优缺点以及使用场景者优先。"
"职位描述：
        
        岗位职责：
1. ? ? 负责PB级别用户数据实时/离线计算的架构设计和开发；
2. ? ? 构建数据管理平台,用于存储、计算、分析、挖掘用户行为、用户交易等日志数据处理和分析；
3. ? ? 对大数据相关的前沿技术进行预研，利用挖掘技术分析用户偏好特征，构建用户画像、精细化运营等业务的数据基础；

任职要求：
1. ? ? 本科及以上学历，计算机或者数学等相关专业；
2. ? ? 熟练掌握Java/scala/Python(任意一种即可)语言，熟练Linux开发环境以及Shell、Python常用脚本语言；
3. ? ? 3年以上大数据开发经验，熟练使用Hadoop，Spark，Storm，Hive，Hbase，ES等开源技术，并对其中1到2个组件有定制开发或者开源贡献；
4. ? ? 在实时计算、多维度olap分析方面有实践经验；
4. ? ? 对技术有执着的热情。
加分项
1. ? ? 有图像对比、音频对比实践经验；
2. ? ? 具有DMP、程序化广告、网盟、广告监测、反作弊、风控等业务经验；"
"职位描述：
        
        岗位职责：
1. ? ? 负责PB级别用户数据实时/离线计算的架构设计和开发；
2. ? ? 构建数据管理平台,用于存储、计算、分析、挖掘用户行为、用户交易等日志数据处理和分析；
3. ? ? 对大数据相关的前沿技术进行预研，利用挖掘技术分析用户偏好特征，构建用户画像、精细化运营等业务的数据基础；

任职要求：
1. ? ? 本科及以上学历，计算机或者数学等相关专业；
2. ? ? 熟练掌握Java/scala/Python(任意一种即可)语言，熟练Linux开发环境以及Shell、Python常用脚本语言；
3. ? ? 3年以上大数据开发经验，熟练使用Hadoop，Spark，Storm，Hive，Hbase，ES等开源技术，并对其中1到2个组件有定制开发或者开源贡献；
4. ? ? 在实时计算、多维度olap分析方面有实践经验；
5. ? ? 对技术有执着的热情。
加分项
1. ? ? 有图像对比、音频对比实践经验；
2. ? ? 具有DMP、DSP、程序化广告、网盟、广告监测、反作弊、风控等业务经验；"
"职位描述：
        
        岗位职责：1、负责大数据平台以及智能数据产品的规划和搭建、系统及功能模块设计，平台的维护和优化, 制定清晰的大数据产品技术研发路线图；2、负责规划数据挖掘的整体流程，并参与用户产品和数据产品的决策；3、与业务部门密切配合，寻求数据层面的业务价值，利用数据分析结论推动产品优化；4、带领团队对于产品数据进行分析，指导工程师完成数据挖掘相关的算法、应用的设计与开发；5、技术团队的管理及考核，制定开发、运营规范，撰写相关技术文档指导和培训工程师；负责大数据核心技术团队的人才培养；6、关注前沿技术，研究其中的商业价值，根据公司战略进行应用转化。任职要求：1、计算机、数学相关专业，全日制本科及以上学历2、8年以上工作经验，5年以上团队管理经验，具备30人以上数据与技术团队管理经验为佳。3、精通Hadoop／Spark、Hive、HBase等主流的大数据技术，至少3年以上产品／平台项目研发经验；具备大型复杂Hadoop数据平台的建设实施经验；精通Java及Python；4、领导开发过数据产品，能够把数据和业务系统形成闭环；5、对数字，数据敏感，具备良好的逻辑思维能力，能够从海量数据中发现有价值的规律；4、有极强的项目管理能力和资源协调能力，有很好的沟通能力；"
"职位描述：
        
        岗位职责：
1、负责管理开发团队，分解任务、指导成员并监控、改进团队协同流程，提升开发效能；
2、负责建设行业数据仓库体系、数据挖掘体系、数据安全体系、数据推荐体系等架构；
3、对业务需求深入分析，从而进行大数据平台核心应用的架构设计、开发和技术支持；
4、规划业务应用系统和数据平台的技术架构，参与需求分析、建模、架构设计、技术决策以及详细设计；
5、把握复杂系统的设计，确保系统的架构质量，编写核心部分代码；
6、带领团队攻克例如大数据量、高并发、高稳定性等带来的各种挑战及技术难关。
任职要求：
1、本科或以上学历，计算机相关专业，5年以上研发经验，3年以上大数据平台相关工作经验；
2、精通海量存储、计算系统的架构和原理，具备丰富的大规模并发处理系统的研发和架构经验;
3、深刻理解大数据处理（流计算，分布式计算，分布式文件系统，分布式存储等）相关技术和实现方法；
4、基于Hadoop的大数据体系有深入认识，具备相关产品（Hadoop、Hive、HBase、Spark、Storm、Flume、sqoop、Kafka、ES等）项目应用研发经验和架构设计经验；
5、设计过数据分析、数据挖掘、数据可视化、在线数据相关产品经验优先考虑。"
"职位描述：
        
        工作职责:1、参与数据收集、数据分析、数据提取等数据处理相关工作；2、持续优化数据平台架构，管理维护数据采集、数据湖、数据集市；3、参与大数据治理，管理维护数据模型、元数据、数据标准、数据质量、数据生命周期、数据分布与存储、数据服务；4、分析产品、发行、运营的业务场景开发各种数据应用。任职资格:1、具备线性代数、概率论与数理统计等数学基础；2、计算机或数学相关专业，本科及以上学历；3、具备Linux环境研发能力，深入理解数据结构和算法设计；4、熟悉大数据处理流程和Hadoop生态技术栈；5、熟练使用SQL，熟练应用关系型、非关系型数据库与大数据环境； 6、熟练使用大数据环境中的数据分析引擎；7、有海量数据处理经验者优先；8、有大数据平台治理经者优先。"
"职位描述：
        
        
1、负责大数据平台的搭建、问题解决和调优；
2、负责项目中和公司已有系统及外部系统的数据对接和ETL工作；
3、负责大数据平台上的模型构建和数据挖掘算法的实现；
4、负责其他和大数据平台相关的项目的设计和实现；
5、维护大数据平台的稳定和可靠。
职位要求：
1、全日制本科及以上学历，计算机相关专业；
2、具备基于Hadoop大数据处理和分析的多项技术的应用技能，包括但不限于HDFS，Yarn，MapReduce，Hive，Spark，HBase等；
3、熟悉ETL相关开发工具和技术，了解大数据平台技术及分布式运算技术原理；
4、了解主流关系型数据库，精通SQL；
5、熟悉数据开发测试部署规范和流程，掌握git代码库的使用和发布知识；
6、能够灵活使用Java、Python、Scala三种语言中的一种；
7、具有很强的学习能力，分析能力和沟通能力。"
"职位描述：
        
        
工作职责：
1、面向公司业务的数据仓库结构设计;??
2、对业务数据源提取数据工作，高质量地完成ETL开发;
3、对ETL过程的测试，数据结果的验证，保证ETL逻辑的正确性、数据的准确性，保证数据质量;
4、定义并丰富数据维度，帮助业务部门从各个维度使用数据。
职位要求：
1、全日制本科及以上学历，计算机相关专业,并有互联网工作背景；
2、3年以上数据仓库项目工作经验，2年以上大数据平台开发经验；
3、熟悉目前大数据平台的常用应用组件，包括但不仅仅限于：Hadoop、Hive、Spark、HBase、ES等等，并具有相关开发经验；
4、熟练使用SQL、Python、Scala其中一种语言进行数据开发和快速场景分析；
5、具备优秀的团队意识和沟通能力，主动性强，具有钻研精神，充满激情，乐于接受挑战。
6、有丰富的跨团队与部门的合作能力， 具备一定的互金业务知识；
7、热爱数据，对数据及逻辑关系敏感，并对数据体系有深入的认识；"
"职位描述：
        
        1、独立完成项目的系统分析，设计，并主导完成详细设计和编码的任务，确保项目的进度和质量；
2、负责公司数据产品平台（敏捷BI、OLAP引擎、实时计算等）开发和维护。
?
任职要求：
1、本科以上学历，3年以上Java开发经验，有互联网应用产品开发经验；
2、Java基础扎实，对容器、多线程、JVM的原理有一定的理解，熟悉Spring & Spring boot, Mybatis等各开源组件；
3、熟练Mysql数据库，有SQL优化经验；
4、熟悉linux系统中的常用命令,以及在该系统下项目的部署；
5、熟悉web开发相关技术：html、js及js框架、模板引擎等。
?
有以下技能优先：
1、熟悉前端js框架、h5、Android & iOS开发优先；
2、熟悉大数据相关技术栈：hive、spark、storm等；
3、写过python，用python写过数据处理或web相关。
?
软性要求： 诚实、具有合作意识、勇于承担压力和责任。"
"职位描述：
        
        职位描述：1、负责数据开发所涉及的应用及服务的部署、维护、管理、架构设计工作；2、负责数据仓库的建设、优化、维护以及大数据项目生态系列产品的优化、维护；3、负责ETL设计开发、工作流调度设计、存储过程开发、自定义函数开发、性能调优，ETL相关软件和工具的研发和改进；4、负责各业务系统数据源业务调研、数据调研、准确性完整性验证；5、负责与其它业务系统产品及开发进行数据对接、数据预处理、数据清洗、数据处理、数据导入、数据校验相关开发工作；6、负责数据平台日常管理、跑批、维护、监控、处理临时数据需求。岗位要求：1、计算机或相关专业以上，BI行业或数据开发工作3年及以上经验，熟悉数据仓库建设理论,至少参与过一个中大型项目，具有大数据处理及并发经验处理经验的优先；2、熟悉Greenplum、MySQL、PostgreSQL等主流数据库的一种或多种；有Greenplum搭建和运维经验的优先；3、熟悉掌握数据查询语言SQL、存储过程等开发技术,具有一定数据分析统计能力；4、熟悉linux 操作系统,具备一定的开发能力,熟悉至少一门脚本语言(shell/python等),熟悉至少一门开发语言(Java/C++等)；5、熟悉Hadoop生态中Hbase、Hive、Spark、Sqoop等，有部署管理使用经验"
"职位描述：
        
        技能要求：
1.熟悉linux操作和了解shell编程
2.了解java web
3.了解并使用过大数据相关组件，如hadoop、hive、spark等

工作职责：
1.负责linux系统常规运维工作
2.负责web模块开发
3.负责大数据相关工作开发

该岗位实习期为3~4个月，欢迎大二、大三的同学投递简历。"
"职位描述：
        
        岗位职责：
1、负责用户数据挖掘工作，主要工作内容包括用户体系建设、用户行为、用户习惯画像等；
2、负责用户数据的管理，为数据分析、挖掘等提供强有力的支撑。
?
任职要求 ：
1、本科及以上学历，机器学习、数据挖掘、计算机或相关专业；
2、2年以上的工作经验，熟悉数理统计、数据分析、数据挖掘，熟知常用算法；
3、熟悉C++ & Spark & Python开发，对数据结构和算法设计有较为深刻的理解；
4、熟悉大规模数据挖掘、机器学习并具有实际工作经验；
5、有较强的技术选型及规划能力、较好的沟通能力、积极主动，愿意接受挑战；
6、具有海量数据处理、大数据方向相关背景和工作经验优先。"
"职位描述：
        
        岗位职责

1.基于海量数据，支持业务对数据的分析和使用：数据的流式处理、构建数据仓库、分析用户行为等。?


岗位要求
1.?有扎实的编程能力，有优秀的设计和代码品位，对解决具有挑战性问题充满激情；?
2.?对大数据处理有丰富的经验和广阔的视野；
3.?熟悉常用的开源组件：Hadoop/Hive/Spark/Storm，并了解其特性和使用场景；?
4.?优秀的沟通理解能力，能快速理解业务，用数据解读业务；?
5.?推荐或机器学习相关的开发工作优先。"
"职位描述：
        
        工作内容：
1.搭建数据平台和系统，支撑业务数据需求?
2.规划及搭建大数据系统，分析教学行为，结合数据提升业务效率和价值?
3.组建数据分析团队，快速敏捷的响应数据需求?
岗位要求：
1.计算机，数学、统计学等专业，硕士及以上学历，5年数据工作经验以上；?
2.精通数据库仓库、数据分析方法，能灵活根据业务情况选择选择及设计数据模型?
3.对mysql非常熟悉，有实际根据mysql搭建数据仓库的经验，处理过海量数据?
4.有大数据搭建及运维经验，对数据导入、清洗、使用过程非常熟悉?
5.有大数据处理经验，有人工智能、自然语言处理、机器学习等背景者优先；?
6.熟练掌握shell及python、java等开发语言；?
7.良好的沟通能力，能够洞悉业务发展的数据需求"
"职位描述：
        
        工作内容：?
1.为业务部门、运营部门提供数据处理支持 ；
2.Review及评估数据库表设计的合理性 ；
3.负责公司的数据清洗、加工、处理入库等工作 ；
4.大数据系统建设及开发 。

岗位要求：?
1.计算机，数学、统计学等专业，本科及以上学历，数据相关工作经验3年以上；?
2.熟练使用mysql数据库，精通SQL语句，有丰富的ETL经验；能够快速根据数据的状况决定采用技术、保证数据入库的正确性?
3.熟悉shell及python脚本语言，能够快速高效的使用脚本完成简单的数据处理任务；?
4.熟悉java开发语言，能够基于java完成map/reduce等功能开发?
5.对常用机器学习算法熟悉，能够基于场景完成相应相应算法的开发和实现?
6.对数据敏感，能够从数据中寻找到规律，同时能够保障数据输出的正确性和完备性?
7.具备大数据处理经验、自然语言处理、机器学习等背景者优先；"
"职位描述：
        
        岗位描述：
1.负责火石医健数据仓库建设，包括：数据仓库（离线、实时）的数据架构、数据模型规划及实施、数据质量保障；
2.负责火石数据服务框架设计、实现；数据服务流程规范制定、执行和优化；研究高性能、高可用的数据API系统的实现方案；

岗位要求：
1.从事数据仓库或大数据开发至少5年以上，熟悉数据仓库模型设计与大数据开发经验，掌握维度建模设计方法，具备海量数据处理经验；?
2.熟悉数据仓库领域知识和技能者优先，包括但不局限于：元数据管理、数据开发测试工具与方法、数据质量、主数据管理；
3.熟悉数据库技术，熟练运用SQL及其他Z言，能高效的与技术团队进行沟通；
4.有从事分布式数据存储与计算平台应用开发经验，熟悉Spark和ELK生态相关技术并有相关实践经验着优先，如Hdfs、Elasticsearch、Hive、Hbase、Spark；
5.熟练掌握一门或多门编程语言，并有大型项目建设经验者优先，如Java、Python、Shell；
6.有丰富的数据分析经验，较强的数据、平台、技术理解能力；
7.良好的语言沟通与表达能力，自我驱动；
8.熟悉和热爱开源项目，对新技术，新趋势敏感者优先。"
"职位描述：
        
        岗位职责

1.负责海量实时数据的处理，包括数据收集，etl，入库等 ；
2.负责数据仓库和数据集市产品的搭建，为公司提供决策支持；

岗位要求
1.从事数据仓库领域至少2年以上，熟悉数据仓库模型设计与ETL开发经验 ，具备海量数据加工处理（ETL）相关经验 ；
2.有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验着优先 ；
3.熟悉数据仓库领域知识和技能者优先，包括但不局限于：元数据管理、数据开发测试工具与方法、数据质量、主数据管理；? ?

我们能给您提供什么？
? 极具前景的行业（人工智能、大数据、医疗健康）
? 飞速发展机会（指数级增速）
? 优秀成熟的团队（行业大咖）
? 简单、认真、投入的氛围
? 竞争力的薪资、股票计划、餐饮交通补助、节日福利、定期团建
? 充沛的学习机会，火石学堂…"
"职位描述：
        
        岗位职责：
1、负责大数据系统平台业务、运营数据支撑业务相关需求的研发工作；?2、对所负责平台开发需求进行规范设计，合理安排研发进程，保证研发质量；?3、根据公司业务发展需要，完成对数据的采集、分析、存储平台模块开发；?4、参与大数据平台服务器架构设计和管理，支持大数据平台运维拓展；?5、积极参与公司知识产权体系建设、丰富技术文档等内容；?6、完成上级交办的其他任务。

任职要求：
1、热爱数据平台开发工作，有相关教育背景；?2、做事认真负责，重视工作执行细节；?3、有较强的责任心和学习、总结能力；?4、对数据敏感，有较强的逻辑思维能力和问题分析能力；?5、熟悉PHP语言，一年以上PHP开发经验。

更多信息可查看公司官网哟：http://www.flamingo-inc.com/joinus/"
"职位描述：
        
        岗位职责：

1.负责和交易数据相关的信息抽象，数据仓库建设；

2.主持和参与实时架构设计并实现；

3.基于开源系统大数据系统进行二次开发；

?

任职资格：

1.本科及以上学历，计算机相关专业，5年以上数据平台开发经验；

2.熟悉Java/Python，熟练掌握SQL，对大数据平台有深入的了解；

例如 Hadoop生态系统，MongoDB, Elastic Search， Spark,Flink和图数据库，能够按照业务需求选择底层技术；

3.熟练使用Javaweb，Spring-boot， Redis 等web开发；

4.有大型数据仓库实施经验,应对复杂业务数据建模,经过大型应用场景的考验；

5.热爱数字货币行业。

?

加分项：

有金融风控系统，征信系统经验，金融衍生品知识的优先考虑；

有用户画像，消费行为分析经验的优先考虑；

有团队管理经验者优先考虑。"
"职位描述：
        
        岗位职责：
1.负责和交易数据相关的信息抽象，数据仓库建设；
2.主持和参与实时架构设计并实现；
3.基于开源系统大数据系统进行二次开发；
?
任职资格：
1.本科及以上学历，计算机相关专业，3年以上数据平台开发经验；
2.熟悉Java/Python，熟练掌握SQL，对大数据平台有深入的了解；
例如 Hadoop生态系统，MongoDB, Elastic Search， Spark,Flink和图数据库，能够按照业务需求选择底层技术；
3.熟练使用Javaweb，Spring-boot， Redis 等web开发；
4.有大型数据仓库实施经验,应对复杂业务数据建模,经过大型应用场景的考验；
5.热爱数字货币行业。
?
加分项：
有金融风控系统，征信系统经验，金融衍生品知识的优先考虑；
有用户画像，消费行为分析经验的优先考虑；
有团队管理经验者优先考虑。"
"职位描述：
        
        一、工作职责：
1、参与政府、企业调研，分析客户需求，撰写项目整体规划和具体项目的技术方案；
2、负责大数据项目落地的售前工作及政府、企业大数据咨询工作；
3、与业务负责人进行日常沟通交流、技术协调、资源共享等；
4、研究国家、地区相关政策及行业、产业发展动态信息、前沿技术，撰写行业研究报告、技术报告，参与政府软课题研究；
5、参与政务数据分析、政府课题相关研究工作；
6、完成领导交办的其他工作。
二、任职资格：
1、对政务大数据有多个领域项目经验，大数据项目具有项目整体规划、解决设计与落地实施经验；
2、对自己擅长的领域具有较深的认识，较强大数据应用场景分析设计能力，有一定的创新意识；
3、掌握Hadoop相关技术及生态圈，熟悉分布式计算系统理念，熟悉Strom流式计算；
4、了解常用的机器学习算法，了解不同模型的特性，了解数据分析关键过程；
5、具有快速分析问题和解决问题的能力；出色的沟通理解能力、逻辑思维和语言表达能力；较强的文字驾驭与方案撰写能力，文笔流畅
6、具有较强的学习能力，较强的责任心、事业心和团队合作精神。
7、硕士及以上学历，计算机、应用数学、统计、自动化等相关专业；有技术研发或者产品设计经验后转解决方案售前工作者优先。"
"职位描述：
        
        职责描述：
? ? 1) 根据公司业务及项目与AI算法工程师进行对接；
? ? 2) 负责与AI算法工程师沟通训练数据要求；
? ? 3) 负责AI数据的收集、分类和整理；
? ? 4) 负责参与人工智能的模型训练；
? ? 5) 负责参与数据采集系统的开发和维护；
? ? 6) 按时完成上级领导交代的其他任务。
任职要求
? ? 1) 全日制本科及以上学历，工作1-3年，具有一定的数学理解能力，计算机相关专业优先，优秀应届毕业生可接受；
? ? 2) 工作主动热情，细心耐心、有强烈的责任感和团队合作精神；
? ? 3) 性格外向，学习能力强、逻辑思维能力强，有较强的沟通能力和协调能力；?
? ? 4) 熟悉Linux操作系统及基本原理，具备C/C++/Python开发经验；
? ? 5) 熟悉MySQL、SQLite，有SQL开发经验；
? ? 6) 具有网络爬虫、结构化数据提取、数据分析工具等使用/开发经验者优先；
? ? 7) 具有人脸识别等AI领域相关经验者优先。"
"职位描述：
        
        岗位职责：1、参与大数据平台架构设计和优化, 参与大数据技术方案的制定和实践；2、编写大数据产品的核心代码和技术文档；3、研究大数据技术发展动态，研究新型计算框架，并能够提出优化解决方案；4、参与团队技术人才培养，指导研发团队成员工作，提升团队研发能力。任职资格：1、本科及以上学历，5年以上数据领域相关工作经验，3年以上大数据平台架构经验；2、熟悉大数据生态圈的相关技术，深度了解Druid／ES／Spark／Hadoop／Storm／Hive／Flink／Lucene／ZK／Kafka／Atlas等或其中部分，深入了解大数据处理技术的实现方法；3、精通Java语言开发，熟悉Python、Scala或者Go语言之一,熟练掌握Linux操作系统；4、对大数据治理和安全有比较系统的实践，有分布式计算或海量数据应用经验；5、优秀的沟通协调、分析解决问题能力，了解常见的安防业务流程和数据结构，热爱技术和业务创新；6、具备较强的学习能力和自我管理能力，性格积极乐观，能够在压力环境下工作；"
"职位描述：
        
        职责描述：- 基于每日上亿级数据，搭建大数据处理治理平台；实现流式事件的实时计算，落地储存;- 深入业务，理解并合理抽象业务需求，发挥数据价值，与业务团队紧密合作；- 通过专项分析，输出专项分析报告，为业务模块的决策和产品方向提供数据支持 ；- 理解并合理抽象不同业务需求，做较通用和系统性的支持。任职要求：- 运筹学、工业工程、应用数学、计算机应用、机器学习/AI技术等相关专业，熟悉大数据、优化算法领域的主要理论和常用工具- 具备较强的业务理解和数学建模能力，能快速理解问题、抽象并设计解决方案，能够针对模型开发实际的工程化算法- 了解数据仓库实施方法论、了解数据仓库体系，并支撑过实际业务场景，理解常用的数据建模理论，可独立把控数据仓库的各层级设计；- 具备一定编码能力，掌握 java/python/C++ 开发语言之一，熟练使用 SQL 进行数据访问；- 精通 Hadoop 生态系统基础设施：Flume、Kafka、Hbase、Hive、Spark、Storm、Presto 等，有支撑每日亿级别数据的大数据系统搭建经验- 优秀的英文听说读写能力（有机会与国际**专家/科学家/学者进行对接和学习）- 善于沟通，具备优秀的技术与业务结合能力；- 有 PB 量级数据处理/标准化治理经验者优先；"
"职位描述：
        
        职位描述:

 ? 负责数据平台整体架构设计及实施，以及数据平台产品研发和交付；

2. 一站式数据平台建设，为业务部门的决策、分析、可视化、自助服务提供数据产品支撑； ??
任职资格：

 ? 计算机或相关专业本科以上学历

2. 3年以上互联网项目经验，能够独立完成项目开发及现有项目二次开发；
3. ? 熟悉常见的大数据技术，hbase/hive等；熟悉可视化技术和方案，如Echarts等;
4. ? 熟悉分布式后端服务开发流程和规范，熟练掌握Spring、Mybatis等框架，熟悉SpringCloud， SpringBoot等开发框架；
5. ? 精通Java多线程开发和线程池使用，熟练掌握分布式，缓存，消息队列MQ，搜索等技术体系；
6. ? 掌握Redis，Elasticsearch等技术，精通MySQL的开发设计和调优；
7. ? 对技术有激情，喜欢钻研，主动性高，具有较强的独立工作能力和解决问题的能力;"
"职位描述：
        
        岗位职责
1. 负责数据平台的开发工作
2. 负责挖掘海量数据背后的隐藏价值，赋能业务
3. 负责数据产品的开发工作
岗位要求：
1. 3年以上工作经验
2. 熟悉spark，hadoop，java，python等
3. 有大数据开发经验或者算法平台开发经验
4. 关注业务，对业务有sense
5. 有责任心，有把事情做到极致的激情和决心"
"职位描述：
        
        职位描述：
1.负责地理平台分布式计算相关研发；
2.设计数据分布式处理流程，优化平台数据计算性能；

任职要求：
3-8年工作经验
1. 计算机相关专业，3年及以上相关工作经验,有扎实的计算机理论基础；
2. 熟悉Hadoop、Spark、Storm等分布式计算框架，研究过Hadoop或者Spark源代码的优先；
3. 熟悉Ceph、Hdfs等分布式存储系统，有大规模高并发分布式系统开发经验优先；
4. 精通Unix/Linux下C++、Python、Go、java中至少一种语言，有良好的编码习惯；
5.具有海量地理信息数据处理经验优先，有分布式数据库经验者优先；
6.善于分析和解决问题，比较强的学习和创新能力，有责任心；"
"职位描述：
        
        岗位职责
 1. 负责用户画像系统的的架构设计与开发；
 2. 负责大数据在线服务的架构设计与开发；
 3. 负责实时特征处理系统的架构设计与开发；
 4. 负责机器学习模型服务的架构设计与开发；

岗位要求：
1、计算机或相关专业本科以上学历优先，2年以上工作经验; 
2、具备扎实的Java语言编程基础，具备良好的编程习惯，较强独立解决问题的能力；掌握Spring等常用的开发框架；
3、有丰富的工作经验，参与过大型复杂分布式系统的设计、架构者优先；
3、有Hadoop、Spark、Flink、ES、Kafka等框架开发经验者优先；
4、熟悉多线程编程和JVM性能调优，有高并发、高吞吐量服务开发经验者优先；
6、做事严谨踏实，责任心强；具有良好的沟通能力和团队意识；
7、有机器学习模型开发经验者优先；"
"职位描述：
        
        岗位职责

1. 负责DS部门数据仓库集市和平台建设及优化，有优化和完善数据驱动型基础设施的思路和经验；
2. 深入理解分析师及业务需求,建设完善的数据体系,为提升分析师与业务方的数据分析挖掘效率提供高效&完善的数据仓库和集市；
3. 基于数据驱动的数据科学部核心职能，为业务方和分析师提供各种分析体系的工具化解决方案&数据产品；
4. 负责指标定义梳理及监控看板落地，建设异动检测和异常分析的自动化工具。打造：业务方－数据产品－数据分析 三方互动良好的产品迭代闭环；
5. 数据生产的工具化建设和规范制定及日常治理；
岗位要求：
1) 统招全日制本科以上学历, 计算机、数学相关专业（3年以上工作经验／架构师5年以上经验）,具有知名互联网背景优先;
2) 具备复杂业务需求梳理能力，较强的分析解决问题能力和产品思维；
3) 良好的团队意识，和较强的抗压能力；具备团队管理经验者优先；
4) 熟悉数据仓库模型设计与ETL开发经验 ，具备海量数据（TB级别）加工处理经验；
5) 熟悉大数据开发基本问题、工具和方法，熟悉并使用过各种大数据相关框架或组件优先，如Kafka、Storm/JStorm、Hadoop/Spark、Hive、HBase等；
6) 熟悉linux平台，精通shell/c(c++)/scala/python/等脚本语言的一种或多种，编码基本功扎实 ；
7) 对Druid、Kylin、Impala、Presto等引擎系统有深入使用和底层研究者加分；"
"职位描述：
        
        工作职责
在云端或者本地集群上构建可扩展的实时数据处理流水线，收集、转换、加载并管理各类数据源
构建可扩展的分布式数据存储
确保所构建的数据处理管道具有高质量并可审计
开发相关工具以优化数据的提取、分析及可视化效率
评估数据工程领域的新技术，并开发原型，以持续改善工作
与框架和其他团队合作，确保系统运行符合设计预期
?
工作要求
全日制硕士以上学历，计算机相关专业，CET6
具备大数据相关技术例如Spark, Kafka,Flink, Hadoop, HBase, Hive等的丰富经验
具备五年以上Java、Scala、Python相关工作经验，MySQL， Redshift等SQL相关经验
具备三年以上可扩展实时ETL开发经验
熟悉Azure/AWS/GCP相关工具与知识
良好的书面/口头沟通技巧
具备机器学习算法方面工作经验者优先"
"职位描述：
        
        职位描述：
工作职责：?
1.参与公司数据仓库架构设计与研发，建设的公共数据平台和服务系统，实现高质量数据的互通与共享；
?2.?参与公司数据产品与应用的数据研发，发觉数据商业价值；?
3.?结合实际业务问题，运用数据挖掘、机器学习领域的前沿技术，给出解决方案。?

职位要求：?
1.?精通?Linux/Unix?平台上的?C/C++/Java/Python?编程，对数据结构和算法有较为深刻的理解；?
2.?有大型在线应用系统的开发经验，熟悉?Web?开发相关技术；?
3.?熟悉分布式计算相关技术，有大数据处理经验；?
4.?具备优秀的逻辑思维能力，对解决挑战性问题充满热情，善于解决问题和分析问题，具有良好的沟通能力和团队合作精神。?
有下列经验之一者优先：?
-有海量数据的处理经验，熟练使用?Hadoop、Hive、Spark?等分布式计算工具；?
-有机器学习?/数据挖掘理论和技术基础；?
-有高性能、高并发、高可用性、高扩展性系统架构设计经验。"
"职位描述：
        
        1、电商事业部BI大数据（ETL,SQL）开发
2、电商事业部优惠卡系统开发
3、电商平台后台开发框架和组件开发
4、电商平台数据模型规划设计
5、参与模块概要、详细设计文档的编写
6、良好的代码编写习惯，对自己代码进行复查，并进行简单的测试,及时消除代码中的缺陷
7、深入理解业务需求，提供具体问题的解决方案及相关模块的开发和改进，保证系统性能和稳定性。

岗位要求：
1.?计算机相关专业本科或以上学历，5年以上Java开发经验，2年以上架构经验，至少主导过一个中大型项目的开发上线完整流程；
2.?扎实的编程基础，对于Java基础技术体系（包括JVM、类装载机制、多线程并发、IO、网络）有一定的掌握和应用经验；
3.?熟悉Spring?Cloud、Spring?Boot、Spring?MVC、MyBatis等开源框架和其理念，熟悉常见的一些设计模式；
4.?熟悉Linux下的常用命令，熟悉Mysql，有良好的数据库表设计能力；
5.?熟悉掌握Web相关技术（Http/Https/HTML/CSS/Javascript等);
6.?具有比较强的问题分析和处理能力，有比较优秀的动手能力，热衷技术，精益求精;
7.?熟悉DRDS、Redis、MQ、MongoDb等高性能并发中间件者优先；
8.?具备良好的表达和沟通能力、具备团队合作精神，学习能力较强，有一定的抗压能力，有责任心和独立分析能力。"
"职位描述：
        
        岗位职责：
1、熟悉MySQL/MongoDB/Redis/HDFS等常用数据库，掌握SQL开发技术；
2、熟悉Hadoop/HBase/Hive/MapReduce/Spark等相关技术，并有实际的开发经验；
3、熟悉java和shell，可以熟练的使用linux系统，了解Linux群集技术者优先；
4、掌握MapReduce处理问题思想，熟悉分布式计算模型或有高效索引技术经验者优先。

任职要求：
1、本科及以上学历，计算机算法分析、数据挖掘、机器学习、大数据分析等专业；
2、对数据挖掘、智能推荐、机器学习、领域语言或自然语言分析在互联网行业的应用有深入了解，熟悉相关领域当前热点和前沿技术，对BI有完整的、系统的认识；熟练掌握JAVA编程语言；
3、有相关数据分析和数据挖掘相关学术研究或工作经验优先。"
"职位描述：
        
        岗位职责：
1.主要负责数据的ETL，包括数据的加工和分析处理
2.负责建筑工程数据的挖掘、清洗、分析、统计工作；
3.有一定的数据仓库搭建工作经验为佳；

岗位要求：
1.有大数据的相关研发经验，java，python均可
2.有一定的数据仓库或者数据中心的工作经验，对于数据管控和数据治理有一定的理解；
3.精通关系型与非关系型数据库理论、数据仓库架构及原理、数据仓库实施方法论；
4.学习能力强，工作态度端正"
"职位描述：
        
        1、 拥有2年以上政务行业经验，有带领团队实施政务大数据项目经验优先。2、 精通大数据查询优化，熟悉条有SQL执行效率。3、 具备政务行业大数据领域业务知识，对行业大数据应用场景具有较为深入的理解。4. ? ?3年以上工作经验。"
"职位描述：
        
        1、 计算机相关专业，大专科以上学历，2年以上可视化报表开发经验或大数据开发经验
2、 熟练国内通用报表中的任何一种，TABLEAU,REPORT,润乾报表或永宏报表3、 熟悉ETL工具KETTLE,有过相关配置经验4、 熟悉SHELL,有相关配置调度的经验5、 熟悉MYSQL或oracle等关系型数据库，具有良好的SQL编程习惯，能写出高效的SQL语句6、 了解JAVA LINUX,有开发经验尤佳7、 具有良好的学习能力，沟通能力，团队协作能力，责任心及分析解决问题的能力，一定的文档编写能力"
"职位描述：
        
        岗位职责：?
1、负责基于Hadoop、Spark平台的海量数据处理、数据计算、数据开发。?
2、负责高并发、高可用性、高可扩展性的线上数据系统开发。?
3、负责数据挖掘应用服务开发和数据挖掘算法包研究和应用。?
4、负责数据产品和数据项目的相关开发支持。
5、负责垂直领域的数据探索，价值数据提取。?
任职要求：?
1、计算机及相关专业本科及以上学历；?
2、精通python或java开发技术，熟练掌握多进程/多线程开发；?
3、熟练掌握Hadoop、Spark等大数据开发技术，进行过大数据项目实践；?
4、有机器学习、数据挖掘、推荐系统经验者优先；?
5、具有分布式计算/搜索引擎/广告引擎等后台开发经验者优先；?
6、有/ElasticSearch/hadoop/Spark/storm/kafka/scribe等开源框架经验者优先；?
7、对技术有激情、有追求；富于技术创新精神，勇于解决技术难题"
"职位描述：
        
        岗位职责：?
1、负责数据仓库的架构设计, 开发和实施；
2、负责数据ETL流程的建设，优化以及解决ETL相关技术问题；
3、负责机器学习流水线的架构设计, 开发和实施；
4、负责数据任务调度系统、数据监控系统的设计，开发和实施；
5、负责数据schema管理系统的设计，开发和实施。

任职要求：
1、本科及以上学历，计算机相关专业;两年以上互联网行业大数据相关工作经验；
2、了解并行和分布式计算的基本原理；熟练掌握Hadoop,hdfs, hive, Spark,Storm,flink，cassandra, hbase、ElasticSearch等常用的大数据系统或式计算框架；熟悉MySQL, postgres, MongoDB等数据库；
3、具备优秀的数据敏感性；
4、优秀的分析问题和解决问题的能力，勇于解决难题；强烈的上进心和求知欲，较强的沟通表达能力与协作推进能力；?
5、热爱互联网，对互联网产品和技术有浓厚的兴趣，热衷于追求技术极致与创新；
6、有开源社区贡献经验的开发者优先考虑。"
"职位描述：
        
        岗位职责
1、负责各种网络资源数据的采集、清洗、整合和大数据的分布式存储；
2、负责大数据类产品的系统分析与架构设计，配合产品经理完成产品的快速研发与交付；
3、负责大数据平台各组件的性能优化工作和部分设计、开发文档的编写工作；
4、负责大数据项目的开发、维护等工作；
?
任职要求
1、理解系统的业务需求，主导重大项目的架构设计和核心模块设计；
2、负责大数据相关数据架构规划、数据建模、数据库设计以及大数据产品研发工作，并为应用开发团队提供技术支持、模型分析；
3、熟悉Hadoop、Spark、Storm、ElasticSearch、Neo4J、Kafka等框架组件，深刻理解分布式数据处理技术原理；
4、熟练掌握Java、Python、Scala、C等语言中的一种；
5、将优先考虑：
（1）至少熟悉HadoopMR、Sparkstreaming、Storm等大数据计算框架中的一种；
（2）有常用网络协议的开发经验；
（3）有数据挖掘相关应用或研究背景；
（4）有微服务架构或开发经验；"
"职位描述：
        
        工作职责：
?
1. 负责数据接入、数据清洗工作；
2. 负责数据仓库ETL实现和优化工作；
3. 参与数据报表开发；
4. 参与海量数据实时处理和分析，实时服务系统设计与开发。
?


任职资格：
?
1. 互联网技术达人，对技术改变世界、用技术解决问题抱有极大热情，对大数据、AI的应用有深入了解；
2. 熟悉主流的大数据产品和数据分析技术并具有相关项目经验；
3. 具有扎实的数据挖掘和机器学习基础；
4. 熟练掌握 Unix/Linux、熟练掌握SQL查询及优化，熟练掌握Java语言；
5. 对商业和业务逻辑敏感，有互联网相关行业背景，有网站用户行为研究经验优先；
6. 熟悉 Hadoop、Hive、Presto、MapReduce等大数据技术、熟悉storm、kafka、spark streaming等流式计算技术优先
7. 具有良好的系统分析、架构设计能力，有独立设计分布式数据开发框架经验优先
8. 超级学习者，知名院校本科及以上学历，技术等相关专业。"
"职位描述：
        
        工作职责：
1、负责大数据产品研发团队产品管理研发项目管理协调，协同业务团队、产品、研发团队推进研发进度
2、全面负责产品研发流程管理
3、跟进、监控产品研发团队整体对内对外项目进度、质量
4、保障业务前端的研发需求，且对平台长期建设有规划和推动力
工作要求：
1、本科以上学历，5年及以上IT/互联网行业工作经验，有大数据AI类行业经验优先
2、对产品研发流程和项目管理有实操经验
3、思维逻辑清晰，强自我驱动力和执行力
4、具备良好的团队协作能力，对外沟通能力强，工作积极主动"
"职位描述：
        
        工作职责：
1、参与公司大数据平台建设；
2、设计数据接入的处理流程，以便从不同的数据源获取数据，并开发相关程序及服务；
3、响应业务对数据的临时分析需求。
任职资格：
1、3年ETL相关工作经验，技能突出者可酌情调整；
2、有良好的业务理解能力，坚信数据驱动业务的价值；
3、从事数据仓库领域至少2年以上，熟悉数据仓库模型设计与ETL开发方法，具备海量数据加工处理相关经验；
4、熟练掌握SQL，理解Hive/MySQL原理和调优方法；
5、熟悉Hadoop、Hive、Spark、Storm等技术体系者优先；
6、有互联网产品用户行为研究/日志采集/大数据处理/数据可视化经验优先。"
"职位描述：
        
        岗位职责：
1、 负责大数据平台的数据开发工作，能够配合数据分析师在机器学习方面提供支撑；
2、 负责数据仓库的数据治理能力平台的设计和开发；
3、 跟踪新技术发展，能够引入合适的技术为业务提供服务；
?
任职要求：
1、 计算机相关专业，本科及以上学历；
2、 至少具备3年以上大数据开发相关工作经历，以及数据仓库建设经验；
3、 熟悉大数据平台生态组件，有TB级及以上大规模数据处理经验；
4、 有优秀的 Java/Scala 编码能力，熟悉Hadoop和 Spark 开发，精通SQL；
5、 学习能力强，思路清晰，理解力强，自我驱动力强；
6、 需要具备良好的团队合作精神，良好的沟通能力；
?
加分项：
1、 有Hadoop、Spark、Hive、HBase深入源代码分析经验；
具备机器学习、数据挖掘算法相关经验;"
"职位描述：
        
        岗位职责:

1、负责大规模海量数据实时计算平台的OLAP平台设计和开发； 2、完善与整个OLAP生态多个产品的兼容性和集成；3、负责BI项目的实时数据平台的需求分析、设计和开发工作。 
任职资格:

1、有1年以上OLAP平台设计和开发经验、了解和熟悉hadoop生态圈技术；2、熟悉分布式系统，有良好的 Java/Scala 编码基础； 3、对SparkSQL/Impala/Presto/Drill，Druid/Kylin/Elastic search等有使用经验和源码研究；4、学习能力强、思路清晰、理解力强，自我驱动力强； 5、有敬业精神和高度的责任感，有良好的沟通交流能力，有较强的团队合作精神。"
"职位描述：
        
        工作职责
1、游戏运营相关数据设计与开发；?
2、数据仓库ETL程序设计与开发；?
3、数据仓库模型设计与开发；?
4、游戏业务基础/生态指标设计与开发；?
5、游戏业务数据的分析。
任职资格
1、研究生学历且有2年工作经验，或本科5年以上数据处理、分析相关工作经验；?
2、参与过数据仓库模型相关工作；?
3、熟练使用SQL、Hive、Presto等技术，了解Hadoop、MySQL工作原理；?
4、熟练使用Excel、Python、Tableau等数据处理与数据分析工具；?
5、具有海量数据处理经验或有游戏行业数据开发经历优先；
6、较强的沟通能力和团队合作精神，承担一定的工作压力。"
"职位描述：
        
        岗位职责：
1) 负责现有项目的部署、维护、升级工作；
2) 游戏基础运营数据、游戏活动数据、游戏生态数据的开发、分析以及挖掘；
3) 参与项目技术方案的制定工作；
4) 按时完成团队规定完成的工作；
岗位要求：
1) 研究生，5年以上java、数据处理、分析相关工作经验；
2) 熟悉数据仓库及数据集市设计，具有模型设计理论和实践经验。
3) 熟悉常用的数据挖掘模型，具有一定的机器学习理论和实践经验；
4) 熟练使用spring，mybatis，redis，mq，并了解其原理实现；
5) 熟练使用Python、R等机器学习工具；
6) 较强的沟通能力和团队合作精神，承担一定的工作压力。"
"职位描述：
        
        岗位职责:1)?参与公司大数据平台建设2)?设计数据接入的处理流程，以便从不同的数据源获取数据，并开发相关程序及服务。3)?响应业务对数据的临时分析需求
任职资格:1)?3年ETL相关工作经验，技能突出者可酌情调整2)?有良好的业务理解能力，坚信数据驱动业务的价值 3)?从事数据仓库领域至少2年以上，熟悉数据仓库模型设计与ETL开发方法，具备海量数据加工处理相关经验4)?熟练掌握SQL，理解Hive/MySQL原理和调优方法5)?熟悉Hadoop、Hive、Spark、Storm等技术体系者优先 6)?有互联网产品用户行为研究/日志采集/大数据处理/数据可视化经验优先
工作地址"
"职位描述：
        
        岗位职责：
1、参与数据底层的工具、平台等技术体系的建设与研发；
2、基于PB级别数据仓库的数据和表的标签画像业务建设及优化；
3、配合分析师进行日常数据提取和数据处理工作。
任职要求：
1、 计算机相关专业本科及以上的应届毕业生；
2、 具备较好的Java编程基础，熟练掌握SQL和Shell的使用，了解大数据生态；
3、 具备机器学习相关知识，可以在数据分析师的指导下进行开发工作；
4、 学习能力强，思路清晰，理解力强，自我驱动力强；
5、 需要具备良好的团队合作精神，良好的沟通能力；
6、 有Hadoop生态的相关培训经验、实习经验、源码阅读经验优先考虑。"
"职位描述：
        
        岗位职责：
1、负责数仓现有项目的维护、升级工作；
2、游戏基础运营数据、游戏活动数据、游戏生态数据、标签数据等的开发、分析；
3、按时完成团队规定完成的工作。
任职资格：
1、计算机、数学等相关专业本科及以上学历；
2、熟悉数据仓库及数据集市设计，具有模型设计理论和实践经验；
3、熟练使用hive, spark, mysql, sqoop等工具，并了解其原理实现；
4、良好的编程开发能力，熟悉Python、Shell、Java、Scala等语言至少一种开发；
5、较强的沟通能力和团队合作精神，能承担一定的工作压力。"
"职位描述：
        
        一、岗位职责1.基于大数据平台的应用系统设计、开发、维护。2.根据业务和产品情况对数据模型和逻辑进行规划、设计和实现，并参与数据模型优化。3.负责业务需求的需求理解、数据开发、提供面向业务的数据服务；4.参与相关数据分析、评估监控的工具平台的研发，负责数据模型设计、ETI开发等工作
二、技能要求:??????? 1）计算机、电子信息工程等相关专业背景，本科及以上学历; 2）熟悉Hadoop、Hbase、Spark、Kafka等大数据相关技术，并至少具备2年以上大数据应用开发经验；3）有扎实的Java基础, 熟练掌握jvm机制、多线程、常用容器、反射等基础知识；4）掌握Spring、Ibatis、SpringBoot、SpringCloud、缓存、消息等主流Java框架及原理最佳；5）熟练使用scala语言对数据进行分析和处理,有良好的面向对象思想；6）具有良好的学习能力、沟通技能和团队合作能力，热爱技术，有责任心"
"职位描述：
        
        JAVA数据开发工程师
?
北京清智物联科技有限公司依托清华大学科研平台，致力于打造行业顶尖的能源数字孪生平台。目前正在筹建武汉研发中心，急需JAVA开发人才。
?
【岗位职责】
1.??? 参与国家电网一体化监测平台底层数据平台研发。
2.??? 设计底层数据平台构架，参与开发并实现。
3.??? 同业务系统进行对接，提供相关查询API接口。
?
【任职条件】
1.??? 有三年及以上工作经验。
2.??? 熟悉JAVA语言和Linux操作系统。
3.??? 有SpringBoot、MyBatis开发经验，熟悉主流Java开发框架。
4.??? 有Python开发经验，了解Hadoop及相关的大数据平台。
5.??? 有Mysql、Redis、MongoDB、MQ使用经验。
6.??? 沟通和学习能力强，具有良好的团队合作精神，工作积极主动。
?
【工作地点】
武汉光谷广场"
"职位描述：
        
        职位描述
* 负责健康医疗、社会科学等大数据平台Web产品的功能及性能测试工作* 熟悉开发和测试脚本语言，如Python、Java等* 与产品设计师、前端工程师一起探讨、设计、反馈Web产品的功能及改进方案* 与基础架构工程师、运维工程师一起实现和调优稳定、可扩展、维护性高的部署服务* 负责数据平台相关开发、测试、使用等文档整理和撰写* 参与项目进度管理、日常产品研讨和产品相关会议工作

任职资格
* 对计算机相关基础知识有较好理解，熟练掌握计算机使用* 掌握至少一门编程语言，如 Python、Ruby、Java、PHP 等* 熟悉常用 Web 开发及测试相关技术* 掌握关系数据库及大数据技术者优先考虑* 具有大数据思维，有志于大数据与行业交叉融合发展者优先考虑* 良好的编码风格及测试习惯* 良好的沟通能力，有团队合作精神和责任感* 有很强的学习能力，有主动性和上进心，能承担压力
清数D-Lab是一个大数据及人工智能的创新基地。其中，健康医疗大数据是基地的一个重要发展版块，设立独立的实体运营即“清医智慧”，以“医工融合创新平台”以“医工结合”为理念，让临床医学与信息科学对接，成为推进医疗健康发展产业的新思路。联合清华大学、北京大学等高校利用自身特有的工科优势，结合临床医学研究机构，把医学专家积累的宝贵经验，转化成标准化的知识基础，做到数据驱动医疗服务，因此大大提高供给端的服务能力和效率，解决中国医疗领域存在的诸多需求。清医智慧作为临床科研大数据平台的推动者，发展20个以上多中心科研合作，推动多学科、多病种临床科研发展，以最前沿的大数据、人工智能、区块链技术推动真实世界临床研究，整合海量多中心医疗健康大数据，进行智能处理、信息挖掘、机器学习，为公众健康、临床决策、精准医疗、精益管理、政府决策提供有力支持。清医智慧的“医工融合创新平台”依托清华大学和重点医疗机构的合作和研发，立足健康医疗数据全生命周期产品线发展，荣获2019年中国科技产业促进会的科学技术二等奖。"
"职位描述：
        
        工作内容：参与领域行业大数据分析项目，包括金融、农业、医疗和工业大数据平台、项目和产品的研发和实施。职位描述: 负责数据分析平台前端开发、优化及维护，主要开发语言为JavaScript、HTML5配合运营同事，提供技术和数据支持，通过前端开发实现支持大数据计算平台、数据建模、分析挖掘、机器学习、CRM、BI等的功能 与基础架构工程师、运维工程师一起实现稳定、可扩展的平台服务 数据驱动，不断通过产品和技术数据进行改进，并完成快速迭代 职位要求: 1、熟练掌握HTML、CSS3、ES6、webpack等规范和技术，熟悉常见跨域、跨浏览器问题，了解必要的计算机网络协议； 2、熟练掌握VueJS及相关框架和技术，理解框架设计原理，有良好的WEB前端优化经验； 3、熟悉Canvas、SVG、D3.js、Charts、HightCharts、GoJS等可视化技术，喜欢专研可视化交互技术者优先； 4、有HTML5大屏展示、矢量图、地图、脑图等最新前端展示效果开源库使用和开发经验者优先；5、学习能力强，有较强的问题分析和处理能力，具有团队合作精神；6、有扎实的编程功底，熟悉一门后端语言者优先，如 Python、NodeJS（JavaScript）、Java、PHP、Golang等7、优先考虑熟悉Web开发框架、协议、安全等，熟悉Flask、Tornado、Django者优先考虑8、有很强的学习能力，有主动性和上进心，不拘泥于框架，追求最佳实践

薪酬以能力和潜力而定，欢迎各位有志在大数据与AI领域发展的童鞋们，若是实习需要至少半年以上"
"职位描述：
        
        工作内容：参与领域行业大数据分析项目，包括金融、农业、医疗和工业大数据平台、项目和产品的研发和实施。职位描述: 负责数据分析平台后端开发、优化及维护，主要开发语言为Python配合运营同事，提供技术和数据支持，完成大数据计算平台、数据建模、分析挖掘、机器学习、CRM、BI等的开发及维护 与基础架构工程师、运维工程师一起实现稳定、可扩展的平台服务 数据驱动，不断通过产品和技术数据进行改进，并完成快速迭代 职位要求: 对计算机相关基础知识有较好理解，了解常用数据结构和算法 有扎实的编程功底，熟练掌握至少一门编程语言，如 Python、NodeJS（JavaScript）、Java、PHP、Golang等 掌握关系数据库及 SQL 相关知识，了解基本的设计和优化原则，熟悉MySQL、PostgreSQL、Oracle等优先考虑熟悉一种 NoSQL 数据库，熟悉Redis, MongoDB等优先考虑熟悉常用Web开发相关技术，包括Web框架、协议、安全等，熟悉Flask、Tornado、Django者优先考虑熟悉前端HTML5、JavaScript、CSS技术，熟悉jQuery、Bootstrap、AngularJS、ReactJS等优先考虑有很强的学习能力，有主动性和上进心，不拘泥于框架，追求最佳实践 薪酬以能力和潜力而定，欢迎各位有志在大数据与AI领域发展的童鞋们，若是实习需要至少半年以上。"
"职位描述：
        
        工作职责:
1、负责离线/实时大数据存储/计算平台的设计开发和维护工作；
2、负责设计基于大数据的各种计算，etl流程设计和开发；
3、通过设计运用合适的技术方案来支撑各种业务场景：推荐，转化，增长，商业化等；
4、负责新技术的研究和搭建.
任职资格:
1、三年以上相关工作经验；
2、熟练掌握Linux操作系统，精通Python/Scala/C++/Java语言的一种或多种；
3、熟悉主流大数据工具Hadoop、spark、Storm、ELK中两个及以上,并熟悉所使用工具的技术原理、主要特点；
4、熟练使用flume、Kafka、hbase、redis、mysql等常用工具；
5、有SparkStreaming的实时统计或实时推荐整体架构开发经验优先、有sparkML开发经验优先；
6、有OLAP大数据平台开发经验者优先。"
"职位描述：
        
        经验要求：
1、 熟悉C, C++,Python，Java其中一种语言。
2、 熟悉关系型数据库，例如MySQL。熟悉HIVE，了解Hadoop生态优先。
3、 优秀的学习、分析和解决问题能力，责任心强，具备良好的沟通能力和团队合作精神。
4、 协助开发工程师完成数据开发，编写部分文档。
任职要求：
1、 985/211院校或一本院校的本科/研究生在读，计算机相关专业。
2、 熟悉Java，C++, Python其中一种语言。
3、 熟悉SQL语句，熟悉HIVE者优先。
4、 自我学习、驱动能力强，能够编写开发文档。"
"职位描述：
        
        职责描述：
1、负责大数据应用项目的研发。
2、参与项目的需求分析、系统设计和文档编写。
3、根据需求和设计进行软件开发。

任职要求：
1、本科及以上学历，5年以上大型复杂Java项目或产品经验。
2、具有扎实的Java基础，深入理解Java应用框架和工具链、精通设计模式，熟悉常用软件架构思想。
3、对数据库的基本理论和内部实现机制有深刻的理解，熟练使用MySQL、Oracle等主流数据库。
4、熟练使用JS、JQuery，有RequireJS、AngularJS、ExtJS、NodeJS开发经验者优先。
5、熟悉HTML5、CSS3、Bootstrap，能独立编写前端页面及样式，并兼容主流浏览器。
6、技术视野开阔，学习和抗压能力好，有很强的分析和解决复杂问题的能力，具有良好的沟通和组织协调能力。
7、有大数据开发经验者优先。"
"职位描述：
        
        职责描述：
1、 负责公司大数据产品的设计及相关模块开发。
2、 对公司大数据产品进行优化。
3、 参与大数据应用项目的核心部分的设计和开发。

任职要求：
1、 计算机或相关专业本科及以上学历，5年以上大数据项目或产品研发经验。
2、 精通Java语言，掌握常用设计模式和开发框架，熟悉并发、分布式编程。?
3、 熟悉linux操作系统、算法、数据库原理和并行处理技术，对大数据处理技术有深入的了解。
4、 精通大数据相关技术，具备Hadoop、HBase、Hive、Spark、Storm、Kafka、ES等主流组件开发经验。
5、 具有良好的需求分析、软件设计能力，良好的系统架构设计和分析能力。
6、 有数据交换共享平台、数据治理平台、数据服务总线开发经验者优先。
7、 有深入研究大数据框架的运行机制、实现原理、源码经验。"
"职位描述：
        
        岗位职责：
1、负责大规模分布式图数据引擎的架构、开发和优化。
2、负责大规模知识图谱构建，负责知识挖掘、知识推理和知识融合等算法。
3、负责知识图谱底层引擎的架构设计以及实现。
4、负责知识图谱应用实施，探索公安领域的智能应用。

任职资格：
1、计算机相关专业本科及以上学历，3年以上工作经验。
2、熟悉NLP、信息抽取、知识管理、知识本体等相关系统和算法。
3、熟悉至少一种图数据库（Neo4j, Titan, OrientDB,Janusgraph、DGraph），熟悉图查询语言Cypher或Gremlin。
4、熟练掌握Java/Python语言。
5、参与或主导过大型知识图谱项目，有海量数据挖掘、知识图谱相关系统研发经验加分。
6、良好的抗压能力和团队协作。"
"职位描述：
        
        职责描述：
1、负责大数据应用项目的研发。
2、参与项目的需求分析、系统设计和文档编写。
3、根据需求和设计进行软件开发。

任职要求：
1、本科及以上学历，3年以上大型复杂Java项目或产品经验。
2、具有扎实的Java基础，深入理解Java应用框架和工具链、精通设计模式，熟悉常用软件架构思想。
3、对数据库的基本理论和内部实现机制有深刻的理解，熟练使用MySQL、Oracle等主流数据库。
4、熟练使用JS、JQuery，有RequireJS、AngularJS、ExtJS、NodeJS开发经验者优先。
5、熟悉HTML5、CSS3、Bootstrap，能独立编写前端页面及样式，并兼容主流浏览器。
6、技术视野开阔，学习和抗压能力好，有很强的分析和解决复杂问题的能力，具有良好的沟通和组织协调能力。
7、有大数据开发经验者优先。"
"职位描述：
        
        职责描述：
1、 负责公司大数据产品的设计及相关模块开发。
2、 对公司大数据产品进行优化。
3、 参与大数据应用项目的核心部分的设计和开发。

任职要求：
1、 计算机或相关专业本科及以上学历，3年以上大数据项目或产品研发经验。
2、 精通Java语言，掌握常用设计模式和开发框架，熟悉并发、分布式编程。?
3、 熟悉linux操作系统、算法、数据库原理和并行处理技术，对大数据处理技术有深入的了解。
4、 掌握大数据相关技术，具备Hadoop、HBase、Hive、Spark、Storm、Kafka、ES等主流组件开发经验。
5、 具有良好的需求分析、软件设计能力，良好的系统架构设计和分析能力。
6、 有数据交换共享平台、数据治理平台、数据服务总线开发经验者优先。
7、 深入研究过大数据框架的运行机制、实现原理、源码者优先。"
"职位描述：
        
        
岗位职责：?1. 负责大数据平台的架构规划与开发，解决海量数据面临的挑战；?2. 管理、优化并维护Hadoop、Spark等集群，保证集群规模持续、稳定；?3. 负责HDFS/HBase的功能、性能和扩展，解决并实现业务需求；?4. 协助建立数据模型，对数据进行挖掘、优化及统计。?任职要求：?1. 统招本科及以上学历，计算机、软件、电子信息等相关专业，2年及以上相关工作经验；?2. 熟悉Hadoop/HBase/Spark，熟悉数据统计与挖掘；?3. 具备Java、Scala、python等开发经验；?4. 善于发现问题、解决问题；?

【工作时间】
9：00---18：00 ?午休时间：12：00--13：30?
周六日双休、国家法定节假日休息

福利待遇：五险一金、午餐补助、通讯补助、节假日福利、旅游拓展、部门不定期聚餐、团建、结婚礼金、年终奖金、年度体检、茶话会、健身卡

招聘流程：投递简历→简历筛选→专业面试→综合面试→发放录取通知书→入职
?

工作地址： 武汉东湖高新区武大科技园航域二区B3栋1488及7028
乘车路线： 1、地铁2号线光谷广场站下倒公交789，405
? ? ? ? ? ?2、坐公交405,751,789,785，909，922于武大园路武大园二路下"
"职位描述：
        
        岗位职责：
1. 独立分析、评估并解决问题，具备独立承担工作的能力。
2. 参与公司产品核心模块的设计开发，负责底层服务、组件的维护优化。
3. 参与后端架构设计和产品研发，开发高性能、高可靠性的服务。

任职要求：
1. 精通Java，熟练使用python/go/php等至少一种脚本语言，有良好的代码能力。
2. 掌握linux下进程间通信、内存管理机制等。具备linux下开发、调优能力。
3. 熟悉Socket，Netty，文件io，多线程等编程。
4. 熟悉Webservice、restful、HTTP等Web开发，了解TCP/IP，HTTP工作原理。熟悉Nginx/Tomcat等至少一种web容器。
5. 熟悉分布式计算、存储相关技术，包括不限于Hadoop、Hbase、Spark、Storm、Kafka、ES等开源组件。
6. 有大规模高并发应用的设计和开发经验，熟悉常规的分布式架构，有海量数据分析处理经验者优先。"
"职位描述：
        
        岗位职责1. 熟悉公司业务流程，对接业务人员和客户整理核对数据，对数据的准确性和有效性负责；2. 整理数据，为数据整理清洗提供支持；3. 负责与各部门、客户等保持良好的沟通，了解数据收集及分析要求；岗位要求：1. 本科以上学历;2. 良好的代码习惯；2. 对数据敏感，具备一定的数据判断和问题解决能力；4. 工作严谨细致，有责任心；"
"职位描述：
        
        职责：1.负责分布式网络爬虫系统的架构设计与开发；2.负责海量数据的爬取、清洗、解析、入库；3.负责破解各类反爬机制；4.不断提升数据抓取系统的自动化水平。
要求1.计算机等相关专业本科及以上学位；1年以上开发经验；2.熟练使用Python或Java；3.具有爬虫、信息抽取、文本分类、大数据处理相关实战开发经验者优先 ；4.熟悉数据库（MysqlOracleSqlServer任意一个或多个），具有优秀的SQL编写及调优能力，熟悉常见NoSQL存储(RedisMongoDB) 5.良好的编码习惯，较强的沟通、需求理解能力和良好的责任心、团队合作能力"
"职位描述：
        
        岗位职责：1、负责信息安全团队大数据平台建设 2、参与数据的整个ETL流程 3、参与AI数据挖掘和建模的解决方案设计 4、参与建立信息安全团队的数据仓库。
任职资格：1、国内外高校计算机、数学类相关专业，本科以上学历 2、3年以上大规模数据研发、挖掘、分析相关工作经验 3、熟悉MySQL、Oracle、SQL Server或至少其中一种，熟悉SQL语言 4、熟悉Hadoop、Hive、HBase、Spark、Storm等开源工具 5、具有Python、Shell开发经验 6、熟悉数理统计、数据分析与挖掘，熟悉常用机器学习算法，有运用机器学习算法建模的理论或实际经验者优先 7、有风控建模相关工作者优先。"
"职位描述：
        
        懂HIVE，基础数据库oracle
懂oracle开发，PL/SQL
做过hive2年，Hadoop2年，
数据熟悉Python语言"
"职位描述：
        
        １．精通ｈｄｆｓ、ｈｉｖｅ、以及ｓｑｌ性能调优；
２．有较强的编程能力，熟悉掌握ｓｈｅｌｌ，Ｊａｖａ，或Ｐｙｔｈｏｎ开发；
３．负责数据集市设计，开展长期数据治理工作，数据标签开发
４．学历统招本科，学信网可查"
"职位描述：
        
        平安系 招商金科等金融it行业 外包岗
1.熟悉数据建模与开发。
2.熟悉数据仓库系统，数据集市的应用架构，设计模式；
3.熟悉分布式存储和NoSQL数据库技术(如MonogoDB/Redis等)；
4.熟悉Java开发，熟悉Oracle数据库；
5.全日制大专及以上学历，2年以上工作经验"
"职位描述：
        
        工作职责

""1.?基于大数据平台结合保险领域，负责BI、画像、数据仓库的开发和应用；2.?基于海量用户行为数据，建立、评估、持续优化数据模型，包括但不限于：用户价值评分、用户风险评分、用户偏好预测?、用户画像构建等等，产出用户标签；3.?结合公司的业务场景，进行数据产品设计，解决业务痛点，提升用户体验，探索新的商业模式；""

任职资格

""1.?本科及以上学历，计算机或数学相关专业，工作3-6年及以上；2.?思维清晰敏捷，逻辑分析能力强，具有良好的语言和书面表达能力；3.?精通hive?sql，有海量数据处理的调优经验；4.?熟悉spark优先；5.?用户画像构建和应用实战经验的优先；6.?有数据挖掘实践经验，擅长从海量数据中发现有价值的规律的优先；7.?有大型互联网公司或保险行业背景优先，有带领团队，具有管理经验的优先；"
"职位描述：
        
        1、公司产品和项目的功能设计、开发和实现；
2、参与需求分析，承担业务模块的代码开发；
3、维护和升级现有软件产品和系统，快速定位并修复现有软件缺陷
任职要求：
a)?计算机相关专业本科以上学历，1年以上相关工作经验；
b)?精通Hadoop体系结构、对Hadoop生态圈有较全面了解；
c)?熟悉大数据开发框架，精通CDH相关工具，包括HDFS/HBase/Hive/Spark/Kafka/Sqoop/Solr及Elasticsearch等；有大数据项目的实施经验；
d)?能够使用Java、Scala中至少一门语言进行数据处理；
e)?熟悉Linux系统以及Shell脚本语言；
f)?具有一定的数据库架构设计能力，能够撰写规范的技术文档；
g)?掌握常用的设计模式和架构模式，能够熟练使用建模工具进行系y设计；
h)?具备良好的自学能力、沟通能力、独立解决问题的能力，有责任心及团队合作精神
i)?数据挖掘经验者优先，能适应出差"
"职位描述：
        
        岗位职责：
1. 参与设计数据中心大数据应用的算法设计与研发。包含但不限于推荐系统，用户画像，营销推送等；
2. 负责数据分析、加工、清理、处理程序的开发;
3. 负责数据相关平台的搭建、维护和优化。
4. 负责基于Hadoop/Spark/Hive/kafka等分布式计算平台实现离线分析、实时分析的计算框架的开发；

任职要求：
1. 扎实的数据结构及算法基础, 良好的英文文档阅读能力，熟悉数据仓库模型设计与 ETL 开发；
2. 熟悉Java和Scala语言、熟悉常用设计模式、具有代码重构意识；
3. 熟练使用hadoop、hbase、Kafka、hive、spark、熟悉底层框架和实现原理；
4. 使用Spark Streaming和Spark SQL进行数据处理, 并具有SPARK SQL优化经验；
5. 熟悉Linux/Unix操作系统, 了解常见NO-SQL数据库；
6. 有大规模hbase集群运维经验或对hbase存储原理熟悉者优先；
7. 有数据挖掘、数据分析、机器学习研发实践经验者优先"
"职位描述：
        
        工作职责：（主ETL方面工作）
1、主导数据库设计搭建，数据库应用性能系统性优化、备份恢复、高可用架构设计；
2、负责数据库生产运维重大问题跟进、对外应用服务、部门内部项目、重要任务及重大变更的实施（升级、迁移、合并、转型等）；
3、数据库新技术、新产品、新架构引入及推广，数据库规范制定等；
4、重大变更技术方案的制定及跟进，自动化运维工具开发；
5、保障数据库稳定运营，提升数据库运算效率，能够根据业务需求有针对性的对数据库运算效率进行优化；
6、 负责数据仓库项目ETL详细设计、开发、部署、维护工作
7、知识产权数据清洗、建库导入
8、 知识产权数据分析与深加工
9、机器学习算法应用
10、协助上级完成外部数据收集工作

任职资格：
1、全日制本科及以上学历，计算机相关专业毕业，毕业后2年以上工作经验；
2、掌握数据仓库基础理论知识和ETL设计技术,有实施经验；
3、精通ORCALE数据库，了解数据库的各类优化，具有良好的SQL语言开发技能，掌握存储过程、函数等开发技术,熟悉一种NOSQL数据库；
4、熟悉linux/unix环境开发经验，掌握shell，熟悉python；
5、对数据敏感，具备良好的逻辑分析能力，熟悉数据可视化的基本方法；
6、对Hadoop、HIVE、HBASE、Spark、Storm等大数据存储与运算平台有着浓厚兴趣。

福利待遇：
1.与能力相匹配的薪资。
2.有五险一金，入职签订劳动合同，白纸黑字，童叟无欺。
3.公司结构扁平，氛围轻松，同事领导nice，给予你足够大的空间与支持实现你自己的梦想。
4.工作时间周一至周五，双休，早上9:30-下午18:00 ；节假日按国家规定放，以后别问什么时候放假啦，自己打开手机日历app看一看就知道啦。
5.享有带薪年假，满足你说走就走的愿望，当然婚假、产假、病假等等也是一应俱全。
6.一个和谐有爱的团队。在这里没有森严的阶级观念，也没有不务正业游手好闲之人，工作的时候大家兢兢业业，私下有逗逼的中二少女，有一言不合就开车的上司，有闷骚的理工男，也有千杯不醉的IT女，这里是一个伐木累。"
"职位描述：
        
        岗位职责：
1、参与建设大数据分析系统；
2、对海量业务数据、用户数据进行分析挖掘，为公司在车联网行业精准营销、运营及决策提供业务分析及数据支持；
3、根据研究成果及业务需求，形成解决方案，实施应用项目；
4、开发出独立知识产权算法及知识库，固化成数据产品；

任职要求：
1、本科及以上学历，计算机、应用数学、统计学、交通等相关专业；
2、熟练Scala、Java、Python、Go、C/C++等服务端编程，有良好的编码习惯。
3、具有3年以上数据挖掘/数学建模相关工作经验, 具有深厚的统计学、数学、人工智能和数据挖掘知识基础，具备数理统计理论基础
4、深入理解HADOOP生态各种组件框架、查询引擎、存储引擎,熟练使用Hadoop、Spark、Hbase、Phonix、Presto等,有CDH运维经验优先。
5、熟练使用StructuredStreaming和Apache Carbondata进行流式计算和离线计算。
6、熟练使用MYSQL/MSSQL关系型数据库,扎实的SQL编写/优化功底。
7、熟悉文本挖掘分析方法及分布式数据分析工具使用；
8、具有高度的责任感、良好的敬业精神和团队合作精神；能够主动获取新知识，具有较强领悟力，有系统性思考解决问题能力；
9、精通数据挖掘方法论，熟练掌握回归、决策树、聚类、分类等算法及应用者优先；
10、有车辆网海量数据处理经验者优先；
11、在华为、中兴、BAT等从事过相关经验者优先考虑；
12、有相关从业经验研究生学历者优先考虑。"
"职位描述：
        
        大数据开发工程师
职位描述：
岗位职责：

1、参与大数据平台、工具平台的架构、设计以及实现；

2、参与对项目的开发需求进行评审，制定项目的设计文档、开发计划文档等；

3、负责公司各类数据产品数据抽取、清洗，以及数据算法与存储的设计和优化；

4、优化大数据平台的性能，提高稳定性；

5、负责大数据平台的组件升级与参数优化。

岗位要求：

1、本科及以上学历，3年以上相关技术背景，具备扎实的数据结构和算法基础，扎实的工程实现能力；

2、熟悉hadoop大数据相关技术体系，包括但不限于Hbase、HDFS、Storm、Kafka、Spark、Hive、Flume等；

3、精通Java或Python，能熟练编写规范代码，有较强的数据库及SQL开发调优能力；

4、熟悉自然语言处理/机器学习/数据挖掘领域，熟悉常用的机器学习算法优先考虑；

5、有大规模数据收集，日志处理经验，有电商数据分析背景优先考虑；

6、深入研究过大数据框架的运行机制、实现原理、源码者优先考虑。"
"职位描述：
        
        1. 本科及以上学历，计算机或数学相关专业，工作2年以上；
2. 精通hive sql,spark sql，spark上的JAVA开发
3. 有2年以上用户画像构建和应用实战经验，有数据挖掘实践经验，擅长从海量数据中发现有价值的规律。
4. 思维清晰敏捷，逻辑分析能力强，具有良好的语言和书面表达能力；
5. 自我驱动能力强，踏实勤勉，对有挑战的问题充满激情。
6. 有大型互联网公司或保险行业背景优先。"
"职位描述：
        
        岗位职责：
1、 负责公司大数据平台及应用的设计、开发、环境搭建、调优及故障诊断；
2、 参与公司大数据方向技术创新，针对特定业务场景，能在架构师指引下，快速完成技术预演、实施上线；
3、 负责数据模型架构的构建，建立数据抽取、清洗、校验等数据加工流程规范及OLAP多维数据分析模型；
4、 对海量数据进行挖掘分析，构建数据模型及监控体系；
5、 将数据分析能力应用于业务进行实践落地；
6、 持续对系统的技术架构进行改进和优化，提升海量数据的查询性能和用户体验。
任职要求：
1、 本科及以上学历，计算机相关专业，2年以上大数据平台研发经验；
2、 精通Java开发，有脚本语言（shell,python)开发经验者优先；
3、2年以上的海量数据处理工作经验，对主流大数据技术有深入了解，如hadoop、hbase、spark、flink等等；
4、掌握Hive/HBase/Spark的架构及实现原理，能对其进行故障分析、性能调优；
5、熟悉常用的分类、回归、聚类等算法及应用场景，并有相关实战经验；
6、热爱技术，认真严谨，具备良好的学习能力、分析和解决问题能力；
7、具有高度的责任心和团队合作精神；
8、有互联网、人工智能行业数据分析经验优先；"
"职位描述：
        
        岗位职责：
1、负责本公司大数据相关系集群（Yarn、HDFS、Hbase、Flink、Spark等）的维护和优化；
2、集群运行问题排查，缺陷修复，跟进社区Patch更新情况； p参与大数据平台的规划设计；
3、负责全公司大数据相关集群的规划、管理工作并保证集群的高可靠；
4、开发各种Hadoop大数据自动化运维与监控工具；
5、深度优化数据平台作业/计算框架/存储技术，提升集群吞吐并降低成本。
岗位要求：
1、计算机及相关专业本科以上学历，互联网公司背景，5年以上技术研发相关工作经验；
2、JAVA基础扎实，理解IO、多线程、集合等基础框架，对JVM原理有一定的了解；
3、熟悉各种SQL框架，对Oracle,，MySQL等主流数据库有调优能力；
4、有分布式缓存和消息中间件的开发经验，能编写支持高并发和水平扩展的高质量代码；
5、掌握常用的设计模式，并能灵活应用；
6、责任心强，抗压能力强，工作积极主动，沟通协作能力较强；
7、有Hadoop/Spark/Storm/HIVE/Hbase等应用开发经验，并且对分布式计算、数据仓库理论有深刻理解 ；
8、研究过Hadoop或者Spark源代码的优先；"
"职位描述：
        
        岗位描述：
1、负责架构设计以及核心技术问题的攻关，承担系统核心功能的开发，保证系统的性能稳定性高可用；
2、带领其他成员按时高质量完成系统模块的开发任务。

任职要求：
1、3年以上Java开发经验，全日制本科学历，985/211/硕士毕业生优先考虑；
2、JAVA基础扎实，熟练掌握数据结构，java动态代理，反射，多线程等相关技术，掌握常用的设计模式，编码认真严谨规范；
3、熟悉使用Spring mvc，SpringBoot，Hiberate，Spark，Zookeeper等开源框架；
4、熟悉分布式，缓存，消息等机制，熟悉memcache，redis，mongodb等主流NOSQL存储开源项目；
5、熟悉至少一种常用数据库的应用开发，如Oracle，MySQL；
6、有一定的linux基础，能够熟练使用linux常用工具；
7、熟悉常用的RabbitMQ，ActiveMQ，kafka，redis等消息中间件技术；
8、有良好的团队合作精神，具有较强学习能力，和逻辑分析能力和独立系统设计能力。"
"职位描述：
        
        一、岗位职责:
1.配合产品/项目客户完成需求调研和需求分析，提出技术解决方案；
2.参与系统设计、开发与实现；
3.结合需求设计实现安全、稳定、高伸缩性、高性能、易维护、易用性好的业务系统；
4.负责数据平台及 hadoop 集群稳定性保障;
5.支持相关部门在数据应用上的各类技术问题;
6.负责集群的版本升级、系统优化、故障处理等工作。

二、任职资格：
1.计算机及相关专业本科以上学历；
2.至少2年以上大数据平台经验；
3.精通Java语言及面向对象设计和开发；
4.熟悉 Hadoop、Hbase、Hive，有实际开发经验；
5.理解 MapReduce 计算框架的思想，熟悉分布式计算模型或有高效索引技术经验者优先；
5.熟悉Linux/Unix操作系统，至少熟练使用 Shell、Python、Perl 一种脚本语言；
6.有良好的工作及编码习惯；
7.良好的团队协作意识，能承受一定工作压力。"
"职位描述：
        
        岗位职责:
1.配合产品/项目客户完成需求调研和需求分析，提出技术解决方案；
2.参与大数据分析系统设计、开发与实现；
3.结合需求设计实现安全、稳定、高伸缩性、高性能、易维护、易用性好的业务系统；
4.负责数据平台及 Hadoop 集群稳定性保障;
5.支持相关部门在数据应用上的各类技术问题;
6.负责集群的版本升级、系统优化、故障处理等工作。

任职资格：
1.计算机及相关专业本科以上学历；
2.至少3年以上大数据平台经验；
3.精通Java，Scala语言及面向对象设计和开发；
4.熟悉 Hadoop、Hive、Hbase，有实际开发运维经验；
5.理解 MapReduce 计算框架的思想，熟悉分布式计算模型或有高效索引技术经验者优先；
5.熟悉Linux/Unix操作系统，至少熟练使用 Shell、Python、Perl 一种脚本语言；
6.有良好的工作及编码习惯；
7.良好的团队协作意识，能承受一定工作压力。"
"职位描述：
        
        岗位职责：
1、负责大数据相关技术研究，解决海量数据不断增长面临的挑战；2、负责海量数据的处理、分析、挖掘和存储；3、大数据挖掘计算平台集群管理、部署、优化、排错；4、大数据分析项目的软件开发、维护、架构设计，文档编写等工作；?
任职要求：
1、计算机相关专业本科及以上学历；2、有扎实的Java语言基础，熟悉JVM运行机制和内存管理，熟悉Scala语言者为佳；3、熟悉HHadoop 2.0以上版本体系结构、各个模块的功能，对Hadoop生态圈有较全面了解，同时具有源码级开发经验；4、对Hive、HBase、Map/Reduce、Spark有深入了解，能熟练编写Map/Reduce程序和Spark程序；5、熟悉Hadoop运行监控及调优技术；6、具备机器学习算法理论基础，如分类、聚类、推荐、关联规则，具备相关项目经验为佳；7、有互联网公司或海量数据处理工作经验，数据分析和挖掘经验者优先;"
"职位描述：
        
        岗位职责：
1、负责大数据业务开发，根据业务需求，进行设计和开发工作。
2、能够对业务进行抽象，对数据进行清洗、分析、统计及接口开发。

岗位要求：
1，具备基础的网络、计算机基础知识体系。
2、有一年以上大数据业务开发经验。有海量大数据分析、机器学习、深度学习经验、数据仓库建设经验的优先。
3、熟练使用分布式计算、存储技术如Elasticsearch、MongoDB、Hadoop、Hbase、Spark、Hive、Hdfs、Storm等；
4、熟悉并掌握一门或多门语言（Python、java、PHP、GO、C/C++、shell）的使用，有Python、GO、Scala经验优先；
5、具备扎实的SQL功底，熟练使用Mysql。
6、具备良好的学习能力、沟通和理解能力，有良好的团队协作精神。"
"职位描述：
        
        岗位职责?负责云端互联网后台基础平台设计开发岗位要求1、本科及以上学历，3年以上基础平台、大数据、共性组件领域研发经验，满足三项中的一项即可；2、熟悉容器平台开发或者大数据管理工具平台开发，有docker、kubernetes、cdh、ambari相关开发经验更佳；3、精通Elasticsearch、spark、Hbase、Hive、hdfs之一的原理和应用；4、熟悉并掌握一门或多门语言（Python、Java、PHP、Go、C&C++、shell）的使用，有Python、java开发经验优先；5、了解MongoDB6、了解日志系统、监控告警系统、自动化技术平台，有相关开发经验优先"
"职位描述：
        
        岗位职责：1、负责大数据业务开发，根据业务需求，进行设计和开发工作。2、能够对业务进行抽象，对数据进行清洗、分析、统计及接口开发。
岗位要求：1，具备基础的网络、计算机基础知识体系。2、有一年以上大数据业务开发经验。有海量大数据分析、机器学习、深度学习经验、数据仓库建设经验的优先。3、熟练使用分布式计算、存储技术如Elasticsearch、MongoDB、Hadoop、Hbase、Spark、Hive、Hdfs、Storm等；4、熟悉并掌握一门或多门语言（Python、java、PHP、GO、C/C++、shell）的使用，有Python、GO、Scala经验优先；5、具备扎实的SQL功底，熟练使用Mysql。6、具备良好的学习能力、沟通和理解能力，有良好的团队协作精神。"
"职位描述：
        
        工作职责：
1.?基于业务需求，搭建、开发、维护、优化数据相关的平台工具；
2.?数据加工、清理、分析、处理等程序的开发；
3.?用户实时行为，历史行为等相关系统的开发；
4.?负责营造团队技术氛围，推动技术能力的沉淀。
?
任职资格：
1. 1. 计算机、信息系统、数学或相近专业本科以上学历，5年以上相关研发经验经验；
2. 强悍的 system 设计&编码能力，追求优雅的设计和优秀的代码质量，高标准，快速行动；
3. 思路清晰，具备生产系统快速 trouble-shooting 的经验和能力，擅长分析更深层次的原因；
4. 存储方向，至少掌握 HDFS, HBase, Elasticsearch,?Kafka, mysql/postgres的一项或多项有经验者优先；
5. 计算方向，至少掌握 Spark, MapReduce, Storm, OLAP 的一项，有多项有经验者优先；
6. 集群管理方向，对 YARN, Mesos 的一项或多项有经验者优先；
7. 有大规模云平台使用经验者优先；
8. 不怕困难，有关键技术攻关的决心和能力，能够适应和享受高压力的工作；
9. 开源社区贡献者优先，请在简历上说明"
"职位描述：
        
        工作职责：
1. 负责大数据项目中各种数据收集部分的设计及实现，包括但不限于灵活可扩展的RESTFul API，消息队列，数据存储以及数据抓取；
2. 负责指导工程师进行技术验证与实现，核心技术问题的攻关，解决项目开发过程中的技术难题；
3. 负责项目对外技术沟通，具有较强的沟通，表达和文案能力；
4. 负责营造团队技术氛围，推动技术能力的沉淀；
?
任职资格：
1. 计算机、信息系统、数学或相近专业本科以上学历，5年以上相关研发经验经验；
2. 精通高并发情况下后端服务的设计及实现。
3. 强悍的 system 设计&编码能力，追求优雅的设计和优秀的代码质量，高标准，快速行动；
4. 思路清晰，具备生产系统快速 trouble-shooting 的经验和能力，擅长分析更深层次的原因；
5. 有优秀的业务理解能力，善于在复杂需求情况下，梳理业务并进行合理的模块和架构设计。
6.?熟悉并应用过大数据相关组件者优先；
7. 有全栈经验者优先；
8. 不怕困难，有关键技术攻关的决心和能力，能够适应和享受高压力的工作；
9. 开源社区贡献者优先，请在简历上说明"
"职位描述：
        
        职位描述：
1、参与公司用户行为数据的收集和实时计算开发;
2、根据业务需求实现实时和离线数据ETL过程
3、对外应用系统、数据服务接口的开发
4、开发实时数据处理、统计功能,支撑上层业务,如:数据监控、统计分析、日报展现、业务方调用等

任职要求：
1、计算机/软件工程或相关专业出身，工作5年以上
2、扎实的代码基础；擅长java或scala。
3、熟悉大数据的生态圈和相关组件（hadoop、hive、spark、flink、kafka、hbase等）,能够深了解集群和周边模块
4、对spark RDD模型有深刻的理解，能针对线上问题进行调优;
5、熟悉Mysql，Redis，能够快速理解业务模型和数据模型
6、熟悉Linux环境及脚本开发（Python/Perl/Shell等）"
"职位描述：
        
        职位描述：职位描述：

1、数据分析平台的设计和开发，为数据分析和运营等人员搭建友好高效的数据产品；

2、核心实时指标、离线指标、图计算指标开发；

3、其它大数据平台技术相关的技术工作。



岗位要求：

1、熟悉分布式系统的基础理论知识，了解大数据处理的常用算法；

2、熟悉Java或Scala语言，有扎实的开发功底；

3、熟悉Spark/Hadoop，Hbase，Storm，Kafka等大数据处理框架；

4、有图计算经验和大数据平台开发经验优先。"
"职位描述：
        
        工作职责:1、负责构建大数据平台，大数据处理构架；2、负责业务数据收集整理，对海量数据进行分析，并利用算法挖掘数据之间的相互作用关系和联系，发现潜在规律，建立机器学习算法并优化；3、负责数据的自动化分析处理和统计工作；任职资格:1、统招本科及以上学历，计算机、电子或相关专业2、3年以上Java,python开发经验，精通python数据分析,ETL3、基于Hadoop的大数据体系有深入认识，熟悉spark streaming、flume，kafka等开源软件的优先考虑，熟悉了解机器学习，有sklearn项目经验优先考虑；4、有较强的逻辑思维能力，善于分析和解决问题；有较强的主动性和自驱力，能够发现问题，并推动系统演进至完美状态；5、具备大容量、高性能、高可用、分布式架构设计和调优经验"
"职位描述：
        
        职位描述
1.?负责项目中数据处理工作(数据采集、清洗、汇总、集成等),保证数据的准确性和稳定性；
2.?负责协助完成应用系统中数据上下层衔接处理工作；
3.?对用户数据进行分析和挖掘，提供决策支持；
4.?大数据数据产品策划，对数据库信息的深度挖掘，充分体现数据的商业价值职位要求；
?
任职要求:
1.?熟悉Java和python，具备大型(数据)平台开发经验；
2.?熟悉HTTP协议;
3.?加分项：熟悉Hadoop/Hive/Hbase/Spark/Storm等分布式计算环境进行海量数据分析与计算经验者优先;
4. 以结果为导向，具有强烈的责任心、钻研精神和良好的团队沟通能力。"
"职位描述：
        
        1、具有5年以上实际项目编程经验；具有3年以上大数据和云平台开发经验。有较强的分析、设计能力；
2、精通java编程语言，熟悉软件工程、设计模式等；
3、具备良好的沟通能力和团队合作精神，接受能力强，对编程工作有强烈兴趣，善于钻研新技术、新知识。
4、具备在云平台下进行大数据应用研究经验者优先；
5、熟悉电力业务，具有电力软件开发经验者优先；
6、有大型平台项目经验者优先；
7、熟练掌握HADOOP、ORACLE、数据仓库技术者优先。"
"职位描述：
        
        岗位职责：
1. 参与公司大数据产品规划,大数据处理分析平台的设计;
2. 负责数据分析、加工、清理、处理程序的开发;
3. 负责数据相关平台的搭建、维护和优化;
4. 负责基于Hadoop/Spark/Hive/kafka等分布式计算平台实现离线分析、实时分析的计算框架的开发.


职位要求：
1. 熟悉Java和Scala语言、熟悉常用设计模式、具有代码重构意识;
2. 熟练使用hadoop、hbase、Kafka、hive、spark、presto,熟悉底层框架和实现原理；
3. 使用Spark Streaming和Spark SQL进行数据处理, 并具有SPARK SQL优化经验;
4. 熟悉MySQL数据库性能优化方法, 了解常见NO-SQL数据库;
5. 有大规模hbase集群运维经验或对hbase存储原理熟悉者优先；
6. 需要有至少2年实时流开发经验,有flink开发经验优先。"
"职位描述：
        
        岗位职责：
1. 参与公司大数据产品规划,大数据处理分析平台的设计;
2. 负责数据分析、加工、清理、处理程序的开发;
3. 负责数据相关平台的搭建、维护和优化。
4. 负责基于Hadoop/Spark/Hive/kafka等分布式计算平台实现离线分析、实时分析的计算框架的开发；

职位要求：
1. 熟悉Java和Scala语言、熟悉常用设计模式、具有代码重构意识；
2. 熟练使用hadoop、hbase、Kafka、hive、spark、presto,熟悉底层框架和实现原理；
3. 使用Spark Streaming和Spark SQL进行数据处理, 并具有SPARK SQL优化经验；
4. 熟悉MySQL数据库性能优化方法, 了解常见NO-SQL数据库；
5. 有大规模hbase集群运维经验或对hbase存储原理熟悉者优先；
6. 有数据挖掘、数据分析、机器学习研发实践经验者优先。"
"职位描述：
        
        职位描述：
1.负责大数据平台的设计与开发实现
2.负责大数据应用相关产品需求分析、架构设计以及开发实现
3.负责数据产品的服务接口开发和维护


职位要求:
1.本科及以上学历，2年及以上大数据相关技术背景
2.熟练进行Java/Scala/Python/PHP的代码编写，良好的代码编写素养，良好的数据结构算法技能。
3.熟悉spring boot、mbatis、dubbo等开发框架，熟悉前后端分离开发流程
4.有数据平台开发经验，包括但不限于离线开发平台、数据质量中心、元数据管理、数据资产管理，实时流平台等
5、熟悉使用Spark/Flink、Storm等数据实时流式处理技术。
6、熟悉数据仓库理论，对多维数据建模有深入理解和实际经验。
7、熟悉开源大数据平台如HBase、ES、Kylin、Druid等，有实际的报表平台、多维度分析工具、etl平台、调度平台中至少一种工具的实际建设经验。
8、有过使用flink做实时计算平台成功案例者和用过hera系统做过离线任务平台者优先。"
"职位描述：
        
        岗位职责：
1.负责大数据平台的设计与开发实现
2.负责大数据应用相关产品需求分析、架构设计以及开发实现
3.负责数据产品的服务接口开发和维护

岗位要求:
1.本科及以上学历，2年及以上大数据相关技术背景
2.熟练使用java开发语言
3.熟悉spring boot、mbatis、dubbo等开发框架，熟悉前后端分离开发流程
4.有大数据平台开发经验，包括但不限于离线开发平台、数据质量中心、元数据管理、数据资产管理等
5.熟悉hadoop大数据相关技术体系，包括但不限于Hive、HDFS、Kafka、Flume、Spark,airflow 等
6.具备良好的沟通能力以及团队合作精神
7.具有一定的Scala/Python语言开发能力"
"职位描述：
        
        岗位职责：
1.负责公有云、私有云的平台建设及其维护，包含从数据收集到统计数据的全部生命周期的维护和开发；
2.根据业务情况，进行业务模型的优化、数据仓库的建设，保证基础表的稳定和高效；
3.善于学习和发现新的事物，有自己的想法去优化、修改现有的服务体系和平台系统，在一定level上提出优化的建设性建议。

任职要求：
1.计算机相关专业，本科或以上学历；
2.3年以上相关工作经验；
3.有过大数据平台建设和数据仓库建设者优先；最好运维过数据平台；
4.熟悉HTTP，TCP/IP网络协议，并能熟练的基于网络协议进行相关开发；熟悉Mysql、Redis相关技术，能进行性能优化及解决常见问题；熟练使用Linux，对Linux常用维护命令熟悉；有2-3年服务器研发经验，精通Java，具备springboot框架的使用经验者优先；熟悉Python或Shell等脚本语言；有大数据家族(Hadoop / Hbase / Storm / ? Spark / Flume / Kafka)使用相关经验；崇尚CI理念；
5.能独立阅读英文文档、有自己的技术BLOG优先、经常关注开源社区优先。"
"职位描述：
        
        岗位职责：1. 负责公司大数据平台研发?2. 负责大数据接口API相关开发3. 负责公司大数据产品采集(ETL)功能的增强及流式计算的开发

任职要求：1. 本科及以上学历?2. 四年以上大数据开发经验?3. 熟练掌握Scala/Java开发4. 熟练应用 ELK 进行开发5. 有相关Hadoop及Flink/Spark开发经验优先6. 了解Akka分布式框架,有相关开发工作经历优先7. 有相关ETL软件开发/使用经验优先?8. 有金融行业,IT运维监控等开发工作经验者优先?9. 熟悉 Linux 等操作系统,有一定的脚本能力（Python，Shell）10. 有良好的沟通能力和较强的工程实践能力"
"职位描述：
        
        岗位职责：1. 负责公司大数据平台研发?2. 负责大数据接口API相关开发3. 负责公司大数据产品采集(ETL)功能的增强及流式计算的开发

任职要求：1. 本科及以上学历?2. 四年以上大数据开发经验?3. 熟练掌握Scala/Java开发4. 熟练应用 ELK 进行开发5. 有相关Hadoop及Flink/Spark开发经验优先6. 了解Akka分布式框架,有相关开发工作经历优先7. 有相关ETL软件开发/使用经验优先?8. 有金融行业,IT运维监控等开发工作经验者优先?9. 熟悉 Linux 等操作系统,有一定的脚本能力（Python，Shell）10. 有良好的沟通能力和较强的工程实践能力"
"职位描述：
        
        岗位职责：
1、负责大数据开发及图算法挖掘工作，对大数据应用产品设计及解决方案设计；
2. 负责数据模型架构的构建，建立数据抽取、清洗、校验等数据加工流程设计；
3. 持续对系统的技术架构进行改进和优化，提升海量数据的查询性能和用户体验。
任职要求：
1、使用过ArangoDB／Neo4j／TigerGraph中的一种或者多种，有性能优化经验者优先；
2、有扎实的Java编程功底，熟练掌握JVM调优，熟悉设计模式、多线程、nio；
3、熟练掌握Spark原理及Spark core、Spark Streaming、Spark SQL的使用，有Spark ML算法及Spark Graphx项目经验者优先；
4、熟悉掌握HBase原理及API编程；
5、深入理解KAFKA原理，并且具备丰富的项目经验；
6、熟练运用scala编程语言；
7、熟悉Elasticsearch搜索引擎，有性能调优者优先；
8、熟悉MapReduce原理及编程、Yarn原理；
9、熟悉掌握ZooKeeper原理及API编程；
10、熟练掌握Linux常用指令以及Linux Shell脚本编写，具备一定的linux运维经验；
11、熟练运用maven项目构建工具及git版本管理工具；
12、熟练掌握Hive常用语法、Hive优化、UDF/UDTF编写；"
"职位描述：
        
        
岗位职责：
－?负责通用大数据分析平台产品的核心功能研发、架构设计相关工作
－?负责hadoop/Spark大数据集群的性能调优、稳定性改进、系统调优工作
－?负责团队内初中级大数据平台工程师的技术指导、技术培训工作


本岗位需要用到主要技术有：
???主要开发语言：python、scala
???主要平台：hadoop/spark，重点是Spark
???系统：Linux操作系统和shell
???其它：docker，ansible，redis，mysql

岗位要求：
-??计算机、数学、统计学等相关专业毕业，本科或以上学历
-??精通hadoop/Spark,?做过至少一年以上相关开发工作，有较强的问题定位和性能优化的能力，尤其是Spark的问题定位和性能调优。
-??精通Linux操作系统、熟悉Shell，有一定解决系统问题的能力
-??至少熟练运用Java、Scala、python语言中的1种，都熟悉优先。
-??熟悉docker、andsible优先
-??熟悉星环、华为或CDH之一的优先
-??有很强的学习能力
-??逻辑思维清晰，具有很强的问题排查能力
-??有很强的责任心
-??有较强沟通能力
-??有较强的自我驱动动力和自我管理能力"
"职位描述：
        
        岗位职责：
1、负责大数据开发及图算法挖掘工作，对大数据应用产品设计及解决方案设计；
2. 负责数据模型架构的构建，建立数据抽取、清洗、校验等数据加工流程设计；
3. 持续对系统的技术架构进行改进和优化，提升海量数据的查询性能和用户体验。
任职要求：
1、使用过ArangoDB／Neo4j／TigerGraph中的一种或者多种，有性能优化经验者优先；
2、有扎实的Java编程功底，熟练掌握JVM调优，熟悉设计模式、多线程、nio；
3、熟练掌握Spark原理及Spark core、Spark Streaming、Spark SQL的使用，有Spark ML算法及Spark Graphx项目经验者优先；
4、熟悉掌握HBase原理及API编程；
5、深入理解KAFKA原理，并且具备丰富的项目经验；
6、熟练运用scala编程语言；
7、熟悉Elasticsearch搜索引擎，有性能调优者优先；
8、熟悉MapReduce原理及编程、Yarn原理；
9、熟悉掌握ZooKeeper原理及API编程；
10、熟练掌握Linux常用指令以及Linux Shell脚本编写，具备一定的linux运维经验；
11、熟练运用maven项目构建工具及git版本管理工具；
12、熟练掌握Hive常用语法、Hive优化、UDF/UDTF编写；"
"职位描述：
        
        岗位职责：
1、负责大数据和AI商业化产品的研发和交付；?
2、了解客户需求，按期保质完成研发计划；?
3、协助解决方案团队，完成客户化方案的实施；?
4、协助运维团队，保障已交付产品的运营和服务。
岗位要求：
1、985/211本科以上学历，计算机相关专业；
2、精通Linux和C/C++、PHP/Python、Java等一种或几种编程语言；?
3、有大数据系统使用和开发经验，包括但不限于Hadoop/Spark/Hive/Hbase等
4、熟悉研发管理和质量管理流程，有云计算产品或SaaS服务交付经验；?
5、能独立完成模块开发和交付工作；?
6、具备良好的沟通表能力及团队协作精神、有较强的主动性、责任心与执行能力； 本科或以上计算机相关专业。"
"职位描述：
        
        职位描述1、负责数据化体系的建设，通过数据+算法+工程化能力，为数据化运营、决策提供有效支撑；2、负责大数据平台基础架构，包括数据资产、数据产品、数据质量及稳定性保障。?职位要求?1、具有主流大数据工具/平台实际项目经验Hadoop/Hive/HBase/Spark等，并熟悉所使用工具的技术原理、主要特点。?2、较为丰富的数据平台的架构及工程化经验、数据建模及实战能力；有较为系统的海量数据性能处理经验，在数据产品和应用一定的成功经验；?3、扎实的?JAVA?开发功底，理解IO、多线程、集合、并发包，对?JVM?原理有一定的了解，具备机器学习算法能力尤佳；?4、良好的思维逻辑性、语言表达能力。"
"职位描述：
        
        工作职责：
1. 运用各种数据开发工具设计实施ETL流程，设计并优化数据主题模型；
2. 参与开发数据报表、建立数据监控、告警机制、保障数据质量；
3. 分析海量数据并从中挖掘有效信息，为实际业务提供数据支持；
4. 将分析的方法和经验进行抽象和沉淀，建设数据分析产品，实现业务支持的规模化和快速横向扩展。

岗位要求：
1. 两年以上ETL工作经验优先，本科及以上学历，计算机、数学或统计等专业；有数据分析工作经验优先，或者非统计专业但是具备扎实的统计基础优先。
2. 极好的SQL能力，熟悉hive/odps/spark等大数据开发工具，有参与埋点相关项目经验优先；
3. 熟悉java/scala/python/R/shell等至少一钟高级语言，能够编写脚本处理、分析数据；
4. 具有较强的逻辑思维能力和数据敏感度；
5. 良好的沟通表达能力，工作认真负责，能够在一定压力下高质量完成工作；
6、有良好的沟通表达能力、抗压能力和团队合作精神，热衷于技术，乐于挑战和突破自己；"
"职位描述：
        
        工作职责：1、负责大数据平台架构设计（包括不仅限于离线/实时计算，存储框架/模型设计）、数仓建模和ETL开发，构建可扩展的数据仓库和分析解决方案；2、研究大数据相关技术，关键性技术研发和性能优化、测试;3、负责数据产品的研发, 包括但是不限于数据的收集, 转化, 存储, 展示；4、制定数据口径和数据规则，沉淀数据字典。沉淀数据分析和数据挖掘思路，提炼业务产品需求，协同和推动数据产品的落地；岗位要求：1、有大数据相关经验3年以上；2、具有主流大数据工具/平台实际项目经验Hadoop/Hive/HBase/Spark等，并熟悉所使用工具的技术原理、主要特点；3、有大型数据仓库项目实施经验，熟悉数据仓库方法论和ETL架构，理解元数据管理；4、熟悉Linux平台，熟练掌握 Hive SQL，以及ETL过程设计和开发；5. 良好的沟通表达能力，工作认真负责，能够在一定压力下高质量完成工作；6、有良好的沟通表达能力、抗压能力和团队合作精神，热衷于技术，乐于挑战和突破自己。"
"职位描述：
        
        工作职责：1、负责大数据应用的开发，包括但不限于报表系统、取数工具、数据服务平台、大数据门户、数据大屏、数据罗盘、BI系统等数据应用产品的研发。2、根据开发规范与流程完成系统设计、编码及先关文档的编写，满足质量要求;3、分析数据、分析需求，协同产品优化数据应用，推动数据产品的落地与应用；岗位要求：1、3年及以上JAVA开发经验，精通JAVA语言；2、有JAVA WEB开发经验，熟悉Spring、MyBatis等成熟框架；熟悉主流数据库原理及使用，如MySQL；熟悉常用中间件使用如Redis、Dubbo等。3、熟悉大数据相关技术栈优先（包括但不限于Hadoop、Hive、HBase、Spark、Flink等）；4、电商背景优先。5. 良好的沟通表达能力，工作认真负责，能够在一定压力下高质量完成工作；"
"职位描述：
        
        工作职责：1、参与数据服务平台的设计及开发工作；2、负责数据服务平台数据检索，索引、关系建模及计算、任务调度相关开发工作；3、跟进大数据前沿技术的发展，适时引入合适的技术支撑业务场景。任职资格：1、全日制统招本科及以上学历，5年以上相关工作经验；2、熟悉Hadoop/Hive/Spark的体系结构、原理和特性，对Hadoop生态系统有一定的了解；3、熟悉Java，有丰富的并发编程经验，可以熟练使用Python/Shell等脚本语言，熟悉Linux操作系统；4、有海量数据分析、处理的相关系统的开发及优化经验；5、有推荐、广告、搜索等相关系统开发经验者优先；6、有良好的数学基础，了解机器学习常用算法，具备自然语言处理、特征分析等方面知识及应用经验者优先；7、责任心强，良好的沟通能力和团队协作精神。"
"职位描述：
        
        1、参与数据服务平台的设计及开发工作； 
2、负责数据服务平台数据检索，索引、关系建模及计算、任务调度相关开发工作； 
3、跟进大数据前沿技术的发展，适时引入合适的技术支撑业务场景。

任职资格：
1、本科及以上学历，计算机相关专业。5年以上大数据开发工作经验； 
2、熟悉Hadoop/Hive/Spark的体系结构、原理和特性，对Hadoop生态系统有一定的了解； 
3、熟悉Java，掌握Python/Shell等脚本语言，熟悉Linux操作系统； 
4、有数据分析处理优化经验，推荐、广告、搜索等相关系统开发经验者优先； 
5、有良好的数学基础，了解机器学习常用算法，具备自然语言处理、特征分析等方面知识及应用经验者优先； 
6、责任心强，良好的沟通能力和团队协作精神。"
"职位描述：
        
        任职要求：
1、统招本科或以上学历，计算机相关专业， 3年以上软件开发经验、2年以上大数据项目经验。
2、Java基础与算法功底扎实，精通面向对象分析、具备丰富的系统架构设计(J2EE)经验。
3、具备较丰富的大数据平台相关构建，维护及调优经验，有超大数据量级下的大数据集市相关经验。
4、具备较丰富的基于Hadoop或Hive或Spark等大数据处理项目经验，具备一定的数据挖掘经验。
5、具有良好的业务理解、沟通和协作能力，具有较强的学习和总结能力。
6、优秀的团队合作精神、诚实、勤奋、严谨，敢于接受挑战。
7、机器学习技术、数据挖掘经验丰富者优先考虑。
岗位职责：
1、负责公司大数据平台系统架构设计、核心开发工作（Hadoop&Spark技术方向），基于业务场景设计最优的系统解决方案。
2、构架支持超大数量级的数据的大数据平台系统，及相关监控，拓展系统设计及实现。
3、利用Hadoop、Spark等大数据技术对海量数据进行处理，支持建模（算法）的工程化实现。
4、通过机器学习等技术进行数据分析及建模的方案的系统化设计，负责数据挖掘项目的架构设计工作。
5、对现有系统的进行架构深入分析及系统优化，进一步提升系统的性能及数据处理能力。"
"职位描述：
        
        任职要求：
1、统招本科或以上学历，计算机相关专业， 8年以上软件开发经验、5年以上大数据项目经验。
2、Java基础与算法功底扎实，精通面向对象分析、具备丰富的系统架构设计(J2EE)经验。
3、具备较丰富的大数据平台相关构建，维护及调优经验，有超大数据量级下的大数据集市相关经验。
4、具备较丰富的基于Hadoop或Hive或Spark等大数据处理项目经验，具备一定的数据挖掘经验。
5、具有良好的业务理解、沟通和协作能力，具有较强的学习和总结能力。
6、优秀的团队合作精神、诚实、勤奋、严谨，敢于接受挑战。
7、机器学习技术、数据挖掘经验丰富者优先考虑。
岗位职责：
1、负责公司大数据平台系统架构设计、核心开发工作（Hadoop&Spark技术方向），基于业务场景设计最优的系统解决方案。
2、构架支持超大数量级的数据的大数据平台系统，及相关监控，拓展系统设计及实现。
3、利用Hadoop、Spark等大数据技术对海量数据进行处理，支持建模（算法）的工程化实现。
4、通过机器学习等技术进行数据分析及建模的方案的系统化设计，负责数据挖掘项目的架构设计工作。
5、对现有系统的进行架构深入分析及系统优化，进一步提升系统的性能及数据处理能力。"
"职位描述：
        
        岗位职责：
（1）根据业务进行数据需求的调研、设计、开发及验证工作，并持续进行数据业务的优化；
（2）负责大数据整体设计和开发工作，包括数据接入、清洗、计算、校验等数据加工流程，并沉淀文档；
（3）持续对系统的技术架构进行改进和优化，提升海量数据的查询性能和用户体验。
（4）驻场开发：新疆：6个月
任职资格：
（1）统招本科或以上学历，计算机、数学等相关专业，工作至少3年以上；
（2）熟悉Java/Scala开发，有脚本语言（shell,python)开发经验者优先；
（3）至少熟悉一种大数据处理栈技术，如Hadoop、Spark; 熟悉流计算应用开发，如spark streaming, flink;熟练掌握大数据生态各个工具的原理及使用，如hive, sqoop, kafka等
（4）掌握HBase、Redis、Elastic Search等开源大数据存储技术，并能结合不同的业务场景深入使用；
（5）熟悉storm，spark streaming，flink，beam至少一种
（6）熟悉kafka，redis，es等相关组件
（7）对解决具有挑战性的数据问题充满激情，具有良好的分析问题和解决问题的能力，能够胜任部分数据分析，挖掘，建模工作。"
"职位描述：
        
        岗位名称：大数据研发经理

岗位职责：
1、负责大数据小组团队管理；
2、负责公司的大数据平台的构建与开发；
3、负责公司大数据平台研发过程中的设计文档的撰写；
4、撰写规范专业的技术文档，研究行业前沿技术；
5、参与小组的产品设计讨论，共同讨论和设计产品；
6、大数据平台的新技术调研。?

任职要求：
1、本科五年工作经验及以上，有至少五年的大数据技术实践经验；?
2、熟练使用hadoop及hadoop生态圈中的常用组件原理及应用，如 HBase、Hive、Pig、Kafka、Storm等全部或者部分组件；
3、熟练掌握Java，Shell 编程，具有一定JVM调优经验；
4、熟悉大数据算法原理及应用；
5、熟悉软件开发流程和配置库的使用，拥有软件开发流程中的代码规范意识、配置管理规范意识、文档撰写规范意识和团队合作沟通交流意识；
6、对新生事物或者新技术有浓厚兴趣者优先，有较好的自主学习能力。"
"职位描述：
        
        中级3-5年工作经验、高级5年以上工作经验；
1. 负责公司大数据平台底层框架的整体架构设计和开发；
2. 负责公司大数据平台实时流框架的设计和应用；
3. 负责架构优化及系统关键模块的设计，协助解决技术难题；
4. 数据治理，新技术的调研和推广。
?
工作要求：
1. 计算机专业本科及以上学历，3年以上互联网后台开发经验；
2. 掌握linux环境下python/c/java/golang中的一种或几种；
3. 掌握常见的数据结构和算法；
4. 有海量数据处理经验优先；
5. 深入理解大数据基础组件的使用/原理/调优者优先，如Flume/Hadoop/Hbase/Spark/Storm/ELK/kafka/Hive等"
"职位描述：
        
        中级3-5年工作经验、高级5年以上工作经验；
1. 负责公司大数据平台底层框架的整体架构设计和开发；
2. 负责公司大数据平台实时流框架的设计和应用；
3. 负责架构优化及系统关键模块的设计，协助解决技术难题；
4. 数据治理，新技术的调研和推广。
?
工作要求：
1. 计算机专业本科及以上学历，3年以上互联网后台开发经验；
2. 掌握linux环境下python/c/java/golang中的一种或几种；
3. 掌握常见的数据结构和算法；
4. 有海量数据处理经验优先；
5. 深入理解大数据基础组件的使用/原理/调优者优先，如Flume/Hadoop/Hbase/Spark/Storm/ELK/kafka/Hive等"
"职位描述：
        
        会数据库和报表开发。数据采集，能快速融入开发任务
1：做过一年以上JAVA开发
2：大数据项目有一年的工作经验
3：熟悉hive，spark组件"
"职位描述：
        
        岗位职责：1、负责部分Oracle逻辑处理；2、负责部分hive数据逻辑处理。3、根据需求进行Cognos报表的设计开发工作；任职资格：1、精通SQL语言，具备存储过程开发能力，能熟练进行SQL查询优化；2、有Cognos建模开发者优先"
"职位描述：
        
        ?大数据开发工程师岗位要求：1、? 计算机科学、应用数学、物理学等相关专业；2、? 具有2年以上大数据平台上建设数据仓库相关工作经验，熟练掌握HIVESQL开发语言，精通HIVESQL优化，并能结合数据仓库的最佳实践和前沿理论，不断调整、优化仓库设计。3、? 优秀的职业素养，善于主动思考和行动，有良好的口头和书面表达能力。4、? 有承压能力和良好的结构化问题解决能力。5、? 互联网、银行、信用卡、保险等金融机构或主流金融公司工作经验优先考虑。"
"职位描述：
        
        职位描述：
1、负责实时数据流应用系统开发，包括流数据处理、查询统计和分析预测等在线计算服务；
2、善于发现系统的性能瓶颈、设计缺陷，提出改进方案并实施；

职位要求：
1、掌握分布式实时流处理框架的底层工作原理，深入使用过某种流数据处理技术，如Spark Streaming、Flink或Storm，熟悉Flink的优先；熟悉并理解kafka工作原理；
2、熟悉并使用过NoSQL数据库，包括redis,hbase等开源存储；
3、具有快速定位和解决问题的能力；
4、具有强烈的责任心，良好的沟通、学习能力，良好的团队合作意识，勇于接受技术挑战。"
"职位描述：
        
        1、熟悉数据仓库架构、熟悉Hadoop平台BI项目的实施流程；
2、精通Oracle常用函数、分析函数，熟练使用SQL完成业务需求；
3、熟练使用PL/SQL编写存储过程；?
4、熟悉hadoop，熟练使用hive；"
"职位描述：
        
        职位描述：
1、负责实时数据流应用系统开发，包括流数据处理、查询统计和分析预测等在线计算服务；
2、善于发现系统的性能瓶颈、设计缺陷，提出改进方案并实施；

职位要求：
1、掌握分布式实时流处理框架的底层工作原理，深入使用过某种流数据处理技术，如Spark Streaming、Flink或Storm，熟悉Flink的优先；熟悉并理解kafka工作原理；
2、熟悉并使用过NoSQL数据库，包括redis,hbase等开源存储；
3、具有快速定位和解决问题的能力；
4、具有强烈的责任心，良好的沟通、学习能力，良好的团队合作意识，勇于接受技术挑战。"
"职位描述：
        
        1、基于Hadoop环境进行数据仓库开发，使用sqoop.、Kettle等同步工具从Oracle等关系型数据库同步数据。
2、用户标签开发,支持建设画像产品及标签应用。
3、对hive表进行数据质量监控、 性能优化、数据治理等。
4、对接业务,用大数据解决业务痛点、提升业绩。
5、与组内外同事形成良好沟通。 ?

任职资格：
1、专科4年、本科3年、研究生1年以上大数据开发工作经验,处理数据量为千万条以上。2、熟悉hadoop平台的hive开发和调优,熟悉数据仓库。
3、熟练使用一种及以上关系型数据库。4、能快速理解业务,善于沟通和表达,工作积极主动。
5、有用户画像和标签开发及应用经验优先。"
"职位描述：
        
        职位描述：
负责数据仓库模型架构设计和实施；
完成各种面向业务目标的数据分析模型的定义和应用开发；
逐步构建基于用户行为、喜好的标签系统，并应用于相关的个性化系统和业务分析中；
?
1、本科及以上学历，计算机、数学及相关专业，5年以上经验,互联网经验3年以上；
2、具有丰富的数据开发经验，对数据处理、数据建模、数据分析等有深刻认识和实战经验；
3、熟悉主流的大数据产品和数据分析技术并具有相关项目经验；
4、有大数据分析与数据仓库设计及开发经验；
5、熟悉主流的开源大数据产品，如spark, Hbase, HIVE 等；
6、熟悉数据仓库相关技术，有互联网数据仓库搭建经验更佳；
7、积极乐观、诚信、有责任心，具备强烈的进取心、求知欲及团队合作精神。
有以下2条件者加分：
有数据挖掘算法实施经验，熟练掌握大规模数据挖掘、机器学习，有实际开发经验者更佳；。
有大型数据项目经验优先，有用户行为分析、用户建模、业务建模经验者优先。"
"职位描述：
        
        岗位职责：
1、参与大数据应用平台的设计与开发，解决海量数据面临的挑战；
2、负责大数据机器学习等模型的优化和集成工作，实现各类模型按统一的规范对外提供restful服务；
3、负责智能化决策平台的优化完善，实现大数据资源、模型资源能够实时对接到业务系统；
4、协助团队成员建立数据模型，对数据进行挖掘、优化及统计。
岗位要求：
1、数学、统计、计算机等相关理科专业，全日制本科及以上学历；?
2、三年以上海量数据下数据挖掘和算法实施相关工作经验；?
3、熟练运用python或者spark进行数据建模，熟悉hive、hadoop大数据处理技术的优先考虑；
4. 有金融行业、风险防控等领域经验的优先考虑。"
"职位描述：
        
        1：熟悉常用ETL工具，如KETTLE，Datastage,informatica等:
2：了解常用数据库及SQL编写，如oracle，Mysql,Postgresql,Hive"
"职位描述：
        
        岗位要求：
1、计算机及相关专业本科以上学历；?
2、3年以上3年以上报表开发项目相关工作经验，熟练使用一种数据库，如Oracle/Mysql，有Tableau等BI工具使用经验者优先；?
3、有金融行业大数据数据数据仓库、报表平台设计研发等经验者优先，有SAS编程经验者优先。?
岗位职责：
1、具备独立完成某一报表开发及数据开发的能力；?
2、具备良好的解决问题的能力，工作认真细致，积极主动，责任心强。"
"职位描述：
        
        1.精通数据仓库、存储过程
2.熟练使用传统数据库：oracle、mysql、pg等，有较好的SQL性能调优经验
3.熟练使用datastage等ETL工具
4.熟练使用现有的大数据相关工具：oozie、hive、hbase等
5.熟练使用linux命令、shell脚本
6.本科，5年以上数据工作经验"
"职位描述：
        
        职位描述：
1、负责实时数据流应用系统开发，包括流数据处理、查询统计和分析预测等在线计算服务；
2、善于发现系统的性能瓶颈、设计缺陷，提出改进方案并实施；

职位要求：
1、掌握分布式实时流处理框架的底层工作原理，深入使用过某种流数据处理技术，如Spark Streaming、Flink或Storm，熟悉Flink的优先；熟悉并理解kafka工作原理；
2、熟悉并使用过NoSQL数据库，包括redis,hbase等开源存储；
3、具有快速定位和解决问题的能力；"
"职位描述：
        
        本科学历
1、熟练使用Scala/Java，了解分布式存储系统如HDFS/Redis以及分布式计算系统如Hadoop/Spark；
2、有较强的分析和解决问题能力，有海量数据存储以及计算相关项目经验者优先。"
"职位描述：
        
        本科学历
1、熟练使用Scala/Java，了解分布式存储系统如HDFS/Redis以及分布式计算系统如Hadoop/Spark；
2、有较强的分析和解决问题能力，有海量数据存储以及计算相关项目经验者优先。"
"职位描述：
        
        职位描述：
1、负责数据仓库模型架构设计和实施；
2、完成各种面向业务目标的数据分析模型的定义和应用开发；
3、逐步构建基于用户行为、喜好的标签系统，并应用于相关的个性化系统和业务分析中。
岗位要求：
1、本科及以上学历，计算机、数学及相关专业，5年以上经验,互联网经验3年以上；
2、具有丰富的数据开发经验，对数据处理、数据建模、数据分析等有深刻认识和实战经验；
3、熟悉主流的大数据产品和数据分析技术并具有相关项目经验；
4、有大数据分析与数据仓库设计及开发经验；
5、熟悉主流的开源大数据产品，如spark, Hbase, HIVE 等；
6、熟悉数据仓库相关技术，有互联网数据仓库搭建经验更佳；
7、积极乐观、诚信、有责任心，具备强烈的进取心、求知欲及团队合作精神。
有以下2条件者加分：
有数据挖掘算法实施经验，熟练掌握大规模数据挖掘、机器学习，有实际开发经验者更佳；。
有大型数据项目经验优先，有用户行为分析、用户建模、业务建模经验者优先。"
"职位描述：
        
        岗位要求：
1、计算机及相关专业本科以上学历；?
2、3年以上3年以上报表开发项目相关工作经验，熟练使用一种数据库，如Oracle/Mysql，有Tableau等BI工具使用经验者优先；?
3、有金融行业大数据数据数据仓库、报表平台设计研发等经验者优先，有SAS编程经验者优先。?
岗位职责：
1、具备独立完成某一报表开发及数据开发的能力；?
2、具备良好的解决问题的能力，工作认真细致，积极主动，责任心强。"
"职位描述：
        
        岗位职责：
1、负责数据仓库模型的需求分析、建模；运用BI工具，根据场景需求、投递BI数据需求，研发可视化界面。 ? ? ? ? ? ? ? ? ? ?
岗位要求：
1、本科及以上学历，5年以上经验，至少2年BI工作经验 ?
2、熟悉掌握：Qlikview ?Tableau Cognos等精通： ? ? ? ? ? ? 3、数据仓库架构及远离，能进行数据仓库数据模型的设计、开发、精通Python ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 4、熟练掌握hadoop+spark+hase大数据平台构建、使用"
"职位描述：
        
        会数据库和报表开发。数据采集，能快速融入开发任务
1：做过一年以上JAVA开发
2：大数据项目有一年以上的工作经验
3：熟悉hive，spark组件"
"职位描述：
        
        1.? 计算机相关专业本科及以上学历，5年以上大数据工作经验,有扎实的计算机理论基础；2.? 熟练使用MapReduce、Spark提供的API编程，具备海量数据加工处理（ETL）相关经验；3.? 熟练使用大数据的工具平台，熟悉Hadoop生态环境，对Hadoop、Spark、Storm、HBase、Hive等至少一个项目有着深入了解；4.? 掌握数据分析的基本流程，具备数据采集、清洗、分析等环节的实战经验；可以进行数据产品ETL需求的调研及开发；5.? 熟悉ETL任务调度及管理；6.? 熟悉Shell命令，进行简单的Shell编程；熟悉Linux文本处理命令，VI、AWK、Sed等命令7.? 熟练使用Hadoop或其他分布式平台的一种，能使用Java、Python或其他语言编写MapReduce进行大数据处理优先；8.? 有大型金融项目经验者优先。"
"职位描述：
        
        职位描述：
负责数据仓库模型架构设计和实施；
完成各种面向业务目标的数据分析模型的定义和应用开发；
逐步构建基于用户行为、喜好的标签系统，并应用于相关的个性化系统和业务分析中；
?
1、本科及以上学历，计算机、数学及相关专业，4年以上经验,互联网经验3年以上；
2、具有丰富的数据开发经验，对数据处理、数据建模、数据分析等有深刻认识和实战经验；
3、熟悉主流的大数据产品和数据分析技术并具有相关项目经验；
4、有大数据分析与数据仓库设计及开发经验；
5、熟悉主流的开源大数据产品，如spark, Hbase, HIVE 等；
6、熟悉数据仓库相关技术，有互联网数据仓库搭建经验更佳；
7、积极乐观、诚信、有责任心，具备强烈的进取心、求知欲及团队合作精神。
有以下2条件者加分：
有数据挖掘算法实施经验，熟练掌握大规模数据挖掘、机器学习，有实际开发经验者更佳；。
有大型数据项目经验优先，有用户行为分析、用户建模、业务建模经验者优先。"
"职位描述：
        
        岗位职责：
1、对销售数据、市场数据，用户行为数据等进行搜集、分析和整理，撰写和汇总分析报告，为业务部门提供精准的数据支持与理论依据；
2、负责业务报表的开发和维护，并能及时响应Ad-hoc的数据及分析需求；
3、能根据业务特性协助在olap层搭建数据分析平台，提高数据性能及分析时效；
4、开发机器学习模型和数据产品，追踪反馈及文档整理。
岗位要求：
1、2-5年互联网/金融行业/电子商务相关经验；
2、2-5年以上数据处理、统计分析或市场调研等相关工作经验；
3、精通Oracle/SQL，Hadoop Hive/impala，Python，R，Tableau等系列软件；
4、熟悉数据挖掘和机器学习算法等常用算法，并对机器学习算法和理论有较深入的研究，熟悉常用算法（如决策树、聚类、逻辑回归、关联分析、SVM，贝叶斯等）原理和实现；
5、优秀的数据思维和强烈的数据决策意识，良好的数据敏感度，能从海量数据提炼核心结果，善于用简单语言表述复杂结论；
6、清晰、严谨的逻辑思维能力和分析能力，有敏锐的市场洞察力，良好的沟通和协调能力；
7、思路严谨，具有良好的心理素质及能承受较大的心理压力，良好的团队协作能力。"
"职位描述：
        
        工作职责：1、负责公司BI和数据仓库的搭建；2、参与公司BI和大数据处理方向的技术创新。
应聘要求：1、大专3年或本科2年以上毕业年限。
2、精通DS、KETTLE、ODI、PG等工具，精通PL/SQL，有BI报表开发经验，精通SQL语句，有大数据经验的前面的要求忽略。
3、沟通能力优秀，有责任心，能按时完成项目组安排的工作。
4、有大数据HADOOP，HIVE，python等经验优先考虑
5、有金融项目经验、大公司大项目经验优先考虑。
6、具备良好的学习能力、分析和解决问题能力；7、具有高度的责任心和团队合作精神;8、有快速学习，运用新技术的能力。优先考虑项：1、带过团队负责过BI项目的优先。"
"职位描述：
        
        1.大专2年毕业年限
2.1年以上HIVE或者sqoop或hadoop等大数据开发经验
3.项目中有使用过oracle数据库，熟练使用sql
4.到岗时间10天以内
5.能接受在福田区会展中心上班的距离
6.稳定性强，良好的沟通协调能力。"
"职位描述：
        
        职位描述：
1、负责实时数据流应用系统开发，包括流数据处理、查询统计和分析预测等在线计算服务；
2、善于发现系统的性能瓶颈、设计缺陷，提出改进方案并实施；

职位要求：
1、掌握分布式实时流处理框架的底层工作原理，深入使用过某种流数据处理技术，如Spark Streaming、Flink或Storm，熟悉Flink的优先；熟悉并理解kafka工作原理；
2、熟悉并使用过NoSQL数据库，包括redis,hbase等开源存储；
3、具有快速定位和解决问题的能力；
4、具有强烈的责任心，良好的沟通、学习能力，良好的团队合作意识，勇于接受技术挑战。"
"职位描述：
        
        1.大专2年毕业年限
2.1年以上HIVE或者sqoop或hadoop等大数据开发经验
3.项目中有使用过oracle数据库，熟练使用sql
4.到岗时间10天以内
5.能接受在福田区会展中心上班的距离
6.稳定性强，良好的沟通协调能力。"
"职位描述：
        
        有至少2年的大数据开发经验，熟悉大数据相关组件：hive、kafka等。有一定的java开发经验，有oracle编程，有存储过程编写经验，oracle sql性能优化技能优先。"
"职位描述：
        
        有至少2年的大数据开发经验，熟悉大数据相关组件：hive、kafka等。有一定的java开发经验，有oracle编程，有存储过程编写经验，oracle sql性能优化技能优先。"
"职位描述：
        
        岗位职责：
1、 负责大数据业务需求开发；
2、 负责大数据平台系统设计和开发；
3、 参与数据平台的监控、维护及优化。
?
基本要求：
1、 计算机相关专业本科及以上学历，2年及以上数据开发经验；
2、 精通Hadoop相关技术，包括Mapreduce，Hive，Spark，Storm等；
3、 熟悉shell，python等至少一种脚本语言使用；
4、 对大数据技术和开发有热情，工作认真负责，有较强的学习能力和团队合作意识；
5、 有实时计算平台开发或NoSQL工作经验者优先。"
"职位描述：
        
        岗位要求：?
1、3年以上javaPython开发经验，2年以上大数据开发经验；本科以上学历计算机、数学、信息管理相关专业；?
2、熟悉hadoop大数据生态圈大部分框架的搭建、应用、优化（如Spark、Mapreduce 、Sqoop、Kafka 、Hdfs、Hive、hbase等）；?
3、熟练使用Linux、Unix等操作系统具备编写shell的能力；熟悉SQL和noSQL数据库的设计和开发
4、深刻理解大数据处理（流计算，分布式计算，分布式文件系统，分布式存储等）相关技术和实现方法；?
5、熟悉主数据、元数据、数据质量等企业数据管理相关的体系和方法；?
6、熟悉使用ETL工具的使用优先；具有统计学、数据挖掘、机器学习理论优先；有丰富的java开发经验和互联网背景优先；?
7、强烈的主动性与工作责任心，对所负责工作有owner意识，并能自我驱动不断成长；


岗位职责：负责客服机器人或金管家机器人报表体系搭建及开发，专项需求分析需求，数据库库等日常维护
任职资格：1、熟悉数据仓库架构、熟悉Hadoop平台BI项目的实施流程，有大数据技能（sqoop、hive、spark）更优；2、精通Oracle常用函数、分析函数，熟练使用SQL完成业务需求；3、熟练使用PL/SQL编写存储过程，能看懂Oracle执行计划，会使用hints进行SQL性能优化； 4、熟练使用python4、热爱技术研究，逻辑性强，善于学习以及和项目关联方沟通合作；5、工作年限大专5年或本科3年；"
"职位描述：
        
        岗位职责：

 基于海量用户行为数据，建立、评估、持续优化数据模型，包括但不限于：用户价值评分、用户风险评分、用户偏好预测 、用户画像构建等等，产出用户标签。2. 负责标签体系规划和制定、标签的设计和开发、标签产品的构建。3. 促进标签产品在公司各业务领域的应用，持续提升用户产品体验，并探索新的商业模式。


任职要求：
1. 本科及以上学历，计算机或数学相关专业，工作6年以上；2. 精通hive sql,spark sql，spark上的JAVA开发3. 有2年以上用户画像构建和应用实战经验，有数据挖掘实践经验，擅长从海量数据中发现有价值的规律。4. 思维清晰敏捷，逻辑分析能力强，具有良好的语言和书面表达能力；5. 自我驱动能力强，踏实勤勉，对有挑战的问题充满激情。6. 有10人以上的项目管理经验；7. 有大型互联网公司或保险行业背景优先。"
"职位描述：
        
        工作职责:
1.? 负责数据集市和数据仓库的代码开发，完成从业务需求到数据实现的开发工作。
2.? 负责数据集市和数据仓库的代码调优，完成日常数据加工逻辑的运维调优。
任职要求:
1、丰富的数据架构规划、数据建模、数据库设计以及程序设计、开发经验
2、2年以上Hadoop分布式平台项目、数据仓库项目经验；
3、数据解决方案或数据架构（数据仓库、数据集成、数据管理）构建经验；
4、熟练掌握hive、oracle任意一种大数据处理语言;
5、熟练掌握shell脚本开发；
6、性格积极乐观，主动性和执行力强，有良好的沟通能力，抗压能力，有强烈的学习/技术研究能力和良好的团队精神；
7、有cognos报表开发经验优先；
8、有python开发经验优先；"
"职位描述：
        
        1.计算机相关专业，3年以上计算机行业开发经验； ? 2.熟悉数据仓库理论和一些建模知识。 ? 2.熟悉常用的报表工具：Cognos，Tableau，Pentaho等 ? 3.熟悉ETL工具：Datastage，Kettle, Informatica Powercenter等 ? 4.精通使用Oracle，MySQL等关系型数据库，熟悉SQL编写，存储过程编写以及海量数据的SQL查询优化 ? 5.最好熟悉Hadoop Hive的数据处理开发。 ? 6.良好的逻辑思维和沟通表达，工作积极负责 ? 7. 责任心强，自我驱动型，具备良好学习、沟通能力及团队协作精神；"
"职位描述：
        
        1、熟悉数据仓库架构、熟悉Hadoop平台BI项目的实施流程；
2、精通Oracle常用函数、分析函数，熟练使用SQL完成业务需求；
3、熟练使用PL/SQL编写存储过程；?
4、熟悉hadoop，熟练使用hive；"
"职位描述：
        
        1. 熟练掌握SQLSASR等（最基本技能SQL跟SAS要很熟练）2. 比较熟练hive和 Oracle及报表开发系统3. 对数据采集及报表开发工作理解比较深刻4. 有过报表搭建（如：宽表搭建、报表开发、报表加工等）经验者优先5. 责任性比较强，服从安排，沟通思维敏捷，沟通技巧比较强"
"职位描述：
        
        岗位职责：

 基于海量用户行为数据，建立、评估、持续优化数据模型，包括但不限于：用户价值评分、用户风险评分、用户偏好预测 、用户画像构建等等，产出用户标签。2. 负责标签体系规划和制定、标签的设计和开发、标签产品的构建。3. 促进标签产品在公司各业务领域的应用，持续提升用户产品体验，并探索新的商业模式。


任职要求：
1. 本科及以上学历，计算机或数学相关专业，工作6年以上；2. 精通hive sql,spark sql，spark上的JAVA开发3. 有2年以上用户画像构建和应用实战经验，有数据挖掘实践经验，擅长从海量数据中发现有价值的规律。4. 思维清晰敏捷，逻辑分析能力强，具有良好的语言和书面表达能力；5. 自我驱动能力强，踏实勤勉，对有挑战的问题充满激情。6. 有10人以上的项目管理经验；7. 有大型互联网公司或保险行业背景优先。"
"职位描述：
        
        职位描述：1个，（男生）希望有Hadoop程序经验的最好负责数据仓库模型架构设计和实施；完成各种面向业务目标的数据分析模型的定义和应用开发；逐步构建基于用户行为、喜好的标签系统，并应用于相关的个性化系统和业务分析中；?1、本科及以上学历，计算机、数学及相关专业，5年以上经验,互联网经验3年以上；2、具有丰富的数据开发经验，对数据处理、数据建模、数据分析等有深刻认识和实战经验；3、熟悉主流的大数据产品和数据分析技术并具有相关项目经验；4、有大数据分析与数据仓库设计及开发经验；5、熟悉主流的开源大数据产品，如spark, Hbase, HIVE 等；6、熟悉数据仓库相关技术，有互联网数据仓库搭建经验更佳；7、积极乐观、诚信、有责任心，具备强烈的进取心、求知欲及团队合作精神。有以下2条件者加分：有数据挖掘算法实施经验，熟练掌握大规模数据挖掘、机器学习，有实际开发经验者更佳；。有大型数据项目经验优先，有用户行为分析、用户建模、业务建模经验者优先。"
"职位描述：
        
        工作职责：(偏数仓方向）
1.进行数据仓库模型设计、ETL程序开发。
2.根据业务需求，开发和设计数据报表和BI前端展现。
3.参与数据产品的数据开发和调优工作。
4.参与大数据处理，算法实施的工作。

任职要求：
1. 有2年以上数据仓库项目后台开发经验，熟悉数据仓库概念和数据仓库项目的实施流程；
2. 熟悉MYSQL、HIVE等数据库开发，熟练编写PL/SQL存储过程，熟悉海量数据处理及性能优化；
3. 熟悉ETL数据处理流程以及ETL的调度流程；
4. 具备较强的数据分析能力，熟悉BO、COGNOS、SSIS等前端展现工具优先；
5. 熟悉linux 操作系统，至少熟悉一种脚本语言shell/phython/java/R语言。
6. 对业务有强烈的好奇心，相信数据能够提升业务。"
"职位描述：
        
        岗位职责：
1、 负责大数据业务需求开发；
2、 负责大数据平台系统设计和开发；
3、 参与数据平台的监控、维护及优化。
?
基本要求：
1、 计算机相关专业本科及以上学历，2年及以上数据开发经验；
2、 精通Hadoop相关技术，包括Mapreduce，Hive，Spark，Storm等；
3、 熟悉shell，python等至少一种脚本语言使用；
4、 对大数据技术和开发有热情，工作认真负责，有较强的学习能力和团队合作意识；
5、 有实时计算平台开发或NoSQL工作经验者优先。"
"职位描述：
        
        职位描述：
1、负责实时数据流应用系统开发，包括流数据处理、查询统计和分析预测等在线计算服务；
2、善于发现系统的性能瓶颈、设计缺陷，提出改进方案并实施。
职位要求：
1、掌握分布式实时流处理框架的底层工作原理，深入使用过某种流数据处理技术，如Spark Streaming、Flink或Storm，熟悉Flink的优先；熟悉并理解kafka工作原理；
2、熟悉并使用过NoSQL数据库，包括redis,hbase等开源存储；
3、具有快速定位和解决问题的能力；
4、具有强烈的责任心，良好的沟通、学习能力，良好的团队合作意识，勇于接受技术挑战。"
"职位描述：
        
        
工作内容：
1、负责业务需求的沟通评估、设计；
2、根据需求进行数据仓库建模；
3、负责离线和实时大数据开发及管理工作；
4、生产问题及日常任务调度问题处理、临时数据采集支持。?

任职资格：
1.计算机科学、软件工程及相关专业本科及以上学历;
2、熟悉Hadoop生态圈、Mapreduce工作机制；
3、精通hive数据库，具备数据仓库建模能力，能熟练进行HQL查询优化；
4、熟悉Oracle数据库，熟练使用DataStage、cognos开发工具；
5、有大数据实时处理产品产出者优先；
6、能接受加班，主动性强愿意自学提高自身技术水平；"
"职位描述：
        
        1、 使用大数据相关的技术（HIVE，hadoop，hdfs）解决业务相关问题；
2、 利用大数据平台实现对数据的分析和处理；
3、 负责各类离线系统的业务调研，并与公司其他部门负责沟通协调；
4、 负责协助完成离线系统中数据上下层衔接处理工作；
5、 负责各类离线系统数据的开发、部署等工作"
"职位描述：
        
        岗位职责：1、 负责大数据业务需求开发；2、 负责大数据平台系统设计和开发；3、 参与数据平台的监控、维护及优化。?基本要求：1、 计算机相关专业本科及以上学历，2年及以上数据开发经验；2、 精通Hadoop相关技术，包括Mapreduce，Hive，Spark，Storm等；3、 熟悉shell，python等至少一种脚本语言使用；4、 对大数据技术和开发有热情，工作认真负责，有较强的学习能力和团队合作意识；5、 有实时计算平台开发或NoSQL工作经验者优先。"
"职位描述：
        
        职位描述：1、负责实时数据流应用系统开发，包括流数据处理、查询统计和分析预测等在线计算服务；2、善于发现系统的性能瓶颈、设计缺陷，提出改进方案并实施；职位要求：1、掌握分布式实时流处理框架的底层工作原理，深入使用过某种流数据处理技术，如Spark?Streaming、Flink或Storm，熟悉Flink的优先；熟悉并理解kafka工作原理；2、熟悉并使用过NoSQL数据库，包括redis,hbase等开源存储；3、具有快速定位和解决问题的能力；4、具有强烈的责任心，良好的沟通、学习能力，良好的团队合作意识，勇于接受技术挑战。"
"职位描述：
        
        岗位职责：
1.负责大数据平台的数据接入、存储、检索、查询
2.参与基础数据的整理与分析
3. 负责在特定应用下大数据平台整体的集群搭建、性能评估与优化
4.负责大数据平台与多个应用对接的接口和框架设计
5.负责大数据层面相关业务的开发?
?岗位要求：
1. 计算机或数学相关专业大学本科及以上学历
2.2年以上大数据开发经验，3年以上DBA经验
3.熟悉Linux开发环境，熟练掌握Java/Scala?/Python其中一种或者全部语言的开发?
4. 熟悉DB2 UDB、Oracle 、SQL Server等一种或多种数据库，熟悉SQL、PL/SQL语言
5. 熟悉Hadoop生态圈开源技术，包括HDFS、Spark、Kafka、ZooKeeper等
6. 熟悉Spark、Strom、Flink等，有文本分析、机器学习相关经验者优先
7. 熟悉ETL系统，有日志采集，数据同步，ETL系统建设以及处理经验
8. 有Gb/s级别实时数据处理经验者优先"
"职位描述：
        
        工作职责：1、EDA/BI项目开发2、大数据项目设计和需求方案岗位要求：1、计算机等相关专业本科以上学历 ；2、具有电信行业数据仓库项目经验，数据模型设计经验；3、至少熟悉或了解hadoop、oracle、DB2、sybaseIQ一种或以上的数据库语法/操作，并具有1年以上使用或项目实践经验；4、至少熟练使用shell，python，perl一种或以上脚本语言；5、具备大数据应用需求分析能力及数据库基础知识优先；6、有电信行业大数据/经分/BI项目实施经验者优先7、具备良好的沟通能力，团队协作能力"
"职位描述：
        
        工作职责： 1. 大数据平台业务作业的开发，维护，优化和升级 2. 负责处理平台Hadoop/Hive/spark/kafka等疑难问题的研究和解决  3. 负责数据平台业务代码的编写 4. 根据业务需求开发各类工具  工作要求： 1. 计算机、数学或者统计学相关专业本科以上学历 2. 三年以上java开发经验，编程基础扎实，掌握常见的设计模式，掌握基本的数据结构及算法，一年以上hadoop或大数据生态系统开发经验 3. 熟悉MR/spark/pig/hive/hbase/kafka等，有spark streaming流式处理开发经验更佳 4.主人翁意识强，积极主动，善于团队协作，主动思考，自我驱动力强"
"职位描述：
        
        
1.计算机及相关专业本科以上学历。2.对技术有追求，扎实的Java语言基础，3年以上大型分布式计算平台的使用和并行算法的研发经验，2年以上大数据平台架构和研发经验；熟悉软件项目管理、敏捷管理方法论，在中大型项目中有所实践。?3.熟悉大数据相关组件如：Hadoop/HBase/ZK/Spark/Hive/Kafka/Storm/Flink/ElasticSearch等的架构和内部技术细节，具有研发和定制优化能力。?4.优秀的团队合作能力和沟通能力，在技术方面有前瞻性视野，学习能力强，有创新思维，对数据技术和业务发展有高度敏感性。抗压力强，有责任心，心态开放，思路清晰。有国际化背景以及大数据架构研发经验者优先。5.有客户画像、图计算、图数据库优先、机器学习等经验者优先；"
"职位描述：
        
        
大数据开发工程师

1.计算机及相关专业本科以上学历。2. 扎实的Java/python语言基础，3年以上Java/python开发经验，2年以上大数据相关开发经验, 熟悉大数据相关组件技术Hadoop/HBase/Spark/Hive/Kafka/Storm/Flink/ElasticSearch等。

3.有分布式大数据平台开发经验，对CDH/HDP等大数据集群的应用和调优有一定的经验。4.有较强的责任心，良好的组织协调能力、优秀的团队合作能力、沟通能力、分析报告撰写能力，有强烈的学习能力和创新应用能力。

5.在技术方面有前瞻性视野，学习能力强，有创新思维，对数据技术和业务发展有高度敏感性。"
"职位描述：
        
        数据开发工程师
职位描述：
1、负责公司各平台系统数据的接入与整合工作，参与构建基础数据仓库和元数据管理，进行各类业务指标和用户行为分析等的数据处理和统计工作。
2、负责或参与如下工作: 数据产品的研发, 包括但是不限于数据的收集, 转化, 存储, 展示;
3、负责精准医疗类、医疗辅助决策类数据产品的设计和维护, 开发可靠, 高效准确的数据应用, 并提供技术支持;
4、维护和升级数据仓库基础设施；

任职条件：
1、本科以上学历，并有实际项目经验；
2、熟悉MYSQL及至少一种主流关系型数据库，懂数据库优化者优先；
3、熟悉SQL开发，良好的SQL语句功底，了解数据分析的基本方法和常见问题；
4、熟悉常规数据ETL工具使用及配置，有过实际的ETL开发经验；
5、熟悉数据仓库的建设和维护，有过实际的数据仓库建设的建设经验；
6、符合以下条件者优先:?
? ?有良好的SQL语句功底，有SQL调优经验，熟悉Python，对数据结构和算法设计有较为深刻的理解；
? ?有java或web开发经验者优先；
? ?有过DBA经验者优先；
? ?参与过企业级数据仓库的设计和实现；
? ?有大数据分析平台, 任务调度系统, 风控系统其中之一开发经验。"
"职位描述：
        
        岗位职责：
1、负责大数据平台的数据接入、存储、检索、查询
2、参与基础数据的整理与分析
3、负责在特定应用下大数据平台整体的集群搭建、性能评估与优化
4、负责大数据平台与多个应用对接的接口和框架设计
5、负责大数据层面相关业务的开发

岗位要求：
1、计算机或数学相关专业大学本科及以上学历
2、2年以上大数据开发经验，3年以上开发经验
3、熟悉Linux开发环境，熟练掌握Python，有Java/Scala开发经验者优先
4、熟悉DB2 UDB、mysql 、SQL Server等一种或多种数据库，熟悉SQL、PL/SQL语言
5、熟悉Hadoop生态圈开源技术，包括HDFS、Spark、Kafka、ZooKeeper等
6、熟悉Spark、Strom、Flink等，有文本分析、机器学习相关经验者优先
7、熟悉ETL系统，有日志采集，数据同步，ETL系统建设以及处理经验
8、有Gb/s级别实时数据处理经验者优先"
"职位描述：
        
        职位描述1、负责大数据平台（Hadoop/Spark/Kafka/Hive/Presto/Impala/Oozie/Sqoop等）的系统规划与优化、故障处理、集群监控等工作；2、为项目开发人员提供大数据技术指导及解决大数据平台应用中遇到的技术难题；3、解决规模增长带来的技术和业务问题，确保大数据平台高效完成公司的数据任务工作。职位要求1、具备3年以上相关研发经验，计算机相关专业本科及以上学历；2、精通Hadoop生态圈相关的主流产品，有TB级生产项目经验；3、精通Java/Python，精通MapReduce，熟悉linux环境；4、熟悉主流数据库技术（如Oracle、MySQL、MangoDB、Redis等），并熟悉SQL开发。5、良好的沟通能力、逻辑思维能力以及学习能力；"
"职位描述：
        
        团队介绍】
执御是中国领先的出海移动电商平台，旗下的购物APP JollyChic已经成为了中东地区知名度最高，综合排名第一的购物APP，覆盖全球多个国家和地区，注册用户已超过二千万人，业务的快速发展积累了丰富的数据。
大数据与AI部是一个以数据及数据技术为本、人工智能为核心引擎、专注于数据价值的泛“数据”团队，负责建设整个集团的大数据基础设施和AI落地，部门核心人员来自美国知名大学教授以及多名前阿里云/淘宝的高级技术专家，期待和您一起玩数据、玩AI！
-----------------------------------------------------------------

职位描述：
1. 负责公司海量数据的分析和处理；
2. 参与公司的大数据项目；

任职要求：
1. 具备1年及以上相关研发经验，重点大学计算机相关专业本科及以上学历，该职位的资深岗位要求3年及以上工作经验；
2. 具备扎实的计算机系统知识，至少掌握Java/Python/C++其中一门编程语言，熟悉Linux环境；
3. 具有Hadoop/Hive/Spark/流式计算等开发经验，具备海量数据处理和性能调优经验；
4. 熟悉数据仓库、机器学习算法等，有相关研发经验者优先；?
5. 具备良好的沟通能力、逻辑思维能力以及学习能力；
6. 有知名互联网公司大数据项目开发经验者优先。"
"职位描述：
        
        一、岗位职责：1.协助项目部门分析城市照明数据；2.与其他同事一起建立起城市照明系统的数据仓库。二、岗位要求：1.统计、数学、计算机等与数据相关的本科学历；2.对数据非常敏感，对大数据方向感兴趣者优先；3.会写SQL，熟悉Python或者R语言优先；4.对数据仓库感兴趣者优先。"
"职位描述：
        
        岗位描述
1.参与大数据精准学平台设计与研发，在大数据采集、存储、分析及应用领域都会有所涉及。
2.参与需求分析、系统架构设计、并完成需求设计相应文档的编写。
3.参与核心代码实现、系统性能优化。
4.保质保量地完成项目组分配的开发任务。
5.协助项目经理进行技术支持工作，共同解决产品研发过程遇到的技术难题。
任职要求：
1. 具备3年及以上大数据系统开发经验，计算机相关专业本科及以上学历；
2. 有实时流处理经验，掌握Flink、Storm等实时处理框架；?
3. 熟悉并会使用spark mllib、机器学习、自然语言处理等相关技术和算法；
4. 具有Hadoop/Spark，以及kafka、flume、hbase、hive、zookeeper等大数据生态圈实际开发经验。深入了解Hadoop/Spark生态圈产品的工作原理及应用场景；
5. 具备较强的数据分析，问题分析，逻辑思维能力，良好的沟通，团队协作能力。"
"职位描述：
        
        岗位职责
1、参与大数据各类底层组件，平台和系统的开发及优化；
2、参与大数据相关上层数据产品和应用开发和推广；
3、对公司各类业务开发团队提供技术支持；
4、跟踪业界技术动态，推动公司大数据相关技术的持续进步；
5、不限以上，具体责范围，岗位适配取决于你的能力大小，欢迎来挑战。

岗位要求
1、本科及以上学历，3年以上工作经验，2年以上大数据领域工作经验；
2、精通java或python至少一门编程语言；
2、精通shell脚本编程，至少熟悉Python或perl等一门语言；
3、熟悉HTTP协议；
4、熟悉HADOOP ／ Hive ／HBase ／ Spark ／Storm ／ Kafka ／ kylin / Druid /postgresql/Mongodb等分布式计算环境进行海量数据分析与计算经验者优先；
5、做过数据仓库，对数据治理、数据标准及元数据有很好理念及实施经验的优先；
6、良好的沟通能力和团队精神,具备创新意识；
7、相关开源领域的活跃贡献者或大型互联网公司相关从业经验者优先。"
"职位描述：
        
        岗位职责：
1.参与项目需求的分析和设计工作；
2.完成软件系统代码的实现，编写代码注释和开发文档；
3.辅助进行系统的功能定义,程序设计；
4.根据设计文档或需求说明完成代码编写，调试，测试和维护；
5.分析并解决软件开发过程中的问题；
6.协助测试工程师制定测试计划，定位发现的问题；
7.完成大数据平台及产品的开发工作；
任职要求：
1、本科及以上，两年以上大数据经验优先；2、熟悉Linux操作系统底层架构；3、精通 Java，Scala编程语言；熟悉Python，Shell编程语言优先；4、精通包含但不限于；Hadoop/Spark/HBase/Hive/Storm/Impala等开源大数据技术；5、熟悉大数据部署平台Ambari；6、熟悉大数据ETL处理过程，具有大数据ETL应用开发经验；7、熟悉Flume+Kafka日志实时采集、数据共享实施经验或具有日志索引分词及搜索实施经验；8、熟悉大数据可视化，具有大数据可视化应用开发经验；9、熟悉K8S、Docker、Golang优先；10、个性开朗，对技术钻研好学、逻辑思维能力强，沟通能力优秀，有团队合作精神。"
"职位描述：
        
        岗位职责：1.?搭建实时计算平台，满足实时报表和实时特征需求2.?为数据分析和实时风控，构建数据处理流程3.?支持业务对数据进行流式处理和用户行为分析任职要求：1.?本科以上学历，3年以上工作经验，有互联网、金融经历者优先；2.?具有Spark平台搭建和开发经验；3.?精通SQL，具有数据仓库和维度建模经验者优先；4.?熟练使用Hadoop、HBase、Hive等大数据平台和数据仓库，具有Map/Reduce开发经验者优先；5.?推荐或机器学习相关的开发工作优先。"
"职位描述：
        
        岗位职责：
1. 利用机器学习方法解决实际业务问题；
2. 根据公司技术战略，确定具体算法方案。
任职要求：
1. 计算机/数学或相关领域学位，统招本科及以上学历；
2. 扎实的算法、编程基础，熟练使用Java、Python中的至少一种编程语言；
3. 熟悉常用的机器学习、深度学习算法，有实践经验者优先；
4. 熟悉并具有使用Scipy，Scikit-learn，TensorFlow或类似框架的经验；
5. 具备良好的代码风格，熟悉版本管理，具有使用Git的经验；
6. 熟悉机器学习，统计学或数值优化；
7. 具备大数据处理能力，有分布式环境下非结构化数据处理经验者优先；
8. 善于学习，思维活跃，乐于挑战，有良好的沟通表达能力和团队精神。"
"职位描述：
        
        岗位职责
1. 利用机器学习方法解决实际业务问题；
2. 根据公司技术战略，确定具体算法方案
?
岗位任职条件：
1. 计算机/数学或相关领域学位，统招本科及以上学历；
2. 扎实的算法、编程基础，熟练使用Java、Python中的至少一种编程语言；
3. 熟悉常用的机器学习、深度学习算法，有实践经验者优先；
4. 熟悉并具有使用Scipy，Scikit-learn，TensorFlow或类似框架的经验；
5. 具备良好的代码风格，熟悉版本管理，具有使用Git的经验；
6. 熟悉机器学习，统计学或数值优化；
7. 具备大数据处理能力，有分布式环境下非结构化数据处理经验者优先；
8. 善于学习，思维活跃，乐于挑战，有良好的沟通表达能力和团队精神；"
"职位描述：
        
        职位诱惑：
免费早午餐,15天年假,早晚班车,发展空间大
? ?
职位描述：
职位诱惑：
15天年假,免费早午餐,数据量大,弹性工作
职位描述：
我们能给你：
丰富+前沿 的技术栈（lambda架构，离线计算、实时计算全覆盖，hadoop、spark、hive、OLAP栈(DRUID kylin)， 有什么酷炫的前沿技术想尝试又一直没有机会尝试？如何进行技术选型和扎实落地？来这里爆发你的潜能！
高速发展的 to C 业务（目前 百亿级 数据量，千万级 设备激活量，数据指数级增长：16年中旬至今，日活/月活以及各种数据量基本都翻了一番还多），现在仍在高速增长中，可以体验业务量从10到100的发展。
数据驱动，数据团队在公司权重很重，目前为CTO直接带队。
良好的内部孵化环境，非常好的技术氛围，敏捷开发/等技术培训，技术书籍专项经费。
执行力强，想象力丰富，扁平化的团队；思维活跃，极客精神，代码洁癖的小伙伴们。

职位描述：
参与基础大数据平台的建设,数据仓库和大数据处理模块的研发；
参与基于Spark技术的海量数据的处理、分析、统计、挖掘工作；
基于hive框架的数据仓库的研发，维护；
根据需求使用Spark Streaming和Spark SQLCore进行数据处理、查询、统计等工作。

职位要求：
3年以上工作经验，2年以上Spark开发经验：熟悉Spark相关技术，有良好的java基础；
熟悉Scala语言，对Scala原理、底层技术有深入研究者优先；
熟悉Spark Streaming和Spark SQL, RDD、DataFrame编程；
有hadoop、hive集群搭建及挖掘经验优先；
了解整个大数据生态圈组件如hdfs、HBase、Hive、Pig、ZooKeeper、kafka、storm等；
对新技术感兴趣，较强的学习能力，有优良的Trouble Shooting能力；
有过海量数据系统开发和数据分析挖掘经验者优先。"
"职位描述：
        
        职位诱惑：
15天年假,免费早午餐,数据量大,弹性工作
职位描述：
我们能给你：
丰富+前沿 的技术栈（lambda架构，离线计算、实时计算全覆盖，hadoop、spark、hive、OLAP栈(DRUID kylin)， 有什么酷炫的前沿技术想尝试又一直没有机会尝试？如何进行技术选型和扎实落地？来这里爆发你的潜能！
高速发展的 to C 业务（目前 百亿级 数据量，千万级 设备激活量，数据指数级增长：16年中旬至今，日活/月活以及各种数据量基本都翻了一番还多），现在仍在高速增长中，可以体验业务量从10到100的发展。
数据驱动，数据团队在公司权重很重，目前为CTO直接带队。
良好的内部孵化环境，非常好的技术氛围，敏捷开发/等技术培训，技术书籍专项经费。
执行力强，想象力丰富，扁平化的团队；思维活跃，极客精神，代码洁癖的小伙伴们。

职位描述：
参与基础大数据平台的建设,数据仓库和大数据处理模块的研发；
参与基于Spark技术的海量数据的处理、分析、统计、挖掘工作；
基于hive框架的数据仓库的研发，维护；
根据需求使用Spark Streaming和Spark SQLCore进行数据处理、查询、统计等工作。

职位要求：
3年以上工作经验，2年以上Spark开发经验：熟悉Spark相关技术，有良好的java基础；
熟悉Scala语言，对Scala原理、底层技术有深入研究者优先；
熟悉Spark Streaming和Spark SQL, RDD、DataFrame编程；
有hadoop、hive集群搭建及挖掘经验优先；
了解整个大数据生态圈组件如hdfs、HBase、Hive、Pig、ZooKeeper、kafka、storm等；
对新技术感兴趣，较强的学习能力，有优良的Trouble Shooting能力；
有过海量数据系统开发和数据分析挖掘经验者优先。"
"职位描述：
        
        岗位职责：

1.参与大数据平台整体架构的规划和设计，包括但不限于数据采集系统，实时分析系统，多业务数据仓库，机器学习等。

2.负责海量用户数据的管理，为数据分析、挖掘等提供强有力的支撑。

3.负责浏览器画像数据相关系统（数据流系统和在线应用系统）的开发，建立数据灰度、ABTest能力。

4.负责数据仓库模型设计，迭代与开发。

5.负责离线、实时大数据存储、计算平台的设计开发和维护工作。6.负责设计基于大数据的各种实时、离线计算，ETL流程设计和开发。? ? ? ??

岗位要求：

1.本科以上学历，计算机相关专业，3年及以上Java EE相关开发经验，1年及以上互联网大数据开发经验。

2.熟悉使用Hadoop（包括HDFS、MapReduce、HBase、Hive等）、Spark集群相关技术进行开发。

3.了解关联分析、分类预测、聚类分析、回归分析、时间序列分析等常用分析方法。

4.具备一定的算法能力，了解一些常见的算法工具，包括但不限于：K-means聚类、神经网络等。

5.熟悉Java、Python，Scalal等一种或一种以上编程语言。

6.熟练使用RabbitMQ/RocketMQ、ElasticSearch等。

7.有较强的技术选型及规划能力、较好的沟通能力、积极主动，愿意接受挑战,有责任心强、良好的对外沟通和团队协作能力。

8.有良好的逻辑分析能力、分析问题和解决问题的能力，对数据敏感。

9.对常见的数据分析模型有一定的了解，有海量数据分析项目经验、数据挖掘项目经验者优先。"
"职位描述：
        
        岗位职责:1.负责用户画像.用户推荐,场景化营销，核保核赔，信保的规则建模。2.参与“BigData/AI/IoT”保险解决方案的需求分析.业务场景创新.客户价值转化.业务价值分析.数学建模.BI/UX.汇报材料制作等工作3.基于各种建模工具（R,SAS,SparkMlib,Python，Matlab,etc），分析挖掘客户转化规律，支持业务决策，提升客户转化率，分析互联网保险各类场景下的客户需求与投保风险4.基于数据分析的基础，数据资源的挖掘.分析.展现，深度挖掘数据价值，建立模型，提升数据的商业应用价值
任职资格:1.统招本科以上学历，数学专业.精算专业毕业。熟悉数理统计分析理论.数据分析原理，掌握常见数据分析工具2.至少三年以上统计分析经验，熟练使用SAS/R/Python/Matlab等工具语言，至少三年以上算法建模经验（LR.RF.GBDT.KernelSVM,Regression,AHP，HMM,TimeSeries），或三年以上人工智能和深度学习领域实际项目经验（NLP,CNN,GraphicModel3.熟练进行数据清洗.数据处理.特征工程，并有实际项目经验4.精通SQL语言，熟悉主流面向对象语言（Java，.net等）5.具备互联网思维，并接纳互联网行业工作模式6.有金融行业经验7.了解敏捷开发流程,有敏捷开发经验者优先8.有咨询背景者优先"
"职位描述：
        
        负责集团大数据平台开发和日常运维管理，整合全集团范围各类数据源，使用ETL工具对数据进行整合、清洗、加工，按照业务主题进行建模，通过数据仓库和Hadoop大数据平台为数据分析应用提供数据产品。"
"职位描述：
        
        技术要求
? ? ? ??本科以上、计算机相关专业，2年以上工作经验
? ? ? ? 熟练使用常用数据库(MySQL,Oracle),对数据仓库,数据立方体,数据湖等概念有较深刻的理解，具有较强的SQL功底。
? ? ? ? 有扎实的大数据理论基础，熟悉hadoop、hive、Hbase、Kafka、spark等
? ? ? ? 至少熟练掌握一种开发语言（java、Scala）
? ? ? ? 掌握linux系统、Oracle/mysql等常用数据库操作
? ? ? ? 了解数据挖掘、机器学习、等概念及使用场景
? ? ? ? 了解决策树、聚类、逻辑回归、关联分析、svm、贝叶斯等算法。
岗位职责描述：

? ? ? ? ? ?参与大数据平台的开发工作
? ? ? ? ? ?公司客户大数据平台的技术支持工作和调优工作
? ? ? ? ? ?对已有的大数据产品进行升级迭代工作
? ? ? ? ? ?对已有的数据分析模型算法进行调优"
"职位描述：
        
        ? 精通 Hadoop（HDFS 和 Yarn）、Hive、Spark 等大数据平台的基础组件
? 具备丰富 Spark Streaming 实时数据流实践经验
? 熟悉大数据平台在操作系统、服务器硬件、网络等方面的部署方案
? 能够持续推进大数据平台在运维方面的自动化
? 精通 Linux Shell，具备 Python/Java/Scala 能力
? 熟悉Tableau 等数据分析展示工具
? 拥有阿里云、腾讯云等主流云服务的大数据模块实践经验
? 具备良好的沟通能力、团队协作能力
-----------------------------------------------------------------------
公司是刚成立不久的创业型公司，主要发展方向是物联网、大数据，智能库房。运用的技术包含嵌入式、RFID、传感器、Web前后台、安卓触屏互动等。我们崇尚硅谷Startup的工作氛围，形塑一个开放、扁平化、不怕挑战的企业文化。"
"职位描述：
        
        岗位职责：1、 负责数据需求的调研及分析，形成技术方案。2、 解决数据处理流程中出现的数据问题。3、 设计数据架构，编写设计文档及映射文档。4、 数据开发代码编写。5、 负责初级数据人员培训及培养。6、 对业务需求的理解，实现业务到数据的实现。7、 配合技术经理完成数据相关的工作任职要求：1、 熟悉主流数据库，如：Oracle、DB2、Sqlserver等，熟练SQL语句的编写及存储过程的编写2、 了解数据仓库基本理念，熟练运用ETL开发工具及主流BI展现工具，如：DataStage、Informatic等，会DataStage优先考虑3、 2年以上金融银行数据开发工作经验，有银行项目开发经验优先4、 了解银行资产负债业务数据情况。5、 良好的沟通能力和独立工作能力，积极主动及良好的团队合作意识与责任心薪资:面谈"
"职位描述：
        
        岗位职责：1、 ETL开发工作，负责ETL工作的设计和开发；2、 报表开发工作，负责相关报表的设计和开发工作；3、 负责与业务部门沟通，确认需求内容，编写需求相关文档；4、 相关操作文档、测试文档等编写；

任职资格：
1、?大学本科及以上学历，计算机相关专业；2、?熟练使用DATASTAGE进行运维、开发；3、?熟练使用SQL语言，至少熟悉Mysql、Oracle其中一个数据库，并进行相关SQL、存储过程、函数等编写工作；4、?有Cognos、SmartBI等工具使用经验者优先；5、?有保险银行行业经验者优先。"
"职位描述：
        
        岗位要求：1.具备2年或以上ETL开发经验；2.熟悉ORACLE基本原理，能熟练使用PLSQL编写ORACLE函数function、存储过程sp及包package；3.具备扎实的ORACLE技术功底，熟练掌握建表、分区、索引、分析函数；4.具备分析执行计划及复杂SQL性能调优能力；5.熟练掌握一至两个ETL开发工具如Datastage、Informatic、kettle优先；6.熟练使用数据仓库调度工具如Moia、Control-M、TASKCTL等。项目介绍：??五条高速公路项目群是CBG，ISC+的战略项目，有IMEI360，SKU360,客户360，合同360，订单可视等项目，主要聚焦与数据底座模型设计，为其他BI系统，业务系统，华为外部系统等提供实时和离线两种模式的数据服务。??数据湖作为华为公司统一数据底座的产品，对公司提供“可信、实时、一致、完整”的数据。数据湖以传统ORACLE与FusionInsight（开源Hadoop）为核心平台架构，依托统一融合的数据平台，全流程拉通公司产品研发制造、供应存储、安装交付多环节数据，增强数据交互，强化数据孪生与价值，自动化、智能化提升公司运作效率。欢迎自荐或者推荐，薪酬高，福利待遇好，岗位要求可直接微信详细了解！（自由时间、班车、一档社保、公积金，每年固定3月份调薪一次，带薪年假5～20天（最低工龄为5天），婚假产假陪产假丧事假、年终奖（满一年为条件），各种员工活动补贴（生日，电影票，购物卡）等。"
"职位描述：
        
        岗位职责：
1.负责实现大数据处理、分析的平台化?
2.根据实际需求，制定系统实现目标、系统实现计划?
3.协调团队成员，齐心协力完成系统建设
任职要求：
1.具有较深的大数据技术栈，熟悉常用的大数据处理组件。?
2.精通大数据ETL处理架构，精通基于hive的数据仓库架构和建设?
3.具有比较扎实的Java开发基础。?
4.熟练掌握Hadoop生态组件，例如：MR、hdfs、spark、hive、hbase等?
5.逻辑思维清晰，有较强的团队协作能力，踏实上进。"
"职位描述：
        
        1、统招本科及以上学历，5年及以上大数据相关工作经验，精通Java/Python服务端设计开发经验；2、具备成熟的系统设计架构能力，丰富的高并发、分布式的系统设计经验；3、熟悉业界先进的大数据生态组件（MR/Spark/HBase/ElasticSearch/ClickHouse），有成熟的系统设计应用经验；4、对新技术保持求知欲，有优良的Trouble Shooting能力；5、熟悉Mysql/Redis/MongDB等系统原理机制以及线上应用经验原则；6、具有优秀的代码治理经验，良好的表达能力和团队协作精神；7、具备知识图谱、算法平台、实时多维分析、搜索可视化经验者优先；8、有大数据产品线上大型系统设计开发/线上算法设计实践经验者优先。"
"职位描述：
        
        工作职责：
1、基于Hadoop/Hive/Spark构建沪江集团与各子公司的数据仓库和数据集市架构；
2、与团队成员设计稳定、可复用、可扩展的数据仓库模型，用户画像数据模型，快速支持公司决策数据需要、各方向数据分析和挖掘需要；
3、构建统一的数据模型建设、管理与治理机制，带领团队确保公司数据一致性，可持续发展；整个数据链路合理，数据计算高效；

任职资格：
1、 本科及以上学历，最少3年以上数据仓库相关工作经验，熟悉数据仓库各类建模理论以及数据仓库数据层级关系，具备大型数据仓库逻辑模型和物理模型设计经验；
2、良好的Hadoop、Hive SQL开发能力和程序调优经验；熟悉实时数据计算，有Java项目经验者优先；
3、熟悉大数据生态，熟练使用大数据工具，如Spark/Kylin/HBase/ElasticSearch/Presto/Storm/Flink等
4、良好的元数据管理、数据质量管理经验；
5、良好的逻辑分析能力、沟通能力；
6、良好的推动力，强烈的责任心、良好的团队协作，乐于沟通交流和分享"
"职位描述：
        
        工作职责：1. 基于开源组件和AWS搭建、维护、持续完善大数据处理系统2. 对海量异源异构数据进行汇总、清洗、聚合，保证数据及时、准确3. 根据业务模型对海量数据进行深入分析，为业务做决策提供高效的数据支持工作要求：1. 计算机或相关专业本科及以上学历，1年以上相关工作经验2. 必须精通一门脚本语言Python/Php/Shell，精通SQL，有C++/Java经验更佳3. 熟悉Linux，有过基于Hadoop/Spark/AWS等的实际大数据项目经验4. 熟悉常用数据分析方法，对数据有足够的敏感度，善于发现数据之间的关联、波动5. 有较强的学习能力、逻辑思维能力、沟通能力和抗压能力"
"职位描述：
        
        岗位职责：?1. 数据集市的架构、设计相关开发建设；?2. 完成项目数据统计与分析任务，包含离线和实时任务，对业务组提供数据支持服务，ETL实施、ETL优化、报表等；?3. 配合产品经理完成数据梳理和技术分析。?岗位要求：?1. 较强的数据库及SQL以及SQL优化能力，熟悉 Hadoop/Spark/Storm/Kafka/Hive/HBase 等大数据相关技术, 具有大数据处理经验；2. 三年以上HIVE数据仓库项目经历，有较强的调优能力(hive调优)；?3. 熟悉Druid、Kylin、Elasticsearch等引擎系统者优先；4. 了解Linux脚本编程，有java、python、scala等编程经验或编程能力加分；?5. 对数据敏感，有较强的逻辑分析能力，对大数据处理和分析技术有强烈热情；?6. 有用户画像目经验和模型设计者优先。"
"职位描述：
        
        工作职责：1.负责汽车金融无抵押业务的数据全流程开发，数据接入/数据生产调度/报表体系等；2.理解业务需求,为业务方提供快速、准确、灵活的数据支持;3.参与对金融数据的规划和治理。任职要求：1、1-3年的数据开发经验，了解数据仓库体系，并支撑过实际业务场景；?2、熟悉linux命令, 具备较强的编码能力，至少掌握hive及python或者java中的一项。3、对数据敏感，工作负责，善于从数据中发现疑点；4、善于沟通，具备优秀的技术与业务结合能力。"
"职位描述：
        
        岗位职责：
1.参与系统的数据需求调研和分析，撰写相关数据映射及数据字典文档
2.搭建系统数据环境，完成系统框架和核心代码的实现；
3.项目概要设计、详细设计、开发计划等的编制并实施；系统开发测试、部署和集成；
4.负责解决开发过程中的技术问题；参与代码维护与备份。

任职资格：
1、计算机或电子相关专业，?3年以上相关工作经验，具备海量数据的DW模型设计与ETL开发经验；
2、熟悉数据仓库领域知识，包括但不局限于：数据质量、元数据管理、主数据管理、数据开发测试工具与方法；
3、熟悉perl开发，有一定SQL性能调优经验；有金融数据处理经验者优先；

4、有良好的沟通能力、文字表达能力和团队合作精神，有快速学习上手的能力。"
"职位描述：
        
        岗位职责：
1.参与系统的数据需求调研和分析，撰写相关数据映射及数据字典文档
2.搭建系统数据环境，完成系统框架和核心代码的实现；
3.项目概要设计、详细设计、开发计划等的编制并实施；
4.系统开发测试、部署和集成；
5.负责解决开发过程中的技术问题；
6.参与代码维护与备份。

任职要求：
1.?全日制院校计算机及相关专业本科以上学历；
2. 2年以上工作经验，具有银行业工作经验者优先；
3.?对Unix/Linux操作系统有初步的了解，具备日常操作的能力；
4.?熟悉Oracle或DB2数据库，能熟练使用SQL语句进行数据库操作；
5.?有Oracle或DB2优化经验，能独立编写高质量的后台实现脚本，能熟练编写存储过程；
6.?为人友善，乐于进取，有较强的学习能力；
7.?有良好的沟通交流能力和团队合作意识；
8.?能吃苦耐劳，并能积极接受出差任务。"
"职位描述：
        
        岗位描述

1、数据仓库的相关需求收集和分析工作;

2、数据仓库的相关设计、开发工作;

3、数据仓库的相关运行支持工作。

岗位要求

1、计算机、信息管理及其相关专业

2、热爱数据仓库工作,具有较强的学习欲望、良好的逻辑和抽象思维能力;

3、善于沟通,独立并积极主动,责任心强;

4、具备扎实的数据库操作经验,熟练掌握存储过程、SQL脚本,能够编写高效的数据库应用者优先;

5、精通Java语言,熟悉J2EE主流技术者优先;

6、熟悉LINUX或UNIX操作系统,具有Shell、PERL等

脚本语言开发经验者优秀;

7、具备大型数据仓库架构设计、模型设计、性能调优、开发经验者优先

无相关经验，但是肯吃苦耐劳努力钻研者也予考虑"
"职位描述：
        
        ? 1）一年以上数据仓库开发工作经验；熟悉SQL等编程语言，熟悉数据仓库开发流程和相关理论知识； ??
? ? ?2）有模型设计和TD开发经验者优先；有银行业务系统的开发经验优先
? ? ?3）工作踏实认真、责任心强，具备良好的学习能力，能够承受工作压力；
? ? ?4） 具备良好团队协作精神及沟通能力。"
"职位描述：
        
        工作职责:1、负责基于大数据技术的业务系统开发2、大数据平台搭建与常见问题解决、性能调优以及日常维护3、大数据领域技术并分享，提升团队技术能力
任职资格:1、有3年以上的Java开发经验，2年以上的大数据开发经验2、熟悉Hadoop、Spark、HBase、Yarn、Storm、Kafka等大数据组件3、 熟悉Mysql、Elasticsearch4、能够熟练使用scala语言进行开发5、 有支付行业工作经验优先6、有数据仓库建设经验者优先"
"职位描述：
        
        一、岗位工作范围和职责：1、负责海量(最高万亿级别)数据的分析、处理、开发工作；2、根据业务需求，负责算法模型的建立和实现，配合项目经理进行技术决策和风险评估，协助项目经理完成项目前期工作计划制定；3、参与公司大数据平台上业务应用的功能设计及架构规划，负责公司大数据平台相关产品的设计，开发、文档撰写和项目改进 。二、专业知识和技能要求：1、 本科及以上学历，计算机、应用数学、人工智能、模式识别、自控、统计、运筹学专业，具备扎实的数据结构和算法功底；2、 熟悉常用数据挖掘算法（聚类、分类、回归、关联规则、图模型）等算法及原理，具备实际的建模经验；熟悉常用机器学习算法原理，如朴素贝叶斯，决策树/随机森林，Logistic回归，SVM等，并具备相关应用经验；3、 熟悉hadoop、spark分布式计算平台，并具有基于Spark的实际开发经验；4、 熟悉或精通Java/Scala编程语言，编码能力强悍，良好的编码习惯，简练的编码风格；5、 极强的数据敏感度，能从海量数据中挖掘出数据核心价值；6、 严密的数学思维、突出的分析归纳能力和表达能力；7、有自然语言处理经验者，有cnn、rnn、lstm、dbn等深度学习实战经验者优先考虑。8、 富有创新精神，充满激情，乐于接受挑战，良好的沟通技巧和团队合作精神。三、公司福利：1、全年年收入约14.5个月工资，另外约有1.2万左右的现金福利；2、六险一金，员工年度健康福利体检；其中住房公积金按照月度工资总额的12%购买；3、五天7小时工作制，带薪年假、各类法定节假日、有薪假及出差探亲假等；4、各类过节福利、节日礼品、生日礼品、慰问品等；5、差旅费、差旅津贴、业务招待费、通讯补助、用餐补助、保密补贴等；6、每月不定期暖心下午茶，部门不定期旅游、聚餐；7、公司设有健身房、篮球场、乒乓球室、壁球室等休闲设施，并定期组织各类业余活动。"
"职位描述：
        
        岗位职责：
1. 负责知识图谱数据建模、处理加工工作；；
2 负责知识图谱数据建模、处理加工工作；；
3. 专注于流式计算、分布式计算、数据挖掘、分析建模等技术，从事大数据技术研究和开发工作；
4. 参与数据挖掘算法、机器学习其他方面的工作，全面发展；

岗位要求：
1. 统招本科及以上学历，四年以上大数据工作经验，计算机相关专业，具有金融行业项目经验者优先；
2. 熟悉spark granpx或者flink graph等图计算技术，有知识图谱建模经验者优先；
3. 至少熟悉一种图数据库，如neo4j、orientDB、arangoDB、titan等；
4. 有Hadoop / Spark / Hive / Presto / HBase / Kylin / Impala / Kafka / Flink / Storm/ Redis等使用经验和架构设计、部署经验，熟悉上述常用的分布式系统的原理；
5. 有生产环境快速trouble-shooting的经验和能力，擅长分析比较复杂和深层次的原因；
6. 熟悉使用Java/Python/Scala至少一种开发语言；熟悉Linux操作系统；
7. 能够独立承担任务，责任心强，重视团队合作，工作态度积极，勇于进取，抗压能力好；
8. 有OLAP，多维度数据分析、BI系统开发经验优先，对数据仓库有较强的理论基础和理解
9、3年以上大型互联网产品或分布式系统开发设计经验者优先。"
"职位描述：
        
        任职要求：1、3年以上软件开发经验,至少有一个成功项目经验。 2、熟悉java/scala语言,深入理解面向对象编程和函数式编程的思想 3、有大数据经验，熟悉Kafka、sparksql,Spark Streaming、Hive 4、掌握Linux开发环境,能够编写常见的shell脚本或者python 5、精通sql，熟悉mysql、oracle等主流数据库 6、良好的文档撰写习惯，良好的文字表达能力 7、有强烈的求知欲，优秀的自我学习能力，熟悉流行的开源项目 8、工作积极主动，具有强烈的责任心、事业心，具有良好的沟通能力、团队配合精神"
"职位描述：
        
        岗位职责：
1、负责大数据实时平台的开发工作
2、参与业务数据、生产日志的抽取、转储、计算、检索等相关开发工作
3、保证实时接入体系稳定性及扩展性

任职要求：
1、计算机或相关专业本科及以上学历
2、熟悉Linux/Unix开发环境，2年以上大数据开发经验，3年以上JAVA开发经验
3、熟悉常用开源分布式系统，对Flume/Cannel/Kafka/Spark/Flink/HBase/ES中的一项或多项有深入了解，能够独立排查及解决分布式系统的问题
4、具备较强编程能力、学习能力、良好的团队精神和合作意识"
"职位描述：
        
        岗位职责：
1、独立完成项目经理分配的功能模块开发；
2、参与数据挖掘特征提取、整理、数据分析工作；
3、完成常用项目文档的编写,公司门户网站的维护及更新；
4、参与日常项目的巡检。
5、可配合技术支持部门或者客户完成简单问题的定位、分析。
任职资格：
1、计算机相关专业本科及以上学历；
2、深厚的Java功底，5年以上的并发编程经验；对jvm垃圾回收有深入、熟悉java虚拟机高优，精通多线程编程，熟悉NIO、反射等技术
3、参与过分布式高性能服务的设计开发过程，有大规模分布式系统的实践经验；
4、精通Hadoop各个模块的功能，熟悉HDFS/HBase/Hive/MapReduce/Storm/Spark等相关技术,有？MapReduce？程序的实战开发经验；
5、熟悉Hadoop、hbase、zookeeper等运行监控及调优技术；
6、熟悉常见存储技术（Oracle,？Mysql,？NosqlDB），WebService（Json/SOAP）；
7、日处理百亿级数据经验者优先考虑。"
"职位描述：
        
        岗位职责：1、参与并主导公司大数据开发平台/大数据分析系统的设计、开发；2、调研各个大数据开发线对大数据开发平台/大数据分析系统的需求，并形成整体的技术体系架构；3、参与公司级别的数据中台建设和规划；4、参与量化编程平台的规划和建设。任职要求：1、计算机相关专业硕士及以上学历；2年以上相关工作经验；2、熟悉Python或JAVA或Go或Scala等语言或熟悉HiveImpala等SQL语言，熟悉Linux操作系统，熟悉Spark、Hive或Impala，熟悉HDFS、Yarn等Hadoop技术栈基本原理，对大数据调度系统有一定的了解；3、对数据血缘解析、调度系统、Spark开发系统建模等有一定的了解。"
"职位描述：
        
        工作职责:1、利用数据能力帮助永辉新零售业务的发展;2、负责云创企业级数据仓库的ETL设计和开发工作，;3、专注于数仓模型优化、ETL优化等工作,保障数仓的应用能力;4、专注于数仓开发流程化的优化,提升数仓开发的效率;5、专注于新技术探究，目标完成实时数仓和批流统一的构建和推广使用;
任职资格:1、计算机相关专业统招大专及以上学历, 5年以上工作经验;2、熟练掌握python、scala、shell等函数式编程语言;3、熟练掌握分布式计算框架hadoop、spark、hive、presto等;4、至少熟练掌握开源的datax、sqoop中1种及以上的ETL工具;5、熟练掌握azkaban、airflow等开源调度工具;6、熟练使用git代码管理工具;7、有企业级数据仓库搭建、优化、开发等经验的优先;8、有新零售行业经验的优先;"
"职位描述：
        
        职位描述：
1. 针对市场需求和客户痛点，负责数据库相关产品和解决方案的规划、架构设计以及从市场需求到技术需求的转化和分解，提供有竞争力的解决方案功能和技术特性；
2. 负责数据集市相关解决方案与周边产品和解决方案的集成，支撑业务方向的落地，并负责完成架构的落地；
3. 负责跟踪大数据相关领域的技术趋势，竞争对手的产品、技术动态；
4. 参与大数据相关产品、解决方案的战略规划、产品和技术规划、解决方案架构设计；
5. 负责产品研发过程中关键设计的把关；
职位要求：
1. 全日制本科及以上学历，211/985院校或以上优先；
2. 6年以上数据库/数据仓库/大数据相关产品的软件设计开发相关工作经验；
3. 深入理解数据库、数据仓库、大数据、分布式体系架构和关键技术；
4. 精通MySQL/PostgreSQL/Greenplum/MongoDB等其中至少一种主流数据库的实现原理，有开源贡献者优先；
5. 精通Java
6. 深刻理解软件设计原则和设计模式，独立承担过大中型系统设计开发工作；
7. 良好的英语阅读能力；"
"职位描述：
        
        岗位描述：
1、 负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行
2、 负责Hadoop、HBase、Kafka、Spark、Flume等集群的维护、优化工作
3、 开发大数据自动化运维、监控、故障处理工具，监控所有基础设施组件、应用程序
4、 负责实时计算平台搭建，负责对业务的数据接口开发

岗位要求：
1、 本科以上，计算机相关专业
2、 熟悉至少一项分布式计算平台，例如Hadoop，Spark，HBase，Flume，Storm，Kafka，Flink 等；
3、 有日志采集、数据处理、数据仓库建模、实时计算、ETL等经验
4、 有扎实的编程能力，熟悉Java或Python至少一种，熟悉算法数据结构
5、 有独立负责数据某一模块的实际项目经验
6、 3年以上数据开发经验，学习能力强，较好的沟通能力

「提供给您...」
1.顶尖技术团队，这里有BAT等技术大咖，等你过招
2.优越的薪资福利，试用期不打折，年底n薪加奖金
3.免费早餐小零食，定期TB和业余活动
4.帅哥美女，舒适的办公环境，紧邻地铁周边"
"职位描述：
        
        「我们一起做这样的事...」

 负责数据仓库架构设计、建模和ETL开发，构建可扩展的数据仓库和分析解决方案
 负责业务的数据接入、建模、处理分析


「我们希望这样的你...」

 熟悉至少一项分布式计算平台，例如 Hadoop，Spark，Hive，HBase、Storm，Kafka 等
 有日志采集、数据处理、数据仓库建模、ETL等经验
 熟悉 Java 或 Python 至少一种，熟悉 HiveSQL，有一定的hqlsql 性能调优经验
 具有优秀的数据建模和沟通能力，能把应用问题转化为数据问题
 熟悉元数据管理、数据质量
 有数据仓库建设经验者优先


------------------------------
这是一份为职业生涯做乘法的工作~在这里你将亲眼见证并参与每一个牛逼决策的产生和落地，还可以定期得到行业领袖的辅导和技能分享，也能时常跟创始人沈鹏以及各大公司顶尖人才的分享和交流。加入我们，一起去浪尖看风景，打开大健康领域新世界的大门，共同致力于「保障亿万家庭」！"
"职位描述：
        
        岗位名称：AWS数据开发工程师
行业：快消、零售
职位描述：
?
1.?负责基于Amazon Web Service(AWS)的服务平台搭建、开发及维护工作;
2.?负责基于AWS的ETL开发和维护；
3.?负责BI报表系统的开发和维护；
4.?与其他团队紧密配合，满足他们对于数据的需求；
?
职位要求：
1.计算机、软件工程等相关专业本科及以上学历；
2.3年以上数据仓库经验，有整体ETL开发经验；
3.熟悉SQL Server, MySQL, Oracle中的一种或多种，熟练使用SQL；
4.有报表开发工具使用经验，例如Cognos，Tableau，QlikView等；
5.有4个月以上的AWS数据开发经验；
6.有快速学习的能力，对学习新技术有热情；
7.具备团队协作精神，积极的工作态度和责任心；
8.能接受短期出差(2到3个月)，烟台/长沙；
?
加分项：
有Talend、Kettle使用经验；
有提供数据接口工作的相关经验优先；"
"职位描述：
        
        工作职责：-负责公司实时数据项目的设计、开发、落地和推广工作-负责数据服务平台的环境搭建、架构设计、以及稳定性保障-负责大数据实时计算的新技术落地及平台提升 职位要求：-本科及以上学历，计算机、软件工程或相关专业出身，工作3年以上，具有Hadoop、Spark、Spark Streaming、Flink开发与应用经验，熟悉Flume与Kafka等数据采集和消息通道技术，熟练掌握HDFS、Hbase、Hive、Spark、Flink等大数据技能，熟练掌握Spark Streaming、Flink等流计算技术-良好的Java或者scala编程能力，熟悉Java和scala开发工具和调试工具-熟悉Linux环境及脚本开发（Python/Perl/Shell等）-熟悉MySQL，Redis，Druid，能够快速的理解业务模型及数据模型-理解ETL过程，拥有DW项目开发经验，熟练掌握SQL/HQL-积极主动参与讨论、发现并解决问题-学习能力强，拥有优秀的逻辑思维能力、良好的理解和表达能力、较强的抗压能力额外加分项：1. 对Flink / Blink源代码有研究2. 熟悉Kafka, Pulsar等开源的消息队列系统3. 熟悉Storm，JStorm，Spark-Streaming等开源实时分析系统4. 熟悉Hadoop，Spark，Presto等大数据系统（不限于前面提到的）原理，设计和实现5. 对数据中台有相关实施落地经验者优先"
"职位描述：
        
        岗位指责：1、负责决策服务平台的数据可视化项目的开发与实施工作，挖掘数据价值，并运用可视化技术展示数据。2、负责大数据查询分析、商业智能决策、核心业务策略等大数据系统的可视化平台建设工作；3、BI前端展示页面开发设计，管理大屏等产品功能设计、界面设计、开发与可用性测试等4、负责大数据可视化页面和前端交互的开发和优化任职要求：1、本科及以上学历，计算机或统计学相关专业，两年以上相关工作经验；2、精通SQL/HSQL，具备性能优化、SQL调优等能力；3.熟悉fineBI、Tableau、PowerBI、fineBI等可视化分析产品，有数据分析经验者优先4.熟悉一种脚本语言，Python/perl/shell等5.具有可视化大屏或数据驾驶舱设计及数据开发经验6.具有较强的数学、统计知识和较强的数据处理能力，同时具有较好的分析总结能力和数据报告呈现能力；；加分项：1.有帆软BI工具fineBI、finereport工作实际使用经验者优先2.熟悉数据可视化开源方案，有数据分析场景/数据可视化经验者(ECharts/Highcharts/D3)优先,有web前端开发工作经验者优先"
"职位描述：
        
        1、跟进业内前沿技术、持续优化数据基础架构，更加稳定、可靠、高效
2、完善数据链路平台，及时响应用户数据需求，保障链路的稳定、高效
3、查询引擎、画像标签、BI等应用支撑方面数据开发工作
要求：
1、深入了解hadoop，spark生态组件，熟练使用并深入了解其原理，包括但不限于yarn，hdfs，hive，spark，hbase，kylin，presto，druid，flink。
2、丰富的hive，spark，hbase调优经验，对olap引擎有比较深入的了解。
3、熟悉java与scala编程，具备良好的源码阅读能力。
4、具备组件二次开发能力，尤其是yarn，hbase，spark，kylin等。
5、具备良好的沟通合作意识和能力，乐于分享。"
"职位描述：
        
        岗位职责：
1、承担基于Spark生态的大数据实时/离线处理平台；
2、参与业务数据清洗、处理、存储、检索等相关工作；
3、跟进大数据前沿技术的发展，将合适的技术方案适时引入业务场景。

任职要求：
1.具有主流大数据工具/平台实际项目经验,熟练掌握Hadoop、Spark、Storm、Elasticsearch中两个及以上,并熟悉所使用工具的技术原理、主要特点；
2.熟悉Data Pipeline概念，熟练使用Kafka、消息队列，了解工作流概念；
3.熟悉数据仓库、数据挖掘技术，分布式计算技术理论，具有大数据整体系统架构设计经验；
4.精通java,scala语言，熟悉linux操作系统，shell、python编程语言；
5.熟练使用Elasticsearch，并具有优化、设计的项目经验优先；
6.主要有过大数据平台产品的核心功能开发、性能调优、能有制定技术方案能力，有一般大数据架构的能力优先。

福利：
1、每天提供下午茶，每月员工生日会及生日礼品，每年提供员工定期体检；
2、每月无迟到早退请假，可获得月度全勤奖，全年全勤奖最高可达4k；
3、每季度设有活动经费，可进行各项目组内的聚餐、轰趴等活动；
4、每年两次评级调薪机会及满一年调薪 5%-10%；
5、按国家规定缴纳五险。享受年假、婚假、产假、护理假、哺乳假、病假等带薪假期；
6、国家法定节假日，发放节日礼品或慰问金；
7、每年集体活动，如：户外拓展、旅游、篮球、羽毛球比赛等；
8、内部定期培训，以及外部不定期带薪培训，助力员工成长与发展；
9、根据公司每年经营情况，发放丰厚的年终奖金；
10、公司进行月度、季度、年度评选，对表现优异的个人、团队和部门，予以奖金激励。"
"职位描述：
        
        岗位职责： 1?负责知识图谱数据建模、处理加工工作；； 2.?专注于流式计算、分布式计算、数据挖掘、分析建模等技术，从事大数据技术研究和开发工作； 3.?参与数据挖掘算法、机器学习其他方面的工作，全面发展； 岗位要求： 1.?四年以上大数据工作经验，计算机相关专业，具有金融行业项目经验者优先； 2.?熟悉spark?granpx或者flink?graph等图计算技术，有知识图谱建模经验者优先； 3.?至少熟悉一种图数据库，如neo4j、orientDB、arangoDB、titan等； 4.?有Hadoop?/?Spark?/?Hive?/?Presto?/?HBase?/?Kylin?/?Impala?/?Kafka?/?Flink?/?Storm/?Redis等使用经验和架构设计、部署经验，熟悉上述常用的分布式系统的原理； 5.?有生产环境快速trouble-shooting（快速探测）经验能力，擅长分析复杂和深层次的原因； 6.?熟悉使用Java/Python/Scala至少一种开发语言；熟悉Linux操作系统； 7.?能够独立承担任务，责任心强，重视团队合作，工作态度积极，勇于进取，抗压能力好； 8.?有OLAP，多维度数据分析、BI系统开发经验优先，对数据仓库有较强的理论基础和理解。 9、3年以上大型互联网产品或分布式系统开发设计经验者优先。"
"职位描述：
        
        工作内容:1、搭建和维护Hadoop集群，解决海量数据不断增长面临的挑战；
2、负责海量信息分析处理，系统设计；
3、负责根据业务场景，项目需求抽取、分析处理。
?
任职要求:1、计算机或相关专业，本科及以上学历，两年以上大数据相关工作经验（有项目主导经验优先）；2、熟悉Hadoop以及Hadoop生态圈上的各种应用的几种，如HBase、HDFS、Solr、ZooKeeper、Yarn等，能解决Hadoop的复杂问题；
3、有部署大规模Hadoop集群的经验者优先；4、熟悉面向对象设计思想和设计模式，熟悉数据结构和常用的算法，熟悉Linux平台，可以编写代码编程使用Hadoop和基于Hadoop开发大数据处理系统；5、熟悉软件开发流程和配置库的使用，拥有软件开发流程中的代码规范意识、配置管理规范意识、文档撰写规范意识和团队合作沟通交流意识。"
"职位描述：
        
        1. 大数据相关工作3年以上；
2. Java、Python中至少一门语言的2年以上的开发经验；
3. 熟悉运用MapReduce、HDFS、Hive、Hbase、Sqoop、storm、kafka、mongoDB、redis、elasticSearch中至少4种组件，并基于这4种以上组件的开发经验；
4. 熟练使用关系型数据库；
5.? 大数据组件性能、存储优化经验丰富；
6.? 有shell编程经验"
"职位描述：
        
        岗位职责：
1.负责ETL设计、模型设计、开发、技术支持等工作，并保证数据安全、及时、稳定、可恢复
任职要求：
1、3年及以上数据处理（ETL）开发经验，能独立完成数据处理开发工作
2、熟悉mysql/oracle等标准数据库，熟练上述数据库的开发
3、有hadoop和hiveSql的使用经验
4、熟悉ETL设计，熟悉数据仓库的架构、开发规范和流程
5、熟悉至少一种ETL开发工具，如Datastage，Informatica, kettle等
6、具备数据仓库实施经验者优先"
"职位描述：
        
        岗位职责：
分布式数据库设计与软件开发。
岗位要求：
1.计算机相关专业重点本科或硕士及以上学历，1年以上相关工作经验；
1)参与移动区块链平台的数据库系统的开发；
2)移动区块链数据库管理系统的编程；
3)不同应用条件的数据库方案构建；
4)交易数据池设计与编程；
5)sqlite跨平台数据库接口编程；
6)与系统的其它部分工作协调。"
"职位描述：
        
        高级大数据开发工程师：
岗位职责：

1. 运用数据挖掘/统计学习的理论和方法，深入挖掘业务系统产生的数据
2. 参与数据产品设计和评审，
3. 保障数据平台架构稳定健壮
4. 跟踪并分析公司数据商业化产品相关数据，为产品创新、产品设计及产品优化提供数据支持依据，共同建立起商业智能分析工作的流程、规范和方法
5. 建立良好的数据监测和汇报机制，对产品相关核心数据进行例行监控，能及时发现数据变化趋势并能深入分析原因

任职要求：

1. 全日制本科及以上学历，5年以上 java 开发经验，扎实的 Java 基础，最好有 scala 经验
2. 熟练掌握 hadoop 生态圈的各种大数据框架，了解其实现原理和理论依据
3. 具备数据敏感性和探知欲、分析、解决问题的能力，专注数据的价值发现和变现转化
4. 有清晰缜密的逻辑思维能力、独立的分析调研能力
5. 熟悉数据仓库的ETL的开发和数据建模，熟悉数据仓库各类建模理论，具备大型数据仓库架构设计、模型设计和处理性能调优等相关经验"
"职位描述：
        
        职位描述：?
1、负责公司大数据开发平台建设，构建：包括跨地区数据的采集、传输平台，存储、离线/实时计算以及分布式调度系统等；
2、负责大数据/数据挖掘产品开发，有推荐，搜索，广告，BI等业务优先考虑；?
3、负责对业务开发人员进行培训，指导业务开发人员及解决出现的系统问题；?
4、参与公司系统维护与工具开发；

职位要求:?
1. 熟练掌握Java语言，具有扎实的面向对象开发经验，熟悉分布式系统和相关性能调优思想；
2. 熟练Linux环境及shell脚本或者Python，掌握linux环境下多线程及网络编程,对Hadoop MapReduce、HDFS、Hbase、Hive等大数据生态系统中间件原理有一定了解； ?
3. 具有丰富的数据开发经验，对数据处理、数据建模、数据分析等有深刻认识和实战经验 ；
4. 业务理解力强，对数据、新技术敏感并充满热情；"
"职位描述：
        
        岗位职责：

1. 灵活使用大数据相关的技术解决相关的业务问题
2. 开发并维护数据平台的产品和系统
3. 大数据平台的日常运维
4. 与业务部门密切配合，寻求数据层面的业务价值，利用数据分析结论推动产品优化
5. 研究大数据技术领域最新进展并结合业务需求进行合理的应用和实践


任职要求：

1. 全日制本科及以上学历，3年以上 Java 开发经验，扎实的 Java 基础，最好有 scala 经验
2. 有 Hadoop 使用经验，了解 HDFS 运行机制
3. 有 Spark 使用经验，使用过 Spark SQL 和 Spark Streaming 并了解其原理，最好对 Storm 也有了解
4. 有 HBase 使用经验，了解 HBase 的各个模块，以及大致的工作流程
5. 了解分布式系统的一些基本原理和协议
6. 有图数据库使用经验优先
7. 有使用过或了解过 kafka/flume/hive/mongo/zookeeper/sqoop/kerberos/presto 等大数据相关框架
8. 熟悉常用 Linux 命令
9. 良好的沟通和业务理解能力"
"职位描述：
        
        职位描述:1、参与大数据平台的建设及开发2、负责产品/项目的需求调研、数据分析、商业分析及数据挖掘建模等工作3、构建基于大数据的数据产品和应用"
"职位描述：
        
        岗位职责：
1、参与数据标准规范制定，形成相关标准文档；
2、参与数据库设计工作，形成数据库设计文档；
3、参与数据生产技术方案设计工作；
4、参与数据生产工作，完成数据资源的清洗加工任务。
?
任职要求：
1、相关专业专科以上学历，有数据生产工作经验者优先考虑；
2、熟悉MAPGIS/ARCGIS等GIS软件；
3、熟悉ERDAS/ENVI等遥感软件；
4、对园林、国土行业数据有深入了解，具备相关数据生产经验者优先考虑；
5、有较强的沟通能力；
6、良好的团队协作能力。"
"职位描述：
        
        岗位职责：
1、大数据平台相关的设计和开发；
2、大数据平台的日常维护。

任职资格：
1、熟悉C++/JAVA/SCALA/PYTHON至少一种；
2、熟悉linux开发环境；
3、熟悉大数据工程的基本原理，熟悉流式计算等实时计算；
4、熟悉HADOOP、SPARK等离线计算；
5、熟悉大数据存储。"
"职位描述：
        
        岗位职责：
1、负责短视频平台数据整合与数据仓库模型的建立、维护和优化；
2、了解、监控应用需求及数据源的变化，并评估对数据仓库模型的影响；
3、设计数据模型的ETL实现，参与团队ETL流程的优化以及相关技术问题的解决。
任职要求
1、熟悉数据仓库建设生命周期流程规范,并掌握主题建模、维度建模理论；
2、熟悉SQL/HQL，有较好的SQL性能调优经验；熟悉Python/Perl/Shell等至少一种脚本语言；
3、对数据敏感、具有ETL设计与开发、数据建模、数据质量保障、元数据管理、指标体系建设等项目实践经验优先；
4、熟练使用Powerdesigner?、Erwin等相关模型设计软件者优先；
5、有互联网经验、大规模数据/日志处理经验，熟悉Hadoop/Hive者优先；
6、工作认真、踏实、负责，有良好的团队合作精神，良好的分析能力、沟通技巧。"
"职位描述：
        
        工作职责：
1、完成软件产品各模块的功能设计、代码实现工作；
2、参与项目技术难点攻关以及核心代码的编写；
3、设计及运用先进技术于产品开发；
4、了解互联网的技术发展、评估外部技术与解决方案；
5、协助上级完成团队制定的研发计划。
职位要求：
1、3年以上软件开发经验，精通Java开发，2年以上Hadoop/spark相关开发经验；
2、对基于Hadoop的大数据处理体系有深入认识，具备相关（MapReduce/hdfs/hive/hbase）项目应用研发经验；
3、熟练使用Spark，并对RDD/Spark-sql/Spark-streaming有深入认识，具备Scala语言开发经验者优先；
4、对分布式缓存Redis和Nosql数据库（如：MongoDB、Hbase）有一定研发经验；
5、具有良好的沟通及项目协调能力，优秀的分析问题和解决问题的能力，具备强烈的进取心和良好的团队合作精神。"
"职位描述：
        
        1、从事大数据分布式存储/应用服务的设计和开发，挑战大规模、高并发、易运维的分布式系统设计构建；?
2、负责大数据应用产品的开发工作（营销、推荐、搜索、分析统计等），包括系统/算法的设计及实现；
3、解决海量数据高效处理、交互式查询、流式分析等技术难点，对现有系统的不足进行分析，难点攻关；
4、跟踪评估数据产品线上效果，参与各业务部门的产品设计讨论，促进大数据产品的广泛落地各产品线；
5、梳理当前团队技术瓶颈、技术栈短板评估，业务线大数据需求技术预判相关技术预研。"
"职位描述：
        
        工作职责：
1. 精通Java、python语言及相关框架，能熟练掌握常用数据结构和算法；
2. 有实际的Hadoop生态系统HBbase/Hive/MP开发经验；
3. 熟悉Spark、Flink、Storm、Impala等计算和数据处理引擎的环境搭建、开发和管理；
4. 熟悉消息队列的原理，熟练使用Kafka、Activemq、Rabbitmq等常用的消息队列；
5. 掌握数据分析的基本流程，擅长数据采集、清洗、分析等环节，；
6. 具有较强的业务理解能力，并能快速应用于数据分析各阶段；
7. 能熟练掌握Linux的操作和使用；
8. 有云计算中心开发经验的优先。
9.工作认真，负责，良好的团队合作精神和解决问题分析能力。钻研技术克服困难，勇于挑战。
?
岗位职责：
1、负责公司业务系统的数据加工、分析、处理工作；
2、按照业务部门的要求加工数据，生成业务需要的分析数据，用于系统使用使用的用户标签数据；
3、对业务数据进行优化，提升数据分析处理的效率；"
"职位描述：
        
        岗位职责：
1.承担建设基于Hadoop/Hbase/Spark生态的大数据离线/实时处理平台； 2.负责公司大数据集群的构建、运维、开发工作，确保高可用； 3.负责集群容量规划、扩容及集群性能优化，参与大数据基础环境的架构设计与改进； 4.参与业务数据、生产日志的抽取、转储、检索等相关工作； 5.负责数据仓库和大数据处理模块的架构设计和开发； 6.负责海量数据实时处理、分析工作；
7.跟进大数据前沿技术的发展，将合适的技术方案适时引入业务场景。

任职要求：
1.扎实的计算机基础，熟悉常用的数据结构和算法，熟悉Linux系统环境； 2.精通Java/Scala/Python/Perl/Shell等大数据领域常用开发语言的一种或多种； 3.熟悉大数据技术栈，对关系型数据库，以及Hadoop、Hive、Spark、Hbase，ELK，CDH ,ES等有实际项目开发经验； 4.了解相关数据处理框架或工具，例如Storm、Spark/Spark Streaming/Spark MLib、Flink、Azkaban、Flume等一种或几种； 5.具备数据仓库及实时计算业务的设计和实现经验；有用户画像经验者优先； 6.具备数据建模(机器学习,数据挖掘,信息检索等)相关经验； 7.了解常用算法，掌握算法工具，包括但不限于：K-means聚类、LDA.神经网络、欧式距离、SVM.过/欠合等；有深度学习经验者优先； 8. 在开源社群活跃并有积极贡献者优先；"
"职位描述：
        
        岗位职责：
1、负责Hadoop、HBase、Spark、Storm、Flink等系统的搭建、优化、维护及升级工作，保证平台的稳定运行；
2、负责数据的清洗、加工、分类等开发工作，并能响应数据分析师对数据提取的要求；
3、负责大数据平台的底层平台的整体架构设计，确保系统能支持业务不断发展过程中对数据存储及计算的要求；
4、深入业务，指定业务指标，反馈业务问题，为业务发展提供决策支持。

任职要求：
1、熟悉分布式系统的架构，有分布式系统架构设计的经验，有Hadoop系统架构设计经验，至少1个以上大型成熟项目的经验；?
2、精通Hive，并有相当优化经验，理解 Hbase 体系架构，并有相当开发经验；
3、熟悉数据仓库的ETL的开发,有海量数据处理相关经验；
4、熟悉Hadoop、HBase、Hive、Spark、Storm、Flink等软件，至少精读过一个源码；
5、有数据挖掘及机器学习方面的经验优先。"
"职位描述：
        
        岗位职责：
1.负责线上数据业务需求开发，构建数据化业务解决方案；
2.参与数据仓库ETL开发，包括设计、建模、研发及项目管理等；
3.开发公司数据报表，随业务的变化及时更新数据报表指标；
4.从数据完整性、时效性、一致性?度，开发数据监控系统；
5.研究与跟踪数据技术发展方向，参与数据平台架构的设计；
任职要求：
1. 熟练使用Hive SQL，且具备一定的Hive SQL优化能力的优先；
2. 熟悉Java或python中一门编程语，能够根据需求独立开发UDF,UDAF,UDTF等功能；
3. 熟悉数据仓库模型设计，具备海量数据加工处理（ETL）相关经验；
4. 熟练使用mysql关系型数据库，能进行基本的sql优化，了解分布式存储引擎、索引等；
8. 有较强的团队协作精神，独立工作能力、沟通及表达能力强，工作责任心强，能够承受压力；"
"职位描述：
        
        工作职责:1、负责业务相关数据指标的抽取、转换、加载，数据维护相关工作；2、负责数据质量控制和元数据整合相关工作；3、分析业务需求、数据建模以及数据仓库应用产品的设计、开发；4、制定数据质量维护制度、流程，数据质量例行检查。任职资格:1、大专及以上学历，3年以上数据开发经验；有独立负责数据仓库项目实施经验，精通数据仓库方法论和ETL架构，理解元数据管理；2、对MySQL、Redis等数据库有一定的了解和使用经验；3、熟悉Flink/Blink或Spark等数据处理框架；熟练使用Python/Java或者其他语言进行复杂业务逻辑的数据处理工作；4、熟悉Hadoop生态相关系统；如Hive、HBase、Kylin；5、对数据敏感，具备良好的逻辑分析能力；6、具备良好的沟通能力和团队协作能力，可以承受较强的工作压力，认同创业公司文化，责任心强，工作敬业。"
"职位描述：
        
        工作职责：
1、负责公司大数据分析、数据实时/离线处理方案设计、开发、优化
2、参与分布式产品架构设计、技术路线选择、方案讨论；
3、负责跟踪、解决研发与客户所遇到的产品问题；
4、进行代码的重构、审查和技术难点解决；
职位要求：
1、本科以上统招学历，5年以上工作经验
2、精通Java、Scala、Python中的一种，
3、精通spark、熟悉Hadoop；
4、有大数据建模经验、算法经验优先"
"职位描述：
        
        工作职责：
1、负责数据处理，数据对码
2、负责实体对齐等相关算法使用和编写
3、负责公司大数据分析、数据实时/离线处理方案设计、开发、优化
4、参与分布式产品架构设计、技术路线选择、方案讨论
5、进行代码的重构、审查和技术难点解决
职位要求：
1、本科以上统招学历，2-3年左右工作经验
2、精通Scala、Python中的一种
3、熟悉spark、Hadoop，掌握kafka与hive数据获取与存储技术
4、有大数据建模经验、算法经验优先"
"职位描述：
        
        职位描述:
1. 负责客户数据的初步分析
2.负责客户数据至公司产品的导入导出，ETL
3.负责配合业务同事进行业务逻辑代码的修改
4.公司安排的其他项目相关工作

职位要求：
1、3年以上db相关(oracle、mysql、sqlserver等）开发经验。
2、熟悉linux环境下基本操作。
3、工作认真负责，接受不定期出差。"
"职位描述：
        
        职责描述：1. ? ?负责医保、商保风控相关产品的实施开发、部署运维工作；2. ? ?负责个性化需求收集及归档、开发工作（java或spark）；3. ? ?支持部分接口对接、服务器准备等实施相关的售前沟通工作；4. ? ?负责客户数据的初步分析；5. ? ?负责客户数据至公司产品的导入导出，ETL相关工作；6. ? ?负责实施过程中的部署与开发工作；7. ? ?领导交办的其他工作。 任职要求：1. ? ?本科及以上学历，工作三年以上，计算机相关专业；2. ? ?熟悉Linux操作系统和常用命令，了解Druid的工作原理；3. ? ?2年以上db相关(oracle、mysql、sqlserver等）开发经验；4. ? ?熟悉网络基本原理；5. ? ?较强的沟通能力，文档能力，能适应不定期出差（全国）。6. ? ?有社保核心系统、医院HIS系统开发工作经验优先考虑；"
"职位描述：
        
        这是一个需要绝对扎实的数学基础、严密的逻辑思维、高超的编码能力、突出的解决问题能力的高能职位，致力于找出过去事件的特征、预测未来可能发生的事件并找出最优化的结果。我们需要你：1、挖掘分析用户/行业需求，包括用户画像、智能推荐、情感分析、语义处理等；2、以数据挖掘、机器学习为基础，挖掘并促进产品改进，探索新业务形态；3、跟进业界新算法和行业趋势，对人工智能新方向进行预研、实践和产品化。我们希望你：1、研究生及以上学历2020年毕业应届生，应用数学、统计学、计算机等相关专业；2、极具语言天分，精通python/R/Scala/java/C++其中至少一门语言；3、熟悉常用机器学习和数据挖掘算法，了解Hadoop/Spark等大数据平台，会让你更加分；4、保持热情和好奇心，关注最新技术动态，持续学习，有实际的工程项目经验或竞赛获奖经历。"
"职位描述：
        
        岗位职责：1、负责分析和挖掘用户/行业的需求，包括但不限于用户画像、智能推荐、情感分析和语义处理等；2、以数据挖掘、机器学习等为基础，挖掘并促进产品改进，探索新业务形态；3、跟进业界新算法和行业趋势，对人工智能新方向进行预研、实践和产品化。岗位要求：1、研究生及上学历，数学、统计学、计算机等相关专业，2年相关工作经验；2、至少精通 python/R/Scala/java/C++ 等其中1门语言，有实际的工程项目经验；3、熟悉常用机器学习和数据挖掘算法；4、了解Hadoop/Spark等大数据平台，有TensorFlow或者Caffe使用经验者优先；5、具备优秀的组织能力，具有开拓创新精神，能在高强度压力下工作。"
"职位描述：
        
        ? ?岗位技能：
1、开发Kafka/Spark/Storm程序，能解决实际线上生产系统（Hadoop、Hbase、Zookeeper、Redis以及各种生产任务等）的各种问题；2、设计开发自有离线/即席/实时流式数据计算平台等；3、负责大数据平台相关子系统的模块设计、开发实现；4、对Hadoop生态平台运维不断优化，提升数据产品的质量和响应速度；5、开发各种Hadoop大数据自动化运维与监控工具。
? ?基本要求：
1、三年或以上Hadoop实际项目开发经验；2、熟悉Hadoop、Hive、HBase等分布式开源项目及工作原理，有Hadoop集群优化、开发和维护管理经验；3、熟悉Linux操作系统、网络协议、熟练使用Shell；4、熟悉通用软件开发流程和技能，如设计模式/敏捷开发/TCPIP等； 能至少熟练使用Java/Scala/Python/C/C++等主流编程语言之一进行软件开发，熟悉GIT/Maven/Gradle 等常用开发工具；5、工作踏实，具有强烈的责任心和团队合作精神。愿意在技术上深入研究和持续发展，勇于迎接挑战。"
"职位描述：
        
        岗位职责：
1. 负责公司数据平台的架构设计和开发工作，为算法组、产品组和客户提供全方位的业务数据服务
2. 针对各种公有、私有部署环境，设计统一的数据处理流程，为数据分析提供数据接口
3. 负责开发数据可视化的服务，包括业务运营指标、业务效率指标、机器人运维指标等。通过资源利用情况可视化数据，挖掘业务优化方向
任职资格：
1. 计算机、数学、工业工程、物流等相关专业本科及以上学历
2. 5年以上数据分析或者大数据处理经验，有物流行业应用经验优先
3. 熟练使用Java进行开发，了解Python
4. 在实际项目中使用过Kafka
5. 熟悉ETL开发流程和常用工具
6. 熟悉Spark或者Flink等大数据处理框架
7. 熟悉MySQL等数据库的查询优化
8. 有很好的逻辑思维能力、主动学习、乐于分享"
"职位描述：
        
        岗位职责：
1. 负责公司数据平台的架构设计和开发工作，为算法组、产品组和客户提供全方位的业务数据服务
2. 针对各种公有、私有部署环境，设计统一的数据处理流程，为数据分析提供数据接口
3. 负责开发数据可视化的服务，包括业务运营指标、业务效率指标、机器人运维指标等。通过资源利用情况可视化数据，挖掘业务优化方向
任职资格：
1. 计算机、数学、工业工程、物流等相关专业本科及以上学历
2. 3年以上数据分析或者大数据处理经验，有物流行业应用经验优先
3. 熟练使用Java进行开发，了解Python
4. 在实际项目中使用过Kafka
5. 熟悉ETL开发流程和常用工具
6. 熟悉Spark或者Flink等大数据处理框架
7. 熟悉MySQL等数据库的查询优化
8. 有很好的逻辑思维能力、主动学习、乐于分享"
"职位描述：
        
        【工作职责】：
1.参与公司数据平台架构演进。
2.参与公司离线和在线分布式存储系统的架构、优化。
3.跟进大数据生态系统的最新进展。?
【岗位要求】：?
1.本科以上学历，3年以上大数据相关经验，熟悉大数据生态系统，对周边项目有着广泛的了解。?
2.熟悉分布式系统设计理论，有 PB 级数据的 HDFS/HBase/ElasticSearch/Kudu/Cassandra 集群架构、使用和运维经验。
3.扎实的 Java/Scala 基础，对至少一门动态语言有过使用经验。?
4.良好的线上 trouble shooting 能力，能快速定位和解决线上问题。
5.良好的学习能力，保持对新技术的敏感性。"
"职位描述：
        
        【工作职责】：
1.参与公司数据平台架构演进。
2.对主流大数据开源组件(Hadoop，Spark 等)进行优化和定制开发。
3.跟进大数据生态系统的最新进展。?
【岗位要求】：?
1.本科以上学历，熟悉大数据生态系统，对 Hadoop, Hbase, Hive, Spark，Kylin，ElasticSearch 等至少一个项目有着深入的了解。?
2.扎实的 Java/Scala 基础，对至少一门动态语言有过使用经验。?
3.熟悉 Linux 系统常用操作。?
4.对数据有着强烈兴趣，有部署大规模 Hadoop 集群经验者优先。?
5.良好的学习能力，保持对新技术的敏感性。"
"职位描述：
        
        【工作职责】：
1、负责公司各类数据产品数据抽取、清洗，以及数据算法数据的存储设计和优化
2、参与多个数据产品算法设计
3、负责第三方合作公司数据采集清洗，存储结构设计以及分析统计
【岗位要求】：?
1、计算机相关专业本科以上学历
2、熟悉java或者python至少一种，两年以上相关开发经验，有scala语言开发经验优先
3、熟悉linux开发环境
4、熟悉Hadoop或Spark生态相关技术，包括MapReduce、HDFS、HBase、HIVE等
5、有数据统计分析，数据挖掘、机器学习经验者优先"
"职位描述：
        
        【工作职责】：
1.参与公司数据平台架构演进。
2.对主流大数据开源组件(Hadoop，Spark 等)进行优化和定制开发。
3.跟进大数据生态系统的最新进展。?
【岗位要求】：?
1.本科以上学历，熟悉大数据生态系统，对 Hadoop, Hbase, Hive, Spark，Kylin 等至少一个项目有着深入的了解。?
2.扎实的 Java/Scala 基础，对至少一门动态语言有过使用经验。?
3.熟悉 Linux 系统常用操作。?
4.对数据有着强烈兴趣，有部署大规模 Hadoop 集群经验者优先。?
5.良好的学习能力，保持对新技术的敏感性。

注：可接受985、211计算机、软件工程师相关专业应届毕业生"
"职位描述：
        
        职位描述：
1、负责大规模数据的清洗、特征提取、分析和挖掘工作；
2、负责整体数据系统的设计和开发；
3、负责数据相关接口的开发。
职位需求：
1、计算机相关专业本科及以上学历
2、2年以上编程经验，熟练掌握java，scala中至少一种语言；
3、熟悉Hadoop生态，熟悉HDFS/HBase/Hive/Storm，熟练掌握MapReduce程序开发；
4、有过Flume/Kafka/Storm的使用经验；
5、熟悉Spark, 并有实际使用经验者优先；
6、对数据建模、存取、处理、可视化等相关技术有很强的学习热情。
7、有较好的沟通交流能力和逻辑思维能力"
"职位描述：
        
        【职位诱惑】
1、大数据量: 日均百亿级日志量,日均TB级数据增量。
2、高挑战性: 海量日志处理，实时数据处理，参与广告实时统计业务架构开发与设计。
3、核心业务: 参与广告核心业务反作弊，CTR算法等基础数据开发，实时数据。

【工作责职】
1、负责广告DSP业务，SSP业务ETL开发，数据报表统计计算分析
2、负责广告反作弊，CTR算法基础数据开发
3、负责DSP/SSP业务数据仓库的设计与搭建

【岗位要求】
1、计算机或相关专业本科以上学历；
2、精通Java/Scale，熟悉Linux/Unix开发环境；
3、2年以上大规模分布式程序开发的项目经验；
4、熟悉常用开源分布式系统，Hadoop/Hive/Spark/Yarn，精通源代码尤佳；
5、熟悉数据仓库原理，熟悉SQL语言；
6、有持续学习新知识的能力，具有较强的钻研精神。善于沟通和逻辑表达，优秀的团队合作意识。
7、工作认真负责，有较强解决问题和分析能力，良好的逻辑思维能力，能从不同角度思考、分析问题。"
"职位描述：
        
        迎接订单指数级增长带来的挑战，感受海量电单车位置的频繁跳动，您的每一项改进都造福千万用户，为天朝的城镇化运动疯狂打Call！
岗位职责：
1）开发并维护数据基础设施；
2）数据产品开发，如推荐系统组件研发和架构优化；
3）支持运营业务需求，提供数据驱动和决策的能力；
4）提升程序员的自我修养。
任职要求：
1）熟悉大数据相关技术：Kafka/Storm/Hadoop/Spark/HBase 等；
2）了解常见数据结构和算法；
3）严密的逻辑推理能力，价值导向的产品意识；
4）熟练使用MySQL和至少一门编程语言Java/Python。"
"职位描述：
        
        岗位职责：1. 理解产品需求，带领团队完成在线数据产品（风险模型、反欺诈应用等）的设计和研发；2. 负责和数据科学家团队对接，完成量化模型的原型到产品的研发；3. 负责与大数据平台、决策引擎、核心系统等开发团队的开发联调和集成测试；
任职要求：1. 本科及以上学历，计算机专业；2. 精通互联网应用系统框架，熟练使用Java或Golang语言；3. 熟悉web服务的研发流程，有大规模、高可用、高并发、高可扩展性的分布式后端服务的研发经验；4.5年以上软件开发经验，熟练使用敏捷开发流程；5.有知名数据服务商的研发工作经验优先。"
"职位描述：
        
        岗位职责：
1、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；2、负责Hadoop、HBase、Hive、Spark、Kafka等集群的维护、 优化工作；3、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；4、开发大数据自动化运维、监控、故障处理工具，监控所有基础设施组件、应用程序，提供紧急应急措施。
任职要求：
1、计算机相关专业，本科及以上学历；5年以上Hadoop生态系统开发经验；
2、熟悉Hadoop、HBase、Kafka、Hive、Spark等组件的工作原理；3、精通一门以上编程语言(java，python等）,有开发经验者优先；4、熟悉Linux软硬件环境、系统管理和优化，有做过大数据服务监控者优先；5、主动性强，具有良好的沟通、协调和组织能力，富有团队精神，有较强的文档编写能力；6、有Kylin,ELK使用经验者优先，有消费金融大数据开发经验者优先。"
"职位描述：
        
        岗位职责
1.?负责大数据平台的数据接入、存储、检索、查询
2.?负责大数据平台在特定应用下的性能调优
3.?负责大数据平台与多个应用对接的接口和框架设计
4.?参与网络大数据的挖掘分析
?岗位要求
1.?熟悉Linux开发环境，熟练掌握Python开发，有安全知识背景优先
2.?具有大数据开发经验，了解大数据常用框架与技术
3.?熟悉Hadoop生态圈开源技术，包括HDFS、Spark、Kafka、ZooKeeper等
4.?了解ElasticSearch、MongoDB等，有文本分析、机器学习相关经验者优先
5.?逻辑清晰，可承受较强的工作压力，具有较强的自学能力"
"职位描述：
        
        岗位职责：
1、负责公司互联网产品的数据库设计、管理与调优；
2、负责公司互联网产品上线、更新、配合开发人员分析对应的SQL的优化和实现；
3、负责数据库的日常维护、监控、备份恢复工作。
岗位要求：
1、计算机专业专科以上学历，2年以上mysql DBA工作经验；
2、熟练掌握MySQL数据库的运行机制，并对技术细节有较深入了解
3、熟悉数据库性能调优，熟悉PL/SQL或T-SQL、存储过程、触发器；能开发编写数据库管理、SQL脚本，撰写规范的技术文档
4、具备体系化的思维能力、分析判断能力、综合能力、决策能力、良好的沟通能力、合作能力"
"职位描述：
        
        岗位职责：
1.负责数据平台的设计、开发、维护、优化，满足公司各部门的数据分析需求；
2.参与或负责数据仓库设计、建模、研发及项目管理等；
3.就具体业务问题，构建数据化解决方案，包括构建分析框架、进行专题分析，或对具体问题进行相关算法的设计与落地实现，并负责完成核心代码，技术攻坚；
4.研究与跟踪数据技术发展方向，参与数据平台架构的设计；
任职要求：

1. 熟悉Linux系统环境，熟悉常用命令
2. 熟练使用Java/python之一的编程语言，精通Java者优先
3. 悉数据仓库模型设计，具备海量数据加工处理（ETL）相关经验；
4. 熟练使用mysql关系型数据库，能进行基本的sql优化，了解分布式存储引擎、索引等；
6. 至少熟悉以下一种大数据技术组件，Hive、Impala、HBase、Flume、Kafka、Zookeeper、Spark。
7. 3年及以上互联网工作经验 参与过大型数据平台产品、OLAP系统开发者优先；
8. 有较强的团队协作精神，独立工作能力、沟通及表达能力强，工作责任心强，能够承受压力。"
"职位描述：
        
        岗位职责：
1. 参与机器学习平台和指标计算平台的架构设计和开发，系统建设体系化并具有技术前瞻性；
2. 负责基于大数据的机器学习、深度学习、图计算、流式计算、实时计算等相关技术落地；
3. 跟踪大数据前沿技术动态，推动平台技术持续迭代；

岗位要求：
1. 本科以上学历，计算机相关专业，5年以上开发经验；
2. 计算机知识扎实，熟悉Linux环境编程，至少精通Java、C/C++其中一门编程语言；
3. 熟悉大数据技术生态，对Hadoop、Spark、Hbase、Kafka、Flink、Gemfire相关技术中一个或多个有深入了解和源码阅读；
4. 有数据分析、机器学习、精准营销、金融风控、搜索引擎、广告推荐相关的开发经验；
5. 有很强的复杂问题分析和解决能力，技术视野开阔，具备良好的沟通和学习能力；
6. 参加过ACM竞赛优先考虑"
"职位描述：
        
        岗位职责：
1. 参与机器学习平台和指标计算平台的架构设计和开发，系统建设体系化并具有技术前瞻性；
2. 负责基于大数据的机器学习、深度学习、图计算、流式计算、实时计算等相关技术落地；
3. 跟踪大数据前沿技术动态，推动平台技术持续迭代；

岗位要求：
1. 本科以上学历，计算机相关专业，5年以上开发经验；
2. 计算机知识扎实，熟悉Linux环境编程，至少精通Java、C/C++其中一门编程语言；
3. 熟悉大数据技术生态，对Hadoop、Spark、Hbase、Kafka、Flink、Gemfire相关技术中一个或多个有深入了解和源码阅读；
4. 有数据分析、机器学习、精准营销、金融风控、搜索引擎、广告推荐相关的开发经验；
5. 有很强的复杂问题分析和解决能力，技术视野开阔，具备良好的沟通和学习能力；
6. 参加过ACM竞赛优先考虑"
"职位描述：
        
        岗位职责：
1.实时数据和离线数据的处理、分析，为上层可视化提供数据服务；
2.大数据平台的优化；
职位要求：
1、有HBase、Hive、Spark、kylin、storm、kafka等一种或多种技术的相关经验一年以上
2.熟悉Java、Scala、Python其中一种或多种开发
3.有整条数据处理后台经验者加分
4.善于沟通，有团队协作精神
5.学习能力强，能够自我学习和提高"
"职位描述：
        
        职责描述：
1、负责GIS地图数据项目实施计划与进度控制；
2、根据公司战略规划及市场需求，参与地图新产品研发生产；
3、负责项目需求调研分析及技术方案编写
任职要求：
1、地理信息系统、测绘工程等GIS相关专业毕业；
2、2年以上GIS行业数据方面工作经验；
3、熟悉Oracle、PostgreSQL等数据库基本操作；
4、精通FME、ARCGIS软件，有Python基础；
5、了解GIS行业其它常用数据处理软件。"
"职位描述：
        
        岗位职责：

1. 依据业务模型，负责大数据计算平台的架构设计，以及核心功能的开发，为公司用户提供稳定、易用的大数据平台工具和便捷的数据产品；

2. 参与并主导大数据平台工具链的设计、开发以及后续维护；

3. 负责产品、运营、风控部门的数据挖掘与建模分析需求；

4. 不断迭代优化已有大数据平台工具和数据产品，推动大数据平台的发展

5. 新技术预研，解决团队技术难题。

任职要求：

1. 计算机及相关专业；

2. 至少2年以上Java开发经验，其中有1至2年大数据开发经验；

3. 熟悉大数据相关组件如：Hadoop/Spark/Hive/Kafka/Storm等；

4. 熟悉Linux操作系统；

5. 掌握常用的设计模式和架构模式，能够熟练使用建模工具进行系y设计；

6. 能够完成核心产品代码的研发工作，解决项目中关键问题和技术问题；

7. 工作责任心强，具备良好的团队合作精神，良好的沟通及协作能力。

8. 熟悉软件开发流程和配置库的使用，拥有良好的代码规范意识和文档编写能力。"
"职位描述：
        
        
岗位职责：
?负责公司大数据业务平台的架构设计，开发和优化，不断提高系统的稳定性、性能
?
任职要求：
1、3年以上java开发经验，2年以上hadoop大型平台项目实际开发经验；
2、深刻理解和掌握基于Hadoop生态系统（MapReduce、HDFS、Kafka、Flink、HBase、Hive等）的海量数据处理技术，有海量数据处理的优化和性能调优者优先；
3、熟练使用Linux系统，熟练使用Shell、Python等脚本语言；
4、熟悉Kylin、ElasticSearch开发及优化经验者优先；
5、熟练使用Spark以及相关组件，有丰富的RDD使用经验者优先；
6、熟悉ETL开发及优化经验者优先；
7、熟练使用git、maven等工具者优先；
8、性格积极乐观、诚信、有较强的语言表达能力，具备强烈的进取心、求知欲及团队合作精神；"
"职位描述：
        
        岗位职责：
1、参与数据仓库模型设计、主题梳理、分层体系构建、元数据管理以及报表开发；
2、负责数据仓库ETL流程的设计、优化及解决ETL相关的开发；
3、支撑多样的数据分析挖掘场景，负责底层大规模数据的存储、索引和实时查询功能设计和开发；
4、业务模型抽象、数据模型设计开发；
5、负责前瞻技术的调研选型、分享和推广。
任职资格:
1、统招本科及以上学历，计算机基础扎实，3年以上相关经验；
2、有使用主流数据库技术，Python 或 Java 开发经验，熟悉 SQL开发与复杂 SQL 优化；?
3、熟悉数据仓库方法论，熟悉元数据管理和数据质量监控过程、具备丰富的ETL开发经验；
4、有较好的数据模型设计能力，理解Hive/Mysql基本原理和调优策略；
5、对数据和业务敏感，有良好的逻辑和沟通能力，工作认真细致勤奋。"
"职位描述：
        
        大数据开发工程师
【岗位职责】
1. 基于各种大数据技术构建公司数据平台；
2. 基于Spark计算框架进行海量数据处理、分析、统计和挖掘；
3. 协助算法科学家进行数据处理和基础分析。

【任职要求】
1. 计算机相关专业本科以上学历；
2. 3年以上一线开发经验；
3. 熟练掌握Java/Scala/Python编程，有Scala/Python实际项目经验者优先；
4. 熟练掌握Hadoop、Spark等主流大数据框架，熟练掌握Spark Core、Spark SQL、Spark ML等Spark相关编程；
5. 熟悉分布式系统设计，有高并发、高性能系统设计和实现经验；
6. 熟悉PySpark者优先，有数据算法和机器学习经验者优先；
7. 熟悉ELK、Storm、Flink等框架者优先。"
"职位描述：
        
        工作职责
1. 主导大数据平台的设计与开发，解决海量数据面临的挑战；
2. 进行数据收集、整理与分析工作，助力数据化运营业务，构建丰富多样的BI解决方案；
3. 负责 Spark 项目开发，解决并实现业务需求，支持公司对数据的分析和探索；
4. 协助建立推荐等数据模型，对数据进行挖掘、优化及统计。

职位要求
1、本科生及以上学历，3年及以上相关经验，有广告行业经验者优先；
2、熟悉Hadoop/Spark，熟悉大数据ETL工具，对机器学习/深度学习感兴趣，有推荐模型经验者优先；
3、熟练掌握Python语言，熟悉Scala或者JAVA，熟练阅读开源项目源码；
4、对大数据敏感，善于发现问题、解决问题；
5、对开源大数据解决方案感兴趣，有利用技术解决实际问题的热情，开源积极参与者优先。"
"职位描述：
        
        岗位职责：
1、参与数据仓库及ETL架构和规范制定；
2、负责数据仓库及BI项目ETL部分的开发和优化，并及时解决ETL相关技术问题；
3、负责ETL数据准确性验证及报表维护；?
4、海量数据的ETL开发，抽取成各种数据需求。
任职要求：
1、大学本科或以上学历，计算机软件、数学等相关专业；
2、熟悉DB2或者ORACLE数据库，熟练掌握PLSQL；
3、有数据仓库或管理信息系统ETL开发与实施经验者优先；
6、有模型设计经验者优先；
7、熟练掌握ETL工具（如Informatica、DataStage）者优先考虑"
"职位描述：
        
        工作职责:1. 负责基于Hadoop的ETL需求开发。2. 深入理解业务逻辑，完成数据模型设计及优化工作3. 完成海量数据的获取、清洗、分类、整合等数据处理工作任职资格:1. 有丰富的数据处理工作经验, 熟悉了解数据仓库；2. 正直，细心，认真，具有良好的团队合作意识；3. 思路敏捷，沟通能力强，有耐心，责任心强，解决问题能力强，能独立完成工作；4. 有较强的学习能力和上进心；5. 一年以上ETL数据开发经验和Hadoop的数仓开发经验者优先；"
"职位描述：
        
        职位描述：1、负责数据仓库开发、设计与维护，建立数据中台，确保数据质量，为公司其他部门提供数据支撑；2、业务报表的开发以及报表可视化工具开发。职位要求：1、本科及以上学历，计算机或数学相关专业，有数据仓库设计和架构经验优先；2、熟悉阿里云DataWorks、Maxcompute；3、熟练掌握Mysql、PostgreSql?数据库设计、开发经验，熟练掌握SQL语法；4、熟悉python、SAS、大数据优先考虑；5、有数据分析经验优先；6、具备良好的编码习惯和注释习惯、注重细节处理；7、成熟稳重、逻辑思维能力强，具有良好的学习、沟通、协调能力。"
"职位描述：
        
        工作职责:1.进行大数据相关产品的研发，包括时序存储、流计算、离线分析等2.利用统计，机器学习，深度学习等算法解决问题，将人工智能算法应用到各种应用场景任职资格:1.熟悉Java，熟悉数据结构与算法设计，了解并发程序设计，熟悉Python、MATLAB、Octave等某一种的开发经验2.对Hadoop或者Spark有过开发经验，对分布式队列以及分布式数据库有过开发经验3.具有很强的数据分析能力与敏感度，能快速从给定的数据中找出规律4.有扎实的基本功和良好的逻辑思维能力"
"职位描述：
        
        工作职责:1、主要从事B/S结构的应用软件的开发；2、根据需求进行分析，并完成相应技术文档。3、独立完成项目经理所分配的软件开发任务，并与项目组其他成员紧密合作。任职资格:1、熟悉阿里云计算和大数据产品（如ODPS，ADS、BASE等），参与技术预研、选型与技术攻坚工作。2、熟悉oracle/MySQL数据库开发技术，精通SQL语言。3、有较好的编程能力和编程经验，精通J2EE编程，对分布式中间件有一定的了解。4、对大数据、云计算、开源软件、传统数据仓库类产品有一定的深度和广度。5、熟悉数据仓库产品，熟悉数据仓库理论与维度建模，对大数据需求分析与处理有深刻认识和实战经验，如Hadoop/MapReduce/Hive，Storm/Spark，Impala，MPP等的数据应用开发。6、较强的逻辑思维能力和良好的沟通能力，有团队协作精神，工作积极主动。7、有数据挖掘、分析模型与算法、数学建模项目经验者优先。"
"职位描述：
        
        职位描述:
1.?????? 具备金融行业相关知识或跨境电商行业知识，对海关进出口业务有一定的了解，3年以上风险控制项目经验，对风险博弈有较为深入的研究以及独特的见解。
2.?????? 对统计分析、数据挖掘和机器学习算法（分类，聚类，关联规则，神经网络，深度学习）有深刻的理解，熟练操作数据库，熟练使用python，对机器学习领域中的特征工程，模型优化迭代有着丰富的实践经验，有自然语言处理经验尤佳。
3.?????? 有丰富的大数据项目实战经验，能促成大数据项目落地。
4.?????? 有大数据风控建模经验优先。
任职要求:
1.?????? 具备3年及以上大数据系统开发经验，计算机相关专业本科及以上学历；
2.?????? 有实时流处理经验，至少掌握Spark streaming，掌握Flink、Storm等实时处理框架优先；
3.?????? 熟悉并会使用spark mllib、机器学习、自然语言处理等相关技术和算法；
4.?????? 具有Hadoop/Spark，以及kafka、flume、hbase、hive、zookeeper等大数据生态圈实际开发经验。深入了解Hadoop/Spark生态圈产品的工作原理及应用场景；
5.?????? 具备较强的学习能力、自我驱动型、自我管理型。"
"职位描述：
        
        工作职责:1、承担数据仓库主体模型管理、分析、设计工作；2、负责数据集市模型映射及数据校验工作。任职资格:必备技能：从事金融行业数据仓库或统计类系统设计、开发工作2-3年及以上；精通SQL、PL/SQL语言开发；精通DB2，oracle等传统数据库"
"职位描述：
        
        岗位职责：
基础大数据组件研发方向：?1.负责Hadoop的研发资源隔离、预算管理、权限控制、集群联邦方案的研究和开发?2.消息系统kafka研发，负责负载均衡、权限控制、预算管理、资源隔离方案预言与研发?3.KV系统Hbase研发，负责负责负载均衡、权限控制、预算管理、资源隔离方案预言与研发?4.计算系统spark、flink平台化、性能优化、接口封装、调度集成等开发?5.hive扩展能力提升，hive元数据组织方式重构研发。?数据开发平台研发方向：?1、日志采集系统研发（采集agent、采集manager、采集kafka-hdfs等模块）?2、ETL配置服务、配置组件研发?3、资源管理、预算申请、权限控制服务研发?4、kafka、spark、flink、hive平台化开发?5、OLAP解决方案开发?数据应用产品开发与支持方向：?1、基于实时计算的调用链分析系统研发?2、基于实时计算的trace、监控系统研发?3、数据挖掘工程优化与方案调研、研发?4、其他数据产品解决方案研发
任职要求：
基础大数据组件研发方向：?1、精通一门高级编程语言?2、至少精通hadoop、spark、kafka等大数据组件中的1种，并具备其中一种源码分析和开发能力?3、熟悉大数据平台架构?4、熟悉大数据系统的资源管理、高可用建设方案?5、熟悉大数据系统的网络架构?数据开发平台研发方向：?1、精通数据ETL、数据仓库、数据统计分析的开发流程?2、精通基于分布式存储、计算系统的数据应用开发?3、精通hive、spark、mapreduce编程接口?4、熟悉分布式存储和计算系统的基本原理?5、熟悉hive、spark、mapreduce的运行机制?数据应用产品开发与支持方向：?1、熟悉hive、spark、mapreduce编程接口?2、熟悉分布式存储和计算系统的基本原理?3、熟悉hive、spark、mapreduce的运行机制"
"职位描述：
        
        岗位职责：
1、负责公司互联网数据ETL数据清洗工作；?2、负责公司各互联网产品的报表开发及版本迭代；?3、负责平台的整体数据架构设计，对数据有较高敏感性，完成从业务模型到数据模型的设计及开发工作；?4、负责Hadoop平台数据仓库、数据集成、数据管理的整体架构设计工作。
任职要求：
1、本科及以上学历，2年以上大数据开发经验；?2、熟悉hadoop相关各种开源项目，Hive/Hbase等有实际应用开发经验；?3、熟练使用HSql，有一定的SQL编写和优化调优经验；?4、熟练使用Linux系统，有Shell、Python等脚本编程经验；?5、有java编程经验者优先，有数据仓库、BI系统项目开发经验者优先。"
"职位描述：
        
        岗位职责:?
1、参与数据挖掘、数据建模、数据画像等平台相关的产品规划、设计、优化。
2、接口公司BI部门，参与业务专题分析，深入研究用户行为，定期提供各产品、运营数据分析解读，提供决策指导
3、挖掘业务数据，寻找数据价值点，联合BI等公司数据分析资源在业务中实现数据价值落地。
?
任职要求:?
1、?计算机或相关专业，本科及以上学历，3年以上工作经验；
2、熟悉Hadoop、HBASE、Hive、Spark等分布式计算平台，有大数据应用系统开发经验者优先；?
3、熟悉JAVA，熟悉linux，至少熟练使用Shell、Python、Perl等脚本语言之一；
4、精通SQL，有较好的SQL性能调优经验，最好有hadoop,hive,hbase开发经验。
5、熟悉BI开发流程，参与过大型数据仓库类项目；
6、熟电子商务相关业务流程，具有业务分析及建模能力；?
7、良好的逻辑分析能力、分析问题和解决问题的能力，对数据敏感，良好的沟通能力；?
8、工作认真、负责、仔细，有良好的团队合作精神，良好的分析能力、沟通技巧。"
"职位描述：
        
        工作职责： ? ?1. 数据接入、数据仓库建设 ? ?2. 基于数据仓库完成各类业务数据开发、数据可视化展示 任职要求： ? ?1. 计算机相关专业，大四或研究生在读 ? ?2. 熟悉数据库技术，理解数据库、数据仓库设计理论，熟练使用SQL ? ?3. 了解大数据平台技术，如Hadoop、Spark、Hive及相关组件 ? ?4. 熟悉至少一门以上编程语言，如Python、Java、Go等 ? ?5. 了解HTML5、JavaScript，能够基于Web实现数据可视化"
"职位描述：
        
        职位描述：1，负责大数据平台的开发维护，以及分布式系统性能优化，保障数据平台服务的稳定性和可用性；2，参与数仓建设，整合多元化业务数据；3，负责和参与大数据基础架构的监控、资源管理、数据流管理，能够推进及开发大数据自动化运维与监控工具；4，能对系统关键模块进行技术选型分析。
职位要求：1，全日制大学本科及以上学历，2年以上大数据开发经验，经验丰富者可放宽学历要求；2，熟悉Hadoop、Storm、Spark、Flume、Kafka、Hbase等组件的原理，有良好的系统性能优化及故障排除能力；3，对Hadoop平台架构能够不断优化，提升数据产品的质量和响应速度；4，精通至少一种编程语言，Java、Scala、Python；5，有大规模hadoop运维经验者优先，有hadoop/hbase/ES等开发经验者优先。"
"职位描述：
        
        岗位职责：
1.?负责数据中台的设计和落地，降低数据使用成本，让数据赋能业务；
2.?发掘数据的商业价值，深入消费者数据体系、商家数据体系、广告等数据业务，探索数据资产变现方法。

工作内容：
1.研发数据产品，包括但是不限于数据的收集,转化,存储,展示；
2.开发可靠,高效准确的数据集市,并提供技术支持；
3.维护和升级大数据基础设施；
4.进行算法平台的需求分析，方案设计。

基本要求：
1.熟悉hadoop/hbase/storm/spark等分布式计算技术，熟悉其运行机制和体系结构；
2.熟悉Mysql，ES，HBase，Redis等存储引擎的数据存储及使用方法；
3.熟悉基本的算法研发，验证，上线流程；
4.有一定的数据分析和挖掘能力，能从海量数据提炼核心结果，及时发现和分析其中隐含的变化和问题；
5.能够通过数据化运营发现、分析问题和优化流程，推动数据处理流程自动化，提升团队运转效率；
6.对数据敏感，有良好的沟通表达能力和跨团队协调能力，乐于寻求挑战和突破自我。"
"职位描述：
        
        工作职责：
1.?协助算法团队同学做算法技术的工具化和沉淀，提高算法开发效率，缩短算法项目上线周期
2.?负责大数据平台算法平台的设计和构建以支撑通用场景，提高自动化程度
工作内容
1.负责算法平台的需求分析，方案设计
2.负责将tensorflow相关组件和当前spark，hdfs等大数据组件进行有效整合
3.负责算法平台研发过程中的系统开发工作
任职要求：
1.曾经参与过算法平台相关产品的研发，熟悉相关系统架构
2.熟悉基本的算法研发，验证，上线流程
3.熟悉Mysql，ES，?HBase，?Redis等存储引擎的数据存储及使用方法?
4.熟悉Java，Python，Scala等编程语言
5.熟悉Hive，Spark，Tensorflow等工具的使用
成长建议：
1.?了解大数据领域的常用技术栈，如Hadoop/Spark/Flink等，熟悉常用的离线/实时系统开发模式
2.?针对某一个感兴趣的大数据组件，深入研究源码，掌握定制开发的能力
3.?对算法（Spark?mlib/tensorflow等）有一定的了解，可以从常用的算法库入手学习，了解公司内常用的算法开发场景，掌握一定的领域建模和系统抽象能力"
"职位描述：
        
        职位描述：
1.基于Hive， Spark，Hadoop的计算架构，进行大数据开发工作；
2.在分布式集群上进行Hive和Spark数据开发；
3.能够定位数据计算任务的瓶颈并进行性能优化；
4.能够针对具体的业务场景，实现一些机器学习运算。

职位要求：
1.计算机相关本科及以上学历，3年以上大数据开发经验；
2.熟悉数据库、数据仓库建模方法论；
3.精通SQL语言，熟练掌握Hive开发，Spark开发大数据开发技能，有数据计算性能调优经验；
4.有ETL性能调优经验者优先，有数据仓库部门从业经验者优先；
5.使用过阿里云MaxCompute（原ODPS）的优先；
6.有强烈的责任心和团队合作精神、具备良好的沟通能力以及快速学习的能力。"
"职位描述：
        
        岗位职责:
1. 负责数据平台内各个子系统的设计、研发。这些系统包括但不限于数据仓库、ETL、BI、监控、日志等；
2. 负责大数据相关的技术、工具、方法调研与应用；
3. 负责设计和规划各种后台系统的结构，制定统一的数据规范、通信协议等，提升数据质量，提升系统稳定性，互操作性，可扩展性等；
4. 负责分析并解决性能瓶颈，跟团队成员分享最佳实践，参与code review。

任职要求:
1. 精通Java、Python或C/C++至少一种语言
2. 2年以上后台开发经验
3. 酷爱编程，开发能力强，代码能力过硬，熟练掌握常用的数据结构和算法
4. 有独立学习、探索、定位、解决复杂技术问题的能力，可以搞定别人摸不着头脑的工程难题
5. Linux平台下的开发，熟练使用Shell命令，熟练使用MySQL命令，熟悉Git团队开发流程
6. 具有良好的沟通能力，良好的团队合作精神，乐于分享技术经验
7. 能熟练使用elasticsearch，neo4j，flink，spark等相关技术者优先
8. 有过PaaS系统设计和开发经验者优先
9. 有过数据仓库、ETL、BI系统设计和开发经验者优先"
"职位描述：
        
        岗位职责1. 基于对需求的准确理解，前瞻性地构建数据概念模型，逻辑模型及物理模型2. 深入理解业务逻辑，结合当前架构或业务场景设计可行性优化方案参与数据模型体系构建及数据主题设计和开发，搭建离线、实时数据公共层3. 主导数据产品与应用的紧密结合，发掘数据商业价值，充分考虑业务方的可用性和成本，打造极致体验的数据产品4. 主导建立和维护大数据平台技术标准规范，指导开发人员编写代码，编写相关技术文档5. 配合产品经理规划大数据应用设计并实施6. 关注大数据领域前沿技术、方法，并及时分享到团队内部，促进团队能力和工作效率的提升任职要求1.了解未来数据模型和计算框架的创新与落地，包括但不限于以下领域：大规模数据实时化、研发模式敏捷化、数据计算框架轻量化、数据模型组织方式业务化等方面,主导数据架构的优化升级2. 熟练掌握数据仓库实施理论，具备大型数据仓库设计，模型设计优化能力3. 熟练掌握大数据开发语言，具有面向对象编程思想，对底层实现有一定研究4. 熟悉主流分布式处理框架，如spark,hadoop，熟练掌握大数据仓库技术，如HIVE数据仓库的搭建。5. 了解常规的机器学习算法：降维(PCA、SVD)、SVM、逻辑回归(Logistics Regression)、决策树(GBDT、RandomForest)、关联规则(Apriori、FP-Growth)、聚类(K-Means)等优先6. 熟悉互金业务模式逻辑和关键点，熟悉项目全流程关键点，具备快速定位业务问题，并提出实际技术解决方案能力7 具备培养核心骨干，前沿技术输出及培训的能力，具备技术和目标规划、方法论优化应用，并有效推进团队成员高效高质完成工作目标的管理能力"
"职位描述：
        
        岗位职责1. 基于对需求的准确理解，前瞻性地构建数据概念模型，逻辑模型及物理模型2. 深入理解业务逻辑，结合当前架构或业务场景设计可行性优化方案参与数据模型体系构建及数据主题设计和开发，搭建离线、实时数据公共层3. 主导数据产品与应用的紧密结合，发掘数据商业价值，充分考虑业务方的可用性和成本，打造极致体验的数据产品4. 主导建立和维护大数据平台技术标准规范，指导开发人员编写代码，编写相关技术文档5. 配合产品经理规划大数据应用设计并实施6. 关注大数据领域前沿技术、方法，并及时分享到团队内部，促进团队能力和工作效率的提升任职要求1.了解未来数据模型和计算框架的创新与落地，包括但不限于以下领域：大规模数据实时化、研发模式敏捷化、数据计算框架轻量化、数据模型组织方式业务化等方面,主导数据架构的优化升级2. 熟练掌握数据仓库实施理论，具备大型数据仓库设计，模型设计优化能力3. 熟练掌握大数据开发语言，具有面向对象编程思想，对底层实现有一定研究4. 熟悉主流分布式处理框架，如spark,hadoop，熟练掌握大数据仓库技术，如HIVE数据仓库的搭建。5. 了解常规的机器学习算法：降维(PCA、SVD)、SVM、逻辑回归(Logistics Regression)、决策树(GBDT、RandomForest)、关联规则(Apriori、FP-Growth)、聚类(K-Means)等优先6. 熟悉互金业务模式逻辑和关键点，熟悉项目全流程关键点，具备快速定位业务问题，并提出实际技术解决方案能力7 具备培养核心骨干，前沿技术输出及培训的能力，具备技术和目标规划、方法论优化应用，并有效推进团队成员高效高质完成工作目标的管理能力"
"职位描述：
        
        岗位职责
1、负责BI工具的部署和报表系统的研发工作，对外数据对接接口的研发工作，数据爬虫程序的编写和数据爬取工作。
2、根据业务需求，设计软件架构；系统集成，设计系统对接方式。
3、编写优质代码，高效构建web程序和前端js程序，能性能调优和故障处理，解决应用程序端安全性问题。
4、互联网和对接服务日志数据的方案设计和数据存储系统的开发（规划）。
任职要求
1、熟练精通Oracle、MySql等一种或者多种关系型数据库。
2、熟练使用编程语言Java、JavaScript、html等，精通Spring、MVC和SOA等常见软件架构。
3、了解开源系统，图表或者其他可视化报表平台的研发。
4、熟悉精通前端开发，有bootstrap、Echar、Hchart等可视化开源框架和html5开发经验者可优先考虑。
5、熟悉Linux系统，会编写Shell脚本，熟悉Java故障调试和GC分析等服务器问题处理方法。
6、有python的研发经历、数据分析或机器学习的经验，大数据开发经验者更优。"
"职位描述：
        
        岗位职责1. ?负责互联网产品从用户分析、画像模型及内容推荐全流程的数据挖掘产品的设计和实现；2. ?构建有效且通用的模型，支持现有业务并适应业务的不断拓展；3. ?配合数据挖掘工程师工作，建立高效的数据处理和分析流程。任职资格1. ?5年以上大数据开发经验，扎实的编程基础，精通JAVA语言，2. ?熟悉并应用大数据相关技术，Hadoop, Spark, Hive，Elasticsearch等3. ?熟练掌握数据库技术并有优化经验， Mysql, Redis等4. ?良好的分析能力，能够基于对业务的深入理解，设计出灵活可扩展的产品功能；5. ?良好的沟通能力和团队合作精神。"
"职位描述：
        
        岗位职责1. ?负责互联网产品从用户分析、画像模型及内容推荐全流程的数据挖掘产品的设计和实现；2. ?构建有效且通用的模型，支持现有业务并适应业务的不断拓展；3. ?配合数据挖掘工程师工作，建立高效的数据处理和分析流程。任职资格1. ?5年以上大数据开发经验，扎实的编程基础，精通JAVA语言，2. ?熟悉并应用大数据相关技术，Hadoop, Spark, Hive，Elasticsearch等3. ?熟练掌握数据库技术并有优化经验， Mysql, Redis等4. ?良好的分析能力，能够基于对业务的深入理解，设计出灵活可扩展的产品功能；5. ?良好的沟通能力和团队合作精神。"
"职位描述：
        
        职责：1. 负责公司数据平台的设计和开发，包括olap查询引擎/产品/平台化等开发工作，服务于全公司各个产品线2. 日志数据的治理体系：埋点梳理、验证及保障，开发全面完善的产品报表、效果报表和A/B Test报表；3. 灰度实验/abtest系统：线上流量分配器，高查询性能实验数据分析平台的搭建和改造。
要求：1. 熟悉linux c/c++ 、go、python的一种或多种，有良好的数据结构和算法基础；2. 深入理解数据库或NOSQL系统，有实际数据库调优或NOSQL使用经验；3. 有hadoop生态系统的理解和实操经验，对分布式系统原理有较好的理解；4. 逻辑思维清晰，做事有条理，目标导向。


公司简介
小川科技 www.ixiaochuan.cn

1我们做什么
我们看好移动上的兴趣社交。通过发现兴趣和聚集同好，我们帮助年轻人畅快交流，发现自我。
我们理解的兴趣社交是：因为有爱，我们不孤单。
我们约会但不约炮，娱乐但不低俗，我们的愿景是：让你的兴趣不再孤单。?

2我们是谁
我们是连续创业者，我们失败过；我们也坚定的认为，我们将成功。
移动将改变生活，移动是一场革命，我们对此坚信不移。
我们是行动派，简单务实。不做游戏。不追概念。不尚空谈。
我们是最右，2014年底成立。优秀创业团队，著名投资人。?

3我们想建立什么样的公司
我们致力于建立一家有想象力的公司。创新、主动和团队是我们的信条。
在这里，你会创造一些东西。一些不能在其他地方创造的东西，一些让人们深深着迷的东西，一些可以让你自豪的介绍给家人和朋友的东西，一些让这个世界变更美好的东西。
在这里，你可以找到这样的工作。你会为它全情投入、绝不妥协，你会为它追求细节、关注效果，它会让你心甘情愿牺牲休息时间，但完成后会给你带来极大的满足感和成就感。
在这里，你会不断成长。你不再害怕犯错，因为你从成功中成长，也从失败中成长。你不断的发现自己，了解自己，你会发现你一步步变得强大，你会更热爱生活。
这里没有官僚流程，没有打卡，没有KPI，没有不做事的管理者。
这里没有员工。每一位同事都是我们的家人。你的快乐就是我们的快乐，你的困难就是我们的困难，我们期望和你一起努力、一起成长。
我们期望，与你一起，建立一家属于你的公司。?

4我们怎么工作
我们是创业团队，我们找伙伴，不找员工。
我们支持问题解决者。谁能解决问题，谁说了算。
我们一竿子捅到底。写代码，还要测试，还要客服。
我们努力跑得快一点，再快一点。我们自己和自己较劲。
我们很自由。想说什么就说，疲倦了可以打游戏，不想上班就在家歇歇。
我们相信，各人有各人的方式，成功不在于打卡，而在于投入。
我们不做平庸的公司，也不要平庸的员工。我们是创业者，我们一直在路上。?

5福利
员工是伙伴。我们将为小伙伴们提供最好的福利待遇。
我们努力培养你。你有多大能耐，就有多大空间。
与同级别公司相比，最右将提供最好的工资，最多的股票。
弹性工作制，中午2小时午休，免费三餐，每月有住房补贴。
?
6应聘指南
我们只寻找创业者。请认真思考：我真的要创业吗？
在加入之前，试用产品是值得的。质疑反映了你的独立思考，我们很珍惜。
不要反感我们的过关题，一个你将要合作3年的团队，值得你花3个小时。
检查我们，考察我们，拷问我们：这是我在寻找的团队吗？"
"职位描述：
        
        岗位描述：
1. 负责开发实时计算pipeline，服务于全公司各个产品线
2. 灰度实验/abtest系统：线上流量分配器，高查询性能实验数据分析平台的搭建和改造
3.基于druid的olap系统开发优化

岗位要求：
1. 熟悉java 、scala、python的一种或多种，有良好的数据结构和算法基础
2. 至少精通一个实时计算框架，如：flink、storm、jstorm、spark streaming，对其有深入研究优先
3. 熟悉其他的大数据组件，如：flume、kafka、hbase、redis、hive、yarn等
4.有druid、kylin等olap系统开发经验优先
5. 逻辑思维清晰，做事有条理，目标导向

公司简介
小川科技 www.ixiaochuan.cn

1我们做什么
我们看好移动上的兴趣社交。通过发现兴趣和聚集同好，我们帮助年轻人畅快交流，发现自我。
我们理解的兴趣社交是：因为有爱，我们不孤单。
我们约会但不约炮，娱乐但不低俗，我们的愿景是：让你的兴趣不再孤单。?

2我们是谁
我们是连续创业者，我们失败过；我们也坚定的认为，我们将成功。
移动将改变生活，移动是一场革命，我们对此坚信不移。
我们是行动派，简单务实。不做游戏。不追概念。不尚空谈。
我们是最右，2014年底成立。优秀创业团队，著名投资人。?

3我们想建立什么样的公司
我们致力于建立一家有想象力的公司。创新、主动和团队是我们的信条。
在这里，你会创造一些东西。一些不能在其他地方创造的东西，一些让人们深深着迷的东西，一些可以让你自豪的介绍给家人和朋友的东西，一些让这个世界变更美好的东西。
在这里，你可以找到这样的工作。你会为它全情投入、绝不妥协，你会为它追求细节、关注效果，它会让你心甘情愿牺牲休息时间，但完成后会给你带来极大的满足感和成就感。
在这里，你会不断成长。你不再害怕犯错，因为你从成功中成长，也从失败中成长。你不断的发现自己，了解自己，你会发现你一步步变得强大，你会更热爱生活。
这里没有官僚流程，没有打卡，没有KPI，没有不做事的管理者。
这里没有员工。每一位同事都是我们的家人。你的快乐就是我们的快乐，你的困难就是我们的困难，我们期望和你一起努力、一起成长。
我们期望，与你一起，建立一家属于你的公司。?

4我们怎么工作
我们是创业团队，我们找伙伴，不找员工。
我们支持问题解决者。谁能解决问题，谁说了算。
我们一竿子捅到底。写代码，还要测试，还要客服。
我们努力跑得快一点，再快一点。我们自己和自己较劲。
我们很自由。想说什么就说，疲倦了可以打游戏，不想上班就在家歇歇。
我们相信，各人有各人的方式，成功不在于打卡，而在于投入。
我们不做平庸的公司，也不要平庸的员工。我们是创业者，我们一直在路上。?

5福利
员工是伙伴。我们将为小伙伴们提供最好的福利待遇。
我们努力培养你。你有多大能耐，就有多大空间。
与同级别公司相比，最右将提供最好的工资，最多的股票。
弹性工作制，中午2小时午休，免费三餐，每月有住房补贴。
?
6应聘指南
我们只寻找创业者。请认真思考：我真的要创业吗？
在加入之前，试用产品是值得的。质疑反映了你的独立思考，我们很珍惜。
不要反感我们的过关题，一个你将要合作3年的团队，值得你花3个小时。
检查我们，考察我们，拷问我们：这是我在寻找的团队吗？"
"职位描述：
        
        职责：1. 负责公司数据平台的设计和开发，包括olap查询引擎/产品/平台化等开发工作，服务于全公司各个产品线2. 日志数据的治理体系：埋点梳理、验证及保障，开发全面完善的产品报表、效果报表和A/B Test报表；3. 灰度实验/abtest系统：线上流量分配器，高查询性能实验数据分析平台的搭建和改造。要求：1. 熟悉linux c/c++ 、go、python的一种或多种，有良好的数据结构和算法基础；2. 深入理解数据库或NOSQL系统，有实际数据库调优或NOSQL使用经验；3. 有hadoop生态系统的理解和实操经验，对分布式系统原理有较好的理解；4. 逻辑思维清晰，做事有条理，目标导向。"
"职位描述：
        
        职责：
1.负责公司数据平台的设计和开发，包括olap查询引擎/产品/平台化等开发工作，服务于全公司各个产品线；
2.日志数据的治理体系：埋点梳理、验证及保障，开发全面完善的产品报表、效果报表和A/B Test报表； 3. 灰度实验/abtest系统：线上流量分配器，高查询性能实验数据分析平台的搭建和改造。



要求： 1. 熟悉linux c/c++ 、go、python的一种或多种，有良好的数据结构和算法基础； 2. 深入理解数据库或NOSQL系统，有实际数据库调优或NOSQL使用经验； 3. 有hadoop生态系统的理解和实操经验，对分布式系统原理有较好的理解； 4. 逻辑思维清晰，做事有条理，目标导向。"
"职位描述：
        
        职位描述：
1.海量业务数据的ETL，数据准备与清洗；
2.实时特征处理系统的开发与测试；
3.算法服务的开发与测试。

职位要求：
1.本科或以上学历，计算机、软件工程、自动化等相关专业，1年以上大数据处理与开发经验；
2.熟练掌握至少一门编程语言(javascalac++等)；
3.具有Hadoop/Spark/Hive开发与使用经验；
4.了解mysql/hbase/redis等sql与nosql数据库；
5.了解Storm/Spark Streaming等实时数据处理相关工具；
6.有较强的沟通表达能力，善于学习，能迅速理解需求；
7.有数据仓库／ETL经验者优先；
8.有一定的算法背景，了解文本挖掘或机器学习者优先。"
"职位描述：
        
        1.???????? 掌握传统关系型数据库（mysql、oracle、postgreSQL等）以及分布式关系型数据库（hive、hbase等）的原理和知识；
2.???????? 有过支撑实际大数据平台建设及维护经验；
3.???????? 具备较强的编码能力，掌握 java/scala/python 等主流开发语言，熟练使用 SQL 进行数据访问；
4.???????? 具备hadoop生态的大数据计算平台及其相关组件开发和维护能力并有实战经验，包括但不限于hadoop、hive、spark、impala、kafka、flume、hbase、elasticsearch等，能够熟练安装、配置部署和优化大型hadoop集群系统；
5.???????? 熟练使用某种ETL工具；
6.???????? 工作地点为北京、无锡"
"职位描述：
        
        岗位职责：
1. 负责业务、算法数据采集，数据清洗。
2. 负责数据特征提取与数据管理。
?3. 对模型任务供给相应语料。?

任职资格：
1. 熟练爬虫，可对小程序、APP进行爬取。
?2. 具有一定数据处理经验，可对数据做初步分析并提取特征。
?3. 对文本分类类型任务的语料构建，有一定经验。?
4. 具有一定工程开发能力。"
"职位描述：
        
        职责描述：
1、负责设计落地数据整合、收集、关联和计算
2、与算法工程师一起创造高效、可伸缩的算法产品
3、为公司提供大数据存储、分析、计算支持
?
职位要求：
1、计算机相关专业，本科及以上学历,3年以上相关工作经验
2、熟悉flume、kafka、hadoop,spark,hbase,hive等其中一个或者多个技术
3、熟悉git等开发管理工具，熟悉Unix/linux系统
4、熟悉大数据领域的解决方案形态，数据仓库建模和设计，海量分布式数据处理架构
5、阅读并改写过hadoop/spark源码优先
6、语言方面熟悉python、java、Scala者优先
7、了解 Hadoop 生态系统，看过系统组件源码或参与社区建设
8、对hadoop，hbase高可用和安全方面有经验
9、对hadoop,hbase,spark运维监控和性能有深入理解和经验
10、有运维百台规模以上hadoop集群经验（社区或自研版本，非cdh等定制版）
11、良好的沟通能力，有团队合作精神和责任感"
"职位描述：
        
        1、负责设计落地数据整合、收集、关联和计算
2、与算法工程师一起创造高效、可伸缩的算法产品
3、为公司提供大数据存储、分析、计算支持
?
职位要求：
1、计算机相关专业，本科及以上学历, 3年以上相关工作经验
2、熟悉flume、kafka、hadoop,spark,hbase,hive等其中一个或者多个技术
3、熟悉git等开发管理工具，熟悉Unix/linux系统
4、熟悉大数据领域的解决方案形态，数据仓库建模和设计，海量分布式数据处理架构
5、阅读并改写过hadoop/spark源码优先
6、语言方面熟悉python、java、Scala者优先
7、了解 Hadoop 生态系统，看过系统组件源码或参与社区建设
8、对hadoop，hbase高可用和安全方面有经验
9、对hadoop,hbase,spark运维监控和性能有深入理解和经验
10、有运维百台规模以上hadoop集群经验（社区或自研版本，非cdh等定制版）
11、良好的沟通能力，有团队合作精神和责任感"
"职位描述：
        
        职位描述：
1，参与企业级数据仓库的搭建，根据数据仓库及BI项目的需求，制定ETL相关的设计方案和开发计划，并进行后续的设计、实施；2，参与数据仓库及BI项目基础架构规划、安全规划、ETL架构和规范制定；
3，根据各个产品线核心指标，分析这些核心指标背后的原因例如产品的逾期率，通过率等；
4，通过数据分析、调研等手段，解决业务问题，根据资源及项目目标，确定解决方案并推进实现。

职位要求：
1, 计算机相关专业，本科及以上学历, 3年以上相关工作经验;
2, 有大数据BI项目实际开发经验，熟悉saiku、mondrian、kylin;
3, 有丰富的数据分析经验，能够用最快速最简单的方法得出结论，驱动业务;
4, 熟悉Git等开发管理工具，熟悉Unix/Linux系统;
5, 熟悉Hadoop系统，对HDFS、HBASE、HIVE者优先;
6, 语言方面熟悉Python、Java、Go者优先。"
"职位描述：
        
        职位描述：
1，参与企业级数据仓库的搭建，根据数据仓库及BI项目的需求，制定ETL相关的设计方案和开发计划，并进行后续的设计、实施
2，参与数据仓库及BI项目基础架构规划、安全规划、ETL架构和规范制定,
3，根据各个产品线核心指标，分析这些核心指标背后的原因例如产品的逾期率，通过率等
4，通过数据分析、调研等手段，解决业务问题，根据资源及项目目标，确定解决方案并推进实现

职位要求：
1、计算机相关专业，本科及以上学历, 3年以上相关工作经验
2、有大数据BI项目实际开发经验，熟悉saiku、mondrian、kylin
3，有丰富的数据分析经验，能够用最快速最简单的方法得出结论，驱动业务,
4、熟悉Git等开发管理工具，熟悉Unix/Linux系统
5、熟悉Hadoop系统，对HDFS、HBASE、HIVE者优先
6、语言方面熟悉Python、Java、Go者优先"
"职位描述：
        
        1，参与企业级数据仓库的搭建，根据数据仓库及BI项目的需求，制定ETL相关的设计方案和开发计划，并进行后续的设计、实施；
2，参与数据仓库及BI项目基础架构规划、安全规划、ETL架构和规范制定；
3，根据各个产品线核心指标，分析这些核心指标背后的原因例如产品的逾期率，通过率等；
4，通过数据分析、调研等手段，解决业务问题，根据资源及项目目标，确定解决方案并推进实现。

职位要求：
1, 计算机相关专业，本科及以上学历,3年以上相关工作经验;
2, 有大数据BI项目实际开发经验，熟悉spark、saiku、mondrian、kylin;
3, 有丰富的数据分析经验，能够用最快速最简单的方法得出结论，驱动业务;
4, 熟悉Git等开发管理工具，熟悉Unix/Linux系统;
5, 熟悉Hadoop系统，对HDFS、HBASE、HIVE者优先;
6, 语言方面熟悉Python、Java、Go者优先。"
"职位描述：
        
        1、至少3年以上大数据生态系统相关项目工作经验，如Hadoop、Hive、HBase、Spark、Kafka。
2、有扎实的Java基础，有面向对象编程经验，有开发语言、Java和/或Python的客户项目经验，Python经验优先。
3、在处理大量结构化和非结构化数据方面经验丰富。有MapReduce经验者优先。
4、有Linux shell脚本经验，知道如何配置和调优开源软件。
5、有使用JBoss/Wildfly, Git, Gerrit的经验。
6、熟悉RDBMS (MySql、PostgresSql、Oracle等)和NoSQL (HBase、MongoDB、Redis等)。
7、有大数据产品容量和性能调优经验者优先。
8、有Web UI开发经验者优先考虑，尤其是React和其他行业架构。
9、良好的沟通能力，愿意与公司合作。
10、良好的英语读写能力。
11、自我激励和团队合作。"
"职位描述：
        
        任职要求：
1、至少3年以上大数据生态系统相关项目工作经验，如Hadoop、Hive、HBase、Spark、Kafka。
2、有开发语言、Java和/或Python的客户项目经验，Python经验优先。
3、在处理大量结构化和非结构化数据方面经验丰富。有MapReduce经验者优先。
4、有Linux shell脚本经验，知道如何配置和调优开源软件。
5、有使用JBoss/Wildfly, Git, Gerrit的经验。
6、熟悉RDBMS (MySql、PostgresSql、Oracle等)和NoSQL (HBase、MongoDB、Redis等)。
7、有大数据产品容量和性能调优经验者优先。
8、有Web UI开发经验者优先考虑，尤其是React和其他行业架构。
9、良好的沟通能力，愿意与公司合作。
10、良好的英语读写能力。
11、自我激励和团队合作。
岗位职责：
与产品负责人合作，根据需求建立成本效益高、可靠的解决方案。
以商定的成本和良好的质量实施解决方案
将应用程序与其他/外部系统或应用程序集成。
故障排除和bug修复
部署应用程序并支持用户
提出改进和优化思路并跟进"
"职位描述：
        
        职位内容：
为国际领先的人工智能计算平台产品开发和维护大规模分布式数据处理架构。


职位要求：
1. 熟练掌握计算机专业知识（算法和数据结构，分布式系统，数据库等）
2. 具有3年以上基于Linux的分布式系统开发和维护经验；具备云计算项目经验者优先。
3. 具有1年以上基于Spark或Hadoop体系的分布式数据处理架构开发和性能优化经验；
4. 熟悉至少一种分布式文件存储系统(例如Hadoop)的应用和开发；
5. 熟悉至少一种NoSQL数据库(例如MongoDB)的应用和开发；
6. 熟悉Python, C++, Linux Shell。

符合下列条件者优先：
1. 了解Kubernetes/Mesos等容器管理系统；
2. 了解Tensorflow/Caffe等机器学习框架；
3.? 有人工智能相关项目经验。


备注：同一候选人请勿重复投递多个岗位，谢谢~"
"职位描述：
        
        职位描述：
????1.负责大数据部门的数据采集与爬取、解析处理、入库及备份等数据日常工作；
????2.负责数据自动化平台的开发与维护
? ? 3.负责分析新的数据需求, 完成数据处理的设计(文档)和实现；
? ? 4.负责数据质量的监控, 根据实际情况设计方案并实现数据质量的提高；
? ? 5.负责数据处理程序设计改善, 数据处理性能优化, 系统数据处理的能力提高；
? ? 6.负责和数据架构师协同工作, 完成架构升级更新；
?
职位要求：
? ? 1.本科及以上学历, 计算机软件及相关专业；
? ? 2.两年以上数据爬虫和ETL处理相关工作经验；
? ? 3.熟练掌握java或者python编程；
? ? 4.熟悉数据库, 对数据处理和数据质量有较深认识, 有NoSQL数据库使用经验优先；
? ? 5.熟悉Linux系统及基本操作；
? ? 6.有责任心, 学习能力强, 工作积极主动, 思路清晰，擅长沟通；
? ? 7.有良好的英文沟通能力者，优先考虑。
? ? 8.了解AWS相关技术，优先考虑"
"职位描述：
        
        岗位职责：? ??
1、负责离线/实时大数据存储/计算平台的设计开发和维护工作
2、负责设计基于大数据的各种实时、离线计算，ETL流程设计和开发
3、运用合适的技术方案支撑公司各种数据处理场景4、最好有管理团队经验，岗位要求：1、4年以上大数据项目经验，精通Java/Python/Scala语言的一种或多种
2、精通Hadoop生态圈，具备较丰富的大数据平台构建、维护及调优经验，有超大数据量级下的大数据集市相关经验
3、具备丰富的Hive、Spark等大数据处理项目经验，具备一定的数据挖掘经验
4、熟练使用MapReduce、HDFS、Hbase、Redis、Kafka
5、良好的逻辑分析能力、分析问题和解决问题的能力，对数据敏感，良好的沟通能力
6、有移动化应用开发接口经验优先；7、具有良好的沟通与表达能力，具有团队合作精神与敬业精神，能承受一定工作压力。"
"职位描述：
        
        职位信息：1、负责设计、开发、维护大数据爬虫系统及数据抓取，对海量数据进行建模、清洗、分析；
2、负责人工智能机器学习相关算法的研发；
3、负责相关算法模型的设计、训练。任职资格:1、要求本科及以上学历，三年以上工作经验；
2、有大数据爬虫和反爬虫开发经验，有App爬取经验；3、熟悉linux平台开发，精通Python，熟悉大规模网页爬取，深度网页爬取，至少熟悉以下一种框架Nutch、Scrapy、Lucene、Heritrix、Solr、Sphinx等；4、了解MongoDB、Redis、Mysql，掌握MQ，了解HBase、KAFKA等；5、熟悉HTTP协议，熟悉正则表达式、XPath、CSS选择器等，了解常用验证码识别技术；6、能独立解决实际开发过程碰到的各类问题；
7、有SAAS,PAAS企业级应用或者大型网络服务开发经验者优先。"
"职位描述：
        
        岗位职责：1、与产品架构师合作，设计满足海量数据可视化分析要求的大数据平台；2、负责使用成熟开源技术定义大数据平台解决方案；3、负责对系统关键模块进行技术选型分析；4、负责大数据平台以及可视化分析支撑服务的开发实现；5、在敏捷团队中完成每个迭代的具体目标任务；6、参与内部技术方案评审与代码审查。任职资格：1、计算机及相关专业本科及以上学历，五年以上JAVA开发经验，两年大数据相关技术经验；2、具有扎实的计算机基础知识和编码功力；3、至少掌握一种脚本编程语言（Python?Shell?Perl?Javascript），有Hadoop大数据平台技术实际项目经验，熟练使用Linux系统环境；4、有责任心、热爱技术、善于沟通和团队合作；5、能够融入敏捷团队进行快速迭代开发；6、对分布式系统的设计实现有深入理解；7、有图数据库相关开发经验者优先；8、有NoSQL数据库开发经验者优先。"
"职位描述：
        
        工作职责：
1、负责大数据BI设计与开发；
2、数据仓库、数据集市的模型设计与开发；
3、负责ETL数据准确性验证及ETL任务的优化；
4、参与大数据平台和数据仓库的搭建；
?
岗位要求：
1、计算机、统计、数学、信息技术等专业本科及以上学历；
2、1-3年或以上工作经历；
3、熟悉大数据处理相关产品架构和技术（如Hadoop/hive/HBASE/spark/kafka/storm/flume等）；
4、熟悉数据仓库理论与技术，对ETL及BI有概念并具有丰富的实际操作经验，熟悉ETL开发流程；
5、熟悉BI项目，具有数据仓库、BI系统开发经验者优先；
6、对mysql、oracle有丰富经验，有较强的数据库脚本编程能力，有较强的存储过程编写能力；
7、熟悉Linux系统，熟悉shell脚本或Python、java；
8、有较强的逻辑思维能力，善于分析、归纳、快速定位并解决问题；
9、性格积极沉稳、勤奋严谨，强烈的进取心、求知欲和团队合作精神。"
"职位描述：
        
        工作职责：
1、负责大数据BI设计与开发；
2、数据仓库、数据集市的模型设计与开发；
3、负责ETL数据准确性验证及ETL任务的优化；
4、参与大数据平台和数据仓库的搭建；
?
岗位要求：
1、计算机、统计、数学、信息技术等专业本科及以上学历；
2、1-3年或以上工作经历；
3、熟悉大数据处理相关产品架构和技术（如Hadoop/hive/HBASE/spark/kafka/storm/flume等）；
4、熟悉数据仓库理论与技术，对ETL及BI有概念并具有丰富的实际操作经验，熟悉ETL开发流程；
5、熟悉BI项目，具有数据仓库、BI系统开发经验者优先；
6、对mysql、oracle有丰富经验，有较强的数据库脚本编程能力，有较强的存储过程编写能力；
7、熟悉Linux系统，熟悉shell脚本或Python、java；
8、有较强的逻辑思维能力，善于分析、归纳、快速定位并解决问题；
9、性格积极沉稳、勤奋严谨，强烈的进取心、求知欲和团队合作精神。"
"职位描述：
        
        岗位职责：
1.参与大数据平台设计与研发，在大数据采集、存储、分析及应用领域都会有所涉及；
2.设计并实现对BI分析、数据产品开发、算法开发的系统性支持；
3.协助完成日常数据分析查询需求。
4.参与需求分析、系统架构设计、并完成需求设计相应文档的编写；
5.参与核心代码实现、系统性能优化。

任职要求：
1.至少两年大数据平台建设经验，掌握大数据开发框架，Hadoop、Hive、HBase、Spark、Storm、Kafka等大数据主流工具和技术，熟悉常用分析、统计和建模方法，精通Linux操作系统和Shell编程；
2.掌握至少一种内存数据库，如Redis/MongoDB等；
3.掌握至少一种关系型数据库，如Oracle/Mysql等；
4.具备独立进行需求调研及分析、系统分析设计的能力；"
"职位描述：
        
        职责描述：1、负责构建，优化公司的数据处理系统，包含实时和离线两种模式；2、按照业务需求完成数据处理相关的研发，包括但不限于ETL、统计分析、用户画像；3、负责非高频场景的在线服务开发。任职要求：1、计算机及相关专业，本科及以上学历，2年以上大数据相关工作经验；2、熟悉Java/Scala/Python/Go/C++等计算机编程语言中的一种或多种；3、熟悉Hadoop生态体系， 掌握HDFS/MapReduce/Spark/Hive/HBase/Flume/kafka等场景开源项目原理并有实际项目经验；4、熟悉Linux操作系统，有扎实的Shell脚本编写能力；5、具有良好的沟通能力，和良好的团队合作精神。"
"职位描述：
        
        岗位职责：

 负责构建, 优化公司的数据处理系统, 包含实时和离线两种模式
 按照业务需求完成数据处理相关的研发, 包括但不限于:ETL, 统计分析, 用户画像
 负责非高频场景的在线服务开发


任职要求：
??? ?计算机及相关专业, 本科及以上学历，3年以上大数据相关工作经验.??? ?熟悉Java/Scala/Python/Go/C++等计算机编程语言中的一种或多种.??? ?熟悉Hadoop生态体系, 掌握HDFS/MapReduce/Spark/Hive/HBase/Flume/kafka等场景开源项目原理并有实际项目经验??? ?熟悉Linux操作系统, 有扎实的Shell脚本编写能力??? ?具有良好的沟通能力，和良好的团队合作精神."
"职位描述：
        
        岗位描述：
1.Hadoop数据平台建设、开发、测试、部署和优化
2.基于Hadoop的存储平台架构设计与性能优化
3.设计和开发海量数据的管理系统

岗位要求：
1.计算机或相关专业本科以上学历，具有扎实的算法和数据结构基础
2.1年以上Hadoop/Hbase/HIVE/Storm开发经验，或者有相关的分布式平台开发经验者
3.精通Java，熟悉java开发工具
4.对Hadoop源代码有研究和有贡献者优先
5.有海量数据挖掘算法开发经验者优先
6.较好的沟通理解能力，优秀的团队合作品质，乐观向上，踏实上进
7.熟悉linux系统，包括shell/python等语言开发"
"职位描述：
        
        岗位职责?1、负责大数据平台架构的评估、规划和设计?；负责海量数据采集、处理及存储、应用方案的技术选型及架构实现；分布式存储、流式/实时计算等应用层架构搭建及核心代码实现；2、开发大数据平台的核心代码，负责大数据平台的搭建，完成系统调试、集成与实施，技术难题的解决，保证大数据产品的上线运行?；3、根据业务需求持续优化数据架构，保证产品的可靠性、稳定性?；4、指导开发人员完成数据模型规划建设，分析模型构建及分析呈现?，分享技术经验；5、负责大数据平台的架构评审，代码评审，上线评审；参与数据应用需求、设计、审核和评审；6、深入研究大数据相关技术和产品，跟进业界先进技术；岗位技能?1．熟悉hive、hbase、storm、mahout、flume、ElasticSearch、Spark、Kafka等，具备实际项目设计及开发经验；2．熟悉sparkstreaming等相关的实时计算技术；3．熟悉大规模数据挖掘、机器学习、自然语言处理、分布式计算中一项或多项技术，并具备多年的实际工作经验；4．熟悉主流关系型数据库（Oracle、MySql）、NoSql数据库，熟悉pl/sql编程；5．对技术充满热情且具有钻研精神，对新技术以及行业动向保持敏感性。任职要求?1．本科及以上学历，数学或计算机相关专业毕业，不少于5年的工作经验，具有扎实的计算机基础理论知识；2．有3年以上Hadoop、Spark、Hbase平台性能调优经验；熟悉sparkstreaming等实时计算技术3. 精通Linux操作系统，熟练使用Java；熟悉常用框架.如Spring、MyBatis等；4．具有较强的执行力，高度的责任感、很强的学习、沟通能力，能够在高压下高效工作；"
"职位描述：
        
        岗位描述:
1.搭建实时与离线计算平台，满足实时报表和实时特征需求
2.为数据分析和实时风控，构建数据处理流程
3.支持业务对数据进行在线分析
?
任职要求:
1.三年以上Java开发经验，扎实的Java基础并熟知软件开发流程
2.精通SQL，熟悉MySQL具有数据仓库和维度建模经验者优先
3.熟悉Cloudera，Hadoop生态圈各组件的实现原理和运行机制，熟悉Kafka、Redis等流式计算组件的开发，至少掌握一种ETL工具，有大数据应用开发项目经验。
4.有良好的沟通，团队协作，计划和创新能力
5.有金融大数据数仓工作经验优先
6.有金融知识图谱的开发经验优先"
"职位描述：
        
        项目介绍：
? ?我们是一家致力于利用最新的AI和大数据技术进行量化交易策略和系统研发的初创金融科技公司。公司创业团队由来自腾讯，阿里的顶级技术团队和来自恒生，同花顺的操盘高手组成，平均超过10年金融行业经验和人工智能互联网应用开发经验。

岗位职责：
1.负责金融大数据分析平台搭建，实现快速海量金融数据的存储、检索和计算，支撑金融量化策略的研究开发。
2.负责低时延流式数据处理的实现和落地。

任职要求：
1.理工科专业，数学、统计、计算机相关专业本科以上学历。 3年以上相关工作经验。
2.具有大数据理论和实践经验，熟悉大数据处理相关技术和开源工具集。
3.掌握 Java 或者 C++编程语言，并熟悉 Shell，Python 等一门以上脚本语言。
4.有大数据集、分布式计算工具（MR，Hadoop, Spark等一种以上大数据处理工具和技术），实时流数据处理（Flink, Spark Streaming, Storm等一种以上）等工作经验。
5.思路清晰，善于思考，有很强的数据分析能力，能独立分析问题并推动解决问题。团队合作沟通能力强。

有以下工作经验者优先录取：
1.从事过海量数据处理，有高并发，高性能系统实际经验者优先。
2.有金融大数据处理经验优先。"
"职位描述：
        
        工作职责：
1.负责大数据基础平台开发与管理
2.负责大数据基础设施建设：数据采集系统，调度系统，数据开发工具以及可视化工具
3.助力数据化运营业务，构建丰富多样的大数据应用。
4.从事大数据平台化的开发，提升海量数据的处理性能；
5.数据平台的维护优化和重构；

任职资格：
1.3年以上java开发经验，有网站/数据平台架构经验尤佳；
2.熟悉Hadoop、Hive 、Redis、Spark、HBase、Storm、Kafka、Flume等类框架技术者优先；
3.熟悉维度建模和数据仓库数据管理相关的知识
4. 逻辑思维严密，具备一定的项目管理和沟通的能力"
"职位描述：
        
        1、参与大数据平台组件、实时数据处理系统的设计和开发；2、参与数据采集、管理、分析等平台系统的设计和开发, 提升数据易用性和数据质量;岗位要求:1、掌握常用数据结构以及基本的算法, 熟悉数据库原理2、熟悉Linux/Unix环境, 掌握Java/Scala至少一种语言开发；3、了解Hadoop/Kafka/Hive/Hbase/Spark/ES等一种以上大数据处理工具,有大数据处理经验优先4?有较好的沟通交流能力,善于主动思考和行动，乐于解决具有挑战性的问题5、对数据相关工作有热情，愿意在数据领域学习和成长"
"职位描述：
        
        1、负责大数据平台产品的设计研发，完成产品的核心功能、公共核心模块的代码编写；
2、负责应用规划及架构设计，能够出具完成的应用实施解决方案，包括：系统架构设计、接口规范制定、技术文档编写等；
3、具备良好的沟通表达能力，协同他人并组织跨团队协作，保证项目质量与进度。

职位要求：?
1、3年以上的开发经验；
2、扎实的Java编程基础，熟悉各种设计模式，熟练掌握；Spring/Struts或其他主流Java框架，对代码质量有追求；
3、具备大数据处理的架构经验，熟悉典型业务场景下的数据架构方式，有关系型数据库、NOSQL数据库及内存数据库的综合运用经验；
4、了解常见的分布式计算平台Hadoop、Hive或Storm等优先；
5、具备良好的沟通技能及团队协作意识，有能力针对特定场景或要求给出合理的技术解决方案，并跨部门协调完成；
6、具有灵活解决问题能力和抗压能力。"
"职位描述：
        
        职位描述：
1. 建立并维护数据处理系统平台，保证数据正确性和系统可靠性;
2. 参与数据库、数据仓库、数据平台设计，开发，维护与优化等工作;
3. 开发与维护数据展示、监控与报表系统。

任职要求：
1. 211/985计算机、数学、物理或相关专业本科或硕士及以上学历，有海外留学经验佳；
2. 有大数据平台开发和AWS云服务经验，掌握spark、hdfs、hive、scala和hadoop等大数据生态相关技术；
3. 熟悉Linux 基础命令，熟悉shell语言，系统诊断等；
4. 会编写Oracle/DB2 存储过程，数据库的调优等；
5. 了解Hadoop，熟悉Hadoop，HBase，Hive基本命令；
6. 有Hadoop/HBase/Hive/Sqoop/Flume使用经验者优先；
7. 有两年以上大数据项目的实战经验；
8. 做事认真负责，沟通能力良好，自学能力较强，喜欢与团队成员头脑风暴。
（linux、oracle、hadoop 专一技术有精通优先）"
"职位描述：
        
        大数据后端开发工程师
工作职责：
1、 大数据平台管理系统后端的设计与开发；
2、 智能运维平台的设计与开发。
职位要求：
1、 名校本科以上学历，计算机/软件工程专业优先，三年及以上工作经验；
2、 有专业的计算机素养，熟悉网络编程、操作系统、基本数据结构和算法；
3、 具备良好的模块化设计能力，能够对复杂流程抽象和简化，有一定的产品思维；
4、 较强的编程能力，熟练掌握Java或Scala语言者优先；
5、 有分布式系统、自动化运维、机器学习算法等相关经验者优先。

大数据工具开发工程师
工作职责:
1、负责大数据平台管理软件的设计与开发
2、负责大数据工作流调度、ETL、报表工具的设计与开发工作
职位要求：
1、名校本科以上学历，计算机/软件工程专业优先????????????????
2、有专业的计算机素养，熟悉网络编程、操作系统、基本数据结构和算法???????????????????????????????????????????????????????????????????
3、具备良好的模块化设计能力，有一定的产品思维
4、能够对复杂流程抽象和简化
5、较强的编程能力，熟练掌握Java或Scala语言者优先"
"职位描述：
        
        
1.大数据DataOps平台工具开发
2.大数据调度平台工具开发
3.大数据CUBE设计工具开发
4.大数据数据操作与可视化开发
职位要求：
1.计算机专业基础知识扎实
2.熟悉JAVA平台开发
3.实际动手/学习能力强
4.有大数据使用经验优先"
"职位描述：
        
        职位描述：
1、 对Hadoop生态中的工具/系统进行开发与优化工作；
2、 对Hadoop生态中的开源组件进行优化和改进，并贡献至开源社区；
3、对公司大数据平台的组件进行维护，修复前端技术支持、客户支持团队所提交的问题；
4、优化公司大数据平台产品，提升产品的稳定性和可维护性。
职位要求：
1、计算机相关专业，本科及以上学历，掌握软件需求分析和系统设计相关的基础知识；
2、熟悉Hadoop生态相关技术，深入了解大数据计算平台常规架构和相关产品组件（Hadoop、Hive、Spark、Storm、Kafaka）原理，掌握部分组件原理及源码，对Hadoop开源社区有贡献者优先；
3、熟悉C、Java语言及常用库，熟练掌握常用开发工具；
4、熟悉SQL语言，了解Oracle或MySQL的使用和维护。"
"职位描述：
        
        岗位职责：
PoC（Proof of Concept，原型验证），在客户业务场景下验证产品的功能与性能。
在客户现场搭建大数据产品平台，与客户沟通，根据客户的需求或业务场景在大数据平台上实现大数据平台软件的项目实施与安装部署。
进行二次开发和平台运维排障，更具实际情况完善需求解决方案。
职位要求：
计算机或相关专业本科（或以上）学历
熟悉Linux 基础命令，熟悉shell语言，系统诊断等
熟悉Java语言，会编写Oracle/DB2 存储过程，数据库的调优等，
（愿意学习了解hadoop我们有培训的计划和机会，所以是个很好的考虑方向）
了解Hadoop，熟悉Hadoop，HBase，Hive基本命令
有Hadoop/HBase/Hive/Sqoop/Flume使用经验者优先
做事认真负责，沟通能力良好，自学能力较强，能够接受出差。
（linux、oracle、hadoop 专一技术有精通优先）"
"职位描述：
        
        【岗位职责】
1.参与公司大数据产品规划,大数据处理分析平台的架构设计；
2.负责数据存储、清洗、分析程序的开发与平台搭建；
3.负责大数据相关技术发展方向的预研；
4.业务数据仓库搭建；
5.自助数据平台搭建，自助提取数据或自助生成周期报表平台；
6.数据分析与运营，给业务提供支持与驱动产品优化；
7.基于大数据进行数据分析与预测；
?
【任职要求】
1.有过从 0 到 1 搭建数据平台的经验；
2.离线领域hadoop的ETL开发经验；
3.拥有2年以上Hadoop开发设计和实施经验，对大数据相关的技术和产品有全面深入了，如HDFS，MR，Hbase，Hive，Spark，Storm。

【福利待遇】【薪酬体系】具有行业竞争力的薪资+五险一金+年终奖+项目奖金+期权激励+优秀员工金币勋章+全勤奖+伯乐奖【晋升机会】只论能力不论年资，提供横、纵向的升职空间，专业及管理双通道的职业发展方向，大神们带你快速升级~【生活福利】带薪病假+打车报销+住房补贴+每日餐补，咖啡、茶包不限量提供~【节日福利】结婚礼金、生育礼金、慰唁金；春节、端午、中秋等节日礼品，员工家人节日礼品等~【团队活动】公司旅游活动+每周体育活动+每月生日趴+部门活动经费，月月组织聚餐，气氛融洽分分钟笑出腹肌~【年度体检】每年享有一次权威而专业的医疗机构全面健康检查机会，身体健康才能心情棒棒~【工作环境】弹性工作制，错高峰，五星级办公环境，一眼饱览琶洲江景，周边地铁公交便利~

还有无数的福利正在download，虚席以待各类优秀人才的加入，与您共同创造更美好的世界~~~"
"职位描述：
        
        Trade X is a two-sided global?B2B automotive trading platform?to connect buyer and seller in an end-to-end service solution.
Our mission?is to?unlock?the economic benefits and?simplify?the complexity of?global trade through the power of technology.
Our vision?is to develop the future?operating system of cross-border trade.
Our community of traders get access to?transparent?and?efficient?digital?marketplace?and a complete suite of trade instruments to perform?cross-border transactions.?
We have combined?a?global inventory?and?distribution system, trade compliance, digital trade documentation, international payments, global forwarding, trade financing solutions and reputation systems in?a single platform?to deliver a?safer,?faster?and?more efficient experience.
*注：Trade X 为星垂智能 ZENO 持股的合资公司，通过面试的候选人将直接与 Trade X 签订劳动合同，工作地点为上海浦东。

Responsibilities
- 负责垂直网站网页数据的爬取、清洗
- 解决各种反爬取问题，保证爬取进度
- 优化爬取效率，监控数据爬取进展
- 研究网站安全的新技术等
- 数据清洗，数据挖掘等相关研发工作

Requirements
- 两年以上相关开发经验
- 熟悉 Python 或 java 两门语言
- 熟悉 scrapy、pyspider、webmagic、nutch 等任一爬虫框架
- 掌握网页抓取原理及技术，了解基于 Cookie 的登录原理，熟悉基于正则、xpath、cssselector 的网页抽取技术
- 熟悉反爬机制，能解决疑难爬取问题
- 熟悉 Mysql，redis，mongdb，oracle 至少之二，有过数据库调优和海量数据存储经验优先
- 有验证码破解，反爬，分布式爬虫架构，数据挖掘，搭建数据仓库经验者优先
- 具有数据挖掘、自然语言处理、信息检索、机器学习背景者优先
- 良好的英文沟通能力，英文文档写作能力

- 优先考虑有在国际化团队工作经验的候选人"
"职位描述：
        
        
岗位职责：
1. ? 负责大数据平台的任务开发
2. ? 负责编写数据分析和计算任务
3. ? 调研Hadoop生态系统相关框架技术
?
任职资格：
1. ? 有hadoop、hive应用与开发经验，能够熟练得编写mr程序和hive sql和udf
2. ? 能够熟练编写较为复杂的hive sql语句
3. ? 熟悉以下一种或多种语言：java、python、shell、scala等
4. ? 熟悉使用至少一种以上的nosql数据库，如：mongodb、redis、hbase等"
"职位描述：
        
        职位描述：
1.?负责数据仓库、ETL数据开发、数据集市建设；
2.?建立分析模型，设计报表及分析设计展现途径，以及相应的开发工作；
3.?负责数据仓库项目数据库的管理、性能监控、优化等。
职位要求：
1.?大学本科及以上学历，2-3年以上银行数据仓库相关工作经验；
2.?熟悉数据仓库领域知识和技能，包括元数据管理、数据开发测试工具与方法、数据质量、主数据管理；
3.?熟练使用Kettle、SSIS等ETL工具进行数据清洗、转换、整合，元数据管理；
4.?熟悉至少两种关系型数据库，如Oracle、sql server、Mysql等主流数据；
5.?熟悉使用linux系统及shell脚本开发，熟悉Python优先；
6.?有基于星环、华为、CDH产品实施的经验，对Spark，Hive，Hdfs等大数据技术比较熟悉者优先；
7.?对新技术好奇爱学习，主动性和责任心强，对数据敏感，逻辑性强，有良好的抗压能力。"
"职位描述：
        
        岗位职责：
负责公司每天数百亿级数据量的产品研发，数据质量稽核，代码优化及trouble shooting等。

任职要求：
1、至少3年以上的大数据相关工作经验，其中至少有1年数据处理工作经验；
2、熟练掌握spark、presto、hbase、hadoop、es等生态组件之一，熟源码尤佳；
3、在数据方面具有一定的经验，对指标类计算有一定经验，最好有一定的数据建模经验；
4、具有良好的沟通表达能力，可以与其他团队良好协同合作。"
"职位描述：
        
        岗位职责：
1.负责公司数据产品的数仓模型设计、优化；
2.负责数据模型的ETL开发、数据平台建设；
3.负责面向业务的数据消费、提取、分析、报表、挖掘等系统设计和开发工作。

任职要求：
1.有较强的性能优化及问题排查、解决能力；对开源技术非常感兴趣并具有一定的研究能力；
2.工作认真、负责、细致，有良好的团队合作精神，良好的分析能力、沟通技巧；
3.三年以上数据仓库设计和ETL开发经验，熟悉数据仓库建模设计、元数据管理、数据质量监控等；
4.三年以上的离线、实时、OLAP数据分析处理项目经验；
5.一年以上Mapreduce开发经验；
6.精通java、Hive SQL、linux shell；具备较丰富的scala、kafka 开发经验；了解presto、storm优先；"
"职位描述：
        
        职位职责：?
1、负责业务相关数据挖掘核心技术的研发；?
2、负责内容处理逻辑的设计与开发，实现相关业务的实体的关键字抽取、正则化、聚类等基础特征，为后续处理提供数据；?
3、负责大数据基础设施和平台改进，解决生产环境可用性和性能优化问题。?

职位要求：?
1、良好的设计和编码能力；?
2、编程语言不限，有Python经验更佳；?
3、熟悉常用数据挖掘算法，借助回归、分类、预测等算法手段，基于后验数据，优化现有系统；?
4、较好的产品意识，关注数据，以产品为工作的驱动因素。"
"职位描述：
        
        岗位要求：
1.有2年以上MDE、SE工作经验，有软件设计、开发相关工作经验；
2.熟悉java/python其中一门语言.3.具备较好的沟通能力和需求分析能力，能够长期跟踪客户需求，持续迭代解决方案。4.具备政务相关软件设计、开发工作经验优先，具备数据共享交换相关软件设计、开发工作经验优先。
岗位职责：
1.熟悉、了解业内常见政务数据共享交换平台，掌握整体数据共享交换流程。
2.熟悉政府各部门数据相关业务，输出相关工作流程总结性材料，输出各个系统间相互调用关系材料。3.客户面调研，了解、分解、梳理客户需求，和开发、方案设计互动沟通，确保需求落地。4.结合客户疑问，从实际系统中发现问题，梳理问题。结合实际情况，给出改进建议与相关技术点。5.负责新共享交换平台相关功能平台设计、方案设计。基于已有方案重新设计相关系统模块，包括：功能特性设计、流程设计、操作角色设计、界面风格UI设计、周边接口对接设计（考虑系统解耦）。
6.配合、指导合作伙伴完成新共享交换平台开发。"
"职位描述：
        
        岗位职责：? 1、负责基于Hadoop/Spark平台架构的开发、设计和布局?； 2、完成系统框架的设计和核心代码的编写；? 3、针对海量的用户行为数据进行统计、分析与挖掘，不断提高系统运行效率；? 4、负责对数据进行分析，为项目组提供大数据技术指导及分析手段支撑；? 5、负责大数据平台的性能监控和持续优化；针对需求提供大数据分析技术解决方案?；?  任职资格：? 1、3年及以上行业开发经验，计算机或相关专业本科以上学历；? 2、精通Hadoop大数据平台架构，具有扎实的Java/Python等开发语言；并可以开发高效可靠的代码；3、熟悉spark、Hive、storm等计算框架者优先，对分布式存储和计算原理有较深的理解；? 4、严密的数学思维、突出的分析和归纳能力、优秀的沟通表达能；? 5、个性开朗，对技术钻研好学、逻辑思维能力强，沟通能力优秀，有团队合作精神。"
"职位描述：
        
        岗位职责：
1、负责数据仓库优化与迭代2、负责大数据标签体系的搭建、运维及优化，并解决开发中的疑难问题，不断进行系统优化。3、参与优化数据计算任务4、维护和优化数据平台5、参与报表统计开发，为其他部门提供数据产品支持。
岗位要求：
1、熟练掌握spark、kafka、Cassandra、ES、Redis、hive、clickhouse等大数据技术组件的使用2、参与过数据仓库或标签系统相关搭建与研发工作3、具备海量数据计算经验（TB级） - - 聚合排序优化经验4、具备数据仓库ETL经验5、参与过数据管理平台或BI项目者优先6、熟练掌握Java/Scala，熟悉Shell或Python等至少一门以上脚本语言7、本科毕业，5年工作经验（大数据经验至少3年）"
"职位描述：
        
        【职位描述】
1. 产品讨论，参与产品的后端设计
2? 相关数据平台系统的开发与调试；
3? 基于 Hadoop 系统的分布式大数据处理和分析平台的二次开发与实施；
4? 负责搭建行业产品大数据的存储、计算等框架以及主要代码编写；
5? 负责产品的开发工作；?
6? 负责数据库设计，web API设计，web框架搭建等；
7? 能够与前端、人员一起配合清晰理解需求，并主动配合推进项目进度；
8? 分布式技术研究，及关键技术的开发工作；?

【任职资格】
1? 3年大数据开发经验，熟悉各个大数据组件，尤其对HBase，Hive，Spark，Kafka、HDFS、Yarn等能够熟练编写代码，对大数据各个组件原理有清晰深刻理解
2? 3-5年Java开发经验，熟悉JAVA开发，数据库设计，web框架搭建，restful API设计等
3? 精通Linux环境，常用指令操作
5? 能够承担大数据平台运维工作，对大数据平台出问题后的调试有一定经验。
6? 可以承受阶段性出差的工作节奏"
"职位描述：
        
        工作职责:1、 从事大数据平台建设开发，数据治理，分析，编码的工作。2、 负责大数据项目的核心业务设计和开发；3、 随着项目发展，不断优化分布式系统架构，提高可用性，扩展性和性能；4、 调研新的大数据技术并进行应用，助力业务成长；任职资格:1、熟悉Linux/Unix操作系统，熟练掌握java/scala/go/python/php等一种或多种编程语言；2、熟悉 Hadoop EcoSystem，包括但不限于Hadoop, HBase, Hive, Kafka, Flume，ElasticSearch，Spark，Storm, Druid/Presto/Impala 等，具备2年以上开发和使用经验；3、了解Oracle、MySQL、SQL Server、DB2至少一种数据库软件，熟练使用SQL完成常规取数，使用Linux Shell、Python脚本初步处理数据；4、学习能力强，适应能力好，主动性强，抗压能力强，团队协作意识强，能适应一定程度的加班；5、具备良好的沟通能力和表达能力，有较强的数据敏感度，良好的沟通协调能力，能承受一定的工作压力。"
"职位描述：
        
        职责描述：1. 对现有系统的业务流程维护重构，转变开发模式，参与和实施自动化项目的设计，开发，部署以及运维。 2. 完善产品研发，以产品导向，编写高质量的代码
任职要求：1、本科以上；计算机科学与技术、软件工程、网络工程、电子信息工程等专业；2、有二年以上Hadoop生态开发经验；熟悉Hadoop大数据生态圈，包括但不限于HDFS、YARN、Hive、HBase、Spark、Kafka、Nifi、Flink等3、有Linux环境和常用命令使用经验；4、有hadoop及核心组件(Hive、Spark、Flink)性能优化经验的优先考虑5、有ETL和调度系统配置、监控、维护经验优先；6、实际使用过nifi，并性能调优，且熟悉源码7、有高度的责任感、上进心、主动性、团队合作和敬业精神；8、良好的沟通表达能力、理解能力、执行能力、承受压力能力和自我管理能力；9、具备较强的逻辑能力、良好的执行能力和认真负责的态度。"
"职位描述：
        
        基于 Hadoop 系统的分布式大数据处理和分析平台的二次开发与实施；
参与项目的需求分析、概要设计、详细设计，技术文档的编写；
负责开发框架的搭建、改进；
协助完成项目的测试、系统交付工作，对项目实施提供支持。
负责跟进软件系统安全、稳定、维护和性能优化等工作;
分布式技术研究，及关键技术的开发工作；
相关数据平台系统的开发与调试；
负责搭建行业产品大数据的存储、计算等框架以及主要代码编写

1 3年大数据开发经验，熟悉各个大数据组件，尤其对es，hbase，titan，hive，spark，yarn能够熟练编写代码，对大数据各个组件原理有清晰深刻理解
2 熟悉掌握java，web框架，数据库设计等基本web开发工具及技巧
3 有处理高并发，高吞吐数据量的经验。
4 精通Linux环境，常用指令操作
5 能够承担大数据平台运维工作，对大数据平台出问题后的调试有一定经验。
6 可以承受阶段性出差的工作节奏"
"职位描述：
        
        1. 产品讨论，参与产品的后端设计
2? 相关数据平台系统的开发与调试；
3? 基于 Hadoop 系统的分布式大数据处理和分析平台的二次开发与实施；
4? 负责搭建行业产品大数据的存储、计算等框架以及主要代码编写；
5? 负责产品的开发工作；?
6? 负责数据库设计，web API设计，web框架搭建等；
7? 能够与前端、人员一起配合清晰理解需求，并主动配合推进项目进度；
8? 分布式技术研究，及关键技术的开发工作；?

【任职资格】
1? 3年大数据开发经验，熟悉各个大数据组件，尤其对HBase，Hive，Spark，Kafka、HDFS、Yarn等能够熟练编写代码，对大数据各个组件原理有清晰深刻理解
2? 3-5年Java开发经验，熟悉JAVA开发，数据库设计，web框架搭建，restful API设计等
3? 精通Linux环境，常用指令操作
5? 能够承担大数据平台运维工作，对大数据平台出问题后的调试有一定经验。"
"职位描述：
        
        1、 从事大数据平台建设开发，数据治理，分析，编码的工作。
2、 负责大数据项目的核心业务设计和开发；
3、 随着项目发展，不断优化分布式系统架构，提高可用性，扩展性和性能；
4、 调研新的大数据技术并进行应用，助力业务成长；
任职要求：
1、数学、统计、计算机等相关专业，大学本科及以上学历；
2、了解统计学、数学、人工智能和数据挖掘理论基础，了解数据仓库、数据挖掘与分析的相关知识，具有良好的数据模型设计能力，熟悉常用统计分析方法、数据挖掘基本算法；
3、熟悉Linux/Unix操作系统，熟练掌握java/scala/go/python/php等一种或多种编程语言；
4、熟悉?hadoop?ecosystem，包括但不限于Hadoop,?HBase,?Hive,?Kafka,?Flume，ElasticSearch，Spark，Storm,?Druid/Presto/Impala?等，具备2年以上开发和使用经验；
5、了解Oracle、MySQL、SQL?Server、DB2至少一种数据库软件，熟练使用SQL完成常规取数，使用Linux?Shell、Python脚本初步处理数据；
6、熟悉联机分析处理(OLAP)?理论与工具，掌握OLAP数据平台，熟悉大数据结构化及非结构化分析工具；
7、?学习能力强，适应能力好，主动性强，抗压能力强，团队协作意识强，能适应一定程度的加班；
8、?具备良好的沟通能力和表达能力，有较强的数据敏感度，良好的沟通协调能力，能承受一定的工作压力"
"职位描述：
        
        技能要求：Java，Hadoop，数据挖掘，数据库
主要工作职责:
1、负责技术中心产品在现场落地实施的负责海量数据实时/准实时计算产品研发；
2、深入理解计算场景，结合实际需求完成设计以及开发工作；
3、负责技术中心产品在项目落地过程中的技术支持工作，保障产品的项目落地；
4、参与大数据业务场景的业务分析、架构设计、实现及优化
?
任职要求：
1、计算机相关专业，3-5年以上大数据开发经验；
2、计算机功底扎实，掌握一定的数据结构、算法、技术架构方法；
3、熟悉大数据技术栈，掌握大数据技术原理，例Hadoop、Storm、Spark、Flink等；
4、2年以上平台产品设计和开发经验，具备优秀的编程能力和良好的开发习惯。
5、国内一线互联网公司或企业级服务公司从业者优先"
"职位描述：
        
        主要职责：
1、 从事大数据平台建设开发，数据治理，分析，编码的工作。
2、 负责大数据项目的核心业务设计和开发；
3、 随着项目发展，不断优化分布式系统架构，提高可用性，扩展性和性能；
4、 调研新的大数据技术并进行应用，助力业务成长；
人选要求：
1、熟悉Linux/Unix操作系统，熟练掌握java/scala/go/python/php等一种或多种编程语言；
2、熟悉 Hadoop EcoSystem，包括但不限于Hadoop, HBase, Hive, Kafka, Flume，ElasticSearch，Spark，Storm, Druid/Presto/Impala 等，具备2年以上开发和使用经验；
3、了解Oracle、MySQL、SQL Server、DB2至少一种数据库软件，熟练使用SQL完成常规取数，使用Linux Shell、Python脚本初步处理数据；
4、学习能力强，适应能力好，主动性强，抗压能力强，团队协作意识强，能适应一定程度的加班；
5、具备良好的沟通能力和表达能力，有较强的数据敏感度，良好的沟通协调能力，能承受一定的工作压力。"
"职位描述：
        
        主要工作职责：
1、参与客户需求调研，熟悉业务逻辑及数据源表结构等；
2、对源数据全量或增量进行抽取、清洗、转换、加载到大数据平台；
3、参与基于大数据平台的数据仓库/数据集市的数据模型设计；
4、配合数据仓库架构师完成数据仓库/数据集市的ETL设计与开发；
5、负责设计、开发、优化ETL任务调度系统；
6、负责整理和归档所做开发的文档
人选要求：
1、本科或以上学历，计算机、数学或相关专业，3年及以上ETL数据开发经验；
2、熟悉一种或多种常见数据库：MySQL/Oracle/SQLServer/PostgreSQL/DB2；
3、熟悉一种或多种主流ETL开发工具，如：Kettle、SSIS 、Informatica、DataStage等；
4、熟悉数据仓库方法论，熟悉ETL架构搭建，有搭建数仓经验者优先；
5、精通SQL语句，对SQL查询及性能优化有丰富的经验；
6、有linux平台经验，熟悉shell、python语言；
7、有较强的问题排查/解决能力，具备较强的逻辑思维能力，对开源技术非常感兴趣并具有一定的研究能力；
8、有强烈的责任心、良好的沟通协调能力、团队合作精神、优秀的执行能力，能承受工作压力；
9、有海量数据处理经验者优先；
10、有Java/Hadoop/Hive/Spark/Impala经验者优先。"
"职位描述：
        
        1、负责ETL、数据治理以及相关工具的开发工作，包括结构化、非结构化等数据类别的治理。
2、与产品团队协作，提供满足业务需求的数据内容
3、与算法团队配合，输出满足业务需求的数据内容。
4、根据业务需求，沉淀数据治理工具、产品

1、3-5年大型企业级项目的数据架构开发和治理经验。
2、擅长数据库设计和开发，精通SQL语言/Oracle/DB2/MySQL等主流关系数据库技术
3、精通Linux环境，常用指令操作
4、有金融领域海量数据治理经验的优先
5、有基于Hadoop的数据分析系统设计和开发经验者优先"
"职位描述：
        
        岗位职责：
1、从事大数据平台建设开发，数据治理，分析，编码的工作。
2、参与大数据系统的架构设计和开发；
3、负责Hive、Spark、HBase、Kafka等分布式存储和计算组件的疑难问题定位、性能优化、稳定性提升工作
任职要求：
1、掌握数据仓库基础理论知识，了解数据仓库模型设计和ETL设计技术；
2、有丰富的Java/Scala/Python/SQL开发经验，2年或以上大数据开发经验，追求代码洁癖、熟练在Linux上工作，具有系统架构设计及系统调优经验者优先，
3、熟悉Hadoop和Spark生态系统，熟悉2个以上分布式存储和计算组件原理和应用，如Hive、Sqoop、Spark、HBase、Kafka、ES（ElasticSearch）等
4、熟悉流式/实时计算框架如Spark Streaming或Flink的工作原理，具备丰富的实践和调优经验者优先。
5、熟悉联机分析处理(OLAP) 理论与工具，掌握OLAP数据平台，拥有海量数据OLAP系统开发经验者优先。
6、有较强的学习能力和快速定位解决问题能力，对技术有较高的热情，热衷于新技术学习和分享。"
"职位描述：
        
        职责描述：1. 对现有系统的业务流程维护重构，转变开发模式，参与和实施自动化项目的设计，开发，部署以及运维。 2. 完善产品研发，以产品导向，编写高质量的代码
任职要求：1、本科以上；计算机科学与技术、软件工程、网络工程、电子信息工程等专业；2、有二年以上Hadoop生态开发经验；熟悉Hadoop大数据生态圈，包括但不限于HDFS、YARN、Hive、HBase、Spark、Kafka、Nifi、Flink等3、有Linux环境和常用命令使用经验；4、有hadoop及核心组件(Hive、Spark、Flink)性能优化经验的优先考虑5、有ETL和调度系统配置、监控、维护经验优先；6、实际使用过nifi，并性能调优，且熟悉源码7、有高度的责任感、上进心、主动性、团队合作和敬业精神；8、良好的沟通表达能力、理解能力、执行能力、承受压力能力和自我管理能力；9、具备较强的逻辑能力、良好的执行能力和认真负责的态度。"
"职位描述：
        
        【职位描述】

1. 产品讨论，参与产品的后端设计

2? 相关数据平台系统的开发与调试；

3? 基于 Hadoop 系统的分布式大数据处理和分析平台的二次开发与实施；

4? 负责搭建行业产品大数据的存储、计算等框架以及主要代码编写；

5? 负责产品的开发工作；?

6? 负责数据库设计，web API设计，web框架搭建等；

7? 能够与前端、人员一起配合清晰理解需求，并主动配合推进项目进度；

8? 分布式技术研究，及关键技术的开发工作；?



【任职资格】

1? 3年大数据开发经验，熟悉各个大数据组件，尤其对HBase，Hive，Spark，Kafka、HDFS、Yarn等能够熟练编写代码，对大数据各个组件原理有清晰深刻理解

2? 3-5年Java开发经验，熟悉JAVA开发，数据库设计，web框架搭建，restful API设计等

3? 精通Linux环境，常用指令操作

5? 能够承担大数据平台运维工作，对大数据平台出问题后的调试有一定经验。

6? 可以承受阶段性出差的工作节奏"
"职位描述：
        
        【职位描述】
1. 产品讨论，参与产品的后端设计
2? 相关数据平台系统的开发与调试；
3? 基于 Hadoop 系统的分布式大数据处理和分析平台的二次开发与实施；
4? 负责搭建行业产品大数据的存储、计算等框架以及主要代码编写；
5? 负责产品的开发工作；?
6? 负责数据库设计，web API设计，web框架搭建等；
7? 能够与前端、人员一起配合清晰理解需求，并主动配合推进项目进度；
8? 分布式技术研究，及关键技术的开发工作；?

【任职资格】
1? 3年大数据开发经验，熟悉各个大数据组件，尤其对HBase，Hive，Spark，Kafka、HDFS、Yarn等能够熟练编写代码，对大数据各个组件原理有清晰深刻理解
2? 3-5年Java开发经验，熟悉JAVA开发，数据库设计，web框架搭建，restful API设计等
3? 精通Linux环境，常用指令操作
5? 能够承担大数据平台运维工作，对大数据平台出问题后的调试有一定经验。
6? 可以承受阶段性出差的工作节奏"
"职位描述：
        
        岗位职责：
1、从事大数据平台建设开发，数据治理，分析，编码的工作。
任职要求：
1.、数学、统计、计算机等相关专业，大学专科及以上学历；
2、了解统计学、数学、人工智能和数据挖掘理论基础，了解数据仓库、数据挖掘与分析的相关知识，具有良好的数据模型设计能力，熟悉常用统计分析方法、数据挖掘基本算法；
3.、熟悉java，python，scala开发语言，并具有实际开发经验；
4、了解hadoop技术生态圈相关知识，有过hadoop生态圈部署，开发经验；
5、了解Oracle、MySQL、SQL Server、DB2至少一种数据库软件，熟练使用SQL完成常规取数，使用Linux Shell、Python脚本初步处理数据；
6、熟悉联机分析处理(OLAP) 理论与工具，掌握OLAP数据平台，熟悉大数据结构化及非结构化分析工具；
7、熟悉Sqoop，Hive，Impala，spark，Drill，kylin以及BI工具者优先；
其他要求：
1、 学习能力强，适应能力好，主动性强，抗压能力强，团队协作意识强，能适应一定程度的加班；
2、 具备良好的沟通能力和表达能力，有较强的数据敏感度，良好的沟通协调能力，能承受一定的工作压力；"
"职位描述：
        
        岗位职责：
1、负责数据收集、清洗和规约等工作，并抽象出可以多业务复用的数据模型；
2、建设和优化业务、运营、安全、信用等数据体系和展现；
3、根据业务和产品情况，抽象业务逻辑；基于业务场景建立快速迭代原型并持续优化输出；
4、负责数据平台和数据应用开发，以及数据产品后台开发等工作；
5、负责平台数据建模、优化及产品化；
任职要求：
1、深度理解数据模型和数据仓库；
2、熟悉MySQL、Redis、PostgreSQL等数据库，精通SQL查询及优化；
3、掌握Python开发语言，熟练使用pandas、numpy等；
4、有数据挖掘背景，对分类、聚类、关联挖掘和推荐有深刻的认识或经验；
5、优秀的沟通表达能力和协同能力，思维敏捷，执行力强，有较强的抗压能力；
6、了解Hadoop生态、Storm、Spark等技术；"
"职位描述：
        
        岗位职责：
1、负责数据收集、清洗和规约等工作，并抽象出可以多业务复用的数据模型；
2、建设和优化业务、运营、安全、信用等数据体系和展现；
3、根据业务和产品情况，抽象业务逻辑；基于业务场景建立快速迭代原型并持续优化输出；
4、负责数据平台和数据应用开发，以及数据产品后台开发等工作；
5、负责平台数据建模、优化及产品化；
任职要求：
1、深度理解数据模型和数据仓库；
2、熟悉MySQL、Redis、PostgreSQL等数据库，精通SQL查询及优化；
3、掌握Python开发语言，熟练使用pandas、numpy等；
4、有数据挖掘背景，对分类、聚类、关联挖掘和推荐有深刻的认识或经验；
5、优秀的沟通表达能力和协同能力，思维敏捷，执行力强，有较强的抗压能力；
6、了解Hadoop生态、Storm、Spark等技术；"
"职位描述：
        
        岗位职责:
1. 负责海量数据的处理、分析和挖掘工作?
2. 根据业务需求，设计和搭建海量数据处理的基础设施，维护和保证系统的稳定性?
任职要求:
1. 计算机相关专业本科及以上学历，1年以上工作经验;?
2. 熟练掌握Python、Java等编程语言;?
3. 熟悉大数据相关的技术（例如：Hadoop、Spark、Hbase等）优先
4. 具备良好的抽象思维和逻辑思维能力，对数据有敏锐的洞察力，责任心强，有团队协作精神"
"职位描述：
        
        工作职责:
1. 参与AI云服务的亿级别数据建设，包括数据ETL、数仓建设、数据BI产品；
2. 参与新业务和行业的数据商业化探索和数据价值挖掘。
任职资格:
1. 熟悉数据仓库产品，对数据处理、维度建模、数据分析等有深刻认识和实战经验，如Hadoop/Hive，Storm/Spark，Impala，MPP等的数据应用开发；
2. 对大数据平台的构建和实现机制有深刻的理解，有大数据平台运维和开发经验；
3. 对大数据、云计算、开源软件、传统数据仓库类产品有一定的深度和广度；?
4. 有较强的编程能力和编程经验，至少熟悉Java/C++其中一门编程语言，有较强的分布式计算基础和算法工程能力；
5. 具备较好沟通协调能力，主动建立与业务的紧密合作，推动业务升级。"
"职位描述：
        
        工作职责：
1. 参与AI云服务的亿级别数据建设，包括数据ETL、数仓建设、数据BI产品；2. 参与新业务和行业的数据商业化探索和数据价值挖掘。
任职资格：
1. 熟悉数据仓库产品，对数据处理、维度建模、数据分析等有深刻认识和实战经验，如Hadoop/Hive，Storm/Spark，Impala，MPP等的数据应用开发；2. 对大数据平台的构建和实现机制有深刻的理解，有大数据平台运维和开发经验；3. 对大数据、云计算、开源软件、传统数据仓库类产品有一定的深度和广度；?4. 有较强的编程能力和编程经验，至少熟悉Java/C++其中一门编程语言，有较强的分布式计算基础和算法工程能力；5. 具备较好沟通协调能力，主动建立与业务的紧密合作，推动业务升级。"
"职位描述：
        
        工作职责:1. 参与AI云服务的亿级别数据建设，包括数据ETL、数仓建设、数据BI产品；2. 参与新业务和行业的数据商业化探索和数据价值挖掘。任职资格:1. 熟悉数据仓库产品，对数据处理、维度建模、数据分析等有深刻认识和实战经验，如Hadoop/Hive，Storm/Spark，Impala，MPP等的数据应用开发；2. 对大数据平台的构建和实现机制有深刻的理解，有大数据平台运维和开发经验；3. 对大数据、云计算、开源软件、传统数据仓库类产品有一定的深度和广度； 4. 有较强的编程能力和编程经验，至少熟悉Java/C++其中一门编程语言，有较强的分布式计算基础和算法工程能力；5. 具备较好沟通协调能力，主动建立与业务的紧密合作，推动业务升级。"
"职位描述：
        
        1、负责公司企业级AI计算平台搭建；
2、负责用AI算法改进证券的前中后台各项业务，提高交易策略，提升中后台工作效率；
3、算法研究，开发，实施，评估，工程落地。
任职资格
?
1、经济，数学，统计，自动化，计算机等相关专业硕士毕业；
2、熟悉特征工程，机器学习和深度学习理论和实践，并有两年以上工作经验。有相关比赛经验者优先；
3、熟悉Python， Java， R 等编程语言；
4、岗位职责：负责用AI算法改进证券的前中后台各项业务，提高交易策略，提升中后台工作效率；
5、工作内容：算法研究，开发，实施，评估，工程落地；
6、熟悉业界主流开发框架： sklearn， tensorflow, pytorch 等。"
"职位描述：
        
        岗位职责：
1、基于大数据技术实现业务Service的重构；
2、从事大数据平台化的开发，提升海量数据的处理性能；
3、电子商务数据平台的维护优化和重构；
4、集群运维，解决各种疑难杂症，对系统进行性能调优;

任职要求：
1、计算机相关专业本科及以上学历；
2、1年以上java开发经验，有网站/数据平台架构经验尤佳；
3、2年以上大数据开发经验，掌握Hadoop、Redis、Spark、Hive、HBase、Storm、Kafka、Flume等类框架技术；
4、掌握JavaScript、html、css等web前端常用开发技术；
5、了解Spring、Hibernate、iBatis开发，对虚拟机及Linux下的开发环境有较深厚的开发经验；
6、了解网络编程，具有设计和开发对外API接口经验和能力。
7、有开源项目经验优先。

工作时间：周二~周六 8：30~17：30? （介意者慎投）"
"职位描述：
        
        岗位职责：
1、负责全行大数据相关项目及整体平台解决方案的产品化输出；
2、负责全行人工智能系统、大数据分析系统、实时流计算系统、BI系统、数据仓库、数据集市的设计和开发；
3、负责数据调研、数据接入、数据建模、数据清洗、数据映射、数据可视化等工作；?
4、负责对数据进行分析，为项目组提供大数据技术指导及分析手段支撑；
5、负责大数据平台的性能监控和持续优化；针对需求提供大数据分析技术解决方案；
6、负责大数据平台的运维工作，持续完善大数据平台，保证稳定性、安全性；
?
?
任职资格：
1、 数学、统计学、计算机等相关专业本科及以上学历
2、java或etl基础扎实，熟悉 linux 系统， 熟练使用 java,scala,python,shell 等至少一种语言
3、 熟悉Hadoop、HBase、Hive、Streamming、Spark、NoSQL、ES中至少一种技术，阅读过源代码者优先；?
4、 充分理解大数据背景下的计算模型，熟悉MapReduce、Spark开发流程模型中任一，并具有分布式开发经验；?
5、具备较强的逻辑思维能力、学习创新能力、数据分析能力，以及良好的沟通技巧和团队合作能力；
6、具有2年以上相关工作经验，上述职责至少满足一项或担任过一个或多个相关项目的开发工作，传统BI领域人员也可投递简历。"
"职位描述：
        
        岗位职责：?1、负责基于Hadoop、Spark平台的海量数据处理、数据计算、数据开发。?2、负责高并发、高可用性、高可扩展性的线上数据系统开发。?3、负责数据挖掘应用服务开发和数据挖掘算法包研究和应用。?4、负责数据产品和数据项目的相关开发支持。5、负责垂直领域的数据探索，价值数据提取。?任职要求：?1、计算机及相关专业本科及以上学历；?2、精通java开发技术，熟练掌握多进程/多线程开发，熟悉常用设计模式；?3、熟练掌握Hadoop、Spark等大数据开发技术，进行过大数据项目实践；?4、有机器学习、数据挖掘、推荐系统经验者优先；?5、具有分布式计算/搜索引擎/广告引擎等后台开发经验者优先；?6、有/ElasticSearch/hadoop/Spark/storm/kafka/scribe等开源框架经验者优先；?7、对技术有激情、有追求；富于技术创新精神，勇于解决技术难题"
"职位描述：
        
        职位描述：
1、结合公司业务需求，负责构建适合业务的用户画像体系；2、基于海量用户行为和相关数据信息，实现和优化用户画像,并针对具体业务需求场景,负责用户行为预测、用户兴趣、用户分类、人群包挖掘等工作；
3、参与搭建完整的用户画像挖掘系统，包括数据处理、挖掘用户画像、准确性评估等。

?任职要求：
1、熟练掌握数据挖掘、机器学习的基础理论和方法，有丰富的相关研究经验；
2、掌握基于?Hadoop?大数据平台工具的开发与设计，熟悉Hive，Spark开发；
3、熟悉?Linux?平台、Java/Scala/Python/C++?中一种或多种语言编程；
4、有互联网公司有大规模用户画像实践经验,参与过用户画像建模、用户画像系统或?DMP?系统的开发工作优先。"
"职位描述：
        
        大数据开发工程师（Hadoop）
工作职责：

1、负责后台系统研发，分布式调度平台设计开发
2、hadoop集群应用开发与维护
3、搜索离线计算框架应用开发与维护

职位要求：
1、良好的沟通与表达能力、思路清晰，较强的动手能力与逻辑分析能力
2、2+年后端系统研发经验或者基础架构开发经验，熟练掌握 C/C++或 Java 等至少一种主流语言，熟悉一种以上脚本语言，如Shell、Python等，具备扎实的算法和数据结构功底
3、参与过高并发分布式在线系统的研发，解决过相关性能问题
4、精通 NoSQL 数据库技术和内存数据库技术（如 redis, leveldb）
5、扎实的编程能力，熟悉算法和数据结构，熟悉计算机基础理论，熟悉分布式系统原理，有熟悉hadoop/hive/hbase/spark/kafka/redis等经验优先"
"职位描述：
        
        职位描述：
1、负责日常的数据收集清洗、统计分析、报告监控等数据处理相关工作
2、负责反作弊系统、推荐系统等数据系统的开发工作，维护线上相关服务的稳定运行
3、负责用户特征、博文特征等基础数据的挖掘工作，为上层应用提供基础的数据支持
?
岗位要求：
1、本科及以上学历，辅修数学或统计课程者优先
2、熟悉常用算法和数据结构，具备Linux环境下开发能力
3、具备2年以上python后端研发经验，精通python, 高级需熟悉numpy、Scikit-Learn
4、熟悉数据挖掘相关算法，包括但不限于决策树、SVM、聚类、逻辑回归等，并具备2年以上的数据挖掘/机器学习相关工作经验；
5、熟悉Spark,Hadoop,Hive,Storm者优先；
6、具备良好的学习能力和沟通交流能力，能够迅速熟悉业务，融入团队；"
"职位描述：
        
        工作职责：
1、负责公司大数据产品的设计与实现、技术改进与性能优化；
2、参与数据仓库的架构设计和研发，建设公共数据服务平台；
3、规划数据产品/工具，挖掘数据价值，为业务赋能，并回馈开源社区；

任职资格：
1、扎实的数据结构和算法能力，熟练掌握Java/Scala/Python语言。
2、有Hadoop/Spark/Druid等分布式平台相关使用经验。
3、善于积极主动沟通，逻辑思维强，有较强的自我驱动和学习能力。
4、可以长时间实习优先，2020届毕业生优先。"
"职位描述：
        
        工作职责：
1、负责公司产品平台的架构设计与构建，技术改进与性能优化；
2、负责面向海量数据查询、数据计算、数据存储以及数据模型与管理的基础架构搭建；
3、负责规划技术发展方向，新技术领域的探索，将新技术应用到项目中，并回馈开源社区；
4、参与技术团队建设和学习成长，为团队整体的知识积累，技能提升做贡献。

任职资格：
1、熟练掌握java/scala/python开发语言以及相关框架，有大型项目经验优先；
2、负责过大型数据平台或者数据仓库设计，具有扎实的大数据和数据仓库的理论功底；
3、对Hadoop的大数据体系有深入认识，对Hadoop/Kafka/Spark/Druid/clickhouse等有实际应用研发经验，读过关键源码为佳；
4、具备良好的问题分析能力、沟通能力和团队合作能力，具备很强的学习和钻研能力；
5、本科以上学历，5年以上相关工作经验；
6、关注技术发展趋势，热爱开源，为开源项目贡献过代码优先。"
"职位描述：
        
        ?职责描述：
负责搭建互联网企业级数据仓库，包括ETL、数据模型设计和开发、BI等工作。
 任职要求： 1.全日制本科及以上学历，计算机、统计、数学等相关专业；
2.3年以上DW/BI系统的实际开发经验，至少精通DB2、Oracle、Teradata、Greenplum、MySQL其中一种主流数据库及其数据仓库的开发、设计和调优； 3.具备丰富的数据库模型设计及数据库管理经验，熟悉一种以上主流ETL工具，有大型的数据仓库设计优先；
4.熟悉Hadoop、Spark、Hive等，具有相关环境的使用经验；
5.精通PL/SQL & SQL编程，熟悉J2EE架构，能使用JAVA语言编写ETL开发程序；
6.责任心强，有良好的合作精神，沟通能力较强； 7.有海量数据处理经验优先；熟悉金融业务优先。"
"职位描述：
        
        职责描述：
负责搭建互联网企业级数据仓库，包括ETL、数据模型设计和开发、BI等工作。

任职要求：
1.全日制本科及以上学历，计算机、统计、数学等相关专业；
2.3年以上DW/BI系统的实际开发经验，至少精通DB2、Oracle、Teradata、Greenplum其中一种主流数据库及其数据仓库的开发、设计和调优；
3.具备丰富的数据库模型设计及数据库管理经验，熟悉一种以上主流ETL工具，有大型的数据仓库设计或者数据分析经验者优先；
4.熟悉Hadoop、Spark、Hive等，具有相关环境的使用经验；
5.精通PL/SQL & SQL编程，熟悉J2EE架构，能使用JAVA语言编写ETL开发程序；
6.责任心强，有良好的合作精神，沟通能力较强；
7.有海量数据处理经验优先；熟悉金融业务优先。"
"职位描述：
        
        岗位职责：
1. 规划、落地基于hadoop生态的大数据平台；
2. 承担包括但不限于数据集市、实时分析、数据展示等大数据相关项目/产品的核心开发工作；
3. 制定并执行工作计划，指导协助同事解决日常工作中的问题、对系统存在的问题进行跟踪和定位并及时解决；
?
岗位要求：
1. 本科及以上学历，计算机科学、应用数学等相关专业毕业；
2. 具有3年以上大数据/BI/报表相关工作经验，有农牧或大型制造业经验优先；
3. 熟练掌握hadoop技术栈，有一定规划和调优经验，同时具有phyon/storm/spark开发经验优先考虑；
4. 能熟练使用sqoop等作为etl工具，同时有tableau/PowerBI类软件开发经验；
5. 能熟练应用java/spring-boot技术栈进行开发，同时熟悉groovy/scala语言开发优先考虑；
6. 熟练使用SQL，熟悉数据库原理，熟练使用至少一种主流关系型数据库；
7. 熟悉linux操作系统，熟练使用常用命令和shell脚本。"
"职位描述：
        
        岗位职责：
1、参与基于Hadoop生态系统（Hadoop、HBase、Hive、Yarn、Titan、Spark）的大数据平台设计及实施构建。
2、负责公司大数据平台日常的运维、系统高可用性维护及性能调优。
3、负责大数据平台组件间的集成、接口封装，相关的技术文档编写。
4、参与大数据平台组件选型，参与大数据平台组件选型。
5、完成大数据平台批处理（map reduce程序，hive sql等）任务，以及实时处理的的开发工作。
技术要求：
1、正规全日制大学本科及以上学历，计算机相关专业。
2、8年以上Java/Python/Scala语言应用开发经验，5年以上的大数据平台研发经验。熟悉常用的面向对象设计模式和分布式系统开源框架；
3、熟悉linux开发环境及操作系统底层机制，并熟悉分布式系统底层实现机制及Hadoop生态系统各组件技术架构，研究过Hadoop各组件源码或参与过Hadoop开源社区者优先考虑。
4、精通map/reduce应用框架，对流式处理框架storm/flink/spark stream至少熟悉一种。
5、熟练使用hbase等实时数据库进行应用开发，了解时序数据库者优先
6、具备责任心和良好的团队协作精神，乐于沟通交流和分享。"
"职位描述：
        
        岗位职责：
1. 负责数据仓库建设、数据挖掘分析体系构建以及媒体或其他垂直领域相关的数据挖掘和分析；
2. 负责大数据、模型、业务的相关算法的研究及应用；
3. 根据业务的实际需求，制定大数据挖掘与分析方法并实施，产生符合要求的数据结果；
3. 应用数据挖掘和机器学习方法建立数据模型解决实际问题，并与业务部门沟通合作，推动数据模型在实际业务中落地。

任职要求：
1. 计算机相关专业，本科及以上学位，3年及以上相关工作经验；
2. 熟悉Hadoop, Hive, HBase，Spark、Storm、Flink、Kafka、Flume中至少3种以上技术，并掌握其用途、原理和适用条件；（不满足者勿投）?
3. 精通Java、python、或Scala三者之一；（不满足者勿投）
4. 具有良好的分析并解决问题的能力、协作沟通能力；
5. 参与大数据开源项目，对社区有贡献者优先；
6. 在自然语言处理、机器学习、推荐算法有丰富实战经验者优先。"
"职位描述：
        
        职业描述：1.参与公司数据仓库架构设计与研发,建设?PB?级的公共数据平台和服务系统,实现高质量数据的互通与共享2.参与数据产品与应用的数据研发,发掘数据商业价值,打造极致体验的数据产品任职要求：1.从事数据仓库领域至少?2?年以上,熟悉数据仓库模型设计与数据研发经验?,掌握维度建模设计方法等思想,具备海量数据加工处理相关经验2.掌握至少一种分布式平台开发技术:Maxcompute、Hadoop、Spark、Teradata等,灵活运用?MR、SQL、UDF?实现海量数据加工处理3.熟悉?Linux?系统常规?shell?处理命令,灵活运用?shell?做的文本处理和系统操作4.熟练掌握一门或多门编程语言,并有大型项目建设经验者优先,重点考察?Java、Python5.熟悉数据仓库领域知识和技能者优先,包括但不局限于:元数据管理、数据开发测试工具与方法、数据质量、主数据管理6.既能掌握大规模离线数据处理又能掌握实时流计算技术优先,如Storm、Flink、Spark?Streaming、Streamcompute等7.良好的语言沟通与表达能力和自我驱动动力"
"职位描述：
        
        职业描述：
1.负责业务数据和用户行为日志的实时采集、计算、存储、服务,为业务部门提供直接数据决策2.开发可靠、高效、准确的实时和准实时采集和计算代码,并形成整体框架和接口供调用3.建立和维护大数据基础设施,解决海量数据存储、计算的问题
任职要求：
1.掌握实时计算技术体系包括数据采集、计算引擎 storm 、spark streaming、flink等,对实时计算所涉及的事务、容错、可靠性有深入理解 并有实际项目经验2.熟悉 hadoop 生态包括 hdfs/mapreduce/hive/hbase,熟悉 flume、kafka 等实时开源工具并有项目经验3.熟悉 mysql 等关系型数据库,熟悉 redis 内存数据库,熟悉 linux 系统4.熟练使用 sql,熟悉 python、java 等编程语言5.有良好的沟通能力和自我驱动动力,具备出色的规划、执行力,强烈的责任感,以及优秀的学习能力"
"职位描述：
        
        ?岗位职责： ??1、负责公司大数据集群的构建，任务调度、监控预警，持续完善大数据平台，保证稳定性、安全性； ??2、负责集群容量规划、扩容、集群性能优化及日常巡检和应急值守，参与大数据基础环境的架构设计与改进；??3、负责实时数据业务的设计和开发；??4、深入研究大数据业务相关技术，持续优化集群服务架构，探索新的Hadoop生态技术及发展方向。?任职资格： ??1、计算机相关专业，本科及以上学历，3年以上大数据开发相关经验；??2、熟悉 Linux 基础命令操作，能够独立编写Python、Shell脚本； ??3、熟悉Hadoop生态圈Hadoop、Spark、Kafka、Zookeeper、HBase的安装与调试； ??4、熟练spark,flink,kafka等相关技术；??5、熟悉多线程编程，有分布式开发经验值优先；??6、工作认真负责，有较强的学习能力，动手能力和分析解决问题的能力； ??7、能够利用各种开源监控工具、运维工具，HA、负载均衡软件完成工作任务。"
"职位描述：
        
        岗位职责：
1、负责数据仓储底层数据模型，整合多元化的业务数据；
2、创建和维护用于各种大数据分析场景下的数据结构和数据清洗任务；
3、负责大数据仓储平台的日常程序开发和系统性能维护。


任职要求：
1、本科及以上学历，计算机相关专业，2年以上大数据开发经验；
2、掌握常用的数据结构和算法设计，熟练使用Python/Java/Scala至少一门语言；
3、熟悉和掌握Hadoop/Hive/Spark/Kafka等大数据组件的应用场景和制订性能优化方案；
4、熟练掌握大数据生态下离线分析和实时分析的实际开发经验；
5、擅长分布式程序设计开发，熟练常用的HSQL操作与优化；
6、对数据敏感，有良好的逻辑思维能力和业务理解能力。"
"职位描述：
        
        【工作内容】
? 1、负责日常数据挖掘、开发、分析和整理及清洗
? 2、负责数据需求的技术分析和实现
? 3、负责相关业务的数据梳理和流程优化
? 4、配台团队进行数据需求上线和效果分析
【岗位要求】
? 1、计算机基础扎实，计算机、通信、电子等相关专业本科及以上学历
? 2、熟练掌握Python、Shell等常用编程语言，具备Linux下的开发经验
? 3、熟练Mysql、Redis，熟练掌握SQL语句，熟悉Hive、MapReduce等优先
? 4、有较强的学习能力，对技术有钻研精神，并有较高的热情，热衷于新技术、新理论、新开发实践的学习和实践
【实习时间】半年以上，每周至少3天"
"职位描述：
        
        工作职责：1、负责公司各类数据的处理、大数据平台框架的研发设计工作；2、使用Spark、MapReduce、Storm、Kafka等组件进行数据处理；3、新技术框架和解决方案预研与落地，以提高处理和分析大数据的效率和速度。任职资格：1、熟悉Hadoop以及Hadoop生态圈中的多个组件，如HBase、Hive、Kafka、Storm、Impala等；2、精通JAVA编程语言，熟悉Linux操作，可以编写代码编程使用Hadoop生态中的组件和基于组件开发的大数据处理；3、熟悉开源组件源码者优先"
"职位描述：
        
        岗位职责：
1、基于HadoopHBaseSparkFlume等大数据组件，依据业务/产品需求，负责分布式产品平台下的数据架构设计、数据处理流设计与开发工作；?
2、领导大数据团队全面负责公司大数据研发工作；?
3、与系统开发团队的协作，包括对需求的分析、文档输出、以及开发联调等工作。

技能要求：
1、计算机、数学统计或相关专业本科及以上学历，五年以上软件开发工作经验， 三年以上大数据开发实战经验。数据挖掘和BI分析领域优先；
2、有分布式系统分析及架构设计经验，有大型计算集群的基础设施开发维护经验；
3、熟悉Hadoop/Map-Reduce/YARN分布式计算框架，进行数据模型设计、数据ETL开发，熟悉实时数据处理者优先；?
4、熟练使用标准SQL语言，熟悉Java、Scala、Python等编程语言中的一种语言，有较强的自我驱动能力，对数据分析有热情；
5、了解完整的数据挖掘过程方法论，有独立完整的建模实践经验优先，如熟悉回归分析模型、关联规则挖掘、分类和聚类算法、协同过滤算法等数据统计模型和挖掘算法等；?
6、具有良好的沟通与团队协作能力，对未知领域有一定的学习、探索兴趣，有较强的自我驱动能力；有带团队经验优先。

来点儿福利：
双休、三餐补助、五险一金、年终奖、健康体检、带薪年假、福利病假、员工活动经费、半年一次国内旅游、员工生日会、季度优秀员工奖、过年过节礼品、日常工作中提供零食、咖啡、冷饮免费供应等相关福利。

 具有竞争力的薪水；
 GeekPlace、硅谷范儿又不失小清新的工作环境；
 让你出其不意又精彩纷呈的节假日活动；
 优秀员工期权激励计划等。

当然，以上都不重要！
重要的是，斗象科技给你带来的成长：

 朝阳行业，学习更多最新前沿知识，结识更多顶级人物和事物；
 了解国内安全动态及其背后的故事，让你拥有更敏锐的趋势判断，前提如果你够努力；
 兼具面向企业与面向用户的业务，职场成长经验多倍加成。"
"职位描述：
        
        
岗位职责：?
1、负责公司大数据集群的构建，任务调度、监控预警，持续完善大数据平台，保证稳定性、安全性；?
2、负责集群容量规划、扩容、集群性能优化，参与大数据基础环境的架构设计与改进；
3、负责实时数据业务的设计和开发；
4、深入研究大数据业务相关技术，持续优化集群服务架构。

任职资格：?
1、计算机相关专业，本科及以上学历，3年以上大数据开发相关经验；
2、熟悉 Linux 基础命令操作，能够独立编写Python、Shell脚本；?
3、熟悉Hadoop生态圈Hadoop、Spark、Kafka、Zookeeper、HBase的安装与调试；?
4、熟练spark,flink,kafka等相关技术；
5、熟悉多线程编程，有分布式开发经验优先；
6、工作认真负责，有较强的学习能力，动手能力和分析解决问题的能力；?
7、能够利用各种开源监控工具、运维工具，HA、负载均衡软件完成工作任务。

来点儿福利：
双休、中餐补助、五险一金、年终奖、健康体检、带薪年假、福利病假、员工活动经费、半年一次国内旅游、员工生日会、季度优秀员工奖、过年过节礼品、日常工作中提供零食、咖啡、冷饮免费供应等相关福利。
具有竞争力的薪水；
GeekPlace、硅谷范儿又不失小清新的工作环境；
让你出其不意又精彩纷呈的节假日活动；
优秀员工期权激励计划等。
当然，以上都不重要！
重要的是，斗象科技给你带来的成长：
1）朝阳行业，学习更多最新前沿知识，结识更多顶级人物和事物；
2）了解国内安全动态及其背后的故事，让你拥有更敏锐的趋势判断，前提如果你够努力；
3）兼具面向企业与面向用户的业务，职场成长经验多倍加成。"
"职位描述：
        
        工作职责：
1、规划大数据平台技术架构和技术路线；
2、带领团队进行大数据平台功能模块设计，数据平台的搭建，维护和优化；
3、制定数据采集、清洗、装在规范，数据仓库和数据集市的建设；
4、负责团队梯度建设、人才培养、人才输出和能力输出。
?
任职要求：
1、5年以上数据平台建设工作经验、3年以上带领团队经验；
2、精通Hadoop、Hive 、Spark、SparkStreaming、Strom、Kafka等技术体系、熟练使用至少一门编程语言（Java、Python、Scala）；
3、钻研大数据行业技术和应用前沿、日TB级数据、构建过实时数据平台系统；
4、精通Hadoop集群管理，熟悉流行大数据开源平台，有二次开发经验这优先；
5、强烈的好奇心和求知欲、善于深入一线业务、研究业务；
6、具有出色的逻辑思维能力、组织协调能力、沟通交流能力。"
"职位描述：
        
        工作职责：
1、带领团队、负责大数据平台建设、包含数据采集规范、数据仓储层级规范等基础建设和技术核心攻坚；
2、带领团队、构建业务指标体系、建立和完善日常业务报告体系、能够实时、准确、完整地披露业务的运作情况 ；
3、带领团队、负责为数据挖掘、业务分析、商业分析等各端（技术/产品/业务）、提供高效数据能力输出；
4、负责业务数据画像、包括用户、商户、职位等、通过数据进行业务驱动；
5、负责团队梯度建设、人才培养、人才输出和能力输出。
?
任职要求：
1、6年以上数据平台建设工作经验、3年以上带领团队经验；
2、精通Hadoop、Hive 、Spark、SparkStreaming、Kafka等技术体系、熟练使用至少一门编程语言（Java、Python、Go、Scala）；
3、钻研大数据行业技术和应用前沿、日TB级数据、构建过实时数据平台系统；
4、对数据敏感、熟悉常用数据挖掘算法、并有一定实践经验；
5、强烈的好奇心和求知欲、善于深入一线业务、研究业务；
6、具有出色的逻辑思维能力、组织协调能力、沟通交流能力。"
"职位描述：
        
        岗位职责
1、 规划和梳理业务需求，将需求转化成数据思维，独立完成需求的对接和开发；
2、 参与ETL，报表，BI等的开发工作；
3、 参与数据仓库的设计和开发工作；
4、 数据仓库系统日常管理与维护。
任职要求
1、有三年以上数据仓库开发经验；
2、掌握数据库基础知识，SQL基本功扎实，深刻理解数据仓库建模；
3、熟练使用hive,有hsql调优经验；
4、熟悉Hadoop/MapReduce/hive/spark/sqoop等大数据生态 ；
5. 思维清晰敏捷，逻辑分析能力强，具有良好的语言和书面表达能力。"
"职位描述：
        
        岗位职责
1、 规划和梳理业务需求，将需求转化成数据思维，独立完成需求的对接和开发；
2、 参与ETL，报表，BI等的开发工作；
3、 参与数据仓库的设计和开发工作；
4、 数据仓库系统日常管理与维护。
任职要求
1、有三年以上数据仓库开发经验；
2、掌握数据库基础知识，SQL基本功扎实，深刻理解数据仓库建模；
3、熟练使用hive,有hsql调优经验；
4、熟悉Hadoop/MapReduce/hive/spark/sqoop等大数据生态 ；
5. 思维清晰敏捷，逻辑分析能力强，具有良好的语言和书面表达能力。"
"职位描述：
        
        岗位描述：
1、管理MySQL数据库，包括同步、备份、调优等日常工作；
2、设计数据挖掘和分析的目标、流程和步骤；
3、了解Spark等大数据框架的部署和使用；

任职要求：
1、本科计算机，3年以上相关工作经验；
2、精通Linux系统使用，有过大规模数据的管理经验；
3、开发过大数据应用，对数据挖掘和各类人工智能算法有一点了解；
4、热爱学习，乐于分享，思维活跃，乐观开朗。"
"职位描述：
        
        任职资格：
1、本科及以上学历，计算机相关专业；
2、精通一门或多门编程语言(javapythonscala等)，具备海量数据处理以及性能优化的能力；
3、有Hadoop生态体系实际开发经验，至少熟练掌握Hadoop、Hive、Spark、Storm、Flink、ElasticSearch、HBase其中两种以以上开发框架；
4、熟悉机器学习与自然语言处理技术者优先；
5、有游戏、互联网或移动互联网公司背景优先。

公司福利：?
1、工作时间：周一到周六,9:30-12:30;14:30-18:30（每半年可享至少14天带薪假期，公司提供往返国内机票）;?
2、提供高级公寓住宿：自带泳池和健身房，燃烧你的卡路里；
3、每月发放餐饮补贴，一日三餐随心选；
4、办公室无限提供零食和饮料，吃饱喝足再去敲代码；
5、公司为员工办理工作签证，保障出入境自由；
6、年度员工体检，身体也要棒棒的；
7、技术分享会、员工户外运动、团队建设、员工旅游、重大节日抽奖活动，嗨爆你的业余生活；
8、弹性调薪制度、年终奖、全勤奖、伯乐奖、结婚礼金、生日礼金等你来拿！
?
工作地点：马来西亚吉隆坡双子塔附近（请仔细查阅!）"
"职位描述：
        
        任职资格：
1、本科及以上学历，计算机相关专业；
2、精通一门或多门编程语言(javapythonscala等)，具备海量数据处理以及性能优化的能力；
3、有Hadoop生态体系实际开发经验，至少熟练掌握Hadoop、Hive、Spark、Storm、Flink、ElasticSearch、HBase其中两种以以上开发框架；
4、熟悉机器学习与自然语言处理技术者优先；
5、有游戏、互联网或移动互联网公司背景优先。

公司福利：?
1、工作时间：周一到周六,9:30-12:30;14:30-18:30（每半年可享至少14天带薪假期，公司提供往返国内机票）;?
2、提供高级公寓住宿：自带泳池和健身房，燃烧你的卡路里；
3、每月发放餐饮补贴，一日三餐随心选；
4、办公室无限提供零食和饮料，吃饱喝足再去敲代码；
5、公司为员工办理工作签证，保障出入境自由；
6、年度员工体检，身体也要棒棒的；
7、技术分享会、员工户外运动、团队建设、员工旅游、重大节日抽奖活动，嗨爆你的业余生活；
8、弹性调薪制度、年终奖、全勤奖、伯乐奖、结婚礼金、生日礼金等你来拿！
?
工作地点：马来西亚吉隆坡双子塔附近（请仔细查阅!）"
"职位描述：
        
        任职资格：
1、本科及以上学历，计算机相关专业；
2、精通一门或多门编程语言(javapythonscala等)，具备海量数据处理以及性能优化的能力；
3、有Hadoop生态体系实际开发经验，至少熟练掌握Hadoop、Hive、Spark、Storm、Flink、ElasticSearch、HBase其中两种以以上开发框架；
4、熟悉机器学习与自然语言处理技术者优先；
5、有游戏、互联网或移动互联网公司背景优先。

公司福利：?
1、工作时间：周一到周六,9:30-12:30;14:30-18:30（每半年可享至少14天带薪假期，公司提供往返国内机票）;?
2、提供高级公寓住宿：自带泳池和健身房，燃烧你的卡路里；
3、每月发放餐饮补贴，一日三餐随心选；
4、办公室无限提供零食和饮料，吃饱喝足再去敲代码；
5、公司为员工办理工作签证，保障出入境自由；
6、年度员工体检，身体也要棒棒的；
7、技术分享会、员工户外运动、团队建设、员工旅游、重大节日抽奖活动，嗨爆你的业余生活；
8、弹性调薪制度、年终奖、全勤奖、伯乐奖、结婚礼金、生日礼金等你来拿！
?
工作地点：马来西亚吉隆坡双子塔附近（请仔细查阅!）"
"职位描述：
        
        岗位职责：
1、要求能自主完成功能模块的接口讨论、性能调优；
2、负责日常业务需求文档的理解、技术方案设计、技术开发与测试；
3、负责编制与产品或项目相关的技术文档。
?
任职资格：
1、计算机或相关专业，本科及以上学历，3年及以上相关工作经验，至少2年以上实际大数据开发经验；
2、熟悉J2EE，了解各种常用开源框架和技术 线程、缓存、信息等高性能架构相关开发技术有一定了解；
3、熟悉常用开源分布式系统，对Hadoop/Hive/Spark/HBase中的一项或多项有深入了解;
4、理解Hadoop,Spark体系架构，并有相当开发经验；
5、有实时类数据处理项目经验，并有小组管理经验更佳；
6、对技术有激情、有追求，富于创新精神，思路清晰;
7、良好的客户服务意识和沟通能力，良好的团队意识，具有一定抗压能力。"
"职位描述：
        
        主要职责：1、参与大数据项目各类数据源ETL的接口设计和文档、流程规范编写；2、负责数据流程分析和优化，解决ETL相关技术问题；3、负责项目中数据清洗、数据处理、数据校验等相关开发工作；职位要求：1、计算机相关专业本科以上学历；2、有Java或Python经验基础，具备良好的文档编写能力；3、熟练掌握SQL语言，shell脚本编写等；4、熟练掌握MySQL或MongoDB等至少一种数据库操作；5、熟练掌握kettle等ETL工具，2年及以上ETL相关开发工作经验（必须涵盖数据抽取、清洗等经验）；6、熟练掌握ETL架构，了解日常作业的部署和调度；7、具备良好的团队合作精神以及良好的沟通能力；8、工作积极主动，细心，能承受一定的工作压力。"
"职位描述：
        
        岗位职责：1、进行数据分类、搜集和整理，主要是数据清洗、数据处理、ETL方面；2、为系统开发人员提供详细设计方案，并承担部分数据分析工作；3、参与数据仓库/数据集市的逻辑与物理数据模型设计，负责源系统数据探索与数据映射。任职要求：1、大专及以上学历，计算机相关专业；精通Python、Java、scala中至少一门开发语言；熟练使用主流ETL工具DataStage、Kettle等开发；2、掌握多线程及高性能程序设计编码及性能调优，有高并发应用开发经验；3、熟悉缓存技术、服务器优化、集群性能优化、系统性能调优等技术；4、工作态度积极主动、细致、有全局观；具有较好抗压能力；善于与他人合作，具有良好的团队合作意识。"
"职位描述：
        
        岗位描述：
1、负责数美大数据平台的架构和开发；
2、负责数美业务数据的统计和多维数据分析；
3、数据挖掘，机器学习，推荐算法。

任职资格：
1、本科或以上，计算机软件或相关专业毕业；
2、扎实的编程能力，熟悉算法和数据结构，熟悉计算机的基础理论；
3. 熟悉大数据处理相关技术，包括但不限于 Hadoop、Hive 、Hbase、Impala、Spark 、Kafaka、Flume、Sqoop 、Storm、Redis等；
4. 熟悉推荐系统和数据挖掘算法者优先。

公司福利待遇
有竞争力的薪酬
期权奖励
五险一金+商业保险
午餐+晚餐补助
交通+通讯+电脑补贴
结婚+生育+丧葬+住院礼金
伯乐奖金
年假8天起+带薪病假
年度体检、零食畅享、团队建设、生日会、弹性办公
?

?数美领先的大数据技术、产品与服务提供商
我们正在经历一个IT到DT的变革时代。大数据已经渗透到各个环节，各个角落。
这个世界，就是掩藏在表象之下，被数据所揭示的世界！
数美依托积累的海量数据、科技前沿技术， 极致的工匠精神和对数据的深度理解，提供领先的大数据产品与服务。?
我们正在寻找不平凡的你，和我们一起“发现数据之美”
欢迎投递简历

【关于数美】www.ishumei.com
? ? ? 数美由百度、小米、360等顶尖互联网公司联合投资的大数据公司，致力于利用人工智能技术和海量数据解决金融、互联网等领域广泛存在的欺诈问题，先后推出了信贷反欺诈、内容反欺诈、行为反欺诈等系列产品， ? ? ?
? ? ?目前已服务数百家客户，覆盖直播、金融、支付、社交、电商、游戏、O2O等行业。其中包括中信银行、360、小米、58同城、爱奇艺、酷狗、用钱宝、点融、挖财、闪银、熊猫TV、花椒、唱吧等知名企业，并与腾讯云、金山云、七牛云等云服务提供商展开深度合作。
? ? 数美的创始人唐会军在搜索、安全、语音识别等大数据领域拥有十余年研发经验，曾历任百度系统技术负责人、360高级技术总监等职位。创始团队均来自百度、360、小米、宜信、FICO等知名互联网公司，数美核心团队是国内最早一批从事大数据平台与应用研发的团队，曾负责过的大数据平台规模居全球前十。国际顶尖反欺诈技术，拥有十余项专利，同时在安全，反作弊、推荐，广告，语音识别等领域有着丰富的大数据成功应用经验。
? ? ?? ? ??www.ishumei.com"
"职位描述：
        
        360、小米、百度等顶级互联网公司联合投资，顶级大数据公司
?
你将负责
1. 主导数美大数据平台的设计与开发，解决海量数据面临的挑战；
2. 管理、优化并维护Hadoop、Spark等集群，保证集群规模持续、稳定；
3. 负责HDFS/hive/HBase的功能、性能和扩展，解决并实现业务需求；
4. 协助建立数据模型，对数据进行挖掘、优化及统计。
?
我们希望你
1、本科生及以上学历，1年及以上相关经验；
2、熟悉Hadoop/HBase/Spark/Storm/Hive，熟悉数据挖掘策略与算法；
3、熟悉分布式系统设计范型，有大规模系统设计和工程实现的经验 ；
4、数据控，善于发现问题、解决问题；
5、对新兴技术有好奇心，有利用技术解决实际问题的热情，开源社区积极参与者优先
?

公司福利待遇
有竞争力的薪酬
期权奖励
五险一金+商业保险
午餐+晚餐补助
交通+通讯+电脑补贴
结婚+生育+丧葬+住院礼金
伯乐奖金
年假8天起+带薪病假
年度体检、零食畅享、团队建设、生日会、弹性办公
?
数美领先的大数据技术、产品与服务提供商
我们正在经历一个IT到DT的变革时代。大数据已经渗透到各个环节，各个角落。
这个世界，就是掩藏在表象之下，被数据所揭示的世界！
数美依托积累的海量数据、科技前沿技术， 极致的工匠精神和对数据的深度理解，提供领先的大数据产品与服务。?
我们正在寻找不平凡的你，和我们一起“发现数据之美”
欢迎投递简历


【关于数美】www.ishumei.com
数美（全称北京数美时代科技有限公司）成立于2015年6月，是一家专业的大数据科技公司。数美依托先进的核心AI技术和海量的数据基础，致力于解决多场景欺诈问题，为客户提供专业、可信赖的服务。团队均来自百度、阿里、腾讯、360、小米等顶尖互联网公司，在大数据、人工智能、机器学习、金融风控等领域有着丰富的实践经验。目前，业务已覆盖金融、支付、直播、社交、电商、O2O等为代表的多个行业领域，其中包括中信银行、用钱宝、人人贷、51信用卡、360、小米、58同城、爱奇艺、熊猫直播、花椒、唱吧等知名企业，截止到2017年6月，服务客户突破1000家。作为大数据反欺诈专业品牌，数美将持续挖掘数据价值，为金融机构、互联网企业提供智能、创新的一站式反欺诈综合解决方案

…………………………………………………………………………
了解更多
数美公司介绍
https://www.ishumei.com/aboutUs/introduction.html 
数美团队介绍
https://www.ishumei.com/aboutUs/team.html 
数美产品介绍
https://www.ishumei.com/product/creditFengkong.html 
数美解决方案介绍
https://www.ishumei.com/solution/finance.html"
"职位描述：
        
        大数据研发工程师
岗位职责：
1、负责公司数据产品的画像数据仓库表设计、开发、优化；
2、负责元数据管理设计、开发
3、数据处理流程与框架设计与开发
4、数据质量监控设计与开发

任职要求：
1、本科以上，计算机相关专业；2-4年hadoop数据仓库、用户画像建设经验；
2、熟悉hadoop上数据表设计模式、元数据管理、数据处理与监控、数据处理框架开发；
3、有较强的性能优化及问题排查、解决能力；
3、.工作认真、负责、细致，有良好的团队合作精神，良好的分析能力、沟通技巧；

数美领先的大数据技术、产品与服务提供商
我们正在经历一个IT到DT的变革时代。大数据已经渗透到各个环节，各个角落。
这个世界，就是掩藏在表象之下，被数据所揭示的世界！
数美依托积累的海量数据、科技前沿技术， 极致的工匠精神和对数据的深度理解，提供领先的大数据产品与服务。?
我们正在寻找不平凡的你，和我们一起“发现数据之美”
欢迎投递简历

【关于数美】www.ishumei.com
? ? ?数美（全称北京数美时代科技有限公司）成立于2015年6月，是一家专业的大数据科技公司。数美依托先进的核心AI技术和海量的数据基础，致力于解决多场景欺诈问题，为客户提供专业、可信赖的服务。团队均来自百度、阿里、腾讯、360、小米等顶尖互联网公司，在大数据、人工智能、机器学习、金融风控等领域有着丰富的实践经验。目前，业务已覆盖金融、支付、直播、社交、电商、O2O等为代表的多个行业领域，其中包括中信银行、用钱宝、人人贷、51信用卡、360、小米、58同城、爱奇艺、熊猫直播、花椒、唱吧等知名企业，截止到2017年6月，服务客户突破1000家。作为大数据反欺诈专业品牌，数美将持续挖掘数据价值，为金融机构、互联网企业提供智能、创新的一站式反欺诈综合解决方案

…………………………………………………………………………
了解更多
数美公司介绍
https://www.ishumei.com/aboutUs/introduction.html 
数美团队介绍
https://www.ishumei.com/aboutUs/team.html 
数美产品介绍
https://www.ishumei.com/product/creditFengkong.html 
数美解决方案介绍
https://www.ishumei.com/solution/finance.html"
"职位描述：
        
        360、小米、百度等顶级互联网公司联合投资，顶级大数据公司
?
你将负责
1. 主导数美大数据平台的设计与开发，解决海量数据面临的挑战；
2. 管理、优化并维护Hadoop、Spark等集群，保证集群规模持续、稳定；
3. 负责HDFS/hive/HBase的功能、性能和扩展，解决并实现业务需求；
4. 协助建立数据模型，对数据进行挖掘、优化及统计。
?
我们希望你
1、本科生及以上学历，1年及以上相关经验；
2、熟悉Hadoop/HBase/Spark/Storm/Hive，熟悉数据挖掘策略与算法；
3、熟悉分布式系统设计范型，有大规模系统设计和工程实现的经验 ；
4、数据控，善于发现问题、解决问题；
5、对新兴技术有好奇心，有利用技术解决实际问题的热情，开源社区积极参与者优先
?

公司福利待遇：
有竞争力的薪酬
期权奖励
五险一金+商业保险
午餐+晚餐补助
交通+通讯+电脑补贴
结婚+生育+丧葬+住院礼金
伯乐奖金
年假8天起+带薪病假
年度体检、零食畅享、团队建设、生日会、弹性办公
?
数美领先的大数据技术、产品与服务提供商
我们正在经历一个IT到DT的变革时代。大数据已经渗透到各个环节，各个角落。
这个世界，就是掩藏在表象之下，被数据所揭示的世界！
数美依托积累的海量数据、科技前沿技术， 极致的工匠精神和对数据的深度理解，提供领先的大数据产品与服务。?
我们正在寻找不平凡的你，和我们一起“发现数据之美”
欢迎投递简历


【关于数美】www.ishumei.com
? ? ? 数美由百度、小米、360等顶尖互联网公司联合投资的大数据公司，致力于利用人工智能技术和海量数据解决金融、互联网等领域广泛存在的欺诈问题，先后推出了信贷反欺诈、内容反欺诈、行为反欺诈等系列产品， ? ? ?
? ? ?目前已服务数百家客户，覆盖直播、金融、支付、社交、电商、游戏、O2O等行业。其中包括中信银行、360、小米、58同城、爱奇艺、酷狗、用钱宝、点融、挖财、闪银、熊猫TV、花椒、唱吧等知名企业，并与腾讯云、金山云、七牛云等云服务提供商展开深度合作。
? ? 数美的创始人唐会军在搜索、安全、语音识别等大数据领域拥有十余年研发经验，曾历任百度系统技术负责人、360高级技术总监等职位。创始团队均来自百度、360、小米、宜信、FICO等知名互联网公司，数美核心团队是国内最早一批从事大数据平台与应用研发的团队，曾负责过的大数据平台规模居全球前十。国际顶尖反欺诈技术，拥有十余项专利，同时在安全，反作弊、推荐，广告，语音识别等领域有着丰富的大数据成功应用经验。
? ? ?? ? ??www.ishumei.com"
"职位描述：
        
        
我们提供真实的用户画像，图像语音数据，海量用户的操作行为；我们面对的是动态、复杂、多变的各式数据风险，如作弊、欺骗，攻击，涉黄，暴恐，垃圾广告等等；我们不仅利用分布式的计算引擎，进行离线算法实施，也会面对实时同步的在线模型挑战；我们不仅仅针对行为，文本等结构化数据建模，我们也使用图像、语音数据进行识别，分类进行风控建模；
如果你对这些有兴趣、如果你致力于用数据产生价值、如果你想帮助企业通过云服务，获得更加便捷与安全的体验，请加入我们。

岗位职责：
1、负责公司数据产品的画像数据仓库表设计、开发、优化；
2、负责元数据管理设计、开发
3、数据处理流程与框架设计与开发
4、数据质量监控设计与开发

任职要求：
1、本科以上，计算机相关专业；2-4年hadoop数据仓库、用户画像建设经验；
2、熟悉hadoop上数据表设计模式、元数据管理、数据处理与监控、数据处理框架开发；
3、有较强的性能优化及问题排查、解决能力；
3、.工作认真、负责、细致，有良好的团队合作精神，良好的分析能力、沟通技巧；

数美领先的大数据技术、产品与服务提供商
我们正在经历一个IT到DT的变革时代。大数据已经渗透到各个环节，各个角落。
这个世界，就是掩藏在表象之下，被数据所揭示的世界！
数美依托积累的海量数据、科技前沿技术， 极致的工匠精神和对数据的深度理解，提供领先的大数据产品与服务。?
我们正在寻找不平凡的你，和我们一起“发现数据之美”
欢迎投递简历


【关于数美】www.ishumei.com
? ? ?数美（全称北京数美时代科技有限公司）成立于2015年6月，是一家专业的大数据科技公司。数美依托先进的核心AI技术和海量的数据基础，致力于解决多场景欺诈问题，为客户提供专业、可信赖的服务。团队均来自百度、阿里、腾讯、360、小米等顶尖互联网公司，在大数据、人工智能、机器学习、金融风控等领域有着丰富的实践经验。目前，业务已覆盖金融、支付、直播、社交、电商、O2O等为代表的多个行业领域，其中包括中信银行、用钱宝、人人贷、51信用卡、360、小米、58同城、爱奇艺、熊猫直播、花椒、唱吧等知名企业，截止到2017年6月，服务客户突破1000家。作为大数据反欺诈专业品牌，数美将持续挖掘数据价值，为金融机构、互联网企业提供智能、创新的一站式反欺诈综合解决方案
…………………………………………………………………………
了解更多
数美公司介绍
https://www.ishumei.com/aboutUs/introduction.html 
数美团队介绍
https://www.ishumei.com/aboutUs/team.html 
数美产品介绍
https://www.ishumei.com/product/creditFengkong.html 
数美解决方案介绍
https://www.ishumei.com/solution/finance.html"
"职位描述：
        
        大数据研发工程师
岗位职责：
1、负责公司数据产品的画像数据仓库表设计、开发、优化；
2、负责元数据管理设计、开发
3、数据处理流程与框架设计与开发
4、数据质量监控设计与开发

任职要求：
1、本科以上，计算机相关专业；2-4年hadoop数据仓库、用户画像建设经验；
2、熟悉hadoop上数据表设计模式、元数据管理、数据处理与监控、数据处理框架开发；
3、有较强的性能优化及问题排查、解决能力；
3、.工作认真、负责、细致，有良好的团队合作精神，良好的分析能力、沟通技巧；

数美领先的大数据技术、产品与服务提供商
我们正在经历一个IT到DT的变革时代。大数据已经渗透到各个环节，各个角落。
这个世界，就是掩藏在表象之下，被数据所揭示的世界！
数美依托积累的海量数据、科技前沿技术， 极致的工匠精神和对数据的深度理解，提供领先的大数据产品与服务。?
我们正在寻找不平凡的你，和我们一起“发现数据之美”
欢迎投递简历

【关于数美】www.ishumei.com
? ? ?数美（全称北京数美时代科技有限公司）成立于2015年6月，是一家专业的大数据科技公司。数美依托先进的核心AI技术和海量的数据基础，致力于解决多场景欺诈问题，为客户提供专业、可信赖的服务。团队均来自百度、阿里、腾讯、360、小米等顶尖互联网公司，在大数据、人工智能、机器学习、金融风控等领域有着丰富的实践经验。目前，业务已覆盖金融、支付、直播、社交、电商、O2O等为代表的多个行业领域，其中包括中信银行、用钱宝、人人贷、51信用卡、360、小米、58同城、爱奇艺、熊猫直播、花椒、唱吧等知名企业，截止到2017年6月，服务客户突破1000家。作为大数据反欺诈专业品牌，数美将持续挖掘数据价值，为金融机构、互联网企业提供智能、创新的一站式反欺诈综合解决方案

…………………………………………………………………………
了解更多
数美公司介绍
https://www.ishumei.com/aboutUs/introduction.html 
数美团队介绍
https://www.ishumei.com/aboutUs/team.html 
数美产品介绍
https://www.ishumei.com/product/creditFengkong.html 
数美解决方案介绍
https://www.ishumei.com/solution/finance.html"
"职位描述：
        
        360、小米、百度等顶级互联网公司联合投资，顶级大数据公司

岗位职责
1. 主导数美大数据平台的设计与开发，解决海量数据面临的挑战；
2. 管理、优化并维护Hadoop、Spark等集群，保证集群规模持续、稳定；
3. 负责HDFS/hive/HBase的功能、性能和扩展，解决并实现业务需求；
4. 协助建立数据模型，对数据进行挖掘、优化及统计。

任职要求
1、硕士及以上学历，1年及以上相关经验；
2、熟悉Hadoop/HBase/Spark/Storm/Hive，熟悉数据挖掘策略与算法；
3、熟悉分布式系统设计范型，有大规模系统设计和工程实现的经验 ；
4、数据控，善于发现问题、解决问题；


公司福利待遇
有竞争力的薪酬
期权奖励
五险一金+商业保险
午餐+晚餐补助
交通+通讯+电脑补贴
结婚+生育+丧葬+住院礼金
伯乐奖金
年假8天起+带薪病假
年度体检、零食畅享、团队建设、生日会、弹性办公


【关于数美】www.ishumei.com
数美（全称北京数美时代科技有限公司）成立于2015年6月，是一家专业的大数据科技公司。数美依托先进的核心AI技术和海量的数据基础，致力于解决多场景欺诈问题，为客户提供专业、可信赖的服务。团队均来自百度、阿里、腾讯、360、小米等顶尖互联网公司，在大数据、人工智能、机器学习、金融风控等领域有着丰富的实践经验。目前，业务已覆盖金融、支付、直播、社交、电商、O2O等为代表的多个行业领域，其中包括中信银行、用钱宝、人人贷、51信用卡、360、小米、58同城、爱奇艺、熊猫直播、花椒、唱吧等知名企业，截止到2017年6月，服务客户突破1000家。作为大数据反欺诈专业品牌，数美将持续挖掘数据价值，为金融机构、互联网企业提供智能、创新的一站式反欺诈综合解决方案

…………………………………………………………………………
了解更多
数美公司介绍
https://www.ishumei.com/aboutUs/introduction.html
数美团队介绍
https://www.ishumei.com/aboutUs/team.html
数美产品介绍
https://www.ishumei.com/product/creditFengkong.html
数美解决方案介绍
https://www.ishumei.com/solution/finance.html"
"职位描述：
        
        岗位职责

 参与大数据平台体系建设，持续集成相关工具产品，以及搭建大数据业务统一计算层等相关工作；
 参与数据仓库的架构设计和研发，挖掘数据价值，建设与管理百PB级的公共数据平台和服务系统，实现高质量数据的互通与共享；
 参与工具/内容/智能数据产品研发，挖掘数据价值，实现数据赋能业务；
 用数据提高效率和改变业务运营方式，规划数据技术发展方向，带动团队技术氛围。


岗位要求
1.2019年应届毕业生，本科及以上学历，计算机相关专业；
2.扎实的数据结构和算法能力，熟悉至少一种关系型数据库；
3.熟悉一门数据处理语言，如SQL、JAVA、Python、Perl等；
4.善于沟通，主动性好，逻辑思维能力较强，有较强的自我驱动和学习能力；
加分项：1.有Hadoop、Hive、Hbase、Kylin、Druid等分布式平台实践经验；
2.有数据平台、数据仓库、数据产品研发、数据分析与挖掘等相关项目经验；
3.有多线程、缓存、分布式、全栈开发经验。

了解更多 数美公司介绍?https://www.ishumei.com/aboutUs/introduction.html
数美团队介绍
https://www.ishumei.com/aboutUs/team.html
数美产品介绍https://www.ishumei.com/product/creditFengkong.html
数美解决方案介绍?https://www.ishumei.com/solution/finance.html"
"职位描述：
        
        工作职责:
-负责构建大数据分析平台以及数据分析和挖掘工作
-参与支撑业务的数据模型建设及数据指标的计算和分析
-参与海量数据的存储、查询和运营数据分析体系搭建
-运用Hadoop、Spark、ES等分布式计算和存储平台

职责要求:
-计算机相关专业应届毕业生
-对Spark及Hadoop技术有深入了解
-熟悉Python/Java/Scala/Php等编程语言，熟练使用SQL，有良好的编码习惯，对分布式有深刻理解
-了解Windows、Unix、Linux等主流操作系统原理，熟练运用系统层支持应用开发
-技术视野开阔，有强烈的上进心和求知欲，善于学习和运用新知识，勇于解决难题?
-善于沟通和逻辑表达，拥有优秀的分析问题和解决问题的能力，良好的团队合作精神和积极主动的沟通意识?
-有激情，具有自我驱动力，追求卓越
具有以下条件者优先：?
-具备大数据云平台、计算存储平台、可视化开发平台经验，熟悉软件工程开发流程


【关于数美】www.ishumei.com
【关于数美】数美（全称北京数美时代科技有限公司）成立于2015年6月，是一家专业的大数据科技公司。数美依托先进的核心AI技术和海量的数据基础，致力于解决多场景欺诈问题，为客户提供专业、可信赖的服务。团队均来自百度、阿里、腾讯、360、小米等顶尖互联网公司，在大数据、人工智能、机器学习、金融风控等领域有着丰富的实践经验。目前，业务已覆盖金融、支付、直播、社交、电商、O2O等为代表的多个行业领域，其中包括中信银行、用钱宝、人人贷、51信用卡、360、小米、58同城、爱奇艺、熊猫直播、花椒、唱吧等知名企业，截止到2017年6月，服务客户突破1000家。作为大数据反欺诈专业品牌，数美将持续挖掘数据价值，为金融机构、互联网企业提供智能、创新的一站式反欺诈综合解决方案

…………………………………………………………………………
了解更多
数美公司介绍
https://www.ishumei.com/aboutUs/introduction.html
数美团队介绍
https://www.ishumei.com/aboutUs/team.html
数美产品介绍
https://www.ishumei.com/product/creditFengkong.html
数美解决方案介绍
https://www.ishumei.com/solution/finance.html"
"职位描述：
        
        岗位职责
参与大数据平台体系建设，持续集成相关工具产品，以及搭建大数据业务统一计算层等相关工作；
参与数据仓库的架构设计和研发，挖掘数据价值，建设与管理百PB级的公共数据平台和服务系统，实现高质量数据的互通与共享；
参与工具/内容/智能数据产品研发，挖掘数据价值，实现数据赋能业务；
用数据提高效率和改变业务运营方式，规划数据技术发展方向，带动团队技术氛围。

岗位要求
1.2019年应届毕业生，本科及以上学历，计算机相关专业；
2.扎实的数据结构和算法能力，熟悉至少一种关系型数据库；3.熟悉一门数据处理语言，如SQL、JAVA、Python、Perl等；
4.善于沟通，主动性好，逻辑思维能力较强，有较强的自我驱动和学习能力；

加分项：1.有Hadoop、Hive、Hbase、Kylin、Druid等分布式平台实践经验；2.有数据平台、数据仓库、数据产品研发、数据分析与挖掘等相关项目经验；
3.有多线程、缓存、分布式、全栈开发经验。

了解更多数美公司介绍?https://www.ishumei.com/aboutUs/introduction.html 
数美团队介绍
https://www.ishumei.com/aboutUs/team.html
数美产品介绍https://www.ishumei.com/product/creditFengkong.html
数美解决方案介绍?https://www.ishumei.com/solution/finance.html"
"职位描述：
        
        岗位职责
参与大数据平台体系建设，持续集成相关工具产品，以及搭建大数据业务统一计算层等相关工作；
参与数据仓库的架构设计和研发，挖掘数据价值，建设与管理百PB级的公共数据平台和服务系统，实现高质量数据的互通与共享；
参与工具/内容/智能数据产品研发，挖掘数据价值，实现数据赋能业务；
用数据提高效率和改变业务运营方式，规划数据技术发展方向，带动团队技术氛围。

岗位要求
1.2019年应届毕业生，本科及以上学历，计算机相关专业；
2.扎实的数据结构和算法能力，熟悉至少一种关系型数据库；3.熟悉一门数据处理语言，如SQL、JAVA、Python、Perl等；
4.善于沟通，主动性好，逻辑思维能力较强，有较强的自我驱动和学习能力；
加分项：
1.有Hadoop、Hive、Hbase、Kylin、Druid等分布式平台实践经验；
2.有数据平台、数据仓库、数据产品研发、数据分析与挖掘等相关项目经验；
3.有多线程、缓存、分布式、全栈开发经验。

了解更多数美公司介绍?https://www.ishumei.com/aboutUs/introduction.html 
数美团队介绍
https://www.ishumei.com/aboutUs/team.html 
数美产品介绍https://www.ishumei.com/product/creditFengkong.html
数美解决方案介绍?https://www.ishumei.com/solution/finance.html"
"职位描述：
        
        岗位职责
参与大数据平台体系建设，持续集成相关工具产品，以及搭建大数据业务统一计算层等相关工作；
参与数据仓库的架构设计和研发，挖掘数据价值，建设与管理百PB级的公共数据平台和服务系统，实现高质量数据的互通与共享；
参与工具/内容/智能数据产品研发，挖掘数据价值，实现数据赋能业务；
用数据提高效率和改变业务运营方式，规划数据技术发展方向，带动团队技术氛围。

岗位要求
1.本科及以上学历，计算机相关专业；
2.扎实的数据结构和算法能力，熟悉至少一种关系型数据库；3.熟悉一门数据处理语言，如SQL、JAVA、Python、Perl等；
4.善于沟通，主动性好，逻辑思维能力较强，有较强的自我驱动和学习能力；
加分项：
1.有Hadoop、Hive、Hbase、Kylin、Druid等分布式平台实践经验；
2.有数据平台、数据仓库、数据产品研发、数据分析与挖掘等相关项目经验；
3.有多线程、缓存、分布式、全栈开发经验。


【关于数美】www.ishumei.com
数美科技是行业领先的全栈式实时反欺诈服务提供商，创建于2015年，总部位于北京，并在杭州、上海、深圳设有研发中心和分支机构。获顺为资本、360、百度、清流资本联合投资。创始团队来自阿里、腾讯、百度、360、小米等知名互联网公司，在人工智能领域有着超过十年的丰富实践经验，拥有上百项相关核心技术专利。并在北京、上海、广州、新加坡、美国、日本等地搭建全球防御网络，构建了全球反欺诈全栈防御体系。
至今，已为互联网、电商、媒体、游戏、教育、直播、文娱、金融、零售等行业1000余家知名企业客户提供全栈式实时反欺诈服务。合作客户如百度、360、小米、58同城、小红书、同程艺龙、脉脉、迅雷、vipkid、中国银联、OPPO、永辉、万达、龙湖地产、光明网、猎豹、Blued、中信银行、51信用卡、趣店、玖富、洋钱罐、微贷网等。
了解更多数美公司介绍?https://www.ishumei.com/aboutUs/introduction.html 
数美团队介绍
https://www.ishumei.com/aboutUs/team.html 
数美产品介绍https://www.ishumei.com/product/creditFengkong.html 
数美解决方案介绍?https://www.ishumei.com/solution/finance.html"
"职位描述：
        
        360、小米、百度等顶级互联网公司联合投资，顶级大数据公司

岗位职责：
1、针对海量用户行为数据，构建用户兴趣属性，金融属性画像，欺诈属性等多维度画像?
2、基于海量画像数据，构建金融风控，互联网反作弊，精准营销，垃圾内容等模型和服务 ?

职位要求：
1、熟悉使用Hadoop，Storm，Spark，HBase等大数据技术平台，有大规模数据日志处理经验者 优先；?
2、熟悉大规模数据挖掘、机器学习、自然语言处理，图像处理等相关技术和算法；?
3、具备金融风控，互联网反作弊，图像和文本处理，精准营销，推荐系统等相关产品工作经验 者优先；?
4、具备较强的数据分析，问题分析，逻辑思维能力，良好的沟通，团队协作能力。?


公司福利待遇：
有竞争力的薪酬
期权奖励
五险一金+商业保险
午餐+晚餐补助
交通+通讯+电脑补贴
结婚+生育+丧葬+住院礼金
伯乐奖金
年假8天起+带薪病假
年度体检、零食畅享、团队建设、生日会、弹性办公
?

数美领先的大数据技术、产品与服务提供商
我们正在经历一个IT到DT的变革时代。大数据已经渗透到各个环节，各个角落。
这个世界，就是掩藏在表象之下，被数据所揭示的世界！
数美依托积累的海量数据、科技前沿技术， 极致的工匠精神和对数据的深度理解，提供领先的大数据产品与服务。?
我们正在寻找不平凡的你，和我们一起“发现数据之美”
欢迎投递简历


【关于数美】www.ishumei.com
数美（全称北京数美时代科技有限公司）成立于2015年6月，是一家专业的大数据科技公司。数美依托先进的核心AI技术和海量的数据基础，致力于解决多场景欺诈问题，为客户提供专业、可信赖的服务。团队均来自百度、阿里、腾讯、360、小米等顶尖互联网公司，在大数据、人工智能、机器学习、金融风控等领域有着丰富的实践经验。目前，业务已覆盖金融、支付、直播、社交、电商、O2O等为代表的多个行业领域，其中包括中信银行、用钱宝、人人贷、51信用卡、360、小米、58同城、爱奇艺、熊猫直播、花椒、唱吧等知名企业，截止到2017年6月，服务客户突破1000家。作为大数据反欺诈专业品牌，数美将持续挖掘数据价值，为金融机构、互联网企业提供智能、创新的一站式反欺诈综合解决方案

…………………………………………………………………………
了解更多
数美公司介绍
https://www.ishumei.com/aboutUs/introduction.html
数美团队介绍
https://www.ishumei.com/aboutUs/team.html
数美产品介绍
https://www.ishumei.com/product/creditFengkong.html
数美解决方案介绍
https://www.ishumei.com/solution/finance.html"
"职位描述：
        
        岗位职责：
1、负责公司数据产品的画像数据仓库表设计、开发、优化；
2、负责元数据管理设计、开发
3、数据处理流程与框架设计与开发
4、数据质量监控设计与开发

任职要求：
1、本科以上，计算机相关专业；2-4年hadoop数据仓库、用户画像建设经验；
2、熟悉hadoop上数据表设计模式、元数据管理、数据处理与监控、数据处理框架开发；
3、有较强的性能优化及问题排查、解决能力；
3、.工作认真、负责、细致，有良好的团队合作精神，良好的分析能力、沟通技巧；

数美领先的大数据技术、产品与服务提供商
我们正在经历一个IT到DT的变革时代。大数据已经渗透到各个环节，各个角落。
这个世界，就是掩藏在表象之下，被数据所揭示的世界！
数美依托积累的海量数据、科技前沿技术， 极致的工匠精神和对数据的深度理解，提供领先的大数据产品与服务。?
我们正在寻找不平凡的你，和我们一起“发现数据之美”
欢迎投递简历


【关于数美】www.ishumei.com
? ? ?数美（全称北京数美时代科技有限公司）成立于2015年6月，是一家专业的大数据科技公司。数美依托先进的核心AI技术和海量的数据基础，致力于解决多场景欺诈问题，为客户提供专业、可信赖的服务。团队均来自百度、阿里、腾讯、360、小米等顶尖互联网公司，在大数据、人工智能、机器学习、金融风控等领域有着丰富的实践经验。目前，业务已覆盖金融、支付、直播、社交、电商、O2O等为代表的多个行业领域，其中包括中信银行、用钱宝、人人贷、51信用卡、360、小米、58同城、爱奇艺、熊猫直播、花椒、唱吧等知名企业，截止到2017年6月，服务客户突破1000家。作为大数据反欺诈专业品牌，数美将持续挖掘数据价值，为金融机构、互联网企业提供智能、创新的一站式反欺诈综合解决方案
…………………………………………………………………………
了解更多
数美公司介绍
https://www.ishumei.com/aboutUs/introduction.html
数美团队介绍
https://www.ishumei.com/aboutUs/team.html
数美产品介绍
https://www.ishumei.com/product/creditFengkong.html
数美解决方案介绍
https://www.ishumei.com/solution/finance.html"
"职位描述：
        
        工作职责:
1.进行大规模集群的数据处理与优化工作；
3.负责数据的收取、ETL与清洗过程工作；
5.负责大规模数据量前提下业务算法优化工作。
任职资格:
1.五年以上全职工作经验，其中三年以上全职大数据开发相关工作；
2.精通 JAVA，熟悉 Python，shell 等；
3.精通 Mapreduce，Hive，Spark，Hbase，Hadoop 大数据组件框架，原理和使用场景；
4.精通批次与流式数据处理调度与程序编写；
5.对大数据仓库和数据模型有比较深的理解
6.有大规模数据量数据处理经验。"
"职位描述：
        
        职位描述： 1.?负责数澜大数据平台的架构设计和研发，建立数据生态服务，解决海量数据面临的挑战； 2.?管理和优化Hadoop、Spark等集群，计算作业的调优，保证集群和平台的高效和稳定； 3.?负责Hadoop、Spark、Flink的功能、性能和扩展，解决并实现业务需求； 4.?负责大数据产品的自动化、离线与实时计算、即席计算、数据质量、数据安全、机器学习等平台的设计和开发； 5.?调研和把握当前的最新技术，将其中的先进技术引入到自己的平台中，改善产品，提升竞争力； ? 职位要求： 1.?精通Java，熟悉Scala、Python语言加分。 2.?熟悉Hadoop、Spark、Flink、Kafka、Presto、Kylin、ES、Hive、CarbonData等三门以上，熟悉原理源码、有二次开发优先。 3.?有数据传输、开发、计算、治理、安全等平台设计和开发经验的优先。 4.?有数据分析、机器学习、数据挖掘经验者优先。 5.?擅于沟通和解决问题，乐于总结分享，有想法，有冲劲，有团队精神和主人翁意识和责任感。 6.?喜欢去看及尝试最新的技术，追求编写优雅的代码，从技术趋势和思路上能影响技术团队。  加分项： 1.在GitHub或其他平台上有过开源项目? 2.有个人技术博客，公开发布过技术文章、论文等"
"职位描述：
        
        职位描述： 1.?负责数澜大数据平台的架构设计和研发，建立数据生态服务，解决海量数据面临的挑战； 2.?管理和优化Hadoop、Spark等集群，计算作业的调优，保证集群和平台的高效和稳定； 3.?负责Hadoop、Spark、Flink的功能、性能和扩展，解决并实现业务需求； 4.?负责大数据产品的自动化、离线与实时计算、即席计算、数据质量、数据安全、机器学习等平台的设计和开发； 5.?调研和把握当前的最新技术，将其中的先进技术引入到自己的平台中，改善产品，提升竞争力； ? 职位要求： 1.?精通Java，熟悉Scala、Python语言加分。 2.?熟悉Hadoop、Spark、Flink、Kafka、Presto、Kylin、ES、Hive、CarbonData等三门以上，熟悉原理源码、有二次开发优先。 3.?有数据传输、开发、计算、治理、安全等平台设计和开发经验的优先。 4.?有数据分析、机器学习、数据挖掘经验者优先。 5.?擅于沟通和解决问题，乐于总结分享，有想法，有冲劲，有团队精神和主人翁意识和责任感。 6.?喜欢去看及尝试最新的技术，追求编写优雅的代码，从技术趋势和思路上能影响技术团队。  加分项： 1.在GitHub或其他平台上有过开源项目? 2.有个人技术博客，公开发布过技术文章、论文等"
"职位描述：
        
        岗位职责：1、 负责数据产品需求分析、数据建模，主导完成相关设计及编码；2、 完善现有数据产品，优化现有产品数据体系；3、 深入理解业务需求，能从数据角度推动业务发展，开发相应数据产品及工具。岗位要求1. 计算机、数据等相关专业本科以上学历，工作2年以上；?2. 熟悉数据仓库和数据集市的框架结构，具备数据仓库与数据集市的架构设计能力；?3. 精通SQL，熟悉Oracle、MySQL等关系型数据库；4. 熟悉HiveSQL/MapReduce/Spark等数据开发技术；5. 有一定的Java/python开发能力，熟悉linux/Shell；6. 在数据统计、机器学习上有一定基础的优先；7. 沟通与交流能力强，业务理解能力强，具有一定的业务建模能力。"
"职位描述：
        
        岗位描述：
1、负责数据体系的规划和实施，研究跟进业界相关技术;?2、深入理解数据业务，分析用户需求，负责业务计算的抽象和优化，能独立完成项目的系统分析、设计，并主导完成详细设计和编码的任务，确保项目的进度和质量；?3、为客户特定计算需求提供解决方案，从用户角度推动业务发展;?4、能够有效地对新人或普通开发工程师进行辅导，帮助其快速成长。
岗位要求：
1、熟悉数据仓库模型设计，具备数据加工处理（ETL）相关经验；?2、至少熟悉一种关系型数据库如Oracle、mysql等，熟练掌握Hive/SQL，熟悉Hadoop/Map-Reduce/MPI分布式计算框架，有海量数据处理经验者优先；?3、Java/C++开发及设计经验优先，具备优秀的编程能力及良好的开发习惯；?4、熟悉机器学习，自然语言处理，数据挖掘相关理论，熟悉各类算法使用场景，有实际大规模算法应用研发经验者优先；?5、有云计算大数据产品应用经验优先;?6、工作认真负责，有快速学习的能力，热爱数据，主动积极，有好奇心；?7、具有良好的沟通、团队协作、计划和创新的能力。"
"职位描述：
        
        岗位描述：
1.基于阿里云Maxcompute 进行报表相关数据开发工作；? ? ? ? ? 2.基于Maxcompute相关 画像数据分析工作；? ? ? ? ? ? ? ? ? ? ? ? ? 3.相关数据分析工作；
任职要求：
1、本科及以上学历，计算机相关专业背景；
2、至少2年以上的数据开发经验；熟悉Linux操作系统；
3、熟悉数据仓库产品，对数据处理、纬度建模、数据分析等有深刻认识和实战经验，如Hadoop/Hive，Storm/Spark，Impala，MPP等的数据应用开发；
4、对大数据、云计算、开源软件、传统数据仓库类产品有一定的深度和广度；
5、有较强的编程能力和编程经验，至少熟悉Java/C++其中一门编程语言，有较强的分布式计算基础和算法工程能力；
6、最好有数据挖掘、机器学习、推荐算法、人工智能、数学建模项目经验；
7、最好熟悉阿里巴巴云计算和大数据产品（如ODPS，ADS、BASE等）并有实践经验；
8、熟悉某一到多个行业应用领域，如税务，社保，财政，公安，教育，金融、医疗和智慧城市等等；
9、良好的沟通协能力，有较强客户需求调研和需求分析能力；
10、良好的文档整理能力；
11、有阿里云技术认证ACP（阿里云专业认证）、ACA（阿里云高级认证）者优先；"
"职位描述：
        
        工作职责:1、参与数仓模型设计及数据治理的开发工作；2、参与数据上云、数据分析、机器学习等数据开发工作；3、数据项目的对外技术支持，参与用户沟通交流需求。
任职资格:1、计算机、通信等相关专业，本科以上；2、至少2年以上数据开发经验；3、熟悉数据仓库体系知识，熟悉维度建模方法，有实战经验；4、有Hadoop/Spark/Storm 数据应用开发经验；5、精通SQL语言，至少熟悉一种脚本者优先，如shell、python；6、熟悉阿里云计算和大数据产品并有一定实践经验优先，如ODPS,RDS,ADS,数加等7、有一定的沟通能力，且有未来从事大数据相关工作的愿景。"
"职位描述：
        
        岗位职责：
1、负责业务系统集成组件设计与开发；
2、负责Spring?cloud微服务设计与开发；
3、按照项目计划，在保证质量的前提下、按时完成开发任务。

岗位要求：
1、计算机相关专业，本科及以上学历，三年以上Java开发经验；
2、熟练使用SQL数据库，如：Oracle、SQL-Server、MySQL；
3、强烈的技术热情，自学能力强，能迅速掌握新知识.新技术，能在高强度的压力下工作；
4、具备良好的问题定位分析能力、独立解决问题的能力；
5、强烈的责任心和团队精神，善于合作，具备良好的沟通和表达能力；
6、了解EIP集成模式，熟悉Spring cloud、karaf、apache camel，有ERP、SASS等系统集成开发经验者优先。"
"职位描述：
        
        岗位职责：
1、参与电子政务大数据工具箱的应用平台架构设计、开发、优化及运营工作；
2、使用最优秀的架构设计及算法，实现在网络接入、业务运行逻辑、用户数据存储、业务数据挖掘等领域的工作。
任职要求：
1、编程基本功扎实，掌握C/C++/JAVA等其中任意一种开发语言以及常用算法和数据结构；
2、熟悉TCP/UDP网络协议及相关编程、进程间通讯编程；
3、了解Python、Shell、Perl等脚本语言；
4、了解MYSQL及SQL语言、编程，了解NoSQL, key-value存储原理；
5、具备全面、扎实的软件知识结构，掌握操作系统、软件工程、设计模式、数据结构、数据库系统、网络安全等专业知识；
6、了解分布式系统设计与开发、负载均衡技术，系统容灾设计，高可用系统等知识；
7、了解常见开源组件的使用者优先。"
"职位描述：
        
        职责描述：1、负责各个业务指标体系建设；?2、负责业务需求分析和客户沟通；?3、负责数据分析应用平台的建设和应用；?4、负责数据分析专题的建设，通过数据分析为用户提供辅助决策。任职要求：1、计算机科学、信息科学、机器学习、统计学、应用数学等领域专业；?2、3年以上数据相关岗位的工作经验；?3、良好的逻辑思维能力，敏锐的数据洞察力，较强的总结归纳能力,对数据分析统计热爱，善于从数据中发现规律；?4、熟练使用SQL/Hive语句；?5、至少熟悉一门脚本如python、shell；?6、有Hadoop、Spark等平台的海量数据处理经验优先；?7、有国内外互联网公司或其他行业的数据驱动经验优先。"
"职位描述：
        
        岗位描述：1. 参与数坤数据资产平台研发，负责后端相关业务逻辑设计、实现；2. 与算法工程师合作，打造支持算法快速研发的数据平台后端产品；
岗位要求：1. 计算机相关专业重点本科，具有扎实的计算机基础，2年以上研发工作经验；2. 至少精通一门服务器端编程语言，Python或Java优先；3. 熟悉常用的关系数据库查询操作，并掌握至少一种ORM相关框架；4. 熟悉data in， model out流程及细节；5. 熟悉医学影像相关开发，数字图像处理，数字图像存储优先；6. 熟悉linux/git/gitlab/jenkins等开发相关开发工具者优先；7. 熟悉docker，虚拟化，GPU调度及使用、存储技术者优先"
"职位描述：
        
        职责描述：
1. 参与公司数据平台研发，负责后端相关业务逻辑设计、实现；
2. 与算法工程师合作，打造支持算法快速研发的数据平台后端产品；

任职要求：
1. 计算机相关专业重点本科，具有扎实的计算机基础，2年以上研发工作经验；
2. 精通Java优先；
3. 熟悉常用的关系数据库查询操作，并掌握至少一种ORM相关框架；
4. 熟悉data in， model out流程及细节；
5. 熟悉医学影像相关开发，数字图像处理，数字图像存储优先；
6. 熟悉linux/git/gitlab/jenkins等开发相关开发工具者优先；
7. 熟悉docker，虚拟化，GPU调度及使用、存储技术者优先；
8.有数据平台搭建经验优先。"
"职位描述：
        
        工作职责：
1. 参与大数据平台产品的架构和规划，用户基础数据及用户画像的体系建设；
2. 负责大数据平台和基础产品的开发和维护，
3. 建设日均增量100T数据基础平台建设；
4. 基于用户行为数据，构建高性能，低延迟的处理流程；
5. 业务数据仓库架构设计、建模和ETL开发，构建可扩展的数据仓库和分析解决方案；

岗位要求：
1. 3年以上的大型数据仓库/数据调度/数据报表分析平台建设经验；
2. 精通Java/Scala，C++，Python等开发语言至少一个以上，具备良好的面向对象和函数编程思想，了解常用设计模式；
3. 熟悉Hadoop、Flume、Spark、Hbase、Lucene、ES、MR等数据组件，有源代码阅读和剖析经验，Contributor或者Committer优先；
4. 熟悉Mysql/Postgresql，有复杂sql优化经验;
5. 熟悉分布式系统的基础理论, 有高并发系统的架构设计、开发和调试经验
6. 熟悉数据可视化的基本方法，有数据可视化的开发经验优先；
7. 良好的学习和沟通能力，责任心强，强烈的技术敏锐度，良备的逻辑分析能力，独立解决问题"
"职位描述：
        
        工作职责:
在客户业务场景下验证产品的功能与性能。在客户现场搭建大数据产品平台，与客户沟通，根据客户的需求或业务场景在大数据平台上实现；
大数据平台软件的项目实施与安装部署。
职位要求：
计算机或相关专业本科及以上学历，三年以上工作经验；
熟悉Linux shell以及SQL 语言；
熟悉Java语言，会编写Oracle/DB2 存储过程；
了解Hadoop，HBase，Hive基本命令；
有Hadoop/HBase/Hive/Sqoop/Flume使用经验者优先；
工作积极主动，良好的沟通、协调能力和分析、解决问题的能力，能够接受出差。"
"职位描述：
        
        工作职责:
在客户业务场景下验证产品的功能与性能。在客户现场搭建大数据产品平台，与客户沟通，根据客户的需求或业务场景在大数据平台上实现；
大数据平台软件的项目实施与安装部署。
职位要求：
计算机或相关专业本科及以上学历，三年以上工作经验；
熟悉Linux shell以及SQL 语言；
熟悉Java语言，会编写Oracle/DB2 存储过程；
了解Hadoop，HBase，Hive基本命令；
有Hadoop/HBase/Hive/Sqoop/Flume使用经验者优先；
工作积极主动，良好的沟通、协调能力和分析、解决问题的能力，能够接受出差。"
"职位描述：
        
        职位诱惑：
行业前景广,客户稳定,早期有期权
? ?
职位描述：
工作职责:
在客户业务场景下验证产品的功能与性能。在客户现场搭建大数据产品平台，与客户沟通，根据客户的需求或业务场景在大数据平台上实现；
大数据平台软件的项目实施与安装部署。
职位要求：
计算机或相关专业本科及以上学历，三年以上工作经验；
熟悉Linux shell以及SQL 语言；
熟悉Java语言，会编写Oracle/DB2 存储过程；
了解Hadoop，HBase，Hive基本命令；
有Hadoop/HBase/Hive/Sqoop/Flume使用经验者优先；
工作积极主动，良好的沟通、协调能力和分析、解决问题的能力，能够接受出差"
"职位描述：
        
        职位诱惑：
行业前景广,客户稳定,早期有期权
? ?
职位描述：
工作职责:
在客户业务场景下验证产品的功能与性能。在客户现场搭建大数据产品平台，与客户沟通，根据客户的需求或业务场景在大数据平台上实现；
大数据平台软件的项目实施与安装部署。
职位要求：
计算机或相关专业本科及以上学历，三年以上工作经验；
熟悉Linux shell以及SQL 语言；
熟悉Java语言，会编写Oracle/DB2 存储过程；
了解Hadoop，HBase，Hive基本命令；
有Hadoop/HBase/Hive/Sqoop/Flume使用经验者优先；
工作积极主动，良好的沟通、协调能力和分析、解决问题的能力，能够接受出差"
"职位描述：
        
        岗位描述：
1、作为项目成员独立完成基于大数据或BI项目的部分实施开发工作
2、使用Greenplum SQL、Hive/SparkSQL/Impala 进行数据分析与开发工作
3、直接与客户沟通，能理解客户真实需求，并需要时给客户在技术/数据挖掘提供相关培训
4、整理优化开发流程，遵循开发规范，改进开发流程并提升工作效率
5、整理优化项目流程，能发现项目实施流程中的痛点并给出优化建议，编写技术文档及项目相关文档
职位要求：
1、本科以上学历：计算机、信息技术等，2-5年数据分析或编程工作经验
2、有强烈的的责任感和敬业精神，良好的沟通能力以及团队合作能力
3、熟悉Linux操作系统，精通SQL语法，熟悉存储过程、函数等，能编写复杂SQL(有Hive/SparkSQL/Impala经验者优先)
4、熟悉Python或Java编程语言，需要有相关项目经验
5、熟悉Greenplum、Hadoop、Spark等分布式技术，有相关项目经验者优先
6、有相关电商、零售行业项目经验者优先
7、对数据挖掘/机器学习/自然语言处理感兴趣者优先"
"职位描述：
        
        职位描述：
1、使用Greenplum SQL、Hive/SparkSQL/Impala 进行数据分析与开发工作
2、协同开发、产品经理、运营完成各类业务数据开发
3、整理优化数据开发流程，遵循开发规范，改进开发流程并提升工作效率
4、整理优化数据流程，能发现数据开发流程中的问题并给出优化建议，编写技术文档及项目相关文档
5、对各类数据处理流程进行性能优化
职位要求：
1、本科以上学历：计算机、信息技术等，6-8年数据分析或编程工作经验
2、有强烈的的责任感和敬业精神，良好的沟通能力以及团队合作能力
3、精通Linux操作系统，精通SQL语法，熟悉存储过程、函数等，能编写复杂SQL，对于SQL性能优化有较高的认识
4、熟悉Python或Java编程语言、熟悉Hive/SparkSQL/Impala的应用
5、熟悉Greenplum、Hadoop、Spark等分布式技术，有相关项目经验者优先
6、有相关电商、零售行业项目经验者优先
7、对数据挖掘/机器学习/自然语言处理感兴趣者优先"
"职位描述：
        
        1．参与公司数据应用平台技术开发工作，良好支撑线上业务,如流计算平台应用开发（如Flink和spark streaming）、数据同步程序,数据标准化等；
2．优化大规模海量数据查询请求的执行与计算，降低数据的查询成本，提升数据查询的响应效率；
3．灵活运用和实现类似搜索、推荐、优化等技术，完成数据模型构建、数据采集、整理及特征抽取，模型部署和系统维护。
4．系统核心部分代码编写、并能够进行系统优化；
5．打造有行业竞争力的系统，能够支撑快速发展的数据业务。
以下能力项符合1~6或精通其中3项及以上及可,第7项为必备素质
1．有从事分布式数据存储与计算平台应用开发经验，非常熟悉Hadoop生态相关技术并有相关应用开发经验；
2．熟悉Java、Scala技术基础功底扎实，有深入Spark平台下或Flink应用开发，并能够进行系统调优。
3．有OLAPOLTP数据引擎建设及开发经验，熟悉ElasticSearch、TiDB及其他熟悉查询分析技术，并有深入应用调优经验；
4．熟练掌握数据仓库设计，开发工作。能够根据业务设计并开发数据仓。熟悉MySQL处理机制与应用场景限制，熟悉NoSQL如Redis、HBase，TiDB等。
5．对Spark分布式计算的底层原理有深度理解，对复杂系统的性能优化和稳定性提升有一线实战经验，有多年实际开发和应用经验，对开源社区有贡献者尤佳；
6．熟悉数据采集、大数据ETL处理过程，有深入实践开发及优化经验并获得良好生产应用结果。
7．有快速和持续学习的能力，动手能力强，有进取心、责任心强；
8．团队合作意识强，具备良好的沟通协调能力"
"职位描述：
        
        职位描述：
1.负责离线计算平台的开发和维护工作；
2.负责HBase/TiDB的开发与维护工作；
3.负责Spark、Flink开发维护工作；
4.参与数据平台的设计开发，满足业务方对于实时数据的需求。
5.深入理解数据业务，分析用户需求，能够从用户角度推动业务发展，提升公司数据应用能力。
?
资格要求：
1.5年以上数据分析领域开发经验，熟悉Java、Scala/Go的一种；
2.对数据库系统或分布式系统的原理和架构有较好的了解；
3.优秀学习能力、发现和解决问题能力，良好的沟通能力和团队意识。
加分项：
1.熟悉Hadoop生态，参加过开源项目；
2.熟悉Hive、Spark、HDFS、HBase、TiDB、Kafka中至少两种产品的实现细节,并应用开发；
3.有数据库/数据治理产品的开发和运维经验。
4.以上技术栈能够很深入应用或精通某一种也可以，如精通Flink或精通Spark之一即可；"
"职位描述：
        
        职位描述：
1、使用Greenplum SQL、Hive/SparkSQL/Impala 进行数据分析与开发工作
2、协同开发、产品经理、运营完成各类业务数据开发
3、整理优化数据开发流程，遵循开发规范，改进开发流程并提升工作效率
4、整理优化数据流程，能发现数据开发流程中的问题并给出优化建议，编写技术文档及项目相关文档
职位要求：
1、本科以上学历：计算机、信息技术等，2-5年数据分析或编程工作经验
2、有强烈的的责任感和敬业精神，良好的沟通能力以及团队合作能力
3、熟悉Linux操作系统，精通SQL语法，熟悉存储过程、函数等，能编写复杂SQL(有Hive/SparkSQL/Impala经验者优先)
4、熟悉Python或Java编程语言
5、熟悉Greenplum、Hadoop、Spark等分布式技术，有相关项目经验者优先
6、有相关电商、零售行业项目经验者优先
7、对数据挖掘/机器学习/自然语言处理感兴趣者优先"
"职位描述：
        
        职位描述：
1、使用Greenplum SQL、Hive/SparkSQL/Impala 进行数据分析与开发工作
2、协同开发、产品经理、运营完成各类业务数据开发
3、整理相关开发技术文档
职位要求：
1、本科以上学历：计算机、信息技术等，1-3年数据分析或编程工作经验
2、有强烈的的责任感和敬业精神，良好的沟通能力以及团队合作能力
3、熟悉Linux操作系统，SQL语法，熟悉存储过程、函数等，能编写复杂SQL(有Hive/SparkSQL/Impala经验者优先)
4、熟悉Greenplum、Hadoop、Spark等分布式技术，有相关项目经验者优先
5、有相关电商、零售行业项目经验者优先"
"职位描述：
        
        岗位职责:参与大数据平台开发，偏重数据统计分析；业务数据分析建模，良好支撑业务发展需求及快速响应需求变更；基于业务需求将产品设计有效的转化为数据模型，具备一定数据规划能力。岗位要求：1、 3年以上大数据分析和开发经验；2、 熟练使用Java、Python，深度熟练使用SQL或类SQL结构化语言（如sparksql 、hivesql等）进行数据统计分析，熟悉R语言尤佳；3、 至少熟悉下述一个或者多个领域：元数据管理、数据质量、业务数据建模、流式数据采集、多维数据分析引擎等；4、 熟悉Hadoop／Yarn等大数据生态框架有实时数据处理经（Storm／Spark）者优先；5、优秀的分析和解决问题的能力，自我驱动，具有良好的沟通和团队合作精神； 6、计算机或数学专业尤佳，数据分析专项能力尤为突出者其他综合项可降低要求"
"职位描述：
        
        岗位描述：
1. 负责统一实时计算平台的设计、开发；
2. 负责统一计算模型的设计、开发。

岗位要求：
1、三年以上Java开发及设计经验，优秀的编程能力及良好的开发习惯，能够快速的阅读开源项目源代码，具备独立沟通需求，设计，架构，开发、重构的能力；?
2、至少精通一门以上的大数据处理引擎。如：Storm、Spark、Flink、Hadoop等，熟悉核心部分代码；?
3、熟悉分布式系统；熟悉消息中间件、搜索、远程调用等核心技术；有大型分布式、高并发、高负载、高性能、高可用性系统设计开发经验者优先；?
4、熟悉Dataflow模型、 熟读 Millwheel、Streamscope 等论文，有丰富的大数据里理论知识者优先考虑；
5、熟悉各种资源调度系统 Yarn、Mesos、K8s，或者在开源社群活跃并有积极贡献者优先；?
6、熟悉Scala、OOA/OOD和领域建模，数学和统计学，熟悉分布式分析引擎优先考虑；
7、希望你有孜孜不倦的态度，谱写高质量的代码；精益求精的精神，追求高性能的程序。"
"职位描述：
        
        岗位职责：1、负责基于confluent kafka和hadoop平台的大数据研发工作。2、了解基于hive的数据仓库设计,负责公司的数据仓库建设。3、参与公司报表和实时统计相关工作。岗位要求1、计算机相关专业（如统计学、数学）本科以上学历，2年以上大数据处理相关工作经验；2、熟悉 RDBMS（MySQL、PostgreSQL）、NoSQL（MongoDB、Redis）等主流数据库；3、精通Java编程（熟悉python更佳）；4、熟悉kafka（熟悉kafka connect和confluent kafka更佳）；5、精通大数据处理技术，有Hadoop、Hive、Hbase等相关开发经验优先(熟悉Storm、flink等流处理框架更佳)；6、熟悉linux常用操作和shell；7、工作认真负责，具有良好学习能力和解决问题的能力；8、熟悉阿里云相关环境或者有简单的大数据运维经验更佳。"
"职位描述：
        
        工作职责：
1、配合完成产品、财务、客服等业务部门的取数需求；
2、日常数据监控以及数据流程预警，异常数据解读，并找出解决方案；
3、参与数据产品的迭代工作，并且在一定程度上给予评估和建议；
4、分析用户的特征和行为数据，挖掘不同类型用户的行为特性，为产品设计和用户运营提供数据支持；
任职资格:
1、理工科专业本科或以上学历；数学、统计、计算机软件、运筹学、经济学、管理信息系统等专业优先；
2、1-2年以上数据分析经验（知名互联网公司相关经验优先考虑），结构化思维，对数据极其敏感，自我驱动，能通过数据主动发现问题并解决问题；
3、熟练使用SQL语言，能够利用SQL实现复杂报表；
4、积极主动、善于沟通，能够快速理解业务需求；
5、加分项为：掌握shell脚本，对用户画像和个性化推荐有自己的看法。"
"职位描述：
        
        1、BI平台建设与维护；2、报表输出3、智能化报表与数据可视化开发4、数据分析集市需求分析与架构设计职位要求：
1、2年以上BI开发经验, 熟悉至少一种前端BI工具, 如Microstrategy, Cognos, Business Objects, 有开源框架产品平台设计部署和开发经验；2、熟悉至少一种数据库, Nosql, 有Hadoop/Spark平台经验更佳；3、熟悉Unix/Linux环境；4、良好的沟通能力和学习业务能力, 能够为业务部门用户组织和提供培训, 使用BI方法回答和解决业务问题；?
5、统招本科学历及以上，985、211学历优先。"
"职位描述：
        
        工作职责：
1. 基于Flink（Blink）开发携程的实时SQL分析平台2. 负责Flink（Blink）的二次开发和运维工作（主要）3. 负责携程大数据实时数据处理平台开发，管理，推广工作
任职资格：
1. 良好的Java编程能力，熟悉Java开发工具和调试工具2. 熟悉Flink / Blink的原理，API，有实际项目的使用经验3. 熟悉linux系统，熟练使用shell/python完成相关的自动化运维工作4. 有钻研精神，能够沉得下心来研究某一个领域的技术5. 有严密的逻辑思维，有追求卓越的精神6. 有良好的沟通和团队合作的能力额外加分项：1. 对Flink / Blink源代码有研究2. 熟悉Kafka, Pulsar等开源的消息队列系统3. 熟悉Storm，JStorm，Spark-Streaming等开源实时分析系统4. 熟悉Hadoop，Spark，Presto等大数据系统（不限于前面提到的）原理，设计和实现"
"职位描述：
        
        工作职责：
1. 通过机器学习 / 深度学习的方法改良 携程异常检测平台的核心算法2. 通过数据分析，机器学习 / 深度学习的方法改进 携程自动扩缩容系统的核心算法3. 通过数据分析，机器学习 / 深度学习的方法指导 携程的容量规划4. 通过数据和AI技术帮助携程运维和开发人员提升效率
任职资格：
1. 掌握基本的统计学和数据分析的相关知识，有实战经验2. 熟悉机器学习 / 深度学习，有多个实际项目的使用经验3. 能够熟练使用Python （Numpy / Pandas / scikit-learn等）或 R?4. 能够熟练使用SQL5. 具有出色的分析问题的能力和优秀的逻辑思维能力6. 有良好的沟通和团队合作的能力额外加分项：1. 数学，统计学专业硕士及以上学历2. 拥有机器学习 / 深度学习两年或以上的实战经验3. 熟悉Tensorflow / Caffee / PyTorch / Keras等深度学习框架的使用和调优4. 熟悉SparkML, GraphX等分布式的工具"
"职位描述：
        
        项目介绍
商业数据平台实现对搜狗商业数据的全链路、全渠道的统一采集和集中管理，并在此基础上通过产品和技术上的创新，充分发掘数据的商业价值，通过数据产品输出为中小客户、客服和代理商进行数据赋能，提升渠道、运营和销售的工作效率，促进客户营销能力和消耗的增长。
工作职责
1、基于海量数据，支持业务对数据的分析和使用
2、大数据平台的设计与开发
3、数据底层基础设施的规划和建设
任职资格

1、熟悉数据仓库建模理论，5年以上相关领域实践经验；
2、熟悉Hadoop、Hive、Spark等大数据技术；
3、熟练使用Python/Shell或其他语言进行复杂业务逻辑的数据处理工作，具备海量数据处理以及性能优化的能力；
4、具备逻辑思维能力，善于分析、解决问题；
5、良好的沟通协作能力，具备优秀执行力，有一定的全局观，较为丰富的管理经验

搜狗欢迎专情的你，所以提醒你只能选择两个项目，请慎重投递。"
"职位描述：
        
        【岗位职责】??
1、搜索推广、商品推广、输入流推广等多个在线广告平台数据服务系统开发，实时数据流处理系统开发，以及分布式数据计算存储的开发等。??
2、广告离线大数据分析与处理，对每天百亿广告数据提供多维olap秒级分析能力
??
【任职要求】??
1、熟练掌握Java开发，具备扎实的程序设计基本功和学习能力??
2、熟练使用Hadoop/Hbase/Spark/Kylin/Hive等大数据开发工具，对源代码有一定研究者优先；??
3、熟练掌握Shell、Python等任一脚本语言，有大数据实时计算开发经验优先；??
4、掌握数据分析的基本流程，擅长数据采集、清洗、分析等环节，具有较强的业务理解能力"
"职位描述：
        
        职位名称
大数据平台-大数据开发工程师

职位概述
依托大数据，深挖数据价值，通过精准营销的方式来帮助客户直达用户，提高市场占有率。

职位描述：
1. 负责大数据中心各平台（大数据平台、实时计算平台、指数平台等）的开发、优化、及维护。
2. 参与基础数据体系的设计和开发工作。
????????????????????????????????
职位要求：??????????????
1. 计算机或相关专业本科以上学历，三年以上工作经验，热爱技术肯专研；
2. 熟悉C++或JAVA
3. 熟悉Mysql、Memcached、Redis等的应用。
4. 掌握Shell、Python、PHP等任一脚本语言。??
5.?有Hadoop、Storm、Spark、Hive、Kafka、Flume、HBase等大数据生态相关工作经验者优先。
6.??熟悉数据仓库开发者优先。
7. 有分布式数据库开发、重度使用经验者优先。
8. 有独立负责开发项目经验者优先，有互联网行业工作经验者优先。"
"职位描述：
        
        搜狗广告检索端采用业内先进的架构设计，最前沿的技术，结合互联网营销模式，研发在线广告实时检索引擎。
我们的系统是建立在大规模分布式架构统之上，运行于由成千上万节点组成的集群上，每秒钟都要处理海量的请求。在这里，你有机会与业界一流的技术团队一起工作，参与并见证搜狗搜索广告的快速发展，分享公司高速成长所带来的职业发展机会。
【职位诱惑】技术卓越，成长迅速，平台实力强大。

岗位说明：
1. 负责数据工程建设，充分学习大数据技术及架构方案，建设数据服务一体化工程。
2. 负责业务数据开发，解决业务相关数据问题。

任职要求：
1. 计算机相关专业，良好的算法和数据结构基础。
2. 至少熟练掌握一种语言（C/C++/Python/Java 等）。
3. 了解大数据相关处理技术，了解hadoop、spark、mysql等基础和应用。
4. 对数据工程、数据挖掘有热情。"
"职位描述：
        
        职位描述：? ? ? ? ? ? ? ??
* 支持广告业务的数据需求，完善业务的数据分析体系和工具? ?
* 参与ETL、数据应用和服务的设计开发? ?
任职要求：? ?
* 计算机、软件工程等相关专业在读? ?
* 保证连续实习3个月及以上，每周出勤4天及以上? ?
* 熟练使用Java、Python等至少一门开发语言? ?
* 接触过大数据相关技术，有相关实习经历者优先考虑"
"职位描述：
        
        工作&项目描述：?
参与搜狐视频的推荐效果研发。项目组主要任务是为app端提供个性化推荐数据，具体包括候选集生成，用户画像，视频画像等等数据方面工作，算法和策略同时存在，也会伴有服务端开发等工作。
??
职位要求：?
1、具备强悍的JAVA编码能力，再多一些scala更好
2、有spark，hadoop大数据框架的项目经验，熟悉redis和linux
3、最最重要的trouble-shooting能力要强，适合喜欢挑战难题的你
4、重点本科计算机相关专业优先，2年以上大数据或者数据业务相关经验"
"职位描述：
        
        工作职责：
1、负责数据计算平台的架构设计，提升计算效率、提高数据平台的可用性
2、实时计算平台、离线计算平台的维护，解决日常的问题
3、实时跟进社区最新技术，并能应用到实际生产中

岗位要求:
1、熟练掌握java、shell、scala语言
2、阅读过hadoop 核心代码，比如yarn调度部分、hdfs读写部分等
3、对提升用户体验、平台稳定性、设计数据平台产品有一定的经验和独特见解
4、对开源分布式项目有较高热情，并能自主学习社区新框架、新技术，并应用到生产中"
"职位描述：
        
        职位描述
1.负责数据采集、清洗、存储程序以及实时数据计算的开发；?2.支持业务处理数据的流式处理、构建数据仓库、算法模型上线部署等；?3.分析优化现有内容分类模型，数据架构改进，为业务提供支持；?4.大数据相关技术难题的攻关、技术发展方向的预研。
任职要求
1.统招本科及以上学历，2年以上大数据开发经验；?2.熟练掌握大数据处理技术栈，有丰富的 Hadoop/Spark/Streaming/flume/hive/kafka的实际项目使用经验；?3.熟练掌握HDFS/HBase/Hive等分布式大数据存储技术；?4.熟练掌握Java, Python，R语言；有大型项目开发经验优先；?5.精通SQL，熟练使用MySql等关系型数据库；?6.熟悉常用的开源组件：Hadoop/Hive/Spark/Storm，并了解其特性和使用场景；?7.熟悉Linux开发环境，熟悉多线程编程;?8.有良好的沟通能力和责任感，能够承担工作压力，独立分析和解决问题者优先。"
"职位描述：
        
        岗位职责:1.广告数据采集和仓库架构设计，开发和维护； 2.广告流式计算平台和分布式数据平台的开发和维护； 3.参与反作弊系统设计与开发，建立反作弊体系；4.广告数据分析工具的搭建和维护；5.第三方广告数据的分析与合作。
任职资格:1.熟悉数据仓库模型设计方法论，并有实际模型设计及ETL开发经验 ；2.熟悉Hadoop,Hive,Spark具备MapReduce,Hivesql性能调优经验更佳3.熟悉常用的数据挖掘、分析的工具和方法，有数据挖掘工作经验更佳；4.具备快速学习能力、沟通协调能力及团队精神，有较强的责任心和学习积极性；5.统招本科及以上学历，计算机或相关专业。"
"职位描述：
        
        工作职责：
1.负责参与构建高性能、高可用、易扩展的大数据平台；
2.深入理解业务，围绕数据分析搭建完善的数据服务，驱动业务发展。
任职资格：
1、熟练掌握Java开发，具备扎实的程序设计基本功和学习能力 ；
2、熟练使用Hadoop/Hbase/Spark/Storm/Hive等大数据开发工具，对源代码有一定研究者优先；
3、熟练掌握Shell、Python等任一脚本语言，有大数据实时计算开发经验优先；??
4、掌握数据分析的基本流程，擅长数据采集、清洗、分析等环节，具有较强的业务理解能力 ；
5、熟悉系统性能分析与优化；
6、可以快速理解和适应相关业务，有良好的数据敏感度和自驱力，对工作充满激情。"
"职位描述：
        
        职位描述
1、负责大数据平台（基于Hadoop/HDFS）和BI平台的搭建；2、负责大数据平台数据清洗、转换、建模的开发工作；3、负责开源大数据平台与产品和相关技术的追踪及研究；4、负责制定数据建模、数据处理、数据运维和数据安全等架构规范并落地实施；5、设计并实现数据仓库、数据挖掘、BI等数据系统建设、开发；

任职要求
1、大学本科或以上学历，2年以上工作经验，其中hadoop相关数据分析项目设计与开发经验至少1年以上；2、了解Hadoop2.0以上版本体系架构、各个模块功能，了解Hadoop生态圈。了解大数据的基本处理思路和常用算法，技术基础扎实；3、了解HDFS、MR、YARN、SPARK、Storm、sqoop、Zookeeper等开源项目，从事过分布式相关系统的设计、开发、调优工作；4、熟悉Linux，熟练掌握shell、java、python等编程能力；熟悉掌握MYSQL；5、熟悉大数据挖掘、可视化分析，各种BI算法和产品等有较强的分析问题、解决问题的能力，对新技术和业务的领悟力强。"
"职位描述：
        
        岗位职责：?
1、负责探探数据仓库的架构设计,?开发和实施；
2、负责数据ETL流程的建设，优化以及解决ETL相关技术问题；
3、负责机器学习流水线的架构设计,?开发和实施；
4、负责数据任务调度系统、数据监控系统的设计，开发和实施；
5、负责数据schema管理系统的设计，开发和实施。

任职要求：
1、本科及以上学历，计算机相关专业;两年以上互联网行业大数据相关工作经验；
2、了解并行和分布式计算的基本原理；熟练掌握Hadoop,hdfs, hive, Spark,Storm,flink，cassandra, hbase、ElasticSearch等常用的大数据系统或式计算框架；熟悉MySQL, postgres, MongoDB等数据库；
3、具备优秀的数据敏感性；
4、优秀的分析问题和解决问题的能力，勇于解决难题；强烈的上进心和求知欲，较强的沟通表达能力与协作推进能力；?
5、热爱互联网，对互联网产品和技术有浓厚的兴趣，热衷于追求技术极致与创新；
6、有开源社区贡献经验的开发者优先考虑。"
"职位描述：
        
        岗位职责：?
1、负责探探数据仓库的架构设计,?开发和实施；
2、负责数据ETL流程的建设，优化以及解决ETL相关技术问题；
3、负责机器学习流水线的架构设计,?开发和实施；
4、负责数据任务调度系统、数据监控系统的设计，开发和实施；
5、负责数据schema管理系统的设计，开发和实施。

任职要求：
1、本科及以上学历，计算机相关专业;两年以上互联网行业大数据相关工作经验；
2、了解并行和分布式计算的基本原理；熟练掌握Hadoop,hdfs, hive, Spark,Storm,flink，cassandra, hbase、ElasticSearch等常用的大数据系统或式计算框架；熟悉MySQL, postgres, MongoDB等数据库；
3、具备优秀的数据敏感性；
4、优秀的分析问题和解决问题的能力，勇于解决难题；强烈的上进心和求知欲，较强的沟通表达能力与协作推进能力；?
5、热爱互联网，对互联网产品和技术有浓厚的兴趣，热衷于追求技术极致与创新；
6、有开源社区贡献经验的开发者优先考虑。"
"职位描述：
        
        工作职责：
1.负责业务相关数据指标的计算挖掘，掌阅B端产品的数据研发；
2.负责建立精细化运营的标签体系，建立精细化运营平台DMP；
3.负责数据建模以及数据仓库应用产品的设计和开发；
4.负责数据仓库ETL及解决ETL相关技术问题；
5.负责建立用户画像及用户分层的数据；
6.参与项目规划，项目架构设计，数据仓库开发，模型开发，报表开发等。
任职资格：
1.精通Java语言
2.熟悉并行计算或者分布式计算，熟悉Spark，Flink等计算平台；熟悉日志上下游环境，包括Flume，kafka等；
3.对于Redis，hbase，mysql等不同类型存储系统有深入了解；
4.熟悉Hadoop、Hive原理，并对coding保持强烈兴趣；
5.良好的业务理解能力和逻辑思维能力，能够从海量数据中发现关键特征，出色的问题分析及解决能力。"
"职位描述：
        
        职位描述：
1.负责掌阅推荐系统的服务设计和开发，以实现书籍推荐的智能化、高效化、个性化，千人千面；
2.负责数据架构设计；
3.大规模推荐系统及机器学习相关系统设计与实现；
4.设计和实现高可用、可扩展、高性能的存储与计算系统。
任职要求：
1.计算机、信息管理本科以上学历。
2.3年以上搜索引擎、推荐系统、电商系统实际项目开发经验；
3.精通Java语言；
4.熟悉搜索引擎中的常用算法，具备Query分析/自然语言处理/排序优化/数据挖掘/机器学习等其中至少一种项目经历或研究背景者优先；
5.熟悉并行计算或者分布式计算，熟悉Spark，Flink等计算平台；熟悉日志上下游环境，包括Flume，kafka等；
6.对于Redis，hbase，mysql等不同类型存储系统有深入了解；
7.良好的业务理解能力和逻辑思维能力，能够从海量数据中发现关键特征，出色的问题分析及解决能力。"
"职位描述：
        
        岗位职责：
1、负责神州鹰各个业务线的数据仓库的理解，设计并实现；
2、业务的数据模型设计，参与团队数据模型优化；
3、完成数据模型的ETL实施，参与团队ETL流程的优化以及相关技术问题的解决；
4、满足业务方的数据需求，提供面向业务的OLAP、报表、数据提取等数据服务；
5、参与数据产品的设计和开发，助力业务增长。
任职要求：
1、计算机相关专业本科及以上学历；
2、有日志采集、海量数据处理、数据仓库建模、ETL等开发经验；
3、精通hive/mysql,有一定的hql/sql性能调优经验，熟悉Hadoop/MapReduce/spark等大数据处理技术；
4、认同数据驱动业务的理念，重视数据质量与数据开发效率；
5、有较好的逻辑思维能力，较强的抽象、概括、总结能力；
6、熟悉java、python等数据分析语言；
7、熟悉BI系统，有OLAP 项目开发经验优先。"
"职位描述：
        
        1. 负责广告平台大数据基础设施的开发和维护工作，包括但不限于实时报表数据流，MPP数据仓库，Aerospike, ScyllaDB, Kafka, PostgreSQL 等基础设施。2. 负责广告平台日常需求的开发，为运营和商务团队提供技术支撑。3. 负责某些前瞻技术的调研和PoC工作。4. 日常基本使用 Scala 及其 JVM 生态进行开发。任职要求:1. 大专或以上学历，计算机或理工科背景。2. Linux 系统以及 git 基本使用熟练。3. 英语基本功扎实，至少能无障碍阅读计算机英文文档。4. 会 Scala 者极大加分，但不是必须条件。5. 必须能在 60 分钟能做出至少 2 道现场代码笔试题（我们负责提供笔记本电脑）。"
"职位描述：
        
        岗位职责：
1.负责数据平台的设计、开发、维护、优化，满足公司各级部门的数据分析需求；
2.研究与跟踪数据技术发展方向，参与数据平台架构的设计。
3.负责数据报表平台，数据接入平台、数据分析平台以及数据管理平台等开发维护工作；
4.负责概要设计、详细设计，并负责完成核心代码，技术攻坚；
5.根据开发规范与流程独立完成模块的设计、编码、测试以及相关文档；

任职要求：
1.精通Java开发语言，掌握Spring?MVC、myBatis等流行框架；
2.深入理解JAVA面向对象程序设计原则,理解设计模式；
3.对java常用包有深入的认知，了解JVM内存机制；
4.熟练使用mysql关系型数据库，能进行基本的sql优化，了解分布式存储引擎、索引、大量数据分区分表等技术优先；
5.熟悉常用的缓存技术，如memcache，redis等；
6.至少熟悉以下一种大数据技术组件，Hive、Impala、HBase、Flume、Kafka、Zookeeper、Spark。
7.参与过大型数据平台产品、OLAP系统开发者优先；参与过分布式任务调度或管理系统啊开发者优先。
8.有较强的团队协作精神，独立工作能力、沟通及表达能力强，工作责任心强，能够承受压力。"
"职位描述：
        
        岗位职责：
1.负责数据平台的设计、开发、维护、优化，满足公司各级部门的数据分析需求；
2.研究与跟踪数据技术发展方向，参与数据平台架构的设计。
3.负责数据报表平台，数据接入平台、数据分析平台以及数据管理平台等开发维护工作；
4.负责概要设计、详细设计，并负责完成核心代码，技术攻坚；
5.根据开发规范与流程独立完成模块的设计、编码、测试以及相关文档；

任职要求：
1.精通Java开发语言，掌握Spring?MVC、myBatis等流行框架；
2.深入理解JAVA面向对象程序设计原则,理解设计模式；
3.对java常用包有深入的认知，了解JVM内存机制；
4.熟练使用mysql关系型数据库，能进行基本的sql优化，了解分布式存储引擎、索引、大量数据分区分表等技术优先；
5.熟悉常用的缓存技术，如memcache，redis等；
6.至少熟悉以下一种大数据技术组件，Hive、Impala、HBase、Flume、Kafka、Zookeeper、Spark。
7.参与过大型数据平台产品、OLAP系统开发者优先；参与过分布式任务调度或管理系统啊开发者优先。
8.有较强的团队协作精神，独立工作能力、沟通及表达能力强，工作责任心强，能够承受压力。"
"职位描述：
        
        岗位职责
风控引擎开发、平台架构设计，高性能调优

任职条件
1.??Java基础扎实，熟悉J2EE开源框架，如dubbo,?spring-cloud/springmvc,mybatis,Kafka,?Netty,?Redis,Protocal?Buffer等，并对部分开源有深入理解；
2.??深入了解高性能中间件Kafka,?Netty,?Redis,Protocal?Buffer,?docker和dubbo（或类似rpc框架）等；
3.??具有很强在线复杂系统开发、架构经验，能够在快速业务迭代以及复杂系统上下游前提下提出最优设计并高质量完成；
4.??具有10k+级qps的高并发低延迟高稳定性系统开发和架构经验；
5.??经历过类似双十一等大促，对大促时系统的scale以及运营手段有实际经验；
6.??具备良好的沟通能力，工作积极认真，具有创业精神
7.??具有Flink&Spark开发、HBase，Phoenix；ElasticSearch，Tensorflow等相关项目实践，有实时近线计算经验。有独立系统的架构设计经验is?a?plus；
8.??算法背景is?a?plus"
"职位描述：
        
        岗位职责：
1.参与建设投融资数据体系，持续集成相关工具产品，以及搭建大数据业务统一计算层等相关工作；
2.参与公司数据仓库的架构设计和研发，挖掘数据价值， 实现高质量数据的互通与共享；
3.助力数据化运营业务，构建丰富多样的BI应用；
4.对数据采集、数据融合、数据质量、数据应用链路有深入理解，并能协助业务数据集市建设，搭建业务领域模型。

任职要求：
1.数学、计算机、统计学等相关专业本科以上学历，5年以上相关工作经历；
2.从事数据仓库领域至少5年以上，熟悉数据仓库模型设计与ETL开发经验；
3.有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验着优先，重点考察Hdfs、Mapreduce、Hive、Hbase；
4.有实时ETL研发经验，对分布式实时大数据处理系统有深入理解，包括但不限于Spark streaming、Flink、Storm...；
5.熟悉数据仓库领域知识和技能者优先，对数据质量管理有独到的见解；
6.业务sense，能够通过梳理设计业务模型发现业务问题，并驱动业务目标实现；
7.有Neo4j，Word2vec经验优先。"
"职位描述：
        
        1. 负责大型Hadoop集群相关组件的开发、调优、监控等工作；
2. 负责支撑大规模Hadoop集群的自动化运维基础设施规划、方案设计和推动落地；
3. 负责大规模Hadoop集群的AIOps方案的规划和实施。
?
任职需要
1、大学本科及以上学历，计算机或相关专业；
2、深入理解linux系统运维体系结构，以及系统资源规划；
3、能够理解数万规模的大型数据中心运维场景，对Hadoop生态熟悉；
4、熟悉大型互联网企业运维架构解决方案者优先；
5、具备清晰的问题解决思路，良好的沟通能力以及团队协调能力。"
"职位描述：
        
        岗位职责
1、面向PB，EB规模的大型数据平台场景；
2、负责大数据平台多种场景下的存储和计算方案技术选型、规划设计和推动实施；
3、负责团队人才梯队的培养。
?
任职需要
1、大学本科及以上学历，计算机或相关专业；
2、扎实的计算机理论和编程基础，熟悉常见的分布式理论和系统，熟悉JVM和Linux；
3、对Hadoop生态组件熟悉，有Hadoop生态开源项目社区和提交经验者优先；
4、具备科学清晰的问题解决思路，良好的沟通能力以及团队协调能力，崇尚数据价值和数据决策。"
"职位描述：
        
        岗位职责
1、面向PB，EB规模的大型数据平台场景；
2、负责大数据平台多种场景下的存储和计算方案技术选型、规划设计和推动实施；
3、负责团队人才梯队的培养。
?
任职需要
1、大学本科及以上学历，计算机或相关专业；
2、扎实的计算机理论和编程基础，熟悉常见的分布式理论和系统，熟悉JVM和Linux；
3、对Hadoop生态组件熟悉，有Hadoop生态开源项目社区和提交经验者优先；
4、具备科学清晰的问题解决思路，良好的沟通能力以及团队协调能力，崇尚数据价值和数据决策。"
"职位描述：
        
        岗位职责
1.参与建设拼多多统一的数据体系，持续集成相关工具产品，以及搭建大数据业务统一计算层等相关工作；
2.参与拼多多数据仓库的架构设计和研发，挖掘数据价值，建设与管理百PB级的公共数据平台和服务系统，实现高质量数据的互通与共享；
3.助力数据化运营业务，构建丰富多样的BI应用；
4.对数据采集、数据融合、数据质量、数据应用链路有深入理解，并能协助业务数据集市建设，搭建业务领域模型。
?
任职需要
1.数学、计算机、统计学等相关专业本科以上学历，5年以上相关工作经历；
2.从事数据仓库领域至少5年以上，熟悉数据仓库模型设计与ETL开发经验，掌握Kimball的维度建模设计方法，具备海量数据加工处理（ETL）相关经验；
3.有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验着优先，重点考察Hdfs、Mapreduce、Hive、Hbase；
4.有实时ETL研发经验，对分布式实时大数据处理系统有深入理解，包括但不限于Spark streaming、Flink、Storm...；
5.熟悉数据仓库领域知识和技能者优先，对数据质量管理有独到的见解；
6.具有电商行业经验，有业务sense，能够通过梳理设计业务模型发现业务问题，并驱动业务目标实现。
?
更期待你
1.系统能力
2.项目管理能力"
"职位描述：
        
        我们希望您能： 1.参与建设拼多多统一的数据体系，持续集成相关工具产品，以及搭建大数据业务基础计算层等相关工作； 2.参与拼多多数据仓库的架构设计和研发，挖掘数据价值，建设与管理百PB级的公共数据平台和服务系统，实现高质量数据的互通与共享； 3.助力数据化运营业务，构建丰富多样的BI应用； 4.对数据采集、数据融合、数据质量、数据应用链路有深入理解，并能协助业务数据集市建设，搭建业务领域模型。
岗位要求： 1.从事数据仓库领域至少3年以上，熟悉数据仓库模型设计与ETL开发经验 ，掌握Kimball的维度建模设计方法，具备海量数据加工处理（ETL）相关经验； 2.有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验着优先，重点考察HDFS、MapReduce、Hive、HBase； 3.熟悉数据仓库领域知识和技能者优先，对数据质量管理有独到的见解； 4.具有电商行业经验，有业务sense，能够通过梳理设计业务模型发现业务问题，并驱动业务目标实现； 5.熟悉各种NoSQL产品,对分布式架构熟悉者优先；具有图数据库开发经验者优先； 6.对数据挖掘和机器学习有所了解，包括常用的机器学习算法和数据建模过程的优先。"
"职位描述：
        
        【岗位职责】
1. 负责业务相关数据指标的计算挖掘；
2. 负责数据建模以及数据仓库应用产品的设计和开发；
3. 负责数据仓库ETL流程的优化及解决ETL相关技术问题；
4. 负责数据平台的接入和开发。
【任职要求】
1. Java基础扎实，熟悉多线程，熟悉网络编程，了解设计模式，熟悉模块化编程，熟悉Spring等常见开发框架；
2. 熟悉MySQL数据库，熟悉至少一种NoSQL数据库；
3. 熟悉Hadoop，Hive，HBase，Spark，Storm，Kafka等大数据相关开源系统, 熟悉ETL过程；
4. 数据有较强的敏感性，有较强数据分析能力；
5. 逻辑思维能力强，思维敏捷，对新技术有较强的求知欲望；
6. 良好的团队合作，较强的沟通能力，对解决挑战型问题充满激情。"
"职位描述：
        
        我们希望您能：
1.负责大数据架构相关组件的开发、维护和优化
2.负责大数据平台运维管理工具系统的设计和实现
3.确定大数据架构的整体技术路线和架构走向，新技术的调研和落地
岗位要求：
1.熟练掌握Java/Scala，3年以上开发经验
2.熟悉大数据离线计算生态体系，对HDFS、MapReduce、Yarn、Hive、Spark等开源组件有深入研究
3.熟悉日志采集传输、消息队列相关技术，对Kafka、Flume、Fluentd等开源组件有深入研究
4.对于OLAP系统和实时实时数据服务有深入研究
5.具有以上组件的patch, 二次开发经验优先"
"职位描述：
        
        我们希望您能：
1.负责大数据平台相关系统产品的设计和研发，包括数据传输平台、数据开发平台、数据治理平台等
2.与数据架构、数据仓库、BI、数据服务等团队合作，构建准确、高效、安全的数据平台
岗位要求：
1.熟练掌握Java，3年以上开发经验
2.熟悉大数据离线计算生态体系，熟悉Hdfs、MapReduce、Yarn、Hive、Spark等开源组件
3.熟悉数据传输平台开源方案（sqoop、datax等），有设计和开发经验优先
4.熟悉数据开发平台开源方案（airflow、zeus、azkaban等），有设计和开发经验优先
5.熟悉数据治理平台开源方案（atlas、wherehows等），有设计和开发经验优先
6.熟悉数据服务平台开发"
"职位描述：
        
        我们希望您能：
1.负责大数据服务相关组件的开发、维护和优化
2.负责大数据服务运维管理工具系统的设计和实现
岗位要求：
1.熟练掌握Java，3年以上开发经验
2.熟悉大数据计算生态体系，对Hadoop、Spark, Kafka, Druid等开源组件有深入研究
3.熟悉MySQL，HBase，Redis，Cassandra等数据库
4.对于OLAP系统和统一数据服务有深入研究
5.对于高并发系统有深入的了解，有系统调优的经验"
"职位描述：
        
        1.负责电商搜索场景的基础数据的建设，包括数据埋点的设置，数据仓库的建立和维护，报表的开发等
2.负责保证数据的正确性和丰富性
3.负责开发实时数据和离线数据

任职要求：
1.本科及以上学历，计算机，信息管理学等数据管理相关专业
2.熟悉互联网公司实务.数据模型.数据标准，具备电商数据集市建设经验和数据治理经验
3.良好的SQL能力,从事过IT系统分析师等相关工作
4.有较强的执行力，书面表达能力，积极而有效的沟通；良好的适应能力，能在时间限制和任务压力下工作"
"职位描述：
        
        岗位描述:
1）建设拼多多统一的数据体系，持续集成相关工具产品，以及搭建大数据业务基础计算层等相关工作；
2）参与拼多多数据仓库的架构设计和研发，挖掘数据价值，建设百PB级的公共数据平台和服务系统，实现高质量数据的互通与共享；
3）助力数据化运营业务，构建丰富多样的BI应用。

岗位要求:
1）从事数据仓库领域至少2年以上，熟悉数据仓库模型设计与ETL开发经验 ，掌握Kimball的维度建模设计方法，具备海量数据加工处理（ETL）相关经验；
2）有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验着优先，重点考察Hdfs、Mapreduce、Hive、Hbase；
3）熟悉数据仓库领域知识和技能者优先，包括但不局限于：元数据管理、数据开发测试工具与方法、数据质量、主数据管理；
4）有良好的业务及产品感觉，可以站在使用者角度设计技术产品。可以主动并乐于了解日常业务，具备从日常业务中发现问题并解决问题的能力；
5）熟悉各种NoSQL产品,对分布式架构熟悉者优先；具有图数据库开发经验者优先；
6）对数据挖掘和机器学习有所了解，包括常用的机器学习算法和数据建模过程的优先。"
"职位描述：
        
        岗位职责：
1. 负责业务相关数据指标的计算挖掘；
2. 负责数据建模以及数据仓库应用产品的设计和开发；
3. 负责数据仓库ETL流程的优化及解决ETL相关技术问题。
4. 负责数据平台的接入和开发
?职位要求：
1. Java基础扎实, 熟悉多线程, 熟悉网络编程, 了解设计模式, 熟悉模块化编程, 熟悉Spring等常见开发框架
2. 熟悉MySQL数据库，熟悉至少一种NoSQL数据库
3. 熟悉Hadoop, Hive, HBase, Spark, Storm, Kafka等大数据相关开源系统, 熟悉ETL过程
4. 数据有较强的敏感性，有较强数据分析能力
5. 逻辑思维能力强，思维敏捷，对新技术有较强的求知欲望
6. 良好的团队合作，较强的沟通能力，对解决挑战型问题充满激情
加分项：
1. 有大型互联网公司分布式数据仓库和数据产品开发经验者优先有数据建模基础优先。
2. 有Web系统架构设计经验者优先"
"职位描述：
        
        【岗位职责】 ??? 1、负责社交电商业务的数据模型建设，推演业务商业化模型和对各项数值模型进行训练以达到最佳的商业效果。?? ?2、大量数据基础支持，对每天几十亿条的用户操作行为， 进行数据清洗、行为分析和关联系统的建设?? ?3、通过数据发掘新的商业机会和新领域的模式探索。

【任职要求】 ?? ?1. 本科及以上学历，计算机/数学/统计学等相关专业，热爱计算机科学和互联网技术； ?? ?2. 掌握数理统计，线性代数，数据挖掘等常用理论知识，对商业数据有一定的敏感度?? ?3. 熟练使用SQL语言、Excel等； ?? ?4. 对Hadoop, Spark的原理熟练掌握，并有一定的使用经验； ?? ?5. 熟悉Linux、shell，有Python等脚本语言经验者优先； ?? ?6. 善于沟通，逻辑思维能力较强，善于学习新知识。??? 7.有Java开发经验有额外加分"
"职位描述：
        
        岗位职责
1．? 参与拼多多数据仓库的架构设计和研发，建设拼多多百PB级大数据仓库，挖掘数据价值，包括数据模型设计、ETL研发及对应数据主题域的推广应用，实现高质量数据的互通与共享
2．完成对应业务数据研发工作，包含但不限于业务数据需求支持，业务关键指标挖掘
3．助力业务数据化运营，构建丰富多样的数据产品及应用
4．完成对应岗位要求的其他任务
?
任职要求
1.本科以上学历，从事数据仓库领域至少1年以上，熟悉数据仓库模型设计与ETL开发经验 ，掌握Kimball的维度建模设计方法，具备海量数据加工处理（ETL）相关经验
2.有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验着优先，重点考察Hdfs、Mapreduce、Hive、Hbase、Flink
3.熟悉数据仓库领域知识和技能者优先，包括但不局限于：元数据管理、数据开发测试工具与方法、数据质量、主数据管理
4.有良好的业务及产品感觉，可以站在使用者角度设计技术产品。可以主动并乐于了解日常业务，具备从日常业务中发现问题并解决问题的能力
5.熟悉各种NoSQL产品,对分布式架构熟悉者优先
6.对数据挖掘和机器学习有所了解，包括常用的机器学习算法和数据建模过程的优先
7.能自我驱动，有较强的沟通能力及团队合作精神，强烈的责任感及进取精神"
"职位描述：
        
        岗位要求：
1. 参与大数据平台和大数据处理框架的架构设计
2. 深入理解用户的数据统计需求，不断挖掘应用场景
3. 负责基于Hadoop和OLAP框架的海量数据平台建设
4. 协助建立业务模型，对海量数据进行挖掘、优化及统计。

任职资格:
1. 了解Hadoop大数据平台框架，熟悉Spark、Storm、HBase、Hive、Impala等组件的应用设计及开发
2. 1年以上ETL/Adhoc query/OLAP等实践经验
3. 有海量数据高并发、高性能分析及处理经验
4. 充满求知欲，持续学习新技术的能力
5. 有较强的责任心及团队意识，善于分析和解决问题"
"职位描述：
        
        我们希望您能： 1.建设拼多多统一的数据体系，持续集成相关工具产品，以及搭建大数据业务基础计算层等相关工作； 2.参与拼多多数据仓库的架构设计和研发，挖掘数据价值，建设与管理百PB级的公共数据平台和服务系统，实现高质量数据的互通与共享； 3.助力数据化运营业务，构建丰富多样的BI应用。

岗位要求： 1.从事数据仓库领域至少2年以上，熟悉数据仓库模型设计与ETL开发经验 ，掌握Kimball的维度建模设计方法，具备海量数据加工处理（ETL）相关经验； 2.有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验着优先，重点考察HDFS、MapReduce、Hive、HBase； 3.熟悉数据仓库领域知识和技能者优先，包括但不局限于：元数据管理、数据开发测试工具与方法、数据质量、主数据管理； 4.有良好的业务及产品感觉，可以站在使用者角度设计技术产品。可以主动并乐于了解日常业务，具备从日常业务中发现问题并解决问题的能力； 5.熟悉各种NoSQL产品,对分布式架构熟悉者优先；具有图数据库开发经验者优先； 6.对数据挖掘和机器学习有所了解，包括常用的机器学习算法和数据建模过程的优先。"
"职位描述：
        
        岗位职责
1. 建设拼多多统一的数据体系，持续集成相关工具产品，以及搭建大数据业务基础计算层等相关工作；
2. 参与拼多多数据仓库的架构设计和研发，挖掘数据价值，建设与管理百PB级的公共数据平台和服务系统，实现高质量数据的互通与共享；
3. 助力数据化运营业务，构建丰富多样的BI应用。
任职要求
1. 从事数据仓库领域至少2年以上，本科及以上学历；熟悉数据仓库模型设计与ETL开发经验 ，掌握Kimball的维度建模设计方法，具备海量数据加工处理（ETL）相关经验；
2. 有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验着优先，重点考察HDFS、MapReduce、Hive、HBase；
3. 熟悉数据仓库领域知识和技能者优先，包括但不局限于：元数据管理、数据开发测试工具与方法、数据质量、主数据管理；
4. 有良好的业务及产品感觉，可以站在使用者角度设计技术产品。可以主动并乐于了解日常业务，具备从日常业务中发现问题并解决问题的能力；
5. 熟悉各种NoSQL产品,对分布式架构熟悉者优先；具有图数据库开发经验者优先；
6. 对数据挖掘和机器学习有所了解，包括常用的机器学习算法和数据建模过程的优先。"
"职位描述：
        
        【岗位职责】
1.参与拼多多大数据平台体系建设，持续集成相关工具产品，以及搭建大数据业务统一计算层等相关工作；
2.参与拼多多数据仓库的架构设计和研发，挖掘数据价值，建设与管理百PB级的公共数据平台和服务系统，实现高质量数据的互通与共享；
3.参与拼多多工具/内容/智能数据产品研发，挖掘数据价值，实现数据赋能业务；
4.用数据提高效率和改变业务运营方式，规划数据技术发展方向，带动团队技术氛围。
【任职要求】
1.2019年应届毕业生，本科及以上学历，计算机相关专业；
2.扎实的数据结构和算法能力，熟悉至少一种关系型数据库；
3.熟悉一门数据处理语言，如SQL、JAVA、Python、Perl等；
4.善于沟通，主动性好，逻辑思维能力较强，有较强的自我驱动和学习能力；

加分项：
1.有Hadoop、Hive、Hbase、Kylin、Druid等分布式平台实践经验；
2.有数据平台、数据仓库、数据产品研发、数据分析与挖掘等相关项目经验；
3.有多线程、缓存、分布式、全栈开发经验。"
"职位描述：
        
        岗位职责
1、 参与仓库架构设计与研发，建设PB级的公共数据平台和服务系统，实现高质量数据的互通与共享；
2、 参与产品与应用的数据研发，发掘数据商业价值，打造极致体验的数据产品；
3、 助力数据化运营业务，构建丰富多样的BI应用。
?
岗位要求
1、 计算机相关专业，本科以上学历；
2、 从事数据仓库领域2年以上，熟悉仓库模型设计与ETL开发经验，有电商领域数据建设经验优先；
3、 掌握Kimball的维度建模设计方法，具备海量数据加工处理（ETL）相关经验,灵活运用SQL实现海量数据ETL加工处理；
4、 熟悉数据仓库领域知识和技能者优先，包括但不局限于：模型设计、数据开发、数据集市设计、元数据管理、数据质量；
5、 熟悉JAVA语言，有分布式数据存储与计算应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验，重点考察Hdfs、Mapreduce、Hive；
6、 熟悉Linux系统常规shell处理命令，灵活运用shell做的文本处理和系统操作；
7、 良好的语言沟通与表达能力、较强的自我驱动能力。"
"职位描述：
        
        工作职责：

1、对用户行为数据分析，推动产品优化
2、参与并负责大数据架构的搭建、开发和维护监控
3、完成产品经理对数据的各类提取需求
4、从数据的角度，预测和量化运营活动效果


任职资格：

1.本科以上学历，计算机或数学相关专业，2~5年工作经验
2.熟练操作linux，有python/shell/java开发能力
3.能搭建并优化hadoop/spark/elk等大数据平台
4.具备海量数据处理以及性能优化的能力
5.有社交、电商数据相关处理经验者优先"
"职位描述：
        
        岗位职责：
1、作为大数据平台架构师或管理员，负责规划大数据平台架构，实施平台规划，完成大数据基础平台日常管理，推动我行大数据基础平台建设；
2、作为大数据平台开发人员，负责开发大数据基础平台辅助工具，提高平台管理能力和优化平台提供的服务；
3、作为大数据开发人员，负责使用大数据技术完成复杂数据处理和计算；
任职资格：
1、大学本科及以上学历，计算机相关专业（应聘者需获得全日制统招本科毕业证、学位证）；
2、熟悉大数据基础平台技术的原理和内部机制，包括Hadoop、HDFS、MapReduce、Hive、Spark等，具有2年以上Mapreduce、Hive或Spark开发经验；
3、熟悉SparkStreaming计算框架，曾参与基于该框架的准实时数据处理项目设计和开发；
4、曾负责或参与过一定规模Hadoop集群的搭建、管理和性能优化，了解业界主流大数据平台商业产品，如CDH、华为FusionInsight、IBMBigInsight等；
5、学习能力强，对新知识特别感兴趣，具备良好的沟通能力和团队意识。
6、具备以下能力或经验者优先：
1）大数据平台搭建和管理经验
2）搭建或开发过大数据平台监控系统
3）Mapreduce、Hive或Spark开发经验
4）通过大数据技术处理非结构化数据的经验
5）准实时数据处理项目经验"
"职位描述：
        
        岗位职责：
1、作为大数据平台架构师或管理员，负责规划大数据平台架构，实施平台规划，完成大数据基础平台日常管理，推动我行大数据基础平台建设；
2、作为大数据平台开发人员，负责开发大数据基础平台辅助工具，提高平台管理能力和优化平台提供的服务；
3、作为大数据开发人员，负责使用大数据技术完成复杂数据处理和计算；
任职资格：
1、大学本科及以上学历，计算机相关专业（应聘者需获得全日制统招本科毕业证、学位证）；
2、熟悉大数据基础平台技术的原理和内部机制，包括Hadoop、HDFS、MapReduce、Hive、Spark等，具有2年以上Mapreduce、Hive或Spark开发经验；
3、熟悉SparkStreaming计算框架，曾参与基于该框架的准实时数据处理项目设计和开发；
4、曾负责或参与过一定规模Hadoop集群的搭建、管理和性能优化，了解业界主流大数据平台商业产品，如CDH、华为FusionInsight、IBMBigInsight等；
5、学习能力强，对新知识特别感兴趣，具备良好的沟通能力和团队意识。
6、具备以下能力或经验者优先：
1）大数据平台搭建和管理经验
2）搭建或开发过大数据平台监控系统
3）Mapreduce、Hive或Spark开发经验
4）通过大数据技术处理非结构化数据的经验
5）准实时数据处理项目经验"
"职位描述：
        
        岗位职责:1.参与公司HADOOP大数据平台建设；2.参与公司爬虫体系平台建设；3.参与公司客户统一交互（接触）平台建设。
任职资格:1.本科及以上学历；2.精通java，两年以上java相关开发经验 ，有scala语言开发经验优先； 3.熟悉linux开发环境，了解网络、性能等相关命令；4.有分布式运算相关开发经验，有mapreduce、storm、spark 等相关开发经验，有开源代码贡献优先；5.能快速学习，实际动手能力强，勤奋肯干，有责任心。"
"职位描述：
        
        岗位职责:负责搭建互联网企业级数据仓库，包括ETL、数据模型设计和开发、BI等工作。
任职资格:本科及以上学历，计算机、统计、数学等相关专业；3年以上DW/BI系统的实际开发经验，至少精通DB2、Oracle、Teradata、Greenplum其中一种主流数据库及其数据仓库的开发、设计和调优；具备丰富的数据库模型设计及数据库管理经验，熟悉一种以上主流ETL工具，有大型的数据仓库设计或者数据分析经验者优先；熟悉Hadoop、Spark、Hive等，具有相关环境的使用经验；精通PL/SQL & SQL编程，熟悉J2EE架构，能使用JAVA语言编写ETL开发程序；责任心强，有良好的合作精神，沟通能力较强；有海量数据处理经验优先；熟悉金融业务优先。"
"职位描述：
        
        工作职责
负责搭建互联网企业级数据仓库，包括ETL、数据模型设计和开发、数据质量管控、BI等工作。
任职资格
全日制本科及以上学历，计算机等相关专业； 3年以上相关工作经验； 具备丰富的数据库设计和开发经验，有大批量数据的处理经验，数据仓库或BI项目实施和开发经验优先； 具备丰富的数据库模型设计及数据库管理经验，熟悉一种以上主流ETL工具，有大型的数据仓库设计或者数据分析经验者优先； 掌握MySQL、Oracle、SQL Server、DB2等主流数据库及其数据仓库的开发、设计和调优； 精通PL/SQL & SQL编程，熟悉J2EE架构，能使用JAVA语言编写ETL开发程序； 责任心强，有良好的合作精神，沟通能力较强； 熟悉金融业务优先。"
"职位描述：
        
        岗位职责：
1、?? 万亿级金融交易核心数据分析建模，打造金融行业内最先进的大数据金融营销、大数据投研、大数据投顾、大数据风控、大数据投行等深度金融分析模型；
2、? 研究最前沿金融科技大数据成果在投资领域的领先应用，优化投资逻辑与模型。
?
岗位要求：
1、?重点大学2019届硕士或博士应届毕业生，计算机相关、数学、统计学等相关专业；
2、? 熟悉数据建模知识、数据挖掘理论，熟练掌握数据分析体系架构、方法；
3、? 熟悉至少一门主流数据开发或数据分析编程语言，熟悉大数据生态圈相关组件的整合应用、了解实时计算框架；具备优秀的数据编程能力；
4、? 善于分析、钻研，对创新事物有浓厚兴趣和积极性，能够持续研究学习国内外大数据新技术；
5、? 参加过校级及以上级别的专业学科领域竞赛获得名次者优先。"
"职位描述：
        
        岗位职责：1、完善公司大数据平台；
2、参与跨团队的业务讨论，与产品需求部门深度合作，研究并实施可落地的大数据解决方案；
2、参与公司离线、流式大数据处理系统的设计、开发及多个业务模块的集成；
3、性能调优，解决系统性能瓶颈；
4、研究最新大数据处理前沿技术，并评估和解决现实项目中的技术难题；
?
任职要求：
1、统招本科及以上学历，计算机相关专业，至少5年以上工作经验，3年以上大数据开发经验；
2、熟悉Hadoop、HDFS、Hive、HBase、Spark、Storm、Flume、kylin等相关技术的基础架构，有海量数据处理经验者优先；
3、有数据仓库开发经验， 有BI系统开发经验；
4、熟悉Linux系统，熟练使用shell/perl/python脚本处理问题；
5、对深度学习框架（Tensorflow）和机器学习（svm 随机深林贝叶斯等）有一定了解的优先；
6、较强的学习能力和英文阅读能力，能独立调研新技术并实践落地；
7、代码规范，良好的编程习惯；
7、做事认真细心，逻辑思维清晰严谨；而且要具备高度的责任感和良好的沟通协调能力，遇事积极主动；"
"职位描述：
        
        工作职责 :
1.参与大数据平台和大数据处理框架的架构规划设计。
2.根据业务需求整合优化数据架构，主动思考不断优化。
3.关注开源技术动态，推动平台技术架构持续更新。

职位要求 :
1.三年以上大型互联网产品或分布式系统开发设计经验
2.熟练掌握Java或者Scala或Python任意一种语言
3.熟练SQL开发，掌握Mysql等关系型数据库中的一种或几种
4.熟练掌握Hadoop及Map-Reduce应用开发，
5.熟练掌握Spark、Kafka、HBase、Hive、Storm、Impala等大数据开发工具中一种或几种
6.熟悉Linux系统，具备Shell、Python等脚本开发能力者优先
7.有大数据或数据仓库项目经验，了解数据仓库相关理论知识者优先
8.有大规模集群开发运维经验，具备源码级问题解决和集群优化改造能力者优先
9.学习能力强，喜欢研究开源新技术，有团队观念，具备独立解决问题的能力

你将加入这样一群人：
追求自由、平等，提倡简单、透明和分享；
对新事物充满好奇，对技术充满热情；
热爱生活、热爱运动，爱户外、爱篮球、爱羽毛球还有爱二次元的

工作环境上：
免费的午餐、晚餐（由3W大厨掌勺，每天3菜1汤）；
每天个人份水果点心；
定期的运动（羽毛球、篮球都OK，不想出屋的公司也有跑步机）"
"职位描述：
        
        补充：? 该岗位可实习，实习合格的有机会转为正式； ??

工作职责 :
1.参与大数据平台和大数据处理框架的架构规划设计。
2.根据业务需求整合优化数据架构，主动思考不断优化。
3.关注开源技术动态，推动平台技术架构持续更新。

职位要求 :
1.两年以上大型互联网产品或分布式系统开发设计经验
2.熟练掌握Java或者Scala或Python任意一种语言
3.熟练SQL开发，掌握Mysql等关系型数据库中的一种或几种
4.熟练掌握Hadoop及Map-Reduce应用开发，
5.熟练掌握Spark、Kafka、HBase、Hive、Storm、Impala等大数据开发工具中一种或几种
6.熟悉Linux系统，具备Shell、Python等脚本开发能力者优先
7.有大数据或数据仓库项目经验，了解数据仓库相关理论知识者优先
8.有大规模集群开发运维经验，具备源码级问题解决和集群优化改造能力者优先
9.学习能力强，喜欢研究开源新技术，有团队观念，具备独立解决问题的能力

你将加入这样一群人：
追求自由、平等，提倡简单、透明和分享；
对新事物充满好奇，对技术充满热情；
热爱生活、热爱运动，爱户外、爱篮球、爱羽毛球还有爱二次元的

工作环境上：
免费的午餐、晚餐（由3W大厨掌勺，每天3菜1汤）；
每天个人份水果点心；
定期的运动（羽毛球、篮球都OK，不想出屋的公司也有跑步机）"
"职位描述：
        
        岗位职责：
1.负责数据仓库的整体搭建及架构设计；
2.负责数据建模，业务、报表相关数据仓库的设计和开发；
3.负责数据仓库ETL流程的优化及解决ETL相关的技术问题。
岗位要求：
1.本科以上学历；
2.从事数据仓库领域工作至少2年以上，熟悉数据仓库模型设计方法论，并有实际模型设计及ETL开发经验；
3.熟悉Java/Python/Shell等开发语言，有SQL、ETL开发及调优经验；
4.熟悉Hadoop/Hive/Spark/Presto/Impala等大数据相关技术；
5.有独立设计数据仓库经验，熟悉数据仓库相关理论知识者优先。"
"职位描述：
        
        您将负责的工作：
1、负责根据ETL方案开发ETL程序以及ETL程序测试；
2、负责根据产品需求开发、测试数据库脚本；
3、负责根据建设需求部署cdc工具；
4、负责在测试环境上面实现数据模型。
您需具备的能力：
1、本科及以上学历，计算机相关专业；
2、熟悉数据库相关技能（如：oracle、mysql、db2、sqlserver等）；
3、熟练掌握主流ETL工具、cdc工具等；
4、能够根据业务需求开发数据库存储过程、函数等；
5、有责任心、能独立分析解决问题、团队协作能力强;
6、可接受应届毕业生。"
"职位描述：
        
        工作职责：
1. 参与大数据平台的建设和维护
2. 参与设计数据仓库模型、构建分层体系、元数据管理及核心应用开发
3. 参数据服务的开发，为其他部门提供数据服务

岗位要求：
1. 本科或以上学历，计算机相关专业
2. 熟悉数据仓库模型设计和ETL开发经验，该领域2年以上的工作经验
3. 掌握Java/Python/Scala一种或者多种语言
4. 熟练使用 SQL，至少熟悉一种关系型数据库
5. 基于Hadoop的大数据体系有深入认识，具备相关产品（Hadoop、Hive、HBase、Spark、Storm、Flume、sqoop、Kafka、ES等）项目应用研发经验
6. 思路清晰，具备良好的沟通能力和理解能力，较强的学习能力以及快速解决问题的能力；
7. 具有高度的责任心和团队合作精神"
"职位描述：
        
        岗位内容：
1. 负责公司基于Hadoop/Spark生态体系大数据分析处理平台基础研发工作；
2. 负责公司推荐系统的研发；
3. 参与机器学习相关算法的研发；
4. 和业务团队深入合作，解决业务发展中遇到的产品和平台架构问题，具备一定的前瞻性。
岗位要求：
1. 全日制统招本科及以上学历，计算机相关专业；
2. 熟悉hadoop相关各种开源项目，对spark、Mapreduce、hbase、hive至少一个的实现原理有深入理解；
3. 三年及以上实际使用Hadoop开发应用程序的相关经验；
4. 有扎实的Java/scala/python基本功；
5. 熟练使用linux，熟悉shell编程与常用命令。"
"职位描述：
        
        岗位内容：
1. 负责公司基于Hadoop/Spark生态体系大数据分析处理平台基础研发工作；
2. 负责公司推荐系统的研发；
3. 参与机器学习相关算法的研发；
4. 和业务团队深入合作，解决业务发展中遇到的产品和平台架构问题，具备一定的前瞻性。

岗位要求：
1. 全日制统招本科及以上学历，计算机相关专业；
2. 熟悉hadoop相关各种开源项目，对spark、Mapreduce、hbase、hive至少一个的实现原理有深入理解；
3.3年及以上实际使用Hadoop开发应用程序的相关经验；
4. 有扎实的Java/scala/python基本功；
5. 熟练使用linux，熟悉shell编程与常用命令。"
"职位描述：
        
        岗位内容：
1. 负责公司基于Hadoop/Spark生态体系大数据分析处理平台基础研发工作；
2. 负责公司推荐系统的研发；
3. 参与机器学习相关算法的研发；
4. 和业务团队深入合作，解决业务发展中遇到的产品和平台架构问题，具备一定的前瞻性。

岗位要求：
1. 全日制统招本科及以上学历，计算机相关专业；
2. 熟悉hadoop相关各种开源项目，对spark、Mapreduce、hbase、hive至少一个的实现原理有深入理解；
3. 一年及以上实际使用Hadoop开发应用程序的相关经验；
4. 有扎实的Java/scala/python基本功；
5. 熟练使用linux，熟悉shell编程与常用命令。"
"职位描述：
        
        工作职责：
1、负责数据相关平台的搭建、开发、维护、优化，分布式平台应用开发（Hadoop、Spark、Hive、Hbase）；
2、负责数据模型架构的构建，建立数据抽取、清洗、校验等数据加工流程规范；
3、持续对系统的技术架构进行改进和优化，提升海量数据的查询性能和用户体验；
4、参与风控核心系统开发；
5、跟踪业界前沿技术，应用到实际项目中。
?
任职资格：
1、本科以上学历，计算机软件或相关专业；
2、5年以上Java开发经验，有互联网金融行业开发经验优先；
3、精通Java语言，熟悉Linux操作系统；?熟悉关系数据库原理，精通MySQL、DB2等主流数据库之一；
4、精通Hadoop生态圈相关技术(YARN,?HDFS/HBase,?MapReduce/Spark,?Storm等)，至少具有2年以上相关项目开发经验，熟悉cloudera优先；
5、熟悉分布式架构和大数据架构，具备大数据架构设计能力；
6、有数据仓库建设经验、云平台设计开发经验尤佳；
7、熟悉脚本语言，有自动化脚本工具经验者可优先考虑；有丰富的跟踪和解决一线系统问题经验的可优先考虑；
8、工作主动性和积极性高，责任心和执行力强，沟通能力良好，学习能力和意愿强，有想法，有追求。


职位诱惑：
中国金融科技50强、最新融资15亿（阿里、瑞信、建银、IFC）；
团队牛，成员来自花旗、渣打、普华永道、BAT、谷歌、华为、平安等；
薪资高，市场领先的全面薪酬、最高17薪、期权激励；
假期长，20天福利假期（福利年假、全薪病假、生日假……）；
培训多，全员覆盖、定制化课程、外聘讲师、游学基金；
环境好，观海阳台、背靠人才公园、邻近海岸城、氛围积极开放；
福利全，五险一金、补充商业险、餐补、下午茶、团建费；
空间大，年两次调薪，发展通道多，管理岗公开竞聘。"
"职位描述：
        
        工作职责:1、参与实时大数据平台的数据存储、计算、监控、分析、机器学习等模块开发，打造稳定可靠的平台化、可视化、自动化的交互式大数据平台；2、负责基于大数据平台的应用设计、开发和维护及性能提升；3、规划设计大数据产品，包括实时计算平台、数据监控平台、机器学习平台、数据开发平台等。
任职资格:1、计算机、数学相关专业全日制本科以上学历；2、至少5年以上的Java开发经验，3年以上大数据应用系统的开发和设计经验；3、熟悉Hadoop生态圈技术体系，对离线计算、内存计算和流式计算均有深刻理解，如Hadoop、Hive、Spark、Flink、Impala等；4、精通Hive、HBase仓库设计，深刻理解MR运行原理和机制，能进行任务执行效率的优化；5、对机器学习的一般模型如分类、聚类、预测等模型熟悉（LR，CART，RT，DTM，NBM，LDA等），理解一些常用的特征选择和矩阵分解的算法；6、熟悉深度神经网络和常用的模型,如RBM、CNN、DBN、Sparsecoding、RNN等，对常用的开源实现,如Spark ML、Caffe、Theano或ConvNet等有实践经验者优先考虑；7、逻辑思维能力强，做事有条理，责任感强，工作积极主动，执行力强，有良好的团队协作意识。职位诱惑：中国金融科技50强、最新融资15亿（阿里、瑞信、建银、IFC）；?团队牛，成员来自花旗、渣打、普华永道、BAT、谷歌、华为、平安等；?薪资高，市场领先的全面薪酬、最高17薪、期权激励 ；假期长，20天福利假期（福利年假、全薪病假、生日假……）；?培训多，全员覆盖、定制化课程、外聘讲师、游学基金 ；?环境好，观海阳台、背靠人才公园、邻近海岸城、氛围积极开放；?福利全，五险一金、补充商业险、餐补、下午茶、团建费 ；?空间大，年两次调薪，发展通道多，管理岗公开竞聘 。"
"职位描述：
        
        1.学习并理解公司的产品和产品的设计思路；2.参与产品开发管理过程，为创建最好的产品提供专业的建议；3.负责系统设计和业务模块设计，编写核心代码和单元测试代码；4.负责技术攻坚，解决项目中的复杂的问题和技术难题；5.团队合作，与同事一起参与产品开发的整个生命周期。包括: 原型，设计，实现。开发出高性能，可扩展，易于维护的新零售大数据平台；6.使用敏捷开发方式，协调本地及实施团队，推动产品高质量按时交付；7.承担团队领导／经理职责，带领团队完成项目需求，推崇高质量产品的研发交付；8.对团队成员提供技术方面的指导，帮助团队成员成长，建立强大的团队，推动创新新技术的调研。任职要求：1.?7年以上开发经验，有2年以上管理经验，精通Java，有扎实的编程功底；2.?具有较强的团队意识，高度的责任感，对工作积极严谨，勇于承担压力；3.?良好的编程习惯，对设计模式以及原则有较深入了解；4.?熟悉常用的开源框架，如 SpringMVC,MyBatis 等，熟悉MySQL等关系数据库；5.?有ES, HBASE, Spark大数据开发经验；6.?有Scala，akka 开发经验优先，但非必须条件；7.?熟悉SQL语言，能熟练使用Mysql；熟悉NoSQL数据库开发与性能优化，如Redis，MongoDB；8.?有分布式系统的开发经验；9.?熟悉微服务架构优先；10.?对服务器性能优化有深刻了解，有高并发项目经验；11.?熟练地使用svn、git代码管理软件，熟悉产品代码管理方法和原则；12.?有持续和快速学习的习惯，有钻研精神，具备攻坚能力；13.?有敏捷开发和敏捷项目开发经验优先；"
"职位描述：
        
        岗位职责： 1. 负责新零售大数据后台服务开发 2. 对分析报表创建分析任务，优化查询效率，提供数据服务接口 3. 配合架构师完成一定的设计任务
任职要求： 1. 三年以上服务器端开发经验 2. 精通 Java 编程语言和面向对象设计与分析，熟悉常用数据结构和算法，熟悉Scala者优先 3. 对NoSQL数据存储方案有较为深入的认识，2年以上运用Hadoop，HBase，Kafka，Spark，ElasticSearch等工具进行项目开发的经验 4. 有Web应用开发经验，熟悉HTTP协议，对RESTful服务有开发经验者优先 5. 具有强烈的自我驱动性和解决问题的能力，良好的沟通能力和团队协作精神"
"职位描述：
        
        岗位职责： 1. 负责新零售大数据后台服务开发 2. 对分析报表创建分析任务，优化查询效率，提供数据服务接口 3. 配合架构师完成一定的设计任务
任职要求： 1. 三年以上服务器端开发经验 2. 精通 Java 编程语言和面向对象设计与分析，熟悉常用数据结构和算法，熟悉Scala者优先 3. 对NoSQL数据存储方案有较为深入的认识，2年以上运用Hadoop，HBase，Kafka，Spark，ElasticSearch等工具进行项目开发的经验 4. 有Web应用开发经验，熟悉HTTP协议，对RESTful服务有开发经验者优先 5. 具有强烈的自我驱动性和解决问题的能力，良好的沟通能力和团队协作精神"
"职位描述：
        
        岗位职责：1. 主导大数据平台的设计与开发，解决海量数据面临的挑战；2. 管理、优化并维护Hadoop、Spark等集群，保证集群规模持续、稳定；3. 负责HDFS/hive/HBase的功能、性能和扩展，解决并实现业务需求；4. 协助建立数据模型，对数据进行挖掘、优化及统计。
职位要求：1、本科生及以上学历，5年及以上相关经验；2、熟悉Hadoop/HBase/Spark/Storm/Hive，熟悉数据挖掘策略与算法；3、熟悉分布式系统设计范型，有大规模系统设计和工程实现的经验 ；4、数据控，善于发现问题、解决问题；5、对新兴技术有好奇心，有利用技术解决实际问题的热情，开源社区积极参与者优先。"
"职位描述：
        
        ? ? 岗位职责：????1、负责懒人听书海量数据的采集、转换等数据处理程序的开发；? ? 2、基于大数据平台进行统计分析、报表展示的开发任务；????3、参与用户画像、个性化推荐体系的建设，支撑业务的发展； ????任职要求：????1、计算机相关专业，1年以上大数据相关工作经验,?2年以上Java开发经验；????2、熟悉Java语言，熟悉Spring、SpringMVC等常用框架的使用和原理 ????3、熟练使用缓存、消息中间件、MySQL等技术 ????4、熟悉软件研发流程，了解GIT,?SVN,?MAVEN????5、熟练使用linux系统；????6、有包括但不限于hive、kylin、hbase、kafka、TiDB、Cassandra等相关技术实际应用开发经验；????7、熟悉ELK技术栈，有实践经验优先；????8、有较好的沟通能力，对技术有激情，有独立、主动学习能力；"
"职位描述：
        
        工作内容
我们正在寻找对于开发大数据及AI产品充满热情，并且乐于沟通、讨论、分享与团队合作的伙伴。
?
【工作说明】
? 在云端或者本地集群构建可扩展的数据处理流水线
? 规划大数据的处理策略，流程优化及效率的提升
? 与团队成员共同将公司AI技术透过容器扩展转化为可处理大规模数据的产品与服务
? 独立、快速、高品质完成核心程式的编写
?
【任职要求】
? 具有大数据相关技术经验，比如 Spark、Kafka、Hadoop 等
? 三年以上Java 或 Python 相关工作经验
? 熟悉 AWS 等云端平台及相关服务
? 了解 Docker 及 Kubernetes 相关技术
? 优秀的口头与书面交流与表达能力
? 良好的团队协作能力
?
? 加分项目：
- 熟悉 Scrum、Git、CI/CD
- 熟悉 Scala
- 熟悉 MongoDB 或 Hbase、Hive 等存储系统
- 熟悉avro, parquet, carbondata, and Presto/SparkSQL"
"职位描述：
        
        岗位职责：
1. 参与系统的需求分析和技术方案预研；
2. 负责大数据产品的研发、设计工作，及大数据平台的完善；
3. 负责各种生产、测试环境、业务系统等问题的快速定位和解决；
4. 负责代码编写、单元测试，确保代码执行性能、质量和安全。
任职资格：
1.? 本科及以上学历，计算机相关专业；
2.? 3年以上大数据项目和产品研发经验；
3.? 掌握大数据相关技术，具备Hadoop/HBase/Hive/Spark/Flink/ElasticSearch/Presto等主流框架的使用经验；
4.? 熟悉主流开发语言Java/Scala/Python；
5.? 思路清晰，能独立分析和解决问题；较强的沟通能力；责任心强，具备良好的团队合作精神和抗压能力。?
?
如果你热爱人工智能、算法、大数据，?并渴望用科技来改变点什么，?不要犹豫，赶快加入我们，?与技术大拿、业界专家一起切磋，?用Spark、TensorFlow探索未知、玩转AI~?这里有高竞争力的薪资，?也有生日会、各种节日outing?我们管交通、管三餐、管水果?我们需要经验丰富的70后，?我们期待情怀落地的80后，?我们渴望激情四射的90后，?敢于创新也能落地，?立志用科技改变世界，?这样优秀的你，?还不抓住机会赶快上车！未来独角兽期待你的加入~"
"职位描述：
        
        主要职责
1、理解数据的产品应用场景逻辑，通过统计方法和通用分布式框架工具语言如Hadoop，不断加强数据服务质量；2、负责数据清洗、转换、建模等工作,对海量用户行为数据通过Hadoop/Spark等进行离线和实时处理；3、参与用户画像、个性化推荐系统等数据产品的开发工作。4、参与数据、工具平台相关的功能接口、数据接口开发，完成业务功能。
职位必备项
跳槽频繁,一年一跳不考虑
年龄超限
年龄超过35岁不考虑
学校类型
必须一本以上学校
最低学历
必须统招本科以上学历
常规项
外包公司背景不考虑
其他项
3年以上数据研发经验，精通Java或Scala语言，具有面向对象编程思想，对底层实现有一定研究，利用大数据实现过风控系统的具体建设及开发，并且在多个场景应用 精通Spark sql、Spark streaming等编程，具有实际大型分布式集群项目开发经验 熟悉Linux操作系统，熟悉Linux shell编程 熟悉Mysql，Redis等常用数据库，Jetty等中间件 熟悉分布式存储或NoSQL数据库技术，如Hbase等 熟悉Hadoop生态环境，精通以下一种或多种大数据技术，如Flume、Kafka、HDFS、MR、Elastic Search 其他非技术岗位转开发的不考虑"
"职位描述：
        
        、2年以上大数据研发相关经验，熟悉机器学习、数据挖掘等相关技术；
2、熟悉Hadoop、Storm、Spark等大数据相关技术；
3、有良好的算法基础，熟练使用大数据相关平台上的算法工具；
4、精通Java或python，至少2年以上开发经验，精通io，网络通讯、多线程，缓存、消息队列、索引查询等机制，对数据结构和数据统计分析算法有较为深刻理解；
5、有推荐系统、精准营销、信息过滤、信息检索等方面的建模经验者优先。
注：工作地点镇江市润州区长江路758号"
"职位描述：
        
        任职要求：
1、2年以上大数据研发相关经验，熟悉机器学习、数据挖掘等相关技术；
2、熟悉Hadoop、Storm、Spark等大数据相关技术；
3、有良好的算法基础，熟练使用大数据相关平台上的算法工具；
4、精通Java或python，至少2年以上开发经验，精通io，网络通讯、多线程，缓存、消息队列、索引查询等机制，对数据结构和数据统计分析算法有较为深刻理解；
5、有推荐系统、精准营销、信息过滤、信息检索等方面的建模经验者优先；

工作地址：江苏省镇江市长江路758号"
"职位描述：
        
        职位描述：
1、负责大数据算法设计及实现工作，并将研究成果形成应用，推进业务发展；
2、负责大数据算法框架体系架构设计和相关技术路线规划；
3、大数据并行计算框架的设计和建设，并行算法的设计和实现、调试和优化；
4、熟悉软件开发流程，较好的文档能力及编码风格，数学建模、数据挖掘、机器学习或相关领域有一定了解。
职位要求：
1、计算机、软件工程、数学或相关专业，数学基础扎实，算法方向；
2、了解常用算法原理，能独立设计并实现 spark/mapreduce 程序，熟练使用 java/scala；
3、框架方向：了解 spark 框架结构及运行原理，精通 java 及scala 语言；
4、算法相关从业人员，或具备一定算法研究能力；熟悉大数据相关技术，有 MapReduce、Spark、AWSML 等相关工作经验优先。
注：工作地点镇江市润州区长江路758号"
"职位描述：
        
        1、参与惠每医疗大数据平台应用产品架构的整体规划和设计； 2、负责大数据应用开发过程的技术难点攻关； 3、项目管理，指导中高级工程师开发工作 岗位要求： 1、全日制统招本科及以上学历，计算机相关专业； 2、5年以上工作经验，不少于2年大数据架构经验； 3、精通java编程语言，良好的系统编程、算法基础、系统设计能力； 4、熟悉大型分布式系统设计与开发，熟悉常用web缓存、消息队列技术原理； 5、熟悉常用开源分布式系统，精通Hadoop/Hive/Spark/HBase其中一个或多个源代码； 6、熟悉实时计算框架Storm、Flink、Spark Streaming其中之一并有实际项目经验； 7、工作态度积极主动、细致、有全局观，有一定的抗压能力，善于与他人合作，良好的团队合作意识；"
"职位描述：
        
        1.熟练掌握Java或者Scala2.熟练掌握SQL开发，熟悉Mysql、Postgres、Oracle、SQL Server等关系型数据库中的一种或几种3.熟练掌握Hadoop及MapReduce、Spark应用开发4.熟练掌握Sqoop、Kafka、HBase、Hive、Impala等大数据开发工具5.熟悉Linux系统，具备Shell、Python等脚本开发能力者优先6.有大数据或数据仓库项目经验，具有良好的数据模型设计能力，了解数据仓库相关理论知识者优先7.数据挖掘与分析的相关知识，熟悉常用统计分析方法和数据挖掘基本算法优先8.学习能力强，工作积极主动，具备独立解决问题的能力"
"职位描述：
        
        岗位职责：
1) 参与分析业务需求，设计核心解决方案；
2) 参与公司的大数据处理框架的研发设计工作；
3) 研究学习最新算法和技术进展，评估引入新技术；
4) 参与产品测试和系统整合；
5) 保障代码质量，测试完备，维护技术文档。

任职资格：
1) 本科以上计算机等相关专业学历；
2) 精通 Linux Shell； 熟练掌握 Python、Scala 或 Java；
3) 有数据报表、可视化报表等开发经验；
4) 熟悉软件开发流程和配置库的使用，拥有软件开发流程中的代码规范意识、配置管理规范意识、文档撰写规范意识和团队合作沟通交流意识；
5) 愿意学习，善于自主学习、主动解决技术问题；
6) 有大数据分析项目的开发设计经验，特别是 Spark，Hadoop，Scala,Hive等；
7） 有大数据平台安装部署经验；"
"职位描述：
        
        工作职责：
1、负责构建大规模异构知识图谱，分布式分析型图数据库，图计算架构设计。
2、负责机器学习平台架构设计。
3、负责机器学习算法的离线计算，在线流计算，实时图计算，在线学习等架构设计。

职位要求：
1、计算机相关专业，统招本科及以上学历，5年以上大数据相关工作经验。
2、具有扎实的大数据和分布式系统的经验，对于大数据体系基础组件有深入研究。
3、深入理解Hadoop/Spark生态圈和数据应用开发；熟悉Hadoop, HBase, Hive, Spark, Flink, Kafka等相关技术
4、扎实的编程基础，精通Java, Scala等开发语言；
5、很强的学习能力、分析能力和解决问题的能力。?
6、具备很强的自我驱动与结果导向意识，具备创新能力，具备很强的团队协作意识和能力。
7、熟悉neo4j, Spark GraphX, Spark Streaming等技术优先。了解机器学习，深度学习算法优先。"
"职位描述：
        
        工作职责
1、负责大数据部数据业务开发。
2、为项目开发人员提供大数据技术指导及解决数据处理中遇到的技术难题。
3、参与公司数据架构设计与研发，建设PB级的公共数据平台和服务系统，实现高质量数据的互通与共享；

任职要求
1、熟悉Hadoop以及其生态圈上的各种主流组件，深入理解?Hadoop、Hive、HBase、Spark?等源码级技术原理，有丰富的的调优、数据处理优化实战经验。
2、能够独立完成ETL程序（批处理和实时流）开发，面对共性痛点问题能够深入优化和解决，在开发中解决过实际问题优先考虑。
3、有从事分布式数据存储与计算平台应用开发经验，重点考察Hdfs、Mapreduce、Hive、kafka、es、Flume，SQL海量数据处理；?
4、熟悉掌握java,scala,python,shell至少两种语言,掌握spark?stream,flink,storm两种以上实时流处理流程优先考虑
5、思路清晰，学习能力强，强烈的创新意识和责任心."
"职位描述：
        
        1、参与整体数据仓库的体系建设，完成业务指标的全流程分层体系2、参与部门支持数据驱动体系建设，数据分析的业务支持任职资格：1、本科及以上学历，计算机相关专业2、2年以上企业级数据仓库开发经验，数据ETL经验3、熟悉数据仓库，数据分析理论，具备复杂业务需求梳理能力4、熟练SQL开发，精通MYsql,HQL等中的一种或多种5、数据掌握Hadoop、Hbase、Spark等大数据开发工具中的一种或多种6、具备Shell、python等脚本开发者优先7、具备实时数据处理经验者优先"
"职位描述：
        
        1、精通oracle数据库，精通SQL语言、存储过程及相关SQL优化；
2、熟悉ETL相关知识，熟练应用ETL工具如Informatica，能独立进行ETL开发实施。
3、计算机本科相关专业，3年及以上相关工作经验。
4、有大型ETL开发项目经验。"
"职位描述：
        
        岗位职责：
1. 负责大数据平台相关项目的需求分析、架构设计、核心框架及组件的编码等开发工作，推动业务和技术的融合落地；
2. 负责组织技术研究、攻关、培训工作；
3. 负责相关技术文档编写工作。

任职要求：
1.3年以上工作经验，精通java技术，熟悉JVM、缓存、消息队列等；
2.熟悉面向对象和设计模式，熟悉主流开源应用框架，如Spring、MyBatis、SpringMVC、Spring Cloud、Maven、git等开发技术及工具；
3.熟悉分布式、多线程、高并发及高可用、设计、编码和调优；熟悉常用的网络通信协议原理
4.有大数据方面工作经验如Hadoop、Storm、Spark、Hbase等技术的优先；
5.良好的学习能力、团队协作能力和沟通能力。"
"职位描述：
        
        工作内容：
1、负责公司大数据产品的上线、日常运维、优化等工作；
2、研究运维相关技术，制定运维技术方案，编写运维相关的技术文档和标准；
3、负责系统安全和数据安全相关的技术，并协助处理政策相关事务；
4、负责产品的日常管理、维护、保养、检查及日志的监控与分析。
招聘要求：
1.计算机或相关专业本科及以上学历
2.掌握数据仓库基本理论，精通hadoop/hive/spark开发等
3.具有良好的编程能力，熟悉Scala/Java/Python等编程语言
4.熟悉SQL/HQL，有较好的SQL性能调优经验
5.有数据仓库大型项目或数据挖掘经验者优先
6.熟悉证券行业柜台、OTC等数据者优先
7.有很强的数据分析能力，对于通过数据分析发现问题，有独到的方法论
8.对数据有亲切感，主动性强，细心，思维敏捷。有很强的逻辑分析能力，对发现和思考问题充满乐趣
9.能接受出差"
"职位描述：
        
        您的工作内容：
1.负责应用平台维护，保证其有效运行；
2.负责业务数据的挖掘、整合以及分析模型的建立、优化和评估；为业务人员日常工作提供可靠而明确的数据支撑；
3.负责应用平台中报表相关功能的设计、开发工作，并负责报表优化、维护、数据采集；
4.负责系统相关文档的制定和编写。

我们对您的要求：
1.计算机相关专业，本科及以上学历，1年以上ORACLE数据库开发经验；
2.精通PLSQL编程，能够熟练编写ORACLE存储过程、触发器等；
3.思路清晰，逻辑明确，有较强分析与解决问题能力；
4.熟悉大数据开发相关技术，如hadoop、hive、spark、impala、storm、hbase等
5.能深入了解hadoop集群及其周边常用模块(YARN/Zookeeper/Flume/Kafka)；
6.熟练数据仓库，对多维数据建模有深入理解；
7.良好的沟通交流能力，对工作热情、认真、负责，心态积极而平稳，能与团队成员进行良好的合作；
8.电信行业工作经验及经营分析系统／数据挖掘、或业务支撑系统（bss、boss）项目建设经验者优先

我们给您的提升：
1、全称参与整个项目周期、不仅局限在某一环节；
2、过程中技术大牛毫无保留的对您各方面的工作指导；
3、主流技术的实践、技术成果的沉淀、知识网面的拓宽等；

加入我们的理由：
1、一切从薪开始：我们提供具行业竞争力的工资
2、靠谱完善的福利待遇：七险一金+餐补+话补+交通补贴+双休+带薪年假+节日福利等都是小意思
3、不让时间浪费在路上：思特奇位于***、紧邻地铁**号线、交通便利、多条公交线路、分分钟抵达公司
4、带你培训带你飞：定期组织外部和内部职业化和管理能力培训（部门内部培训、公司层面培训）、给予个性化的培训资助
5、透明的晋升机制：明确的晋升制度、健全的管理体系、工资和职位的提升机会就在眼前你是否已经对小公司的发展空间感到窒息？
你是否正在为储存已久的能量寻找更为广阔的平台？
别再犹豫了、生命短暂、经不起一份错误的工作、快加入我们吧！"
"职位描述：
        
        您的工作内容：
1、根据需求说明书完成概要设计、详细设计、编码和单元测试
2、解决关键技术问题和技术难题
3.针对现场问题进行技术支持我们对您的要求：
1、1年以上工作经验，本科及以上学历，计算机相关专业优先；
2、精通java开发，熟悉java面向对象设计；熟悉常用设计模式，熟练使用SSH、SSM等框架；
3、熟悉oracle、mysql数据库，了解常用的linux命令；
4、熟悉jquery、echart、css、html5等前端技术；
5、具备快速学习能力及问题解决能力；
6、喜爱编程，有强烈的责任心和团队精神，乐于分享与沟通；
我们给您的提升：
1、全称参与整个项目周期、不仅局限在某一环节；
2、过程中技术大牛毫无保留的对您各方面的工作指导；
3、主流技术的实践、技术成果的沉淀、知识网面的拓宽等；加入我们的理由：
1、一切从薪开始：我们提供具行业竞争力的工资
2、靠谱完善的福利待遇：七险一金+餐补+话补+交通补贴+双休+带薪年假+节日福利等都是小意思
3、不让时间浪费在路上：思特奇位于***、紧邻地铁**号线、交通便利、多条公交线路、分分钟抵达公司
4、带你培训带你飞：定期组织外部和内部职业化和管理能力培训（部门内部培训、公司层面培训）、给予个性化的培训资助5、透明的晋升机制：明确的晋升制度、健全的管理体系、工资和职位的提升机会就在眼前你是否已经对小公司的发展空间感到窒息？你是否正在为储存已久的能量寻找更为广阔的平台？别再犹豫了、生命短暂、经不起一份错误的工作、快加入我们吧！"
"职位描述：
        
        Citrix Analytics Platform team is hiring a Senior Software Engineer. The ideal candidate is energized by the thought of developing a big data platform and tools for big data ingestion, processing, and analytics.
The candidate is a seasoned software engineer who designs, develops, troubleshoots and debugs complex software applications, demonstrating for others how to resolve issues in innovative and practical ways. This individual will work on a team of talented engineers responsible for designing, developing, optimizing and extending the Citrix Analytics big data platform.
?
Responsibilities?
Design, develop, and maintain the ? ? ?Citrix Analytics platform
Extend the Citrix Analytics ? ? ?platform by researching and applying new big data technologies and stacks ? ? ?to solve business problems
Maintain the Citrix analytics platform ? ? ?by diagnosing, predicting and correcting scaling problems
Work with large streams of data with tools like Spark, ? ? ?Hadoop, Kafka, Flume, and Cassandra
Contribute to our team’s growing ? ? ?set of development platforms, tools, and processes
Build automation and tools that ? ? ?will increase the productivity of teams located in different GEOs.
Provide input and feedback to ? ? ?teams regarding decisions surrounding topics such as infrastructure, data ? ? ?architectures, and DevOps/SRE strategy
・?????? Support and provide guidance to the company’s software engineering processes and standards
・?????? Pursue and encourage others to acquire information and training regarding trends and advancements within area of specialization, incorporating these improvements where applicable
?
Required Skills?
・?????? Bachelor’s degree or equivalent in computer science, electrical engineering, or related field is preferred, with a minimum of 6 years of directly related work experience
Strong ? ? ?CS fundamentals, data structures, algorithms with good understanding of ? ? ?big data
・?????? Familiar with SQL and MS SQLServer, fluency in database specific programming language (T-SQL)
Hands-on ? ? ?experience in relational databases and NO-SQL databases
Ability ? ? ?to design data models, monitor and debug issue and tuning performance
Understand ? ? ?database design principal is a plus
・?????? Experience of working on development and delivery product based on Cloud Services (Azure, AWS) is a strong plus
・?????? Machine Learning experience is a strong plus
・?????? Hands-on experience in designing and implementing data ingestion and transformation for big data platforms (Hadoop, Spark, kafka, storm etc.), proven track record designing highly parallelized data ingestion and transformation jobs in Spark including Spark Streaming is a strong plus
・?????? Capability of using multiple programming languages (python, Java, JavaScript, Node, Scala, etc.) is a plus
・?????? Security knowledge and experience is a plus
Experience ? ? ?with using automation tools (Ansible, Puppet, Chef) and DevOps tools ? ? ?(Jenkins, Travis-CI, Gitlab CI) is a plus
・?????? Strong communication (verbal and written, Chinese and English) and interpersonal skill
Drive ? ? ?to stay abreast new technologies"
"职位描述：
        
        Citrix Analytics Platform team is hiring a Senior Software Engineer. The ideal candidate is energized by the thought of developing a big data platform and tools for big data ingestion, processing, and analytics.
The candidate is a seasoned software engineer who designs, develops, troubleshoots and debugs complex software applications, demonstrating for others how to resolve issues in innovative and practical ways. This individual will work on a team of talented engineers responsible for designing, developing, optimizing and extending the Citrix Analytics big data platform.
?
Responsibilities?
Design, develop, and maintain the ? ? ?Citrix Analytics platform
Extend the Citrix Analytics ? ? ?platform by researching and applying new big data technologies and stacks ? ? ?to solve business problems
Maintain the Citrix analytics platform ? ? ?by diagnosing, predicting and correcting scaling problems
Work with large streams of data with tools like Spark, ? ? ?Hadoop, Kafka, Flume, and Cassandra
Contribute to our team’s growing ? ? ?set of development platforms, tools, and processes
Build automation and tools that ? ? ?will increase the productivity of teams located in different GEOs.
Provide input and feedback to ? ? ?teams regarding decisions surrounding topics such as infrastructure, data ? ? ?architectures, and DevOps/SRE strategy
・?????? Support and provide guidance to the company’s software engineering processes and standards
・?????? Pursue and encourage others to acquire information and training regarding trends and advancements within area of specialization, incorporating these improvements where applicable
?
Required Skills?
・?????? BS or MS degree in computer science, electrical engineering, or related field is preferred, with a minimum of 3 years of directly related work experience.
Strong ? ? ?CS fundamentals, data structures, algorithms with good understanding of ? ? ?big data
・?????? Familiar with SQL and MS SQLServer, fluency in database specific programming language (T-SQL)
Hands-on ? ? ?experience in relational databases and NO-SQL databases
Ability ? ? ?to design data models, monitor and debug issue and tuning performance
Understand ? ? ?database design principal is a plus
・?????? Experience of working on development and delivery product based on Cloud Services (Azure, AWS) is a strong plus
・?????? Machine Learning experience is a strong plus
・?????? Hands-on experience in designing and implementing data ingestion and transformation for big data platforms (Hadoop, Spark, kafka, storm etc.), proven track record designing highly parallelized data ingestion and transformation jobs in Spark including Spark Streaming is a strong plus
・?????? Capability of using multiple programming languages (python, Java, JavaScript, Node, Scala, etc.) is a plus
・?????? Security knowledge and experience is a plus
Experience ? ? ?with using automation tools (Ansible, Puppet, Chef) and DevOps tools ? ? ?(Jenkins, Travis-CI, Gitlab CI) is a plus
・?????? Strong communication (verbal and written, Chinese and English) and interpersonal skill
Drive ? ? ?to stay abreast new technologies"
"职位描述：
        
        岗位职责：
?
1.??? 设计和实现团队敏捷开发基础流程和平台架构，有迭代以及优化的思想，总结团
队可量化的标准和规范；
?2.??? 设计和开发研发团队项目质量保证体系和基础架构；
?3.??? 处理线上和线下日志，实现数据挖掘和展现的基础平台，优化和提升数据价值；
?4.??? 能够整理和分析研发系统平台的系统瓶颈，通过优化平台设计思路，不断演进和
升级，提升研发团队的业务能力。
?5.??? 负责攻克团队遇到的技术难题， 积极将业界先进技术引入、消化、落地；
??
任职要求：
?1.??? 本科及以上学历，2年及以上相关工作经验；
?2.??? 熟悉Java或者python语言，基础扎实；
?3.??? 对分布式系统构建有一定的经验；
?4.??? 对dev-ops模式有相关经验者优先；
?5.??? 有大规模数据挖掘相关经验者优先；
?6.??? 有较强的逻辑思维能力，良好的沟通能力，喜欢挑战，能面对压力。"
"职位描述：
        
        岗位职责：

分析并解决大数据底层组件（Hadoop, kafka，spark等）的问题解决，保证大数据平台可用性、稳定性
参与大数据平台底层组件的定制开发，包括增加监控、权限管理等工作
解决大数据平台底层组件在数据应用开发中遇到的问题
任职要求：
5年以上的大数据相关开发经验，包括数据接入、数据处理和分析等相关研发经验
熟悉掌握Java或Scala语言，并掌握基本的分布式理论知识
熟悉Hadoop大数据生态技术，对分布式存储HDFS，Seaweedfs，Hbase，Hive，Kafka等有相关源码研究者优先
熟悉并掌握离线和实时数据处理流程，熟练使用Spark处理TB级数据优先
对大数据技术有强烈兴趣，学习新技术能力强"
"职位描述：
        
        岗位职责：
分析并解决大数据底层组件（Hadoop, kafka，spark等）的问题解决，保证大数据平台可用性、稳定性
参与大数据平台底层组件的定制开发，包括增加监控、权限管理等工作
解决大数据平台底层组件在数据应用开发中遇到的问题
任职要求：
5年以上的大数据相关开发经验，包括数据接入、数据处理和分析等相关研发经验
熟悉掌握Java或Scala语言，并掌握基本的分布式理论知识
熟悉Hadoop大数据生态技术，对分布式存储HDFS，Seaweedfs，Hbase，Hive，Kafka等有相关源码研究者优先
熟悉并掌握离线和实时数据处理流程，熟练使用Spark处理TB级数据优先
对大数据技术有强烈兴趣，学习新技术能力强"
"职位描述：
        
        职位职责：1. 研发和优化数据采集、处理、存储流程和相关数据处理工具；2. 优化核心数据存储和计算组件性能，bug修改和优化；3. 开发大数据相关工具，如任务调度、日志处理等；基本要求：1. 计算机相关本科或研究生，5年+的软件研发经验，Linux相关开发经验；2. 熟练使用至少如下一种或者多种语言，Java,Scala,Python,Go；3. 良好的代码习惯、关注细节和代码质量；4. 出色的问题分析和解决能力，能独立解决问题或者与团队合作；5. 2年+的软件设计、研发和大数据相关经验；6. 熟练使用大部分大数据相关生态组件，如Hadoop,Spark,Hive,HBase,Kylin等7. 熟悉分布式系统相关的理论和算法。加分项：1. 参与过Apache的开源大数据项目，有过patch贡献；2. 设计和参与开发过分布式存储或者计算系统。"
"职位描述：
        
        职位职责： 1. 研发和优化数据采集、处理、存储流程和相关数据预处理工具 2. 开发大数据服务相关工具，如任务调度平台、日志处理系统等工作 基本要求： 1. 计算机相关本科或研究生，3年+的软件研发经验，Linux相关开发经验 2. 熟练使用至少如下一种或者多种语言，Java,Scala,Python,Go 3. 良好的代码习惯、关注细节和代码质量 4. 具有大数据应用研发和大数据组件研发经验 5. 熟练使用大部分大数据生态组件，如Hadoop,Spark,Hive,HBase,Kylin等，对1-2个组件的原理有比较深入的了解 加分项： 1. 参与过Apache的开源大数据项目，有过patch贡献"
"职位描述：
        
        工作内容：
1、? 基础数据抽取及临时查询SQL支撑；
2、? 数据集市的完善，优化和拓展兼容性；
3、? 对数据工具的并发需求完善支撑和必要优化，要求稳定性，维护和问题修复；
4、? 嵌套较多的基础数据抓取，和临时任务数据的抓取；
5、? 数据校验及数据清洗；
6、? 开发和完善数据工具系统；
7、? 为业务监控预警体系提供SQL支撑；
8、? 协助DB运维维护数据安全性，并保证数据权限机制的正确；
9、? 协助并参与基于Spark的神经网络、逻辑回归、随机森林、基础贝叶斯等算法应用及预测模型校验。
?
任职资格：
1、? 全日制统招大学本科以上学历，数学、统计、计算机、运筹学等相关专业；
2、? 数据分析方面相关培训更佳；
3、? 1年及以上数据抽取经验，有互联网产品、运营数据需求查询经验；
4、? 具有数据分析和数据仓库建模的项目实践经验优先。
5、? 熟练掌握SQL，Mysql，excel；掌握R，Spark，python更佳；
6、? 熟悉OLAP数据系统。
7、? 责任心强，保密意识好；
8、? 逻辑思维严谨，专注；
9、? 具有数据敏感度，反应迅速，能够良好沟通。"
"职位描述：
        
        岗位职责：
1.?????? 理解公司业务，基于DataWorks开发和维护数据仓库相关，对业务部门提供数据支持；
2.?????? 搭建BI报表体系，满足业务人员需求；
3.?????? 报表的日常维护并根据业务需求寻找优化方案；
4.?????? 临时需求的处理。
?
任职要求：
1.?????? 本科以上，数学、统计、信息专业优先；
2.?????? 1-3年数据分析经验，有教育行业背景优先；
3.?????? 熟悉hadoop、hive、及相关hql等工作，熟悉数据仓库的模型搭建；
4.?????? 熟练使用EXCEL/SQL/Python等数据分析工具。
5.?????? 服从部门的管理及安排，推动分析问题的解决，为营销决策提供支持；
有高度的责任心，良好的沟通能力和团队精神。"
"职位描述：
        
        职位职责：
1、参与数据流程建设，数据仓库架构，包括元数据管理、ETL调度系统、数据集成系统、OLAP等子系统的设计和开发
2、解决业务人员在开发过程中遇到的工具使用、系统优化、数据处理技术等技术问题
3、负责快陪练用户数据仓库数据模型ETL开发和技术优化问题解决
职位要求：
1、计算机相关专业本科及以上学历（在校生）
2、掌握常用数据结构以及基本的算法, 熟悉数据库原理, 网络编程, 多线程编程技术
3、熟悉Linux开发环境, 熟练掌握 SQL 结构化查询语言, 熟悉一种脚本语言(Shell、Python等)
4、熟悉Java/Python服务端系统开发，了解数据仓库架构系统属于加分项
5、熟悉Hadoop / Spark / Hive / Hbase 等组件使用场景， 有相关源码有研究属于加分项
6、具有良好的学习能力、时间和流程意识、沟通协作能力"
"职位描述：
        
        一、岗位职责：
1.参与大数据平台开发、大数据计算、数据清洗、数据分析；
2.参与大数据平台项目需求ETL开发、程序优化、应用与维护；
3.参与数据平台架构的设计、开发、流程优化及解决ETL相关技术问题；
4.负责项目中的关键模块开发、项目实施跟踪、相关文档编写等工作；
5.负责与项目组沟通及产品技术支持。
二、任职资格：
1.掌握数据仓库基础理论知识，了解数据仓库模型设计和ETL设计技术；
2.熟练掌握至少下列的一种编程语言：Java，Scala，Python，其中java必须非常熟练
3.具备apache hadoop-2.x，hive，spark，flume，kafka，sqoop等大数据组件的实际使用经验。
4.具备以上这些组件的集群安装与配置的实际经验
5.具有良好的SQL语言开发技能，熟悉Mysql数据库；
6.具备linux环境下常规运维的能力"
"职位描述：
        
        工作职责：?
1.?深入理解业务需求，对业务建模，设计大数据系统架构，满足业务需求；?
2. 维护和升级现有的大数据集群架构，根据业务需求规划集群和架构的扩展；?
3. 解决工作中遇到的技术难题，指导其他同事的开发工作。??
任职条件：?
1.?计算机相关专业本科以上学历，编程基础扎实，有5年以上大数据开发经验；?
2.?对Hadoop生态和体系架构有深入理解，精通一些常见开源工具源码者优先；
3.?在用户行为日志采集、海量数据处理、数据建模、业务理解、大数据架构设计方面有丰富经验；
4.?擅长挖掘和梳理需求，具有良好的逻辑性思维，能协调好各方需求；
能快速的学习新的开源框架和知识体系，并应用到我们的架构体系中；6.自我驱动，热爱创业、创新文化氛围。"
"职位描述：
        
        工作职责：1. 支持公司数据仓库架构设计与研发，建设PB级数据共享平台；2. 负责业务模型抽象和数据模型的设计开发；3. 负责来自业务团队数据需求的研发支撑；任职要求：1. 计算机相关专业本科及以上学历；2. 2年以上数据仓库平台系统的搭建、开发和维护经验；3. 熟悉ETL、数据仓库开发及相关技术，熟悉Hive等主流数据库技术，精通SQL开发与复杂SQL优化；4. 对Apache Kylin以及其他OLAP技术深入了解者优先；5.工作态度积极，热爱团队合作。"
"职位描述：
        
        岗位职责：
1、参与公司核心数据平台、数据需求的开发，包括：用户增长需求、数据仓库搭建和开发、大数据平台开发和维护等数据开发工作；
2、对现有数据平台进行管理、维护和优化；
3、负责日常的数据统计分析需求，并提供适当的解读分析；

任职要求：
1、统招本科及以上学历，计算机相关专业毕业，有2年以上的数据开发经验；
2、熟悉大数据开发和数据分析的工作流程和规范；
3、熟悉Hadoop及其子项目的体系架构、工作原理，熟练使用Spark进行数据处理；
4、熟悉数据仓库搭建、ETL者优先考虑；
4、编程基础扎实；
5、 熟悉Flume日志收集体系；
6、拥有良好的团队协作及沟通能力，能快速的理解需求，并积极的推动项目进度。"
"职位描述：
        
        职位描述：
工作职责:
1、根据需求完成海量数据的处理任务；
2、开发高并发、实时的流处理作业；
3、对Hadoop、flink、Spark等进行定制二次开发；
4、对实时流数据处理应用进行架构设计；
5、运用开源大数据软件解决问题。

任职资格:
1、至少熟练掌握Java、Python、Scala中的两种语言；
2、掌握Spark、Flink开发，掌握作业调优方式，有海量数据处理经验；
3、掌握流处理框架开发，Spark Streaming、Flink；
4、熟悉主流数据库应用开发，如HBase、MongoDB、Redis、greenplum等，有过高并发读写调优经验；
5、熟悉主流全文搜索框架开发，如Solr、ES；
6、有大数据架构经验，能够根据需求完成大数据架构设计；
7、有一定的大数据分析经验；
7、熟悉Hadoop、Spark生态圈，能运用其解决问题；
8、良好的沟通，团队合作意识，非常强的学习能力。"
"职位描述：
        
        岗位职责：1、公共卫生相关信息系统的数据对接和开发工作；2、根据业务需求查询提取所需数据形成各类报表。任职要求：1、熟练掌握常见数据库操作技能（MYSQL、MSSQL等）；2、熟练掌握桌面软件开发技能，至少精通一门编程语言（C#、JAVA、PHP等）；3、有一定的文字功底，可书写对外技术文档；4、具有较强学习能力和外部沟通能力；5、因与外部系统对接需要，可能会长期出差。"
"职位描述：
        
        岗位职责：1、公共卫生相关信息系统的数据对接和开发工作；2、根据业务需求查询提取所需数据形成各类报表。任职要求：1、熟练掌握常见数据库操作技能（MYSQL、MSSQL等）；2、熟练掌握桌面软件开发技能，至少精通一门编程语言（C#、JAVA、PHP等）；3、有一定的文字功底，可书写对外技术文档；4、具有较强学习能力和外部沟通能力；5、因与外部系统对接需要，可能会长期出差。"
"职位描述：
        
        岗位描述：
1、负责快手离线数据统计、广告报表产出分析、效果监测、归因分析和商务支持
2、负责快手商业化数仓建设、ETL和业务建模
3、负责快手DMP、用户画像等系统研发和数据挖掘算法
4、负责快手广告业务商业分析

岗位要求：
- 对数据敏感，有较强数据分析、逻辑推理能力和解决问题能力；
- 有耐心，能冷静的分析和解决问题
- 有广告数据分析经验优先
- 熟悉机器学习、数据挖掘知识优先
- 有创业者基因：你渴望一个能够共同成长的团队，而不是找一份养家糊口的工作
- 有开发高品质产品、编写高质量代码的自我要求
- 自驱力好、产品sense优秀者优先"
"职位描述：
        
        岗位职责:

1. 基于平台内外部数据源，系统分析挖掘用户画像、作品标签、用户行为等，优化快手平台增长和商业化指标；2. 通过搭建完善的数据分析流程，多维度感知分析业务数据，指导业务策略优化；3. 系统化搭建数据分析平台架构，对接公司内多个部门的业务需求。 
任职资格:

1. 本科及以上学历，2年以上数据挖掘、用户画像、或者数据流程平台架构相关经验； 2. 有数据结构和算法功底，灵活使用Python/SQL/C++等离线在线语言； 3. 目标导向，善于结合具体业务场景，灵活的分析与解决有挑战性的问题； 4. 有数据统计，快速对接业务相关经验，熟悉Hadoop/Hive/Spark等大数据处理；5. 逻辑思维能力强，有技术热情，责任心强，能持续推进业务指标结果。"
"职位描述：
        
        工作职责
1、Hadoop生态子系统的研发、测试与优化工作，解决实际业务需求与性能问题，子系统包括但不限于HDFS，HBASE，YARN，SPARK，KAFKA等；
2、承担数千台规模Hadoop集群的管理工作，解决超大规模Hadoop集群在应用与运行过程中的出现各种问题，保证集群的高效稳定运行； 3、和开源社区保持交流，从社区引入对公司业务场景有帮助的特性与系统，或将内部研发的功能贡献到社区。
任职资格
1、计算机或相关专业本科及以上学历；
2、思维活跃，熟悉Hadoop生态子系统（至少一个），精读过源代码者尤佳，所开发代码被开源社区接受者尤佳；
3、优秀的设计与编码能力，工程质量自我要求高，针对业务需求与问题，可快速设计与实现解决方案；
4、很强的问题分析与解决能力，强烈的责任心，对工作有激情，良好的沟通能力。"
"职位描述：
        
        工作职责
1、Hadoop生态子系统的研发、测试与优化工作，解决实际业务需求与性能问题，子系统包括但不限于HDFS，HBASE，YARN，SPARK，KAFKA等；
2、承担数千台规模Hadoop集群的管理工作，解决超大规模Hadoop集群在应用与运行过程中的出现各种问题，保证集群的高效稳定运行； 3、和开源社区保持交流，从社区引入对公司业务场景有帮助的特性与系统，或将内部研发的功能贡献到社区。
任职资格
1、计算机或相关专业本科及以上学历；
2、思维活跃，熟悉Hadoop生态子系统（至少一个），精读过源代码者尤佳，所开发代码被开源社区接受者尤佳；
3、优秀的设计与编码能力，工程质量自我要求高，针对业务需求与问题，可快速设计与实现解决方案；
4、很强的问题分析与解决能力，强烈的责任心，对工作有激情，良好的沟通能力。"
"职位描述：
        
        工作职责
1. 为快手电商新产品构建业务指标体系，建立和完善日常业务报告体系，能够及时、准确、完整的披露业务方向的运作情况；?
2. 负责快手电商新产品数据统计、报表产出、效果监测、归因分析和商务支持；?
3. 通过专项分析，输出专项分析报告，为快手电商的业务决策和产品方向提供数据支持和指导；?
4. 参与埋点设计、数据生产全流程等技术体系建设和保障工作；?
5. 参与数据集市建模与数据开发，建设共享数据集市；
任职资格
1. 本科以上学历；?
2. 灵活运用hive实现海量数据ETL加工处理，HIVE查询优化；?
3. 熟悉数据集市模型设计方法论，并有实际模型设计及ETL开发经验；?
4. 熟悉常用的数据挖掘、分析工具和方法，有数据挖掘工作经验；熟悉linux平台，精通shell/c(c++)/java/python 等脚本语言的一种或多种，编码基本功扎实；?
5. 具备快速学习能力、跨团队沟通协作能力、团队精神；?
6. [加分]有较强产品sense者优先；?
7. [加分]有数据洁癖和代码洁癖者优先；"
"职位描述：
        
        岗位职责：
1. 面向全球互联网络持续优化直播、点播视频播放体验；
2. 设计优化的QoS数据上报机制，大数据pipeline，分析和报表系统，不间断监测平台的直播点播体验；
3. 通过建设实时数据分析pipeline，实现精细化的CDN调度策略；
4. 通过与多家CDN供应商密切沟通合作，推进质量改进，优化流量成本。

任职要求：
1. 计算机、网络、通信等相关专业硕士以上学历，有移动端拍摄相关优化经验者优先；
2. 精通大数据系统构建，深入理解大数据处理的Lambda架构；有Spark Streaming / Flink应用经验者优先；
3. 具有扎实的计算机网络基础，深入理解流媒体相关协议标准，有互联网络拓扑优化、小运营商优化经验者优先；"
"职位描述：
        
        工作职责
1、 数据仓库研发；
2、 数据集市研发；
3、 用户画像研发；
具体工作：
1、数据收集，反作弊数据仓库，用户数据仓库，ugc数据仓库，审核数据仓库的研发；
2、A/B测试实时ETL研发，转化漏斗分析平台研发。
任职资格
1、有hive，kafka，spark，storm，hbase，flink等两种以上两年以上使用经验；
2、熟悉数据仓库建设方法，对3NF范式，星型模型和雪花模型有一定理解；
3、熟练使用SQL，对类SQL有过优化经验，对数据倾斜有深度的理解，了解特征工程常用方法；
4、具备优秀的数学思维和建模思维；
5、本科三年以上工作经验，硕士两年以上工作经验；"
"职位描述：
        
        工作职责
研发高可靠，高可扩展，易用的一体化数据平台
具体工作：
1、调度系统，元数据系统，权限管理系统，多维分析引擎，数据集成开发平台研发；
2、调度系统，元数据系统，权限管理系统，多维分析引擎，数据集成开发平台性能优化。
任职资格
1、有hive，airflow，kafka，sqoop，hbase，elasticsearch，kudu，impala等两种以上三年以上使用经验；
2、参与或主导过大型数据平台建设项目，对大数据平台有整体的感知能力；
3、熟悉分布式基本原理，对高可靠，高并发系统特性有一定理解； 4、精通java，protocol buffer，具备架构和研发实现能力；
5、本科三年以上工作经验，硕士两年以上工作经验。"
"职位描述：
        
        职位描述：
1. 与产品经理一起完成数据集成平台相关需求的整理，并独立设计实现方案；
2. 负责一站式数据集成开发平台的后台实现。

任职要求：
1.统招本科及以上学历，2年及以上Java后台开发经验；
2. 扎实的Java基础，熟悉intellij，git等开发相关工具，熟悉面向对象和接口设计技术，包括设计模式；
3. 熟悉主流的Java开源框架，对Netty、 Spring、 Tomcat等有深入的了解和使用；
4. 熟悉Redis和Memcached等缓存技术，有实际应用经验；
5. 扎实的计算机专业基础知识，包括操作系统、 数据结构等；
6. 逻辑思维强，学习能力强。
符合以下条件优先：
1. 研究过开源代码并有代码贡献；
2. 有大数据使用经验，熟悉hdfs，hive，hbase等大数据系统。"
"职位描述：
        
        职位描述：
研发高可靠、高可扩展、易用的公司统一大数据平台，包括大规模工作流调度、异构数据源交换和同步、全链路数据血缘分析、精细智能化SLA管控系统等核心大数据系统和工具链的研发和性能优化。
任职要求：
1、有hive，clickhouse，presto，impala，airflow，kafka，datax，sqoop，mapreduce，spark，flink等两种以上三年以上使用经验；
2、参与或主导过大型数据平台建设项目，对大数据平台有整体的感知和把控能力；
3、熟悉分布式基本原理，对高可靠，高并发，高吞吐系统特性有一定理解；
4、精通java，具备较强的分布式架构和研发实现能力；
5、本科三年以上工作经验，硕士两年以上工作经验。"
"职位描述：
        
        工作职责
1、 参与公司数据需求收集和整理；
2、 对接业务与分析人员，负责数据集市的研发；
3、 处理支持日常数据统计和数据分析工作。
任职资格
1、 计算机相关专业，熟练使用SQL，有三年以上的hive使用经验；?
2、 懂得基本分布式计算原理；
3、 熟悉基本数据仓库模型?；
4、 喜欢新技术，乐于接受挑战，对数据敏感，具备良好的客户需求理解能力，良好的团队协作和优秀个沟通能力。"
"职位描述：
        
        # 关于我们 #
心知科技是一家专注于处理和计算自然界大数据的公司。我们利用大数据和人工智能技术分析海量的自然界大数据，帮助企业降低风险、提高收益，把控天气与环境变化带来的机遇和挑战。

#?工作内容?#
负责海量气象、环境等自然大数据的处理、分析和计算
负责开发底层数据处理和存储平台
参与利用机器学习和人工智能技术提高天气预报准确性的开发

#?职位要求?#
有较强计算机编程能力，熟练掌握Python等数据处理编程语言；
熟悉数据分析的基本原理和技术，有一定数据可视化的能力；
熟悉主流SQL、NoSQL数据库的使用；
熟悉常见气象数据格式，熟悉数值模式、气象统计者优先；
对Linux相关的各类技术情有独钟；
追求架构和代码的极致优雅；
对工作追求卓越，相信“认真你就赢了”。

#?当你加入这个团队?#
可以和来自微软、SAP、亚马逊等公司的精英们碰撞；
体验创业公司独有的工作模式和文化，享受硅谷式的弹性工作时间；
除了基础的五险一金，我们还有：
年度至少13薪，并有机会获得股票期权
已认证为高新技术企业，可办理《北京市工作居住证》
中关村最高端的写字楼和办公环境，地下餐厅、电影院、健身房一应俱全
午餐补贴、免费零食饮料投喂
租房补贴
Macbook Pro + 专业显示器
每周羽毛球
生日礼物
年度体检、商业医保等等~
当然最重要的是，和我们一起让人们站在上帝视角认知地球！"
"职位描述：
        
        岗位职责：

1.参与数据相关项目的需求分析，技术评估，方案设计;
2.负责大规模数据系统的架构设计，为业务提供高可用、高效的数据存储和计算支撑；
3.负责离线、实时的数据存储和加工处理，保证数据质量，负责数据流程监控体系的建立和维护；
4.负责大数据相关产品开发，结合算法模型进行处理流程整合，支持需求分析师和算法工程师的数据及平台需求；
5.负责数据管理，推进数据质量管理与改进。?

任职要求：

1、熟悉数据库架构发展方向，了解主流的框架、库使用和原理，互联网行业的特性及发展趋势

2、根据业务需求设计数据库逻辑和模型，数据库问题优化和解决
3、深入了解数据库应用的业务需求，研究新的数据库架构发展方向
4、人际交往和沟通能力，团队管理和跨部门协调能力

特殊技能项：熟悉python、java的编程语言，精通SQL，了解Spark、Storm等大数据相关技术"
"职位描述：
        
        任职要求：
1.?3年以上大数据相关经验，熟悉Spark相关技术，至少有2年以上Spark开发经验。
2.?熟悉Spark?Streaming、Spark?SQL，对Spark体系结构、运行机制和源码有深入研究。
3.?熟悉Scala、Java、Python语言，有丰富的分布式编程经验。
4.?熟悉常用的设计模式，数据结构和算法，具备优秀的技术架构的设计能力。
5.?熟悉常用开源分布式系统，对Hadoop/Hive/Spark/Storm/Flink/HBase/Kafka/Zookeeper中的一项或多项有深入了解，能够独立排查及解决分布式系统的问题。
6.?熟悉ElasticSearch、Lucene优先。
7.?有推荐系统、数据挖掘等领域的理论基础和研发经验优先。
8.?有过海量数据系统开发经验者优先。
9.?对技术有强烈的兴趣，喜欢钻研，具有良好的学习能力。
10.?责任心强，工作认真负责，能够承受一定的工作压力。"
"职位描述：
        
        技能要求:HADOOP，HIVE、SPARK，KAFKA，NIFI，ES，ORACLE
语言要求:JAVA、scala、Python
入职要求:
1.本科以上学历，工作五年以上
2.从事过大数据相关工作
3.做过HIVE-SQL编程开发，熟悉SQL优化流程或做过SPARK实时流开发"
"职位描述：
        
        1、4年以上开发工作经验；2、两年或两年以上大数据项目工作经验；3、熟悉cdh、hadoop、hive、impala、spark、ETL、数据可视化等组件及技术；4、熟悉Liunx、Unix操作系统开发环境使用。"
"职位描述：
        
        岗位职责：
1、负责对设计方案的还原。提供高质量的代码实现，测试和构建自动化工具；
2、负责日常开发与平台运维
岗位要求：
1、 必须拥有3年以上的Spark和大数据生态系统经验，包括构建涉及spark，kafka，hadoop / cassandra / mongodb / hbase的数据管道解决方案；
2、拥有大数据技术框架开发经验包括但不限于Spark / Scala，MapReduce，Hadoop，Hive，HBase，Pig，Zookeeper；
3、2年以上大数据平台项目实施经验；
4、 熟悉分布式计算设计模式，算法，数据结构，安全标准和协议；
5、编程技巧（任何语言）；
6、具有BI系统的开发实施经验，能够独立开发设计数据仓库、ETL设计、Cube建模、OLAP开发、报表开发等；
7、一定的应用系统分析与设计能力，有良好、规范的编程习惯和文档编写习惯；
8、有较强的学习能力，对技术有钻研精神，并有较高的热情，热衷于新技术、新理论、新开发实践的学习和实践；"
"职位描述：
        
        岗位职责：
1、负责大数据平台的搭建、发布部署及相关维护工作；
2、负责大数据平台和集群的预警和监控，搭建监控机制以及及时发现集群问题，持续提升系统稳定性
3、跟进并处理系统事件，对系统问题及故障解决跟踪优化，负责服务状况与服务质量报告，不断提升集群服务质量；
4、梳理优化业务使用集群的流程和规范，使集群使用在资源利用、质量等方面均达到较高水
5、日常跟踪业界技术发展动态，并结合业务发展需求，研究引入新技术。
任职要求：
1、3年以上hadoop集群使用经验；熟悉hadoop相关组件的原理，具备调优和性能优化能力。组件包含不限于：Hadoop/Impala/Hive/Spark/flink/storm/kylin 等等；
2、有实际踩坑经历, 对于相关组件的版本跟进, 补丁跟踪, bug追踪等有相关经验；
3、熟悉计算机网络，精通linux，熟悉shell、perl、java、scala或python其中两种以上编程语言；
4、实际处理过各种集群在线版本升级, 数据迁移, 集群扩容, 稳定性监控等工作；
5、熟悉主流数据库技术，熟悉mysql和pg优先，熟悉常用的ETL工具，kettle优先；
6、积极主动、学习能力强、沟通能力强、肯吃苦耐劳。"
"职位描述：
        
        岗位职责
1、核心数据分析建模，打造金融行业内最先进的大数据大数据风控等深度金融分析模型；
2、研究最前沿金融科技大数据成果在金融风控的逻辑与模型。
?
任职资格：
1.? 重点大学毕业生，计算机相关、数学、统计学等相关专业；
2.? 熟悉数据建模知识、数据挖掘理论，熟练掌握数据分析体系架构、方法；
3.? 熟悉至少一门主流数据开发或数据分析编程语言，熟悉大数据生态圈相关组件的整合应用、了解实时计算框架；具备优秀的数据编程能力；
4.? 善于分析、钻研，对创新事物有浓厚兴趣和积极性，能够持续研究学习国内外大数据新技术；
5.? 责任心强，良好的沟通能力和团队意识。"
"职位描述：
        
        岗位职责：1、负责大数据平台的架构规划设计，构建高性能的存储、计算和访问平台；2、建设稳定高效的实时计算体系，包括日志采集、数据流传输、实时计算和可扩展服务；3、关注业界最新技术，深入理解业务特征，前瞻性的进行技术升级，支持业务的高速发展；任职资格：1、5年以上大数据开发和架构设计经验，深刻理解大数据技术特征和应用场景；2、熟悉大数据开源体系架构，如 hadoop、spark、storm、kafka、hbase 等；3、优秀的团队意识和沟通能力，能够有序推动业务发展和技术进步；"
"职位描述：
        
        工作职责:
1、负责数据仓库工具开发
2、负责核心系统建设和数据仓库建设
3 、针对业务场景编写ETL通用工具脚本
4、开发数据血缘关系管理系统，优化调度与任务依赖系统
岗位要求：
1. 计算机或数学相关专业大学本科及以上学历?
2. 3年以上大数据开发（ETL方向）经验?
3. 熟悉Linux开发环境，熟练掌握Python，
4. 掌握mysql、postgresql、greenplum、redis、mongodb等一种或多种数据库，掌握sql调优技术?
5. 熟悉Hadoop生态圈开源技术，掌握包括HDFS、Spark、Kafka、flume、sqoop、datax等?
6. 熟悉ETL系统，包括元数据、数据质量、调度系统（azkaban）、影响分析等等，有开发过调度系统经验者优先?
7. 有TB级别实时数据处理经验者优先，有mysql DBA工作经验者优先，对Apache顶级开源项目有深入理解者优先"
"职位描述：
        
        工作职责:
1、负责数据仓库工具开发
2、负责核心系统建设和数据仓库建设
3 、针对业务场景编写ETL通用工具脚本
4、开发数据血缘关系管理系统，优化调度与任务依赖系统
岗位要求：
1. 计算机或数学相关专业大学本科及以上学历?
2. 3年以上大数据开发（ETL方向）经验?
3. 熟悉Linux开发环境，熟练掌握Python，
4. 掌握mysql、postgresql、greenplum、redis、mongodb等一种或多种数据库，掌握sql调优技术?
5. 熟悉Hadoop生态圈开源技术，掌握包括HDFS、Spark、Kafka、flume、sqoop、datax等?
6. 熟悉ETL系统，包括元数据、数据质量、调度系统（azkaban）、影响分析等等，有开发过调度系统经验者优先?
7. 有TB级别实时数据处理经验者优先，有mysql DBA工作经验者优先，对Apache顶级开源项目有深入理解者优先"
"职位描述：
        
        岗位职责：
1、负责大数据平台的设计以及开发工作，包括平台组件选型及搭建、平台服务开发；
2、负责离线/实时的数据存储和加工处理，保证数据质量，负责数据监体系的建立和维护；
2、负责海量数据的清洗、处理和挖掘工作，支持数据分析师和算法工程师的数据需求；
3、对数据敏感，基于海量数据进行业务分析，灵活运用可视化工具，参与产品与应用的数据研发，分析数据成因，发掘数据商业价值；
3、研究前沿技术，解决实际场景中的业务问题，优化离线/实时大数据计算任务的性能；

任职资格：
1、计算机或相关专业，3年以上互联网大数据开发经验，有互联网医疗行业经验优先；
2、熟悉Linux/Unix开发环境，精通python/java/shell，扎实的数据结构和算法功底；
3、具有丰富的数据加工处理经验，对数据处理、数据清洗，数据建模、数据分析等有深刻认识和实战经验；
4、熟练使用mapreduce、hive、spark等进行数据加工；熟悉hive和spark的编写和性能调优；
5、熟悉常用开源分布式系统，对Hadoop/Hive/Spark/Storm/Flink/HBase中的一项或多项有深入了解;，能够独立排查及解决分布式系统的问题；
6、清晰的逻辑分析和表达能力，良好的团队精神和合作意识，强烈的责任心，对工作有激情，良好的沟通能力；"
"职位描述：
        
        岗位职责:1. 负责大数据平台、机器学习平台的开发、自动化部署；2. 承担基于Hadoop/Spark生态的大数据离线/实时处理平台的开发。岗位要求：1. 本科及以上学历；5年以上工作经验；2. 扎实的编程基础（熟练使用java、Python），有大数据平台开发经验；3. 熟练使用Hadoop、Spark等大数据处理平台；4. 加分项：机器学习平台开发经验，DevOps经验，机器学习模型训练和应用经验，特征工程经验；5. 有创新意识、协作意识，自我驱动力强，具备很强抗压能力。"
"职位描述：
        
        1，主要负责用户画像、运营平台、推荐等相关数据应用产品设计、研发2，增强、完善大数据到数据价值应用的桥接功能3，保障系统高性能、高质量、完全运行4，提升数据对业务的价值产出和创新能力职位要求：1，精通java，熟悉java web开发；掌握scala、python等任一语言2，对开源框架Spring cloud、kafka、zk、redis、Hbase等有实际应用经验，并能熟练应用3，熟悉至少一种流计算框架，如Spark、Flink等4，熟悉主流基于大数据的sql引擎，如impala、presto、clickhouse、hive等5，有用户画像、BI平台、推荐系统实际项目研发经验优先6，能够自驱，有创新意识，对数据价值应用思路清晰"
"职位描述：
        
        岗位职责：
1.参与海量数据的数据仓库设计、数据模型体系构建及数据主题设计和开发；
2.规划及建设数据报表系统与基础数据平台，推动数据产品化；
3.完成日常数据监控，异常分析，支撑和规划各业务数据需求，为日常运营分析提供数据统计支持。
岗位要求：
1.计算机、数据等相关专业本科以上学历，熟练数据仓库建模理论，5年以上相关领域实践经验；
2.熟悉业界数据仓库建模方法,具有DW/BI应用&数据架构体系中金融领域、互联网领域的专项建设经验;
3.具备数据仓库架构设计、模型设计、ETL设计，调度的相关经验,具备海量数据处理SQL开发及优化；
4.熟练使用HIVE，azkaban 熟悉 HBASE KYLIN SQOOP或DataX；
5.熟悉数据仓库周边生态系统（元数据，主数据，数据质量系统）等；
6.需要有好的团队配合意识和抗压能力"
"职位描述：
        
        【岗位职责】
1、负责微店数据仓库建设，设计、优化和落地；
2、负责数据ETL、建模，业务数据开发和调优。

【职位要求】
1、数据仓库有较扎实的理论基础，数据模型建设、应用层建设有比较丰富的经验；
2、对自己专注的技术或业务领域有深入的理解和把握，能够有自己专注的技术长项；
3、熟练编写各类SQL，对sql有优化经验优先；
4、有Hadoop、Hive、Spark、Impala等大数据技术使用经验者优先；
5、热爱大数据，性格沉稳，沟通顺畅，工作经历稳定。"
"职位描述：
        
        【数据平台研发负责人】
职位描述：

 负责数据后台的搭建和维护工作；
 负责数据仓库，相关的调度系统，展示系统及其他子系统的研发，维护工作；
 负责运营相关的日常数据提取，olap数据平台和报表研发工作；
 参与数据治理工作，提升数据易用性及数据质量；
 参与大数据应用规划、为数据挖掘、应用团队提供应用指导；
 业务把关与团队管理。


职位要求：

 熟悉C++、JAVA、中的一种或多种编程技术，编程能力强；
 3年以上报表开发python，数据开发的经验，2年以上互联网业务数据仓库模型设计、开发经验，可以针对复杂的业务抽象良好的工程架构，支持快速开发；
 掌握Mysql，Hadoop，Hive，Hbase等开源软件和框架，熟悉其中一两项，精通加分；
 有数据开发经验加分；全栈工程师加分；有对业务后台需求分析理解的能力加分；
 熟练使用Hadoop及Hive，熟悉HQL、Java、Python等编程语言；
 具有web开发经验者优先；
 有ElasticSearch、Druid、HBase使用经验者优先。"
"职位描述：
        
        【数据仓库开发专家】
职位描述：

 业务数据仓库建设和管理，包括但不限于数据质量、数据模型、数据安全相关标准的制定；
 负责与业务团队协同规划与设计数据仓库模型，并快速实现；
 参与数据治理工作，提升数据易用性及数据质量；
 参与大数据应用规划、为数据挖据、应用团队提供应用指导。


职位要求：

 本科以上学历，5年以上互联网业务数据仓库模型设计、开发经验；
 熟练使用Hadoop及Hive，熟悉HQL、Java、Python等编程语言；
 具有web开发经验者优先；
 有ElasticSearch、Druid、HBase使用经验者优先。"
"职位描述：
        
        岗位职责：
1、完成公司大数据平台、数据仓库、数据集市的规划及实现；
2、参与大数据平台相关业务产品需求调研，需求分析，并独立完成核心模块代码实现；
3、参与现有大数据平台构架的改进，提质量及效率；
4、协助测试人员进行软件的功能及性能测试。
?
任职资格：
1. 本科以上学历，计算机相关专业；
2. 5年研发以上相关工作经验，3年以上互联网大数据平台研发经验；
3. 有项目管理经验，参与过过多个大型的数据仓库研发项目；
4. 精通数据建模、数据标准管理、元数据管理、数据质量管理 ;
5. 精通大数据Hadoop体系的相关技术，具有大数据平台的架构实战经验。具Flume/Kafka/Sqoop/Hive/Storm/Spark/Hbase等工具的实际开发经验；
6. 良好的沟通表达（口头及书面）和文档交付能力、良好的团队合作精神压力承受能力;
7. 有数据挖掘，机器学习相关经验者优先考虑；
8. 有标签系统、用户画像系统、推荐系统的设计和研发经验的优先考虑;
9. 熟悉OLAP相关技术, 如KylinDruid等工具的实际开发经验的优先考虑."
"职位描述：
        
        工作职责:1、使用大数据相关的技术(Hive、hadoop、hdfs、hbase，es等）解决业务相关问题； 2、基于海量数据建立用户画像，以及对用户画像应用3、利用大数据平台实现对数据的分析和处理； 4、负责各类业务调研，并与公司其他部门负责沟通协调； 5、负责离线、实时系统中数据处理工作（数据采集、清洗、汇总、集成等）； 任职资格:1、2年及以上ETL开发或分析经验，至少有1年大数据开发或分析经验； 2、精通python、shell、java、scala等中的1种以上 ；精通hsql； 3、熟悉主流数据库（Oracle、postgresql、Mysql、Sql Server）中的1种及以上，精通SQL、有较好的SQL性能调优经验； 4、熟练掌握MapReduce原理、对kafka、Hadoop、Hbase、Hive、ES、spark等主流大数据相关软件有充分的了解；5、熟悉Spark、SparkSQL、SparkStreaming等框架；6、具有良好的逻辑思维能力，善于学习，与团队沟通无障碍；7、有数据仓库ETL经验，对调度、元数据、数据质量有一定理解； 8、有互联网数据ETL经验优先；熟悉常用分析方法，挖掘算法优先； 9、有持续学习的能力；喜欢开源软件，乐于知识分享；对工作认真负责；可以独立承担较大工作压力；"
"职位描述：
        
        工作职责:1、负责数据仓库数据模型管理工作（建模，设计，实施，应用结合）；2、负责数据仓库模型标准制定，实施，监督，推广工作；3、负责海量数据建模，自动化分析处理和统计工作，降低数据使用成本；4、负责小组日常业务需求开发，资源合理分配；5、负责数据源调研、入库、开发的全流程工作，并保证数据质量；6、承担数据抽取、清洗、转化等数据处理程序开发。任职资格:1、三年以上数据仓库建模经验；了解数据建模方法论，并且在项目中实践甚至优化扩展；有大型项目建模经验优先；对数据模型有独到理解；2、精通Hadoop，hive，spark，datax，kafka等大数据技术；3、精通SQL，对SQL优化有一定经验；4、有数据仓库ETL经验，对调度、元数据、数据质量等有一定理解；5、有良好的逻辑思维能力，主动思考，善于学习，与团队沟通无障碍；6、有互联网数据ETL经验优先；熟悉常用分析方法，挖掘算法优先； 7、有建设实时平台、实时数仓经验优先；了解医疗行业优先8、有持续学习的能力；喜欢开源软件，乐于知识分享；对工作认真负责；可以独立承担较大工作压力；"
"职位描述：
        
        工作职责:
1、开发径卫数据中心的核心功能模块，包括数据采集、分布式数据存储、数据批处理、流式计算、数据挖掘等方面。
2、负责统筹整个开发的进度和时间。
任职资格:
1、计算机科学与技术、软件工程、或其他计算机相关专业本科及以上学历；
2、3年以上数据仓库、商务智能、大数据平台类项目的实战经验；
3、2年以上技术管理及团队管理经验；
4、熟悉Linux（CentOS/Ubuntu)的操作和管理；
5、精通Java及SQL语言；
6、熟悉传统的数据仓库和BI等相关技术：ETL，DW，BI, OLAP等；
7、熟悉MySQL、SQL Server、PostGreSQL等关系数据库；
8、有Vertica、Greenplum等MPP数据仓库相关经验者更佳；
9、Hadoop/Spark大数据生态相关技术：Hadoop、Spark、Spark Streaming、Hbase、Hive等；
10、熟悉Kafka、RabbitMQ等消息中间件；
11、有从无到有构建过数据类产品的经验"
"职位描述：
        
        岗位职责：
1.? ? ? ? ?参与大数据平台设计、开发、优化数据接入、数据存储、数据计算服务框架；
2.? ? ? ? ?参与大数据平台平台功能开发、建设，包括数据传输、调度、主数据，分析系统等；
3.? ? ? ? ?助力数据化运营业务，构建丰富多样的大数据应用。
?
任职要求：
1.? ? ? ? ?大学本科以上学历，3年以上数据开发经验；
2.? ? ? ? ?熟悉ETL开发，对Hive SQL、Presto SQL、Kylin、Druid等开发和原理性调优有实战经验
3.? ? ? ? ?熟悉python、scala、R编程语言
4.? ? ? ? ?熟悉Hadoop生态，了解存储、计算框架的原理
5.? ? ? ? ?熟悉Redis、HBase等NOSQL数据库，熟练掌握jwm性能调优
6.? ? ? ? ?熟悉Spark/Kafka/elasticsearch
7.? ? ? ? ?熟悉分布式计算系统的工作机制，具有分布式文件系统、分布式数据库系统、集群存储系统等计经验
8.? ? ? ? ?良好的语言沟通与表达能力和自我驱动力
9.? ? ? ? ?具有大数据全链路开发优先
具备强烈的团队协作精神、责任心和使命感"
"职位描述：
        
        1.参与大数据平台设计、开发、优化数据接入、数据存储、数据计算服务框架；

2.参与大数据平台平台功能开发、建设，包括数据传输、调度、主数据，分析系统等；

3.助力数据化运营业务，构建丰富多样的大数据应用。

任职要求：

1.大学本科以上学历，4年以上数据开发经验；

2.熟悉ETL开发，对Hive SQL、Presto SQL、Kylin、Druid等开发和原理性调优有实战经验，熟悉python、scala、R编程语言；

3.熟悉Hadoop生态，了解存储、计算框架的原理，熟悉Redis、HBase等NOSQL数据库，熟练掌握jwm性能调优；

4.熟悉Spark/Kafka/elasticsearch，熟悉分布式计算系统的工作机制，具有分布式文件系统、分布式数据库系统、集群存储系统等计经验。"
"职位描述：
        
        岗位职责
1、负责大数据数据平台建设，带领团队建设数据采集平台及计算平台；
2、负责分布式数据平台框架下，大数据开发和应用架构的研究和设计；
3、理解用户数据分析和挖掘应用场景，抽象为数据产品需求，不断完善基础数据的建设。

任职要求
1、五年以上大数据开发经验，具备较强的数据抽象能力和架构设计能力；
2、熟悉大数据平台生态如hadoop、spark、storm、kalfa、flume等；
3、有丰富的大型平台的架构及设计经验，精通数据结构和算法；
4、对技术有持续追求，强烈的技术领导力和责任心。"
"职位描述：
        
        岗位职责：1、负责项目中流式ETL模块开发和维护；2、负责数据对接和对外服务设计、开发和维护；3、负责基于大数据平台的应用设计、开发和维护；4、负责大数据子系统问题收集、分析和改进方案建议；5、负责规划大数据子系统后期的需求和方案设计。
技能要求：1、大学本科4年以上工作经验，计算机相关专业。2、至少3年以上的Java开发经验，2年以上大数据应用系统的开发和设计经验。3、精通Hadoop、Storm、Spark三个中的任意二个，深刻理解原理和适用场景。4、精通Hive、HBase仓库设计，深刻理解MR运行原理和机制。5、精通Java开发，深刻理解J2EE规范和相关技术。6、熟悉Linux、Shell、Nginx、Tomcat、Redis、Kafka、Oracle、Mysql等相关技术。7、快速研究和学习技术能力"
"职位描述：
        
        1、根据业务需求进行数据报表的开发，作为业务运营，营销策略的客观依据；
2、跟进报表需求进行复杂sql逻辑的开发，实现数据指标计算；
3、跟进业务需求定制开发数据调用接口。

任职要求：
1、本科以上学历，至少3年以上大数据开发经验
2、熟悉Hadoop技术体系的各种分布式计算原理，有hadoop计算集群在实际项目上的开发和维护经验，有Mapreduce/hive/hbase／Storm / Spark 实际应用经验及编程经验；
3、熟悉大数据处理模式，有PB级数据处理和分析处理经验或云平台开发经验优先；
4、能熟练解决hadoop技术平台各类环境问题，能对个别组件实施改造和裁剪；
5、有架构经验者优先；
6、个性开朗，对技术钻研好学、逻辑思维能力强，沟通能力优秀，有团队合作精神。"
"职位描述：
        
        工作职责：
1 负责数据仓库及算法平台的研发工作；
2 海量数据的采集、清洗、传输、存储、计算、调度等全方位设计与开发；
3 挖掘分析用户行为数据，完成各种维度统计数据的计算。
任职要求：
1 统招本科及以上学历，计算机相关专业，熟悉算法设计、数据结构、操作系统等基础知识；?
2 熟悉Hadoop/HBase/Spark/Hive/Python/Java/Scala等平台和开发语言；
3 具有数据分析实习经验者优先；
4 具备良好的沟通能力、团队合作精神、责任感和抗压能力。"
"职位描述：
        
        工作职责：
1.负责数据建模、数据开发、数据生产流程优化及相关技术问题的解决；?2.深入理解公司业务，负责业务相关各数据统计平台、日常报表及数据可视化的设计开发工作；?3.负责数据相关平台的搭建、开发、维护、优化；4..负责相关产品实时数据开发；5.负责数据分析、加工、清理、处理程序的开发；
6.协助管理团队人员事务。
岗位要求：
1.本科及以上学历，有5-10年数据相关开发经验以及团队管理经验；?2.精通SQL，有较好的SQL性能调优经验，理解Hive/Mysql 基本原理和调优策略；?3.熟悉类UNIX系统环境下的开发，掌握Python、Shell等脚本语言至少一种；?4.了解大数据常用技术，Hadoop/HBase/调度系统/Kylin等；?5.对数据和业务敏感，有良好的逻辑和沟通能力； ?6.具有数据仓库相关经验以及海量数据处理、互联网从业背景。"
"职位描述：
        
        岗位职责：
负责产品的整个数据部分的相关工作。包括技术选型、架构设计、数据模型设计、数据字典维护、 数据库表设计、ETL及指标计算开发等；
任职要求：
1．本科及以上学历，3年以上工作经验，参与过至少两个数据类项目；
2．熟练掌握至少一种主流数据库?Oraclea?或?mysql并且有相应的调优经验；
3．熟悉掌握至少一种开发语言java/C/C++等；
4．熟悉并且对ODS、DM、DW有深刻的认识和理解；
5.?熟悉至少一种NoSQL数据库，如MongoDB、Memcached、Redis、HBase等；
?
【我们的福利】
工作时间： 周一至周五提供加薪机会：每年的4月或10月
人才推荐：人才推荐奖金、年度人才推荐之星评比
出差福利：出差补贴、带薪出差探亲假、探亲假费用报销、出差住宿
假期福利：除法定的节假日之外，还享有年假，婚假，丧假，生育假等
办理调户：为符合条件的有意向的员工办理入户（限北京和深圳地区）
其他福利：年终奖、五险一金、年度旅游、年度体检、生日福利、中秋礼金、结婚礼金、生子礼金、餐补、不定期团队活动"
"职位描述：
        
        任职要求：
1、 二年以上Java Web应用开发经验，本科及以上学历；
2、 熟练掌握Java、Scala中的至少一门语言，有Python、R语言开发经验优先；
3、 熟悉开源框架Spark、Hadoop、Storm中的一种，有实际项目应用经验；
4、 熟悉Oracle、Mysql等常用关系数据库，熟练编写SQL语句；有分布式nosql数据库应用经验优先；
5、 熟悉Linux环境，能够熟悉使用shell脚本；
6、 对大数据技术有强烈兴趣，有志于往大数据处理方向发展；工作认真踏实，动手和学习新技术能力强。

岗位职责：
1、 从事Hadoop、Spark、Storm等分布式大数据平台产品的设计和开发；
2、 针对部门大数据业务进行大数据分析、挖掘应用的开发；
3、 为项目开发人员提供大数据技术指导及解决大数据平台应用中遇到的技术难题。

公司福利：
工作时间： 周一至周五
提供加薪机会：每年的4月或10月
人才推荐：人才推荐奖金、年度人才推荐之星评比
出差福利：出差补贴、带薪出差探亲假、探亲假费用报销、出差住宿
假期福利：除法定的节假日之外，还享有年假，婚假，丧假，生育假等
办理调户：为符合条件的有意向的员工办理入户（限北京和深圳地区）
其他福利：五险一金、年度体检、生日福利、中秋礼金、结婚礼金、生子礼金、餐补、不定期团队活动"
"职位描述：
        
        岗位职责：1. 参与数据标准规范的制订；2. 沟通协调数据的采集、标注工作；3. 参与部分测试数据的采集录制工作； 4. 负责数据的管理工作；5. 编写程序进行数据分析、数据转换、数据清洗等工作；6. 参与数据分析工具的开发；任职要求：1. 具备基本的python语言编程能力；2. 了解项目开发过程，有一定的项目开发经验；3. 具有良好的沟通协调能力、团队合作精神；4. 工作积极主动、耐心细致。"
"职位描述：
        
        岗位职责：
负责设计、开发、维护大数据分析处理相关的软件产品和模块；

任职要求:
1. 本科及以上学历，计算机相关专业；三年以上大数据工作经验；
2. 熟练使用Python 语言；
3. 熟悉Linux系统；熟练掌握大数据系统后端开发，如多线程、网络等；
4. 熟悉MongoDB，ElasticSearch，Hadoop，Hive，Spark等组件，有实际数据应用系统开发经验；
5. 熟悉oracle，mysql数据库，掌握常用sql命令；
6. 有一定的架构设计能力,有很强的分析、解决问题的能力；
7. 工作态度踏实、认真、积极主动，能承受一定工作压力，有责任心、有团队协作能力。"
"职位描述：
        
        岗位职责：1. 参与Hadoop等分布式计算平台的架构、设计和布局。 2. 负责针对海量的用户行为数据进行统计、分析与挖掘，提取商业价值。 3. 负责Hadoop相关业务的性能优化与提升，集群性能优化，不断提高系统运行效率。? 
任职要求： ? ?1.计算机、数学等相关专业，统招本科及以上学历。  ? ?2.1-2年以上java开发经验，对JVM原理有一定了解。  ? ?3.2年以上大数据开发经验，对Mapreduce、Hdfs的原理有深入的了解。  ? ?4.有TB级别大数据项目经历，相关工作经验丰富者优先考虑，具备丰富的大中型开发项目的总体规划、方案设计经验者优先考虑；  ? ?5.应具备以下技能，优先考虑：  ? ?（1）精通Hadoop、Hive、Spark等非实时分析工具的一种或者多种。  ? ?（2）熟悉Redis、Hbase、MongoDB等NoSql产品中的一种或者多种。  ? ?（3）熟悉Storm、Spark-Streaming、Kafka、Flume-NG等实时计算的一种或多种。  ? ?（4）了解Presto、Impala、Shark、Phoenix等交互式查询引擎的一种或多种。  ? ?（5）了解spark、Tez等内存计算的一种或多种。 ? ?（6）了解RDBMS：Oracle、MySql一种或二种。"
"职位描述：
        
        工作职责：
1. 负责产品的数据处理、抽取、清洗、转换工作；
2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。

任职资格：
1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；
2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；
3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；
4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；
5. 海量数据处理和挖掘经验者优先；
6. 有docker容器服务技术经验优先；

7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；"
"职位描述：
        
        1. 配合业务场景，使用机器学习技术设计数据建模（模型/算法）解决方案；
2. 对业务数据进行清洗、分析和建模，并负责各类数据挖掘模型的开发、应用、部署和监控优化。
?
任职要求：
1. 本科以上学历，数学与应用数学、统计学、计算机等相关专业毕业，2年以上数据挖掘/机器学习经验；
2. 熟悉数理统计、机器学习算法（线性回归、逻辑回归、随机森林，时序预测，聚类算法），并能根据需求选取适当算法应用到业务中；
3. 熟悉python、kafka、flink、habse、hadoop等大数相关技术和架构；
4. 海量数据处理和挖掘经验者优先；
5. 熟悉docker容器服务技术经验都优先。"
"职位描述：
        
        1. 配合业务场景，使用机器学习技术设计数据建模（模型/算法）解决方案；
2. 对业务数据进行清洗、分析和建模，并负责各类数据挖掘模型的开发、应用、部署和监控优化。
?
任职要求：
1. 本科以上学历，数学与应用数学、统计学、计算机等相关专业毕业，2年以上数据挖掘/机器学习经验；
2. 熟悉数理统计、机器学习算法（线性回归、逻辑回归、随机森林，时序预测，聚类算法），并能根据需求选取适当算法应用到业务中；
3. 熟悉python、kafka、flink、habse、hadoop等大数相关技术和架构；
4. 海量数据处理和挖掘经验者优先；
5. 熟悉docker容器服务技术经验都优先。"
"职位描述：
        
        一、岗位描述
1.协助产品的需求分析、架构设计、编码测试、性能优化等工作；
2.完成软件系统代码的实现，编写需求文档、开发文档等；
3.研究新兴技术，制定产品研发工作流程和标准，研究解决产研发过程中遇到的技术难题；
4.及时准确地判断、定位开发过程或生产运行中的问题并协调解决；
5.完成岗位相关的其它工作任务。
二、应聘条件
1.境内外高等院校全日制大学本科及以上学历的2019年应届毕业生。其中：境内高等院校应届毕业生须在2019年1月1日至12月31日之间毕业，报到时取得国家认可的就业报到证、毕业证和学位证；境外院校归国留学生应当在2018年6月至2019年12月之间毕业，并在报到时取得国家教育部出具的学历（学位）认证。
2.诚实守信，遵纪守法，品行端正。
3.应聘者须为初次就业，未与其他单位建立劳动关系。
4.具有正常履行工作职责的身体条件，符合《公务员录用体检通用标准（试行）》（2010年修订）、《公务员录用体检操作手册（试行）》（2010年修订）的相关规定；具备健康良好的心理素质。
5.综合素质好，具有较强的学习能力、沟通能力和团队合作精神。具有良好的英语听、说、读、写能力。
6.应聘时，本人应如实说明与建设银行及其子公司在职员工有无亲属关系，包括：夫妻关系、直系血亲关系、三代以内旁系血亲及近姻亲关系。
三、相关岗位要求
软件工程、计算机、信息技术、数学、数据分析及挖掘等相关专业研究生或本科生，并符合如下条件：
1.熟练使用linux操作系统，精通JAVA、C、Python等至少一门主流开发语言；
2.有极佳的数学功底，数据结构和算法基础扎实，热衷于技术钻研；
3.熟悉机器学习、数据挖掘，掌握主流的人工智能算法；
4.不墨守成规，善于突破和创新，有自己的见解；
5.主动性强，具有良好的学习沟通能力和合作精神，能接受挑战并承担工作压力。"
"职位描述：
        
        岗位职责：
1、负责大数据设备部署、hadoop、MPPDB等常见商用平台的搭建、应用以及运维；
2、负责海量数据下精准营销平台流计算、实时计算的设计开发；
3、负责海量数据下可视化模块开发，依据业务需求和方案开发可视化产品；
4、负责海量用户行为分析和预测，以及专家模型、分布式算法模型在精准营销方面的实现和应用等。
?
任职条件：
1、全日制大学本科及以上学历，35周岁以下；
2、具有1年以上大数据相关工作经验；
3、计算机、金融科技、应用数学、人工智能等相关专业；
4、精通至少一种编程语言，Java、Scala、Python；
5、熟悉hadoop、mppdb、hive、hbase、zookeeper、hue等中的多个，或者有相关工作经验优先；
6、熟悉spark streaming、storm、flink、redis、es中的多个，或者有相关工作经验优先；
7、熟悉spark mllib/GraphX、图计算、mahout中的多个，或者有相关工作经验优先；
8、具备数据挖掘、数据分析、机器学习知识背景，拥有反欺诈系统、推荐系统、精准营销、信息检索等方面的工作经验优先。"
"职位描述：
        
        岗位职责：
1.?负责数据质量管理、数据治理等工作；
2.?负责数据相关的项目建设与日常运营工作；
3.?负责根据业务场景，搭建算法模型解决问题；
4.?负责数据相关的技术文档撰写；
5.?参与图像识别、遥感数据处理和分析，相关算法研发。
?
任职要求：
1.?计算机、信息管理、数学、统计学相关专业，本科及以上学历；
2.?具备较强的数据收集、分析及整合能力；
3.?精通python语言，熟悉数值计算、分析相关的库，如Numpy,Scipy,Matpiotlib；
4.?熟悉Linux开发环境；
5.?熟悉oracle、mysql、mongodb等数据库的常规使用；
6.?对算法技术有兴趣且对新算法的应用具有较强的敏感度。
?
福利待遇：
1.?薪资待遇：具有竞争力的薪酬和值得您期待的中长期回报；
2.?福利体系：五险一金、法定节假日、带薪年假、年底双薪；
3.?上班时间：每天7.5小时工作制，每周五天班，周末双休。"
"职位描述：
        
        工作职责：
1.负责企业级大数据产品核心功能的设计和开发；
2.保证代码质量、效率和可靠性，编写产品技术文档，按时完成开发目标；
3.配合测试组完成项目测试工作、系统交付工作；
4.对项目交付和客户提供技术支持。
?
任职要求：
1. Linux操作经验
2. MySQL/SQL关系型数据库使用经历；
3.Maven，Java/scala开发调试能力（会写代码及简单的数据结构算法题，底线是二分查找）、JVM基础（堆内存、GC）。
大数据基础
1. 熟悉HDFS&Yarn，MapReduce原理 或 Spark执行原理；
2. 熟悉Hbase存储和查询原理，对Hbase适用场景和关键问题（比如rowkey热点）有认识；
大数据开发项目
1.面向大数据平台组件做过相关开发工作，比如；
a) 数据接入治理：flume, kafka, hive, spark streaming等；
b) 数据存储和查询：hbase，sparksql等。"
"职位描述：
        
        高级数据工程师 ? ?工作职责： ? ?- 进行数据仓库建设、管理、元数据与数据架构构建工作；设立平台运维机制 ? ?- 管理数据仓库、数据平台所需相关技术（包括 Hadoop、以Java搭建之调度平台、开源报表、ElasticSearch等） ? ?- 为数据挖掘、监督学习提供技术上之指导 ? ?- 为初级工程师进行开发、技术上之指导与领导 ? ?- 对未来部门数据使用之潜在需求，提供更优之技术方案以降低数据使用成本 ? ? ? ?职位需求： ? ?- 工程学相关专业，最少 3 年相关数据开发经验 ? ?- 精通 SQL 、有最少一门开发语言于数据业务上之实践经历：建议是 JAVA、Python  ? ?- 熟悉数据仓库、OLAP相关之技术（Hadoop或DB均可）、了解数据仓库架构搭建方法 ? ?- 有报表开发经验，能快速对应业务需求与报表内容 ? ?- 良好的逻辑思维能力、快速学习能力、沟通能力；能对项目进行领导 ? ?- 良好团队合作精神、规划能力与主动意识"
"职位描述：
        
        岗位职责 1. 研究大数据领域相关业务、产品、技术情况； 2. 设计大数据运维产品，包括产出需求，原型与相关的配套文档；  3. 与UED及研发团队合作，推动产品的发布； 4. 与售前及工程团队合作，推动产品的交付；
任职要求 1. 精通ElasticSearch、Kafka等大数据相关技术； 1. 对运维相关产品与技术有一定了解，熟悉业界情况； 2. 具有较好的沟通能力，组织、协调、团队管理及解决问题的能力 3. 熟悉软件产品生命周期及生产过程，有与研发团队配合的经验； 4. 具有较好的方案能力，能设计与编写产品原型、需求与方案配套文档； 5. 具有一定的市场分析、推广能力。 6. 具有强烈的学习、成长意愿；有责任心，能承受较大的工作压力；有团队协作精神，善于挑战。"
"职位描述：
        
        岗位职责：
1. 研究大数据领域相关业务、产品、技术情况；
2. 设计大数据运维产品，包括产出需求，原型与相关的配套文档；?
3. 与UED及研发团队合作，推动产品的发布；
4. 与售前及工程团队合作，推动产品的交付；
任职要求：
1. 精通Kafka、Storm、Spark、Hadoop、ElasticSearch、Flink/Blink等大数据相关技术；
2. 对运维相关产品与技术有一定了解，熟悉业界情况；
3. 具有较好的沟通能力，组织、协调、团队管理及解决问题的能力
4. 熟悉软件产品生命周期及生产过程，有与研发团队配合的经验；
5. 具有较好的方案能力，能设计与编写产品原型、需求与方案配套文档；
6. 具有强烈的学习、成长意愿；有责任心，能承受较大的工作压力；有团队协作精神，善于挑战。
加分项：参与某一开源项目者；
加分项：了解Service Mesh，熟悉Docker、k8s、Mesos，有开发或使用经验者；"
"职位描述：
        
        工作内容：
1、进行系统功能模块的分析设计和核心功能的开发；
2、参与大数据存储系统、分布式计算系统、数据集成等的设计、研发、维护、优化工作；
工作要求：
1、熟练的Java编程技巧，如果会scala更佳；熟练使用spring、mybatis等框架2、熟练的SQL技能3、Spark：了解Spark框架的架构和底层原理；能熟练使用Spark Core的API进行数据分析应用程序开发；熟练使用SparkSQL4、可对Elasticsearch进行安装维护，即基本的日志排查、restful api查询5、能简单安装部署kafka，创建kakfa topic6、会简单的Linux shell命令和shell脚本编写"
"职位描述：
        
        
工作内容：
1、进行系统功能模块的分析设计和核心功能的开发；
2、参与大数据存储系统、分布式计算系统、数据集成等的设计、研发、维护、优化工作；
任职要求：
1、熟练的Java编程技巧，如果会scala更佳；熟练使用spring、mybatis等框架
2、熟练的SQL技能
3、了解Spark框架的架构和底层原理；能熟练使用Spark Core的API进行数据分析应用程序开发；熟练使用SparkSQL
4、可对Elasticsearch进行安装维护，即基本的日志排查、restful api查询
5、能简单安装部署kafka，创建kakfa topic
6、会简单的Linux shell命令和shell脚本编写"
"职位描述：
        
        岗位职责：
1.?? 持续构建数据仓库，全方位支撑公司产品和业务需求；
2.?? 负责业务数据的接入、建模、处理分析；
3.?? 协助业务运营人员快速、及时了解业务数据动态；
4.?? 整合各业务数据，不断挖掘业务数据价值
?
任职要求：
1.?? 本科及以上学历，5年及以上数据仓库建设经验
2.?? 熟练掌握Python/Java/Shell至少一种编程语言，具有hadoop、spark等相关开发经验者优先；
3.?? 至少掌握Oracle/Mysql/Greenplum等主流传统关系型数据库的一种，了解Hive、HBase、Mongo等相关技术者优先
4.?? 熟悉数据仓库模型设计，掌握数据库开发技术，具备数据加工处理（ETL）相关经验，灵活运用SQL实现数据ETL加工处理；
5.?? 熟悉数据仓库领域知识，包括但不局限于：元数据管理、数据质量、数据整合分析、性能调优等
6.?? 具备优秀的业务理解能力，对数字敏感，较强的逻辑分析、抽象、概括、总结能力"
"职位描述：
        
        岗位职责：1、负责大数据分布式应用系统服务器端或客户端软件开发工作（需求开发、故障解决和性能优化等）；2、从事大数据技术研究和开发工作，跟进大数据技术发展方向。

任职要求：1、具备Hadoop大数据相关工作经验，掌握Hadoop/HBase生态环境体系的搭建和管理，掌握Hadoop、HBase、MapReduce、HDFS、Hive、Pig、Zookeeper、Spark等开源项目的原理和使用方法，具有实际集群搭建和调优经验；2、精通Java开发，有大数据平台相关开发经验；3、掌握至少一种NoSQL数据库，具有真正项目使用经验；4、良好团队协作和沟通能力。"
"职位描述：
        
        【岗位职责】
1、参与传统数仓和大数据数仓日常开发工作；
2、参与大数据仓库设计、规划和开发；
3、参与日常工作的优化，提出建设性意见；
3、负责管理项目，负责板块内的资源协调、进度管理、交付管理；
【岗位要求】
1、全日制本科，计算机等相关专业。3年以上数仓开发经验，有银行、金融从业经验者优先。
2、2年以上项目管理经验，具备PMP证书优先.
3、熟悉oracle/hive/spark，熟悉数据处理和性能优化，有UDF自定义函数、MR开发经验优先；
4、熟悉常用ETL工具，熟悉常用的Linux指令，熟悉shell/python任意一种脚本语言"
"职位描述：
        
        ?联雅网络主要从事跨境独立站设计业务,办公地点在越秀区繁华地段，交通便利.
?
工作职责：
负责公司产品所有内部数据的数据接入、清洗、存储和展示；
负责公司产品研发过程中,智能数据部分的建设；
?
工作要求：
本科及以上，具备2年以上相关工作经验；
熟悉?Linux?操作系统和开发环境，熟练掌握SQL；
良好的统计分析基础，较高的数据敏感性；
具备海量数据处理相关经验优先；
对AB测试理论熟悉,有数据分析师工作背景优先；?
具备abtest实验系统建设经验优先；
具备同时上线上百个实验的经验优先
?
薪金待遇:
1.工资：基本工资+高提成
2.购买五险（医疗险、工伤险、养老险、生育险、失业险）
3.公众假期按照国家规定休息，春节休息十天；
4.平均每周工作时间5.5日
5.每年1-2次公司组织旅游；
6.提供健全的培训制度，良好的学习，晋升平台；
7.每月文娱活动，拓展培训。
?
?
欢迎有能力有经验的您加入到我们的年轻的团队共同发展。
官网：www.ueeshop.com
工作地址：广州市越秀区越秀南路185号创举商务大厦10楼整层"
"职位描述：
        
        岗位职责：
1、与公司环境管理大数据平台的架构设计和开发工作；
2、负责大数据项目相关的前期需求的沟通和方案的编制；
3、负责数据分析平台的建设；
4、负责项目组数据提取，分析和建模，相关报告素材编写；
5、参与数据采集方案，公司环境管理平台的升级改造工作和运维工作；
任职要求：
1、计算机相关专业,具有3年以上大数据开发经验，熟悉Java,Linux；
2、熟悉Hadoop大数据处理系统的开发,搭建及部署者优先；
3、熟练地处理数据模型、数据ETL以及存储管理；
4、熟悉HDFS/Hive/MapReduce/Kylin/HBase，能独自进行Mapreduce程序开发者优先；
5、熟悉使用finereport，Biee等报表工具，熟悉报表开发流程；
6、有较强的书面与口头沟通表达能力，独立分析、解决问题的能力。"
"职位描述：
        
        岗位职责:
指标数据集市模型落地开发、报表开发、专题分析应用
技能要求:
1.熟悉使用SQL、Redis或mongoDB其中一种非关系型数据库
2.熟悉python、bash脚本编程
3.有大数据处理工作经验，熟悉ETL流程
4.能够独立完成日常BI项目开发工作
5.具备扎实的编程基本功，熟练使用常见的数据结构，具有良好的数据分析能力
6.动手搭建部署过hadoop、spark、storm集群优先"
"职位描述：
        
        （一）岗位职责：
1、负责源系统数据接入hadoop大数据平台Hive,进行清洗、加工、转换；
2、负责业务指标、报表数据分析、加工；
3、完成项目经理安排的开发任务；
2、负责perl/Shell脚本开发；
4、负责hadoop大数据平台hive开发。
（二）任职资格：
1、计算机相关专业专科毕业；3-5年经验；
2、熟练掌握Hive开发；
3、有Oracle/DB2数据库功能开发、管理经验，意向往大数据开发方向发展亦可；
4、熟练掌握perl/shell脚本开发；
5、熟悉Hadoop大数据平台hive/HBase/sqoop/kafka优先；
6、熟悉数据仓库、etl工具优先；
7、有数据仓库和银行业ETL数据处理相关工作经验优先；
8、熟悉hadoop大数据平台，能够搭建平台者优先；

福利待遇：
?1、购买五险一金；
?2、工作满一年后将提薪；
?3、工作满一年年底有年终奖、年假；
?4、转正后生日当月可申请100元蛋糕补贴；
?5、节日补贴，例如端午节、中秋节等，公司会有一定的节日补贴及小礼品；
?6、旅游活动，公司不定期组织员工外出旅游、户外拓展、聚餐K歌等休闲活动，增强公司凝聚力；? ??
?7、公司与百合网有联盟合作关系，提供婚介服务享有公司额外优惠政策；??
?8、公司员工购买恒大房产、保险享有公司额外优惠政策。"
"职位描述：
        
        职位描述
1.负责公司游戏运营数据平台维护和优化；
2.参与规划公司未来的数据分析平台；
?
职位要求：
1.三年以上相关工作经验；
2.具备良好的操作系统和数据结构基础；
3.熟悉Java、Linux开发环境；
4.熟悉Hadoop/hbase/storm/presto等技术；
5.对业务数据有一定兴趣和敏感；
6.有管理带人经验优先。"
"职位描述：
        
        一、岗位工作范围和职责：
1、负责公司大数据平台相关产品的设计，开发、文档撰写和项目改进 ；
2、参与公司大数据平台上业务应用的功能设计及架构规划；?
3、负责优化平台软件的模块结构和流程逻辑。

二、专业知识和技能要求：
1、两年及以上Java开发经验；
2、熟悉Java语言，熟悉虚拟机原理，数据结构和算法等基础扎实，熟练掌握并应用面向对象的编程思想；
3、熟悉Hadoop以及相关开源大数据技术，如Hive、HBase、Storm、 机器学习等框架；
4、有较强的责任心、上进心以及良好的表达和沟通能力。

三、公司福利：?
1、全年年收入约14.5个月工资，另外约有1.2万左右的现金福利；
2、六险一金，员工年度健康福利体检；其中住房公积金按照月度工资总额的12%购买；
3、五天7小时工作制。带薪年假、各类法定节假日、有薪假及出差探亲假等；
4、各类过节福利、节日礼品、生日礼品、慰问品等；
5、差旅费、差旅津贴、业务招待费、通讯补助、用餐补助、保密补贴、活动经费等；
6、每周免费部门水果，部门不定期旅游、聚餐；
7、量身定制职业装、运动装；
8、公司设有健身房、篮球场、乒乓球室、壁球室等休闲设施，并定期组织各类业余活动；
9、良好的学习平台，公司全额资助优秀员工参加上海交大、同济大学在职研究生学习；
10、提供部分集体宿舍，解决广州户口。"
"职位描述：
        
        职位职责：
1、负责公司大数据技术预研，测试各种大数据组件，为公司大数据产品选定技术组件和整个数据解决方案；
2、负责大数据/机器学习产品的后台开发；
3、负责解决大数据技术的高可用、扩展性和性能问题；
4、参与总体架构设计。
任职要求：
1、至少3年以上大数据相关工作经验；
2、熟悉Hadoop生态相关组件，熟悉Hadoop、Hive、Spark、Presto、HBase、Kylin等至少一种生态组件；
3、对Greenplum、Vertica、ClickHouse等MPP数据库有一定了解；
4、具备扎实的java知识体系，精通java基础知识；
5、具备成熟的Java编程能力，熟悉Linux环境，会编写简单的Shell脚本；
6、在数据处理和计算方面具有一定经验，具备互联网工作经验、数据科学经验者优先；
7、具有良好的沟通表达能力，可以与其他团队良好协同合作。"
"职位描述：
        
        【岗位职责】
1.参与公司大数据产品规划,大数据处理分析平台的架构设计；
2.负责数据存储、清洗、分析程序的开发与平台搭建；
3.负责大数据相关技术发展方向的预研；
4.业务数据仓库搭建；
5.自助数据平台搭建，自助提取数据或自助生成周期报表平台；
6.数据分析与运营，给业务提供支持与驱动产品优化；
7.基于大数据进行数据分析与预测；

【任职要求】
1.有过从 0 到 1 搭建数据平台的经验；
2.离线领域hadoop的ETL开发经验；
3.拥有2年以上Hadoop开发设计和实施经验，对大数据相关的技术和产品有全面深入了，如HDFS，MR，Hbase，Hive，Spark，Storm。

【福利待遇】
【薪酬体系】具有行业竞争力的薪资+五险一金+年终奖+项目奖金+期权激励+优秀员工金币勋章+全勤奖+伯乐奖
【晋升机会】只论能力不论年资，提供横、纵向的升职空间，专业及管理双通道的职业发展方向，大神们带你快速升级~
【生活福利】带薪病假+打车报销+住房补贴+每日餐补，咖啡、茶包不限量提供~
【节日福利】结婚礼金、生育礼金、慰唁金；春节、端午、中秋等节日礼品，员工家人节日礼品等~
【团队活动】公司旅游活动+每周体育活动+每月生日趴+部门活动经费，月月组织聚餐，气氛融洽分分钟笑出腹肌~
【年度体检】每年享有一次权威而专业的医疗机构全面健康检查机会，身体健康才能心情棒棒~
【工作环境】弹性工作制，错高峰，五星级办公环境，一眼饱览琶洲江景，周边地铁公交便利~
还有无数的福利正在download，虚席以待各类优秀人才的加入，与您共同创造更美好的世界~~~"
"职位描述：
        
        岗位职责：
1、负责建设趣专享数据模型及大数据平台/数据仓库；2、负责大数据的实时流转、清洗、转换和计算（实时统计、分析等）的设计和开发；? 3、负责基于大数据技术的海量数据的自动化分析处理和统计工作。岗位要求：1.? 计算机/应用数学/软件工程等相关专业统招本科及以上学历，3年以上大数据相关工作经验，具备大数据处理平台架构设计经验，熟悉数据仓库的设计理念；2.? 熟悉大数据处理相关产品架构和技术（如Hadoop/Hive/HBase/Spark/Kafka/Storm/Flume/Clickhouse等)，对内部实现机制有一定了解,? ? 熟悉Clickhouse使用经验优先;3.? 熟练使用java、python、scala，熟悉linux平台及shell脚本开发;4.? 具有良好的沟通能力、组织能力及团队协作精神，有较强的分析和解决问题的能力;5.? 有Dubbo使用经验优先；"
"职位描述：
        
        岗位职责：
负责大数据基础平台/产品/系统/工具的规划、技术选型、系统设计和开发维护，包括；
1、结合需求设计和实现大数据产品的后台架构，并且能持续优化系统架构，保证高可用性、安全稳定性；
2、参与产品需求的讨论和设计、产品可用性的评估等，从技术和数据角度提供解决方案；
3、带领/主导产品研发、上线和快速迭代，解决各类技术疑难问题；
4、以数据价值为驱动力，关注大数据应用相关方向的前沿研究，能够梳理和抽象各类用户对大数据的需求，沉淀通用性的平台或服务能力，与产品经理/数据分析师合作，研发和持续优化相关产品的质量、性能和用户体验；
5、在项目推进过程中跨部门协调沟通，能够协调各资源以确保产品顺利发展；
?
任职要求：
1、掌握常用架构原则、设计思想，熟悉典型的架构设计和性能优化之道；
2、具有系统需求分析和设计能力，能快速理解业务需求并进行相关技术设计，具有规范的开发能力和经验；
3、有金融业或互联网行业的大数据产品/系统的规划、设计、研发相关经验；
4、熟练掌握大数据相关技术和计算机编程技术，掌握业界主流的开发架构，典型的开源框架，有大数据分析/BI/OLAP后台系统研发经验者优先；
6、优秀的项目管理能力，擅长团队内外协调沟通；
7、要求踏实、有责任心，具有良好的团队合作精神和沟通能力，并有很强的学习能力； 逻辑思维清晰缜密，有独立分析调研能力，有意愿尝试探索新产品方向。"
"职位描述：
        
        岗位职责：
1、负责公司监管报送项目的需求分析、开发、数据运维等工作；
2、按时完成软件编码和单元测试工作，编写相应模块的设计文档；
3、与产品经理、测试工程师、其他团队沟通合作，保证研发工作的质量和进度；
4、研究业界最新技术及其应用，解决创新研发过程中的关键问题和技术难点。

岗位要求：
1、计算机、软件工程相关专业硕士研究生或以上学历；
2、熟悉设计模式和分布式架构模式，精通Java语言及主流框架；熟悉Python；
3、掌握Oracle、Mysql和Hive等主流数据存储系统；
4、熟悉Linux操作系统；
5、具备良好的职业道德，高度责任心和细致工作态度，精力充沛，工作执行力强，诚信踏实，具有良好的团队精神和沟通协调能力；
6、具有基金、资管、私募、券商等相关工作经验者优先；具有券商投保相关工作经验者优先。"
"职位描述：
        
        岗位职责：
?
1.进行大批量数据离线处理，完成手机证券等交易、运营数据的 ETL 工作和数据产品、数据服务的构建；
2.实现实时数据处理过程，提供可靠实时数据服务，对接用户画像、营销系统、个性化推荐等大数据服务构建个性化服务场景；
3.对客户资产、损益数据和手机证券运营数据进行分析，设计大数据模型，构建应用主题集市；
4.实现基本的数据挖掘及机器学习算法，支撑智能型项目数据相关模块的开发；
?
?
?
任职要求：
?
1.2年以上证券交易研发或数据处理相关相关经验；
2.了解场内股票、期货、期权、基金业务，场外期权、理财产品业务；
3.精通SQL，熟悉Java／python编程中的一种；
4.理解 Hive/Hbase 基本原理和调优策略，能熟练进行Hive、Spark和Hadoop之上的开发者优先；
5.有证券从业资格或手机证券数据开发经验优先;
6.具备优秀的业务理解能力，对数字敏感，有较强逻辑分析能力；
7.个性乐观开朗，激情、愿意分享，自驱能力强，良好的结果导向和抗压能力
8.诚恳、踏实、谨慎细致、对工作充满热情、优秀的学习能力，具有良好的自律意识和上进心；"
"职位描述：
        
        岗位职责：
?
1.进行大批量数据离线处理，完成手机证券等交易、运营数据的 ETL 工作和数据产品、数据服务的构建；
2.实现实时数据处理过程，提供可靠实时数据服务，对接用户画像、营销系统、个性化推荐等大数据服务构建个性化服务场景；
3.对客户资产、损益数据和手机证券运营数据进行分析，设计大数据模型，构建应用主题集市；
4.实现基本的数据挖掘及机器学习算法，支撑智能型项目数据相关模块的开发；
?
?
?
任职要求：
?
1.2年以上证券交易研发或数据处理相关相关经验；
2.了解场内股票、期货、期权、基金业务，场外期权、理财产品业务；
3.精通SQL，熟悉Java／python编程中的一种；
4.理解 Hive/Hbase 基本原理和调优策略，能熟练进行Hive、Spark和Hadoop之上的开发者优先；
5.有证券从业资格或手机证券数据开发经验优先;
6.具备优秀的业务理解能力，对数字敏感，有较强逻辑分析能力；
7.个性乐观开朗，激情、愿意分享，自驱能力强，良好的结果导向和抗压能力
8.诚恳、踏实、谨慎细致、对工作充满热情、优秀的学习能力，具有良好的自律意识和上进心；"
"职位描述：
        
        职责描述：1、参与集团级智能金融数据中台（平台）研发，参与智能金融数据中台（平台）系统设计及运营，支撑全集团金融数据的使用。2、参与金融大数据平台设计、研发及建设，支撑金融大数据平台的运营。3、参与金融大数据平台的金融数据集市模型原型设计。4、参与金融大数据平台的可视化设计。任职要求：1、熟悉SQL、有海量数据处理经验，有一定大数据ETL经验。2、熟练掌握Java、Python等至少一门以上面向对象语言，了解JavaScript、Node.js等语言，对新技术有快速学习能力，保持对新语言和新架构的敏锐性3、有较强的业务沟通能力，能快速熟悉新业务4、有一定数据运营经验，能支持金融业务对数据服务的快捷使用5、有参与中大型项目研发经验，工作态度认真，有扎实的计算机专业素养及能力6、有较强需求分析及项目管理能力，能够根据基础需求快速形成开发方案并推进项目进行7、有较为熟练的英语水平，有银行、券商金融行业经历优先考虑。"
"职位描述：
        
        职位职责：

1、参与集团级智能金融数据中台（平台）研发，参与智能金融数据中台（平台）系统设计及运营，支撑全集团金融数据的使用

2、参与非结构化金融数据处理系统设计及研发

3、参与全球资讯数据处理及智能化协同系统设计及研发

4、参与数据探索平台的可视化、智能化插件对接研发

任职要求：

1、熟悉SQL、熟练掌握Java、Python等至少一门以上面向对象语言，对新技术有快速学习能力，保持对新语言和新架构的敏锐性

2、有较强的沟通能力，能快速熟悉新业务

3、有参与中大型项目研发经验，工作态度认真，有扎实的计算机专业素养及能力

4、有较强需求分析及项目管理能力，能够根据基础需求快速形成开发方案并推进项目进行

5、有较为熟练的英语水平，有海外学习经历优先考虑。"
"职位描述：
        
        工作职责
1、把握大数据技术发展趋势，参与制定公司大数据技术发展战略；
2、负责大数据平台整体架构的规划和设计，并组织实施、监控、系统优化；?
3、负责大数据平台技术框架的选型和开发；?
4、负责大数据应用支持及大数据平台的硬件扩容、集群安全等的实施及推进；
5、负责BI平台的规划及全面建设；
6、负责主题数据挖掘工作，包括大数据机器学习、聚类、逻辑回归等；
7、负责大数据部核心团队的架构设计、管理培养。?
8、制定技术标准和规范，对团队成员进行技术培训和指导；
任职资格
1、计算机或GIS相关专业，硕士以上学历,有2年以上的大数据挖掘分析经验；
2、精通空间大数据管理与数据挖掘与人工智能；
3、精通Hadoop、Hive、Spark、elasticsearch、kafka等大数据技术，对大数据技术的发展有深入的研究；
4、能够根据具体需求进行可行性研究、技术选型、系统架构设计、系统功能设计等；
5、能够带领团队进行系统开发，并给团队人员提供方法和技术指导优先。
6、有空间大数据管理、分析经验优先；"
"职位描述：
        
        岗位职责：
1、制订数据库设计开发、运维管理方面的相关标准、规范和流程；
2、监控数据库运行状况，及时发现数据库运行中的潜在问题，并制定策略提前预防，保证数据库稳定运行；
3、根据数据库监控中发现的问题，判断哪些可以通过调优解决，并制定调优方案，保证数据库高效运行；
4、对数据库定期做数据备份，并做恢复演练，保证数据库数据的完整性、可用性、安全性
5、日常跟踪业界技术发展动态，结合公司实际需求，制定数据库总体规划，研究引入合适的技术；
6、研究和推动数据库运维工作的标准化、自动化、产品化和平台化。
任职要求：
1、大专以上；
2、5年以上数据库运维与开发经验，具有大型电商系统数据库管理经验者优先；
3、深入理解MySQL数据库的工作原理，并熟悉其运维管理、性能分析和调优技术；
4、熟悉数据库的性能优化、SQL调优技术，对高并发数据库的锁和事务隔离问题有深入理解；
5、熟悉数据库容量规划、多种集群配置和分库分表设计方法，有海量数据库设计和支持经验优先；
6、熟悉NoSQL相关维护知识，具有mongodb/redis维护经验；
7、熟悉mysql分支(percona、mariadb)及mysql5.7新特性；
8、熟悉至少一种数据库高可用方案；"
"职位描述：
        
        岗位职责：
?搭建集团数据仓库，完成集团数据分析功能相关开发

任职要求：
1、大学本科及以上学历，通信、计算机、应用数学等相关专业毕业；
2、1-2年以上大数据行业研发经验，精通Java或Python等至少一门语言；
3、熟悉Spark、kafka、Flink、Hadoop等大数据存储、计算框架，有使用Spark、Spark?streaming、Flink等工具做数据清洗、数据分析经验
4、熟悉大规模 系统计算、网络、存储的高可用性设计和性能评估方法；"
"职位描述：
        
        1、负责公司数据仓库建设，为公司数据需求提供健壮的模型支持；
2、负责相关数据产品的建设。
任职资格：
1、计算机相关专业本科及以上学历，互联网一年以上数据开发经验；
2、熟悉数据仓库建设，了解数据仓库的分层理论及模型；
3、熟悉hadoop/hive/spark等开发，有较强的sql优化能力；
4、熟练运用r/python/scala/sql等技能中一种或几种；
5、熟悉unix/linux开发；
6、有storm/es/kylin/hbase等开发经验优先；
7、具备良好的学习能力和分析解决问题能力,责任心强; 具有良好的团队合作意识,沟通能力,协调能力,能够承担工作压力"
"职位描述：
        
        工作职责：
1.参与公司大数据相关开发，主要负责数据同步以及存储规划；负责各种数据对接到大数据平台开发；
2.参与公司数据分析和挖掘相关工作，并支撑相关数据输出；
3.根据相关指标，完成统计分析并展示；
4.参与智能报表系统研发；
5.对实时计算有一定经验，并能根据不同业务模型，输出结果。

任职要求：
1.本科及其以上学历；
2.对hadoop及其底层原理熟悉，有阅读源码优先；
3.对OLAP常用技术框架较熟悉，并有一定经历；如kylin
4.对实时计算框架有实际应用，对flink、spark streaming架构熟悉，有阅读过源码优先；
5.对大数据存储技术有一定了解，如kudu、hdfs、hbase等较熟悉；
6.精通java、python语言，对java性能调优有一定经验优先；熟悉python常用算法包，会使用python实现数据分析算法并有实际数据分析项目经验；有推荐系统类项目经验
7.性格开朗，富有责任心，有集体荣誉感。"
"职位描述：
        
        岗位职责：
1.参与数据测试及匹配结果分析工作；
2.使用建模工具进行信用模型及反欺诈模型开发，包括数据准备、建模及数据分析、模型的选取与优化、模型验证等工作；
3.对海量业务数据进行分析，深度挖掘内部数据，构建用户征信的指标体系并具备开发及解释相应衍生变量、规则的能力；
4.参与风控审批、额度、定价策略的制定方法及相应建模流程；
5.针对不同金融机构和业务给出相应的风控建模方案，向客户进行阐释并参与实施；
6.针对企业风控运营情况，设计相应的报表，分析并识别企业风险；

任职要求：
1.2019年毕业全日制本科及以上学历，统计学、数学、计算机等相关专业优先，有较好数学或代码基础者优先；
2.至少能熟练运用SAS、R、Python中的一种进行数据分析或建模，熟悉SQL等常见数据库语言；
3.掌握逻辑回归、决策树、机器学习等算法，了解算法的原理；
4.具备独立思考的能力，逻辑严谨，对数据敏感，善于发现、探索并解决问题；
5.有较强的责任心及抗压能力；
6.有建模大赛经验优先；
7.同等条件下表达能力强者优先。"
"职位描述：
        
        工作职责 :
1、?负责汽配配件行业的相关数据系统开发2、?参与系统数据分析、数据挖掘、数据智能组件开发。3、?负责搜索相关性算法的研究应用
任职资格 :
1、5年以上机器学习、大数据挖掘、运筹优化等相关领域经验，能够深入了解算法细节，能够熟练进行数学建模，以及灵活采取多种方式求解最优解。2、能够贴近业务，迅速的将业务问题转换成数学问题并求解。3、精通对大数据计算平台相关的技术，例如Hadoop、MapReduce、Spark、SQL等，精通Python等建言，并有实际应用经验。4、精通常见机器学习算法（如逻辑回归、SVM、神经网络、决策树、贝叶斯等）。5、有汽车配件行业经验优先"
"职位描述：
        
        岗位职责：
1.能独立与相关业务需求方、技术系统负责人沟通，获得开发所需的各种信息；
2.通过编写存储过程、脚本等方式实现业务需求，完成报表展示开发；
3.参与相关应用项目的开发，完成上级领导分配的各项工作；
4.及时响应所负责系统的维护请求，提供开发支持，确保系统稳定、数据准确；
任职要求：
1、全日制大学本科及以上学历，5年以上工作经验，计算机或相关专业
2、精通oracle数据库，精通SQL编写技能，存储过程/函数编程，精通SQL优化技术
3、有cognos或tableau等BI报表开发经验者优先，熟悉linux、aix等操作系统基本命令
4、熟悉银行业务基本知识、有银行业同类BI项目经验者优先。
5、思路清晰，善于思考，能独立分析和解决问题，善于总结经验；
6、责任心强，具有团队精神以及良好的逻辑思维能力和学习能力，抗压能力强。"
"职位描述：
        
        岗位职责：
1. 负责风险数据系统建设、升级，协助进行集市类系统未来方案规划；
2. 组内大数据类系统方案组织及建设，及大数据类系统相关项目管理、开发等工作。

任职要求：
个人综合素质：
1、全日制本科及以上学历，计算机、金融、应用数据等相关专业，5年及以上工作经验；
2、做事踏实，工作责任心强，具备团队合作意识；
3、逻辑思维严密，沟通良好，有较强的学习和分析能力。

业务领域要求：
1、对金融特别是银行领域有兴趣；
2、了解银行存、贷款业务，特别是对公贷款、个人贷款等业务领域的优先（了解平安银行系统和数据尤佳）；
3、熟悉银行风险管理类系统，如RWA、国际财务报告准则（IFRS9）等风险监管标准或规范的优先。

技术要求：
1、2年以上Oracle/Greenplum/DB2等一种以上数据库设计开发经验；具备良好的SQL基础，熟悉存储过程，具备一定的sql优化能力；
2、有spark、Hive、HDFS、HBASE、YARN、ZooKeeper其中一项或多项使用经验的优先；
3、熟悉ETL数据开发（数据清洗、转换、装载）；
4、熟悉Unix/Linux操作系统，掌握基本的shell命令；
5、熟练使用UE、EXCEL等工具。"
"职位描述：
        
        岗位描述?
1、数据仓库的开发和维护，包括数据源分析、模型设计、ETL开发等；?
2、规划设计数据服务工具，提升数据研发的工作效率，搭建数据服务的工具/产品；?
3、负责数据质量、稳定性等数据管理，数据内部共享融通的数据平台，让数据标准更规范、数据获取更高效。?

任职要求：?
1、本科以上学历，计算机、数学、信息系统管理等相关专业
2、3年以上数据仓库项目经验，精通数据仓库的理论、架构、远离，深刻理解数据仓库建设实施方法论，对金融数仓的层次设计、主题规划等有深刻的了解，具有标签和数据应用开发背景；
3、熟悉数据仓库模型设计与ETL开发；有从事分布式数据存储与计算平台应用开发经验，熟练掌握 Hadoop 生态相关技术，例如 HDFS/MapReduce/Hive/HBase/spark；?
4、有良好的业务及产品感觉，可以站在用户角度设计技术产品；
5、热爱数据，对数据敏感，逻辑思维能力强，善于洞察与发现问题、分析并解决问题；
6、对数据挖掘和机器学习有所了解；
7、态度端正，工作积极主动，有责任心，耐心，并具有很强的团队合作意识。"
"职位描述：
        
        岗位职责：
1、负责大数据团队建设
2、负责大数据平台系统的稳定
3、负责大数据项目开发和维护。
4、负责软件系统的功能模块设计及相关过程文档的编写。
5、参与研究大数据技术应用解决方案等。
6、应用模块、WEB、接口开发，编写相关文档。
7、完成DB/REDIS/接口设计文档
8、完成上级领导交办的其他各项事宜
?
任职要求：
1、精通Java/J2EE编程，熟练使用Eclipse/Git/MVN等开发工具，有2年以上开发经验
2、有良好的代码书写、注释和单元测试习惯
3、熟练使用oracle数据库，有redis，rabbitMQ，spring，zookeeper等经验者优先
4、熟悉Linux操作系统，掌握常用的Linux命令，熟悉脚本编程Shell/Python优先
5、熟练掌握hadoop、hbase、hive、oozie、sqoop等；
6、负责平台数据提取、数据挖掘及数据分析，具有良好的商业敏感度和优秀的数据分析技能，能够解决复杂的商业问题。
7、主动好学，具备良好的沟通合作技巧，较强的责任心及团队合作精神，并有一定领导经验
8、熟练掌握数据结构，操作系统，数据库原理等
9、全日制本科及以上学历，计算机相关专业"
"职位描述：
        
        
岗位职责：

1、负责大数据团队建设

2、负责大数据平台系统的稳定

3、负责大数据项目开发和维护。

4、负责软件系统的功能模块设计及相关过程文档的编写。

5、参与研究大数据技术应用解决方案等。

6、应用模块、WEB、接口开发，编写相关文档。

7、完成DB/REDIS/接口设计文档

8、完成上级领导交办的其他各项事宜

?

任职要求：

1、精通Java/J2EE编程，熟练使用Eclipse/Git/MVN等开发工具，有5年以上开发经验

2、有良好的代码书写、注释和单元测试习惯

3、熟练使用oracle数据库，有redis，rabbitMQ，spring，zookeeper等经验者优先

4、熟悉Linux操作系统，掌握常用的Linux命令，熟悉脚本编程Shell/Python优先

5、熟练掌握hadoop、hbase、hive、oozie、sqoop等；

6、负责平台数据提取、数据挖掘及数据分析，具有良好的商业敏感度和优秀的数据分析技能，能够解决复杂的商业问题。

7、主动好学，具备良好的沟通合作技巧，较强的责任心及团队合作精神，并有一定领导经验

8、熟练掌握数据结构，操作系统，数据库原理等

9、全日制本科及以上学历，计算机相关专业"
"职位描述：
        
        岗位职责：
1、 负责大数据应用服务相关开发。应用大数据生态圈中相关技术，设计并实现数据分析和统计应用，以满足项目和产品需求；
2、 负责银行数据模型开发，反洗钱等相关数据分析工作；
3、 收集汇总各后端数据源的数据，协调合作渠道数据埋点及对接，推动业务部门的数据化运营；处理数据需求的开发与测试。
?
任职要求：
1、计算机或相关专业本科以上学历，计算机基础扎实；
2、精通JAVA语言，至少2年以上相关岗位工作经验；
3、熟悉ORACLE或MYSQL数据库，具有相关关系数据库设计经验；
4、理解并掌握敏捷开发方法论；
5、熟悉Hadoop生态系统和NoSQL数据库，并有实际项目经验、了解银行业务者优先。
6、熟悉HIVE；熟悉主流ETL处理工具，或者熟悉主流报表平台研发工具，如Cognos、Tableau、BO等；
7、对客户需求敏感，能快速分析需求并提出解决方案。
8、具有较强的逻辑思维能力，能承受压力，具有良好的团队协作精神和沟通理解能力。"
"职位描述：
        
        岗位职责：
负责银行大对公数据仓库建设。
?
任职要求：
1、全日制本科及以上学历，计算机等相关专业，2年及以上相关工作经验；
1、熟悉数据仓库技术架构，精通数据仓库相关技术，如数据建模、元数据管理、ETL等
2、精通SQL，有丰富的SQL性能调优经验;
3、熟悉大数据平台的整体技术架构，如Hadoop、HDFS等分布式数据体系，有HSQL开发调优经验优先；
4、 具备优秀的团队合作意识，良好的沟通协作能力，有项目管理经验者优先；
5、 熟悉银行业务和数据，有银行对公业务相关系统开发经验者优先。"
"职位描述：
        
        工作职责
1.完成数据仓库及BI项目的建设需求调研、业务沟通、数据分析等工作
2.负责设计数据仓库的模型结构、ETL流程及mapping逻辑，管理元数据；负责数据仓库及BI项目的系统接口的设计
3.负责基于hadoop平台的数据仓库项目实施；辅助完成应用分析模块的模型和展现设计
4.对公司经营绩效进行跟踪、分析、检视、管理；参与战略规划制定
任职要求
985以上院校数理、计算机、统计等相关专业；全日制本科以上学历，研究生优先，学历学位双证齐全
本科及以上学历，3年及以上金融行业数据仓库项目实施经验；熟悉SQL语句，并有数据库开发经验
精通java和Python语言，精通hive/spark/hbase/hadoop等大数据相关技术
较强的逻辑思维，较好的业务分析能力及抽象能力，良好的沟通协调能力；具备强烈的意愿和责任感，抗压力强，具有进取心，乐于奉献，乐于与人沟通、分享"
"职位描述：
        
        工作职责
1、参与海量数据存储设计、业务数据体系的设计、数据分析及数据建模；
2、依据业务需求，进行数据产品的规划和开发；
3、优化现有数据平台，提升数据处理效率及智能化运维的能力。
任职要求
1、计算机或相关专业本科以上学历；
2、有3年及以上大数据平台开发方面相关工作经验；
3、熟悉数据仓库和数据建模的相关技术细节，有编程经验，熟悉JAVA/Scala/Python语言；
4、熟悉Hadoop或Spark生态相关技术，包括MapReduce、HDFS、Hive、Spark等，1个以上大数据平台项目实施经验;；
5、具有良好的团队协作与沟通能力，热爱开发工作，具有良好的编程习惯；
6、工作认真，有责任信心，具有探索意识并能够承受一定的工作压力。"
"职位描述：
        
        工作职责
1、根据业务需求实时/批量采集数据、加工处理后落地到公司的大数据平台；
2、开发基于公司各类结构化/半结构化/非结构化数据的数据分析和挖掘应用；
3、参与公司数据平台建设，持续优化大数据平台的各项功能。
任职要求
1、本科及以上学历，计算机或应用数学专业优先；
2、熟悉Linux操作系统并有Shell开发经验，熟悉Oracle、SQL Server等传统关系型数据库；
3、熟悉Java、Scala、Python语言，具有3年及以上开发经验，有Python数据分析开发经验者优先；
4、熟悉Hadoop、Hive、Spark等分布式大数据技术，有Spark Streaming、Flink开发经验者优先；
5、有较强的逻辑思维能力和创新精神，具备良好的沟通和文字表达能力；
6、有较强的学习能力，对技术有钻研精神，热衷于新技术的学习和实践；
7、有较强的团队合作意识，对工作有热情，能够承受压力、接受挑战。"
"职位描述：
        
        工作职责
1、负责公司企业级AI计算平台搭建；
2、负责用AI算法改进证券的前中后台各项业务，提高交易策略，提升中后台工作效率；
3、算法研究，开发，实施，评估，工程落地。
任职要求
1、经济，数学，统计，自动化，计算机等相关专业硕士毕业；
2、熟悉特征工程，机器学习和深度学习理论和实践，并有两年以上工作经验。有相关比赛经验者优先；
3、熟悉Python， Java， R 等编程语言；
4、岗位职责：负责用AI算法改进证券的前中后台各项业务，提高交易策略，提升中后台工作效率；
5、工作内容：算法研究，开发，实施，评估，工程落地；
6、熟悉业界主流开发框架： sklearn， tensorflow, pytorch 等。"
"职位描述：
        
        工作职责
岗位描述:
 1. 参与平安租赁大数据的采集、存储、处理，通过分布式大数据平台加工数据，支持业务管理决策;
 2. 参与平安租赁大数据体系的设计、开发、维护，通过数据仓库、元数据、质量体系有效的管理和组织几十PG的数据;
 3. 参与平安租赁大数据产品的研发，通过对数据的理解，发掘数据价值，探索大数据商业化;
任职要求
岗位要求： 
 1. 所学专业是计算机、数学、统计等相关专业皆可;
 2. 有较强的动手能力和学习能力，熟悉SQL,熟悉JAVA、Python,Shell其中一种编程语言，熟悉unix或者linux操作;
 3. 具备扎实的专业基础，良好的沟通能力和团队合作，主动积极、乐于面对挑战;
 4. 有参与数据处理、分析、挖掘等相关项目优先 ;
 5.对Hadoop、Hive、Spark、Hbase等分布式平台有一定的理解优先;"
"职位描述：
        
        工作职责
工作内容：
1.建立统计分析模型，通过数据挖掘与机器学习，深入理解用户与各类内容，建立有效的用户和内容之间的管道；
2、负责系统的特征提取，建立模型，进行聚类、分类分析，实现应用的智能定制；
3、设计复杂NLP、深度学习、或个性化推荐的算法，给出整体解决方案；
任职要求
任职要求：
1、计算机、统计、自动化、应用数学等相关专业；工作年限 1-3年；
2、1年以上算法相关工作经验、对数据结构和算法设计有较为深刻理解，特别优秀者放宽至应届硕士研究生；
3、精通一门编程语言(RJavapythonSpark等)，熟悉常用的机器学习模型的数学原理、优劣以及使用技巧；
4、有资深大规模深度学习（CNN、LSTM、GAN、RL等）、推荐算法项目经验者优先；
5、优秀的分析和解决问题的能力，和快速学习的能力算法方向工作内容：
1. 建立统计分析模型，通过数据挖掘与机器学习，深入理解用户与各类内容，建立有效的用户和内容之间的管道；
2、负责系统的特征提取，建立模型，进行聚类、分类分析，实现应用的智能定制；
3、设计复杂NLP、深度学习、或个性化推荐的算法，给出整体解决方案；"
"职位描述：
        
        工作职责
1、负责大数据平台的功能组件开发，不同数据管道的搭建等 
2、对接BA, 落地实现相关的数据加工作业，并对作业质量负责 
3、构架、维护、调优数据中台，不断提升平台能力满足业务的快速发展 
4、治理整合多方、异构数据，合理实现数据中台的数据分层、组织管理等 
5、对接AI算法团队，对数据挖掘、机器学习模型的部署维护和跟踪调优
任职要求
1、熟悉HDFS,HIVE,YARN,SPARK,HBASE,KAFKA,IMPALA,ZOOKEEPER,ES,KYLIN等其中组件的使用和原理，具备一定的架构能力 
2、扎实的编程功底，精通Python/Scala/Java其中一种语言 
3、熟悉Linux系统以及shell或perl等脚本语言的开发 
4、熟悉数仓维度建模、OLAP，熟悉主流数据库（Oracle、Postgresql)的ETL、SQL开发，性能调优等 
5、具备较强的逻辑思维能力、文档编写整合能力 
6、有数据挖掘、机器学习类项目，如用户画像、大数据精准营销等落地经验的优先 
7、金融相关项目经验 
8、3年以上大数据平台开发经验，5年以上数据开发相关经验 
9、全日制本科及以上学历，计算机相关专业 
10、良好的沟通能力、团队合作精神,优秀的学习能力、分析问题和解决问题的能力。"
"职位描述：
        
        工作职责
1、负责数据仓库、数据报表的设计、开发 
2、负责对源系统数据进行清洗、治理完成入仓 
3、负责业务需求分析，转化为数据开发逻辑，并落地且维护相关的分析、设计文档 
4、负责自开发代码的单元测试，配合完成SIT、UAT测试，提升数据的质量和时效
任职要求
1、熟悉数据仓库、数据集市的建模理论，如维度建模，指标体系建设等，并有具体项目落地经验 
2、精通主流数据库、数据仓库产品的技术（Oracle，Postgresql，Teradata，Greenplum等） 
3、具备较强的SQL编码和调优经验，熟悉Kettle等ETL工具 
4、熟悉Tableau、PowerBI等BI工具 
5、金融相关项目经验，有银行监管报表开发经验的优先 
6、5年以上数据开发经验，8年以上的技术工作经验 
7、具备大数据开发经验的优先 
8、全日制本科及以上学历，计算机相关专业； 
9、良好的沟通能力、团队合作精神,优秀的学习能力、分析问题和解决问题的能力。"
"职位描述：
        
        工作职责1、基于业务场景，如智能营销、关系网络、个性化推荐，构建训练机器学习模型，分析挖掘提升业务效果 2、以集团及公司大数据为核心，对业务进行分析，对数据进行深入挖掘，赋能公司各项业务 3、负责用户画像方向的研发，基于大数据中台，深入挖掘用户的行为与偏好，建立标签体系和用户画像（profile）任职要求1、熟悉用户画像指标体系、精准营销、产品推荐项目经验 2、熟悉机器学习算法，熟悉sk-learn,xgboost等库，能够深入了解算法细节 3、熟悉分布式机器学习框架比如Spark MLLib, SparkSQL,GraphX 4、扎实的工程实现能力，熟练使用Python，PySpark等大数据分析工具，熟悉Hive,SQL,Linux等 5、3年以上工作经验，具有计算机科学、图像处理、模式识别、机器学习、人工智能、数学等相关专业学历 6、学习能力强，对新技术有强烈求知欲和探索能力 7、优秀硕士应届生亦可"
"职位描述：
        
        工作职责1、基于业务场景，如智能营销、关系网络、个性化推荐，构建训练机器学习模型，分析挖掘提升业务效果 2、以集团及公司大数据为核心，对业务进行分析，对数据进行深入挖掘，赋能公司各项业务 3、负责用户画像方向的研发，基于大数据中台，深入挖掘用户的行为与偏好，建立标签体系和用户画像（profile）任职要求1、熟悉用户画像指标体系、精准营销、产品推荐项目经验 2、熟悉机器学习算法，熟悉sk-learn,xgboost等库，能够深入了解算法细节 3、熟悉分布式机器学习框架比如Spark MLLib, SparkSQL,GraphX 4、扎实的工程实现能力，熟练使用Python，PySpark等大数据分析工具，熟悉Hive,SQL,Linux等 5、3年以上工作经验，具有计算机科学、图像处理、模式识别、机器学习、人工智能、数学等相关专业学历 6、学习能力强，对新技术有强烈求知欲和探索能力 7、优秀硕士应届生亦可"
"职位描述：
        
        工作职责
1、 全面负责智慧农业平台数据库搭建和数据分析
2、 通过大数据处理、数据分析、挖掘等技术，对业务数据进行挖掘与分析
3、与核心算法、产品、运营同学深度配合，通过业务数据挖掘业务洞察，并参与到农业政务优化的各环节；用数据说话，用数据推动农业决策辅助
4、参与产品和业务宏观层面评估体系构建，设计并研发评估指标，推进规范化评估流程
5、参与海量用户行为日志设计、数据仓库设计、日志分析计算等相关工作
任职要求
1、本科学历，3年以上相关工作经验
2、具有3年以上数据挖掘/数学建模相关工作经验和数理统计理论基础，具有实施经验者（比如推荐系统）优先；
3、熟悉常用的统计工具软件，如SPARK或者SAS或者SPSS或者R等数据挖掘工具，有hadoop或者spark开发经验更佳；
4、熟悉数据库系统"
"职位描述：
        
        工作职责
1、负责设计、开发ETL系统；
2、负责设计、开发基于hadoop体系的离线数据处理平台；
3、负责设计、开发基于hadoop体系的实时数据处理平台。
任职要求
1、全日制本科及以上学历，计算机相关专业，3年以上相关经验；
2、对Java/scala/python/golang等语言至少精通一门、熟悉一门；
3、精通hadoop、yarn、shell、sql，熟悉sqoop、hive、hbase、spark、kafka、flume、flink，熟悉常用的关系型数据库；
4、具有优秀的领悟、创新能力，优秀的担当精神，丰富的专业知识储备，优秀的执行力，优秀的结果导向型思维，持续付出，努力推进，高质量完成本职工作，自我驱动，主动竞争。"
"职位描述：
        
        工作职责
1.基于每日上亿级展现数据，搭建大数据处理平台；实现流式事件的实时计算，落地储存；对于离线数据完成数据仓库的建立，为数据挖掘提供有效的数据
2.负责数据质量，元数据的监控，整合
任职要求
1. 了解数据仓库实施方法论、了解数据仓库体系，并支撑过实际业务场景；
2. 理解常用的数据建模理论，可独立把控数据仓库的各层给设计；有数据挖掘，机器学习，推荐相关经验优先；
2. 具备优秀的编码能力，熟练掌握至少一种编程语言：Java/Python/Scala以及脚本语言Shell命令，熟练使用SQL、HQL；
3. 熟悉掌握hadoop大数据生态，如：Hadoop、Hbase、Sqoop、oozie、Hive、Spark, Kafka、Flume；
4. 掌握分布式计算框架（如map/reduce)，熟悉Spark ML开发优先；"
"职位描述：
        
        工作职责
1、负责大数据平台子系统各小组开发团队的管理，团队成员培养，带领开发团队完成产品开发任务；
2、负责大数据平台子系统的开发计划制定、开发全流程过程管理、开发质量保证，确保产品按照预定计划高质量地实现和交付； 
3、负责大数据平台子系统的主要模块详细设计及开发实现，确保产品最终的各项质量指标满足设计要求。
任职要求
1、本科及以上学历，计算机/应用数学/软件工程等相关专业，8年以上Unix/Linux平台大型软件的开发和设计经验； 
2、熟悉大数据处理相关产品架构和技术（如Hadoop/Hive/HBase/Spark/Storm/Flume等），或者熟悉基于SOA的服务框架／ESB /PaaS等平台技术，熟悉常用开发框架和数据库，并有3年以上的相关产品和项目开发经验；
3、了解各种互联网常用开源软件（如Zookeeper/Redis/Kafka等），有知名互联网/软件/通信厂商大型项目经验者优先；有政府数据融合共享交换／智慧城市等相关领域的数据平台研发经验者优先；
4、熟悉通用软件开发流程和技能，如设计模式/敏捷开发/TCPIP等； 能至少熟练使用Java/Scala/Python/C/C++等主流编程语言之一进行软件开发，熟悉GIT/Maven/Gradle等常用开发工具；；
5、工作踏实，具有强烈的责任心和团队合作精神。愿意在技术上深入研究和持续发展，勇于迎接挑战。"
"职位描述：
        
        工作职责
1.依据业务数据平台规划负责数据计算引擎架构和实现；
2.与BIM专家一起完成数模分离和数模联动的架构设计和实现；
3.和业务专家合作，负责完成计算模型的搭建、开发、测试和上线；
4.带领数据工程师完成业务数据库结构的设计和实现；
5.对接集团的数据治理和信息安全部门完成业务数据平台的数据治理体系落地；
6.与AI技术专家对接，完成AI技术在业务数据领域的应用落地。
任职要求
1.计算机相关专业本科以上学历，3年以上大数据相关经验； 
2.对分布式系统原理和架构有深刻理解，具有扎实的大数据、数据仓库理论功底及丰富的数据开发经验，熟悉数据建模，ETL设计、Cube多维建模、OLAP开发、报表开发等；
3.对于流行的大数据开源框架如ES、Hadoop、Spark、Storm、Kafka等有丰富应用经验，熟悉其实现原理，能根据业务场景要求进行必要的二次开发和改造；
4.熟悉Java/Python/Scala/Go等至少一门开发语言，熟悉linux操作系统；
5.对数据治理、数据安全等有相关经验优先；
6.对搜索引擎、语义匹配、深度学习等AI领域相关技术熟悉者优先考虑；
7.有金融或建筑领域大数据应用背景优先考虑；
8.逻辑思维能力强、善于团队协作、有强烈的责任心。"
"职位描述：
        
        工作职责
1.搭建大数据平台、及相关公共服务
2.负责离线/实时的数据存储和加工处理，包括业务数据、行情数据
3.负责非结构化数据处理方案，并根据业务场景引入分析模型，挖掘商业价值
4.对数据进行业务分析，灵活运用可视化工具展示分析结果
5.参与产品与应用的数据研发，制定整体数据接入规范
6.研究前沿技术，解决实际场景中的业务问题，持续优化数据处理、分析、展示方式
任职要求
1. 计算机或相关专业全日制本科及以上学历；
2. 3年以上开发经验，2年以上大数据开发经验，精通java，python等语言；
3. 具有丰富的数据加工处理经验，对数据处理、数据清洗，数据建模、数据分析等有深刻认识和实战经验；
4. 熟悉常用开源分布式系统，对Hadoop/Hive/Spark/Storm/Flink/HBase中的一项或多项有深入了解;
5. 有数据挖掘、机器学习、自然语言处理等领域的理论基础和算法实现和优化经验优先；
6. 有机器学习/深度学习平台的开发经验，熟悉参数服务器，有算法并行化实现经验优先；
7. 良好的团队精神和合作意识，强烈的责任心，对工作有激情，良好的沟通能力。"
"职位描述：
        
        

1负责健康险移动业务部大数据平台的开发工作；


2?负责承担大数据平台架构设计、性能及调优工作；


3?规范文档的编写、维护，以及其他与项目相关的研发工作；?


4?负责 大数据 开发团队的建设提升工作，提升团队技术能力和工作效率，帮助团队成长发展；


5进行 大数据技术和业务的探索性预研。



教育程度：本科及本科以上学历(211或985大学计算机专业优先)


相关经验：3年以上 Java 开发经验 ? （知名互联网公司从业经验优先）


专业能力??
1.? 熟练掌握Java编程语言
2.? 熟悉面向对象编程，及Java的各种主流框架
2. 扎实的数据结构/算法基础
3. 熟悉关系型数据库，熟练使用SQL进行数据分析
4. 熟悉Linux的基本使用, 能独立进行Linux应用部署
4. 具备良好的分析解决问题能力
5. 有良好的学习能力和强烈的进取心和创新意识
6. 熟悉分布式系统，有分布式系统开发经验优先
7. 有大数据应用、大型互联网应用项目经验者优先"
"职位描述：
        
        1、承担维护基于Hadoop/Spark生态的大数据离线/实时处理平台及系统调优；
2、参与业务数据、生产日志的抽取、转储、检索等相关工作；
3、跟进大数据前沿技术的发展，将合适的技术方案适时引入业务场景
4、基于大数据分析平台的后台服务,支持部门的数据接入、落地,统计、分析、报告业务;
5、开发实时数据处理、统计功能,支撑上层业务,如:数据监控、统计分析、日报展现、业务方调用等。
岗位要求：
1、2~3年大数据经验，可维护基于Hadoop 大数据平台；
2、熟悉hadoop生态，Hadoop/Spark/Spark Streaming/Hive/Hbase/Impala /Flume/Kafka，了解数据索引技术和大数据计算；
3、熟悉java语言，有相关数据采集，清洗及数据计算经验；
4、掌握SQL，较好的SQL性能调优经验；
5、优秀的分析、解决问题能力，充分的数据敏感度；有一定的高性能支撑经验和故障排除能力；
6、具备强烈的工作责任感，喜欢钻研，态度乐观，团队意识强。"
"职位描述：
        
        岗位职责：
1、负责公司大数据平台及应用平台的规划、架构设计、调优及故障诊断；
2、负责公司大数据开发规范的制定，组织大数据相关技能的培训；
3、负责公司大数据方向技术创新，针对特定业务场景，能快速完成技术预演，提供有效解决方案，并指导相关开发人员实施上线；
?
岗位要求：
1、本科及以上学历，计算机相关专业，拥有8年以上大数据平台研发经验、至少一个中大型Hadoop集群（1000个节点以上）规划实施经验；
2、深入理解HDFS、MapReduce、YARN、Zookeeper的工作原理，至少精通一门开发语言，如Java、Scala等；
3、熟练掌握Hive、HBase、Spark/Spark streaming的架构及实现原理，阅读过部分源码，能对其进行二次开发、故障分析、性能调优；
4、至少精通Impala、Presto、HAWQ、Kylin、Druid、ElasticSearch其中之一，阅读过部分源码，能对其进行二次开发、故障分析、性能调优；
5、具备良好的学习能力、分析和解决问题能力；
6、具有高度的责任心和团队合作精神；
7、对Hadoop社区有重要贡献者 或 有PB级集群管理经验者优先；"
"职位描述：
        
        岗位职责：
1、负责公司大数据平台及应用平台的设计、开发、环境搭建、调优及故障诊断；
2、参与公司大数据开发规范的制定，组织大数据相关技能的培训；
3、参与公司大数据方向技术创新，针对特定业务场景，能在架构师指引下，快速完成技术预演、实施上线；
?
岗位要求：
1、本科及以上学历，计算机相关专业，3年以上大数据平台研发经验；
2、掌握HDFS/MapReduce/YARN的工作原理，至少精通一门开发语言，如Java、Scala等；
3、掌握Hive/HBase/Spark的架构及实现原理，能对其进行故障分析、性能调优；
4、至少熟悉Impala/Presto/HAWQ/Kylin/Druid/ElasticSearch其中之一，能对其进行故障分析、性能调优；
5、具备良好的学习能力、分析和解决问题能力；
6、具有高度的责任心和团队合作精神；
7、对Hadoop社区有贡献者优先；"
"职位描述：
        
        工作职责：
1、 从保险互联网具体的场景和问题出发，建立不同主题的数据仓库/数据集市；
2、基于hadoop对数据集市进行加工整合、深度分析，挖掘数据价值，并把数据整合成数据产品，提供数据服务
3、负责特定专项场景的数据深入分析，并找出潜在的问题所在，用数据说话并提供解决方案；
4、参与AI应用系统的模型应用上线和效果评测，包括系统设计、模型上线、效果追踪和迭代优化等；

应聘要求：
1、本科及以上，计算机、统计、数学等相关专业
2、2年以上大数据开发经验，有海量数据开发经验者优先；
3、熟练掌握hadoop/spark生态体系，深入理解HDFS和MapReduce原理及优化技巧，基于Spark掌握scala或java语言进行数据处理尤佳；
4、具备强悍的编码能力，熟悉 linux环境，工程实现能力强；
5、熟练掌握数据仓库概念，精通SQL，有使用一种ETL方式经验优先；
6、熟练掌握数据仓库开发从需求沟通、标签定义、mapping规范、编码开发、测试验收、版本移交到生产验证整个流程；
7、能独挡一面，具有高度的责任心和团队合作精神，对数据挖掘有较高的兴趣"
"职位描述：
        
        工作职责： 1、为公司业务发展提供模型算法和数据分析方面的支持；
2、负责监控、评估模型表现，推动模型应用落地，不断完善和优化精准营销模型体系；
3、通过对数据的敏锐洞察以及定性和定量分析，完成较深入的客户画像和业务诊断，并形成分析报告。
 任职要求： 1、 本科以上学历，统计、计算机相关专业； 2、 2年以上相关工作经验，熟悉常用机器学习算法，至少熟练使用R、SAS、SCALA、PYTHON中的一种；
3、 了解海量数据处理，有使用Hive，Spark SQL进行海量数据分析的经验；
4、 非常强的跨团队合作能力和沟通能力；
5、 熟悉自然语言处理或爬虫技术优先考虑"
"职位描述：
        
        工作职责
1、 利用数据分析和建模等技术手段为公司业务发展提供支持；
2、针对业务问题制定综合解决方案，推动方案落地，不断完善和优化精准营销模型体系；
3、 完成较深入的客户画像和业务诊断，并形成分析报告
任职要求
1、本科及以上学历，数理统计和计算机相关专业；
2、2年以上相关工作经验，熟悉常用机器学习算法，熟练掌握R、SAS、Scala、Python等工具中的一种或多种；
3、了解海量数据分析，有使用Hive, Spark SQL等进行数据处理的经验；
4、较强的跨团队合作和沟通能力；
5、熟悉自然语言处理或爬虫技术的优先考虑"
"职位描述：
        
        工作职责
1.负责大数据应用平台软件的搭建、开发，以及系统问题的解决和持续优化；
2.负责接口平台、自助分析平台等系统的建设和维护；
3.负责相关开源系统的性能、稳定性、可靠性等方面的深度优化；
4.负责解决项目上线后生产环境的各种实际问题，保障生产安全和平稳运行。
任职要求
1、本科及以上学历、计算机相关专业优先；
2、具有扎实的程序设计基础，精通Java/Scala，熟悉常用的数据结构与算法；
3、具有2年以上Spark大数据处理程序开发经验，深入理解分布式大数据处理的常用方法，能够基于Hadoop/Spark/Storm/Kafka/Elasticsearch等平台进行海量数据应用系统开发；
4、熟悉Spark Streaming 和 Spark SQL的相关开发，熟悉Spark Streaming流式计算技术；
5、热爱技术，有很强的钻研能力，乐于接受有挑战性的任务。
6、具备良好的学习能力、分析和解决问题能力；
7、抗压能力强，具有高度的责任心和团队合作精神."
"职位描述：
        
        岗位职责：
1.基于海量用户行为数据，建立、评估、持续优化数据模型，包括但不限于：用户价值评分、用户风险评分、用户偏好预测 、用户画像构建等等，产出用户标签。2. 负责标签体系规划和制定、标签的设计和开发、标签产品的构建。3. 促进标签产品在公司各业务领域的应用，持续提升用户产品体验，并探索新的商业模式。
岗位要求：
1. 本科及以上学历，计算机或数学相关专业，工作3年以上；2. 精通hive sql,spark sql，spark上的JAVA开发3. 有2年以上用户画像构建和应用实战经验，有数据挖掘实践经验，擅长从海量数据中发现有价值的规律。4. 思维清晰敏捷，逻辑分析能力强，具有良好的语言和书面表达能力；5. 自我驱动能力强，踏实勤勉，对有挑战的问题充满激情。6.?有大型互联网公司或保险行业背景优先。"
"职位描述：
        
        
岗位职责：
1、负责需求的设计开发，独立完成设计方案，指导他人进行开发工作。2、独立解决系统问题，参与系统性能优化，进行代码重构等工作。3、负责领域内较新技术方向的研究，转化。
岗位要求：
1、 3年以上JAVA软件开发实际开发经验，具有独立的技术分析能力，技术视野宽广。2、具有大型网站或技术平台的设计和编码经验，对设计模式、基本的算法、高并发、多线程编程能熟练运用，并有一些理解。3、 精通JavaEE常用框架，Struts2、Spring、mybatis，熟悉JavaEE技术体系（JSP、Servlet、EJB、JNDI、XML、SOAP、JMS等）4、 精通Javascript、html、css、xml等语言，熟练使用JQuery，angularJs等JS框架技术5、 精通SQL、存储过程、熟悉Oracle、Mysql等数据库，熟练掌握数据库的操作、优化和管理"
"职位描述：
        
        岗位职责：
1、参与公司内部大数据平台的建设，包括数据采集、数据治理等；
2、与算法工程师、架构师等同事合作，完成相关模块的需求分析、设计、开发等工作；
3、跟进大数据前沿技术的发展，将合适的技术方案适时引入业务场景。
?
任职要求：
1、全日制统招本科及以上学历，计算机相关专业；
2、两年以上大数据相关项目实战经验；
3、熟练掌握Hadoop、Spark Streaming、Hive、MongoDB、Kafka等相关技术；
4、熟练掌握Scala或Java语言；
5、具备机器学习、深度学习实战经验者优先；
6、热爱技术，主动思考，有很强的学习能力。"
"职位描述：
        
        职责描述：1、深入理解业务，参与需求分析,为业务开发提供架构设计；2、大数据平台工具的需求分析、数据库设计、架构设计，确保系统的架构质量、核心编码，确保代码的可读性、性能等；3、发现和解决存在的性能瓶颈等技术难题，分析并解决线下/线上测试中发现的BUG；4、用创新的思路解决问题，能对现存或未来系统进行宏观的思考，规划形成统一的框架、平台或组件；5、对未来技术架构具有前瞻性和规划能力。任职要求：1、工作年限：3年以上，本科及以上学历；2、行业背景：java web方向；3、知识，技能及经验：a、计算机基础扎实，熟悉常用数据结构和算法，具备较强的逻辑思维能力；b、扎实的编程基础，精通Java开发语言，熟悉JVM，Web开发、缓存、分布式、消息中间件等核心技术；有运行态JVM分析及调优的实际经验；c、熟悉掌握常用的Java类库及框架，如多线程、并发处理、I/O与网络通讯、Spring、iBatis、SpringMVC等；d、有大数据平台方向工具开发如大数据调度系统、元数据管理等经验优先；e、有大数据开源组件如hadoop/spark等经验优先；f、有较强的逻辑/概率思维能力，善于分析、归纳、描述、沟通、和解决问题；g、高度的创业心和投入度，既能搞定技术难题，同时又热切地关注业务，用技术力贡献于业务成功"
"职位描述：
        
        职位描述： 1.负责和品牌厂商沟通，依据所提供的品牌编码属性，共同进行原厂编码的匹配整理；
2.负责对品牌件规格、材质、图片等数据进行整理和更新以确保支持售卖使用。 任职要求：
1.大专或以上学历，有一年以上汽配或数据处理相关工作经验者； 2.熟悉汽车各部分的结构、工作原理，能熟练操作至少1个车品牌的配件查询系统；
3.对数据敏感，逻辑思维良好，具备团队合作能力；
4.熟练使用excel等办公软件。"
"职位描述：
        
        工作职责：
1、 基于hadoop、spark等大数据技术构建数据存储及计算方案供分析平台使用，并管理Hadoop集群正常、稳定运行；
2、 负责接入和管理各业务系统的数据，进行数据采集、抽取、清洗整合工作；
3、 搭建数据开发、部署的流程，保证日常数据稳定、安全、准确；
4、 与小组数据开发成员完成实时计算、离线分析等开发，并对交付质量负责。

岗位要求：
1、 本科及以上学历，计算机/软件工程/统计学/数学等相关专业，互联网/金融等行业3年以上工作经验，2年以上大数据开发经验；
2、 熟悉linux 操作系统,具备一定的开发能力,熟悉至少一门脚本语言(shell/python等),熟悉至少一门开发语言(Java/C++等)；
3、 熟悉hadoop原理、熟悉hadoop集群的搭建、管理及优化；
4、 熟悉数据库开发（Mysql/PostgreSQL/Greenplum等），有数据仓库、ETL工程经验者优先；
5、 熟悉Hadoop/HBase/Spark/Storm/Redis/Kafka/ES/Flume技术及其生态圈，具备相关项目开发经验，有数据实时计算项目经验优先；
6、 责任心强，认真细致，良好的沟通能力和团队协作精神，有清晰的逻辑思维能力及文档编写能力。"
"职位描述：
        
        【工作职责】参与量化数据的整理、数据挖掘、系统对接；【职位要求】
1、数理、统计、计算机等相关专业毕业；?2、熟练使用python以及相关的科学运算包（如python中的Numpy、Scipy、Pandas等），理解基本的数据结构和使用场景，有大数 据集处理经验的优先考虑；?3、熟悉sql语句，能进行基本的增删改查，merge等操作。了解sql语句的高级用法如，rank over、partitionby等；4、有投资经验（如股票、期货、数字货币），了解日内行情数据的优先考虑；5、具备较强的责任心，做事严谨踏实，思路清楚，善于学习总结。"
"职位描述：
        
        工作职责：1、基于Hive与Hadoop，进行数据建模、数据ETL任务开发；?2、负责公司业务报表的开发，包括数据统计、分析与输出；?3、负责分布式数据平台框架下的数据架构设计与开发，以及新数据应用开发；?4、参与数据基础平台搭建，公司业务数据采集任务开发；
任职资格：1、 本科或以上学历，计算机、数学等相关专业，3年以上工作经验；2、 熟悉Hadoop或其他分布式数据开发技术，熟练掌握数据库技术；?3、 有数据仓库（百T及以上）的系统设计和开发，精通数据建模、ETL过程、元数据管理等数据仓库主要环节优先；?4、 精通SQL,PL/SQL，精通Mysql数据库优先；?5、 熟练使用Hadoop或其他分布式平台的一种，能使用Java、Python或其他语言编写MapReduce进行大数据处理；"
"职位描述：
        
        【工作职责】
1、负责手机游戏的数据库部署、备份以及相关维护；
2、负责数据中心的数据处理、报表开发等工作；
3、参与和公司其他部门沟通协调,?支持其他部门工作；
4、具有较强的业务领悟和分析能力
【职位要求】
1、精通MySQL的日常管理与维护；
2、精通SQL脚本和存储过程，满足对数据库的日常查询与统计等需求；
3、至少能熟练使用shell/perl/python之中的一种脚本语言，熟悉Linux系统的日常使用；
4、两年以上数据库管理相关工作经验，熟悉网络游戏行业，有相关从业经历者优先；
5、良好的沟通能力、团队精神，良好的分析和解决问题能力，能承受高强度工作压力；
6、具备较强的工作责任心及自学和独立完成工作能力。"
"职位描述：
        
        [关于工程师爸爸]
灵感源自父爱。
2010年，创始人李文华先生任职盛大文学技术总监，全面负责盛大文学平台的产品和技术，以及当时国内最大的电纸书Bambook。
彼时，李文华先生的女儿Sunny5岁，在为Sunny挑选儿童APP时，做了大量的评测，并把心得记录在BLOG里。专业、好用的内容迅速受到了家长用户的欢迎。
2011年，在众多用户的期盼下，专注于儿童内容运营领域的平台――工程师爸爸正式成立，从此开启了“开挂”的历程：
2012年，“口袋故事”APP横空出世，现已获得3000万家庭的喜欢；
2014年，“工爸云”儿童内容云平台诞生，现已开放超过10万部正版儿童音频给合作伙伴；
2018年，口袋故事累计播放次数已经超过100亿次。
经过7年的经营与成长，“工程师爸爸”成为中国领先的儿童内容运营商，是中国第一家拥有过80%以上儿童获奖作家的作品版权的平台，也是中国第一家与迪士尼的配音团队深度合作的平台。
“工程师爸爸”推出的《大耳朵图图》、《婷婷诗教》、《葫芦娃》、《少儿版四大名著》、《小老鼠丢丢》等上万部的优质作品，均受到广大用户喜爱。
在中国，80%以上的智能终端如腾讯、小米、京东均选择与“工程师爸爸”达成深度内容合作。
一个无心插柳的开始，经过不懈努力，成长出让人自豪的果实。
期待更多的人才，加入我们，一起打造儿童内容平台的NO.1。
我们的愿景：让成长更自由！

[我们为什么要招这个岗位]
随着业务发展，用户数据沉淀愈来愈多，我们需要满足海量用户个性化数据需求，以提供高质量的大数据服务。

[你的核心职责]
1、你会负责公司大数据应用平台的规划、设计、搭建和优化；
2、使用海量数据为用户提供个性化数据服务；
3、抽象，提取，设计业务需求，提供高质量的大数据服务。

[我们希望你是这样的伙伴]
1、行业经验：具备知名K12教育、儿童类、家长社区类、知识社区平台、有声内容类、音乐平台类行业经验；
2、项目经验：5年以上开发经验，2年以上大数据开发经验，有大型互联网项目大数据开发经验为重要加分项；
3、你需要熟悉大数据生态，包括但不限于Hadoop/spark/kafka/hadoop/greenplum/presto/kylin等；
4、最好精通java/python/golang/Scala其中至少一门语言；
5、具有架构师般的抽象能力和逻辑思维；
6、热爱互联网，对互联网C端产品/用户行为/行业知识有一定深度和广度的理解；如果你即懂行业又懂业务，我们会将把你视若珍宝，因为我们认为对行业的理解和研究比数据处理技术更为重要。

[我们可以提供的]
行政妹子精心准备的各种零食；
超过法定数额的带薪年假和病假;
一把让你瞬间爱上的人体工程学座椅；
步行10分钟可达地铁的极佳位置；
每年一次的团队旅行……
――希望能带给你舒心的工作体验。

更重要的是，这是一份有挑战的工作，带给你：
成就感，可以改变千万家庭亲子教育的创新方向；
成长，以及不负努力成果的优渥薪资......
――我们也关心你的牛奶面包，诗和远方。"
"职位描述：
        
        工作职责：
1、参与公司大数据产品规划；
2、大数据处理分析平台的设计与开发；
3、为项目提供大数据技术指导及分析手段支持。

任职要求：
1、统招本科以上学历，4年以上大数据相关工作经验，熟悉Hadoop、Spark生态相关技术，包括MapReduce、hdfs、Hive、Spark等；
2、熟练使用Linux操作系统，精通Java/python语言；
3、熟悉NoSQL生态环境，掌握HBase或MongoDB；熟悉Oracle或MySQL数据库技术；
4、具有一定的技术钻研精神，对大数据领域相关技术有浓厚的兴趣；
5、工作主动性强，具有良好的团队意识和沟通能力。"
"职位描述：
        
        岗位职责：
1、参与公司大数据产品规划；
2、大数据处理分析平台的设计与开发；
3、为项目提供大数据技术指导及分析手段支持。
?
任职要求：
1、熟练使用Linux操作系统，精通Java/python语言；
2、本科以上学历，5年以上大数据相关工作经验，熟悉Hadoop、Spark生态相关技术，包括MapReduce、hdfs、Hive、Spark等；
3、熟悉NoSQL生态环境，掌握HBase或MongoDB；熟悉Oracle或MySQL数据库技术；
4、具有一定的技术钻研精神，对大数据领域相关技术有浓厚的兴趣；
5、工作主动性强，具有良好的团队意识和沟通能力。"
"职位描述：
        
        1.计算机或相关专业，大学本科及以上学历；2.三年及以上大数据开发经验，有产品研发或大型项目经验优先；3.熟悉Java、Scala或其他语言，深谙编码思想，有一定的设计经验；4.熟悉Apache?Hadoop、Spark原生态及主流发行版（CDH、HDP）者优先；5.熟悉HDFS、HBase、Kafka、SparkStreaming、ES等原理，可熟练进行API编程；6.熟悉Linux常用操作，有一定的Shell开发能力；7.具备一定的大数据分析排错能力；8、参与过大数据平台或分布式系统开发工作，有开源代码或者二次开发能力加分项； ? ?
工作地点：光谷或汉口"
"职位描述：
        
        岗位职责:
工作内容： 1、负责电商领域大数据产品功能开发。 2、研究业界新技术及其应用，解决创新研发过程中的关键问题和技术难点； 3、分析需求，根据规范进行系统概要设计和详细设计。 4、根据项目任务计划按时完成编码实现，确保安全、质量和性能。 5、负责对结构化和非结构化数据中建立基于标签描述和层次体系的数据模型设计和挖掘。 6、参与产品技术架构讨论和技术选型。 7、如果你是具有业务思维，敢于挑战未知领域的，I Want You!

任职资格: 1、计算机相关专业，本科及以上学历，5年以上java开发经验。? 2、熟悉Mongodb、Hive、Hbase、redis等NOSQL数据库开发和调优，熟悉图形数据库的优先。? 3、熟悉分布式开源框架和工具如ZooKeeper、Strom、Spark、Hadoop、Impala 等(计算框架会其一即可)。? 4、熟悉Active MQ、Kafka等MQ框架和协议。? 5、具有大数据架构设计能力，并有大型项目实践经验。 6、熟悉JVM原理，有JAVA性能调优实践经验，高并发，高可用，多线程服务器端架构和开发调优的优先。 7、熟悉软件设计流程和软件工程规范，具备良好而规范的设计和技术文档编写能力。? 8、具有良好的沟通能力，有较强的独立工作能力和解决问题的能力。? 9、对业务有敏锐的洞察力，有较强的业务理解与分析能力。? 10、有大型互联网项目、电商、CRM、推荐引擎设计相关实践经验者优先！"
"职位描述：
        
        工作职责:1、主要从事大数据离线平台的设计以及开发工作，维护升级等等；2、负责离线的数据存储和加工处理，保证数据质量，负责数据监体系的建立和维护；3、负责海量数据的清洗、处理和挖掘工作，支持数据分析师和算法工程师的数据需求；4、负责日常数据仓库、监控、分析、性能调优、故障诊断与排除等工作；5、负责数据仓库ETL流程的优化及解决ETL相关技术问题；6、研究前沿技术，解决实际场景中的业务问题，优化离线/实时大数据计算任务的性能。任职资格:1、教育程度：全日制本科及以上学历，计算机或相关专业优先；2、工作经验：3年及以上工作经验，2年以上大数据开发经验，在金融领域或互联网领域有至少1年的从业经验，优秀者可适当放宽； 3、知识技能：熟悉Linux/Unix开发环境，精通数据库基本原理，熟悉SQL语言与shell编程，熟悉Hadoop原理，具备一定的hive、spark开发经验；4、精通数据仓库理论，具备数据仓库开发、维护经验；5、能力素质：良好的团队精神和合作意识，强烈的责任心，对工作有激情，良好的沟通能力，能吃苦耐劳；具备快速学习能力，思路清晰，善于思考。"
"职位描述：
        
        岗位描述：1、负责公司大数据平台及应用平台的规划、架构设计、调优及故障诊断；2、负责公司大数据开发规范的制定，组织大数据相关技能的培训；3、负责公司大数据方向技术创新，针对特定业务场景，能快速完成技术预演，提供有效解决方案，并指导相关开发人员实施上线；
职位要求1. 5年以上大数据系统开发，设计，架构经验2.?熟练掌握Hive、HBase、Spark/Spark streaming的架构及实现原理，阅读过部分源码，能对其进行二次开发、故障分析、性能调优；3. 至少精通Impala、Presto、HAWQ、Kylin、Druid、ElasticSearch其中之一，阅读过部分源码，能对其进行二次开发、故障分析、性能调优；4. 精通多线程编程。有分布式开发经验值优先； 5. 有机器学习、统计学背景的优先。"
"职位描述：
        
        职责内容
1、用数据策略推动学术产品升级，并用产品数据来不断反馈优化数据策略升级
2、分析学员学习特征，以学员为中心，定制阶段化、个性化的学习方案
3、推进自适应学习模型，实现学员、讲师、教学资源的优化统一，完善学员学习路径优化，提升参与率与做题准确率
4、评估学员学习效果，预测学员考试成绩
5、推进学术资源的数据标准化、完整性及产品核心指标的监控、分析
6、推进知识图谱、在线学习方式、方法的研究创新，推进AI、机器学习技术在教学过程中的应用
任职要求
1、大学本科及以上学历，数学，统计学，计算机相关专业，3年以上工作经验
2、熟练掌握Excel、mysql、python、R等。
3、有丰富的数据分析建模经验，对数据驱动业务有一定理解
4、能独立完成数据的采集、处理与分析，完成模型的假设与验证；能从数据中提炼分析结果，挖掘存在的问题或价值
5、思维严谨，热爱分享，学习能力强，有教育行业分析经验优先"
"职位描述：
        
         
 
 
岗位职责:1.负责数据仓库和大数据处理模块的架构设计和开发;2.负责基于 Spark 技术的海量数据的处理、分析、统计、挖掘工作;
3.参与应用选型研究、系统架构设计、核心攻坚工作;
 
任职要求:1.本科及以上学历，计算机相关专业，3 年以上开发经验；
 
2.熟悉 Hadoop/Spark 生态系统组件的使用，至少有 1 年的Spark(Core/Streaming/SQL)开发经验;
 
3.熟悉分布式计算系统理念，熟悉 Hive、presto、Zookeeper 等工具，熟悉MLlib;
 
4.熟悉 Scala/Java 语言，对 Scala/Java 原理、底层技术有深入研究者优先;
 
5.有优良的 Trouble Shooting 能力，对新技术有孜孜不倦的热情，具有良好的 学习能力、团队协作能力和沟通能力;
 
 
 
 
 
 
 
6.熟练使用 Mysql、Oracle、SQLServer 数据库中的一种或多种，并了解 NoSQL技术
 
7.有过海量数据系统开发经验者优先;8.在开源社群活跃并有积极贡献者优先;9.有 HBase、Kafka、ES(ELK)、Greenplum、图计算、图存储等经验者优先;
10.有统计学数学知识，海量数据处理、数据分析和挖掘经验者优先;11.有 linux、python 经验者优先;"
"职位描述：
        
        岗位职责:
・?负责自动驾驶大数据平台系统架构设计、实现及优化；
・?负责自动驾驶负责数据标注与处理流程的可视化工具开发，自动化标注平台的设计与研发；
・?负责解决、攻克大数据平台的核心技术难题。


任职资格:
・?计算机或相关专业，本科及硕士以上学历；
・?熟悉整个大数据的完整处理流程（数据的采集、清洗、预处理、存储、分析挖掘、机器学习和数据可视化等），有完整的大数据项目设计、开发及部署经验；
・?具备扎实的数据结构及算法功底，精通Java/Scala/Python等至少一门编程语言，具有3年以上开发经验；
・?熟悉Linux开发环境，熟悉分布式系统的基本原理和开发调试技巧，具备大型系统架构经验，自动驾驶或BAT相关从业经验优先考虑；
・?有基于SQL及No-SQL数据库的应用程序的设计、开发经验；
・?熟悉REST服务及Web标准，熟练掌握一种主流前端开发框架，如VUE/React/AngularJS，能同时独立构建前端应用优先；
・?熟悉自动驾驶及相关的Lidar、Camera等传感器数据优先；
・?适应创业公司氛围，自我驱动，简单直接沟通，团结合作，高效快速应对变化；
・?熟练的英文听说读写能力，较强的沟通能力、逻辑思维能力和抽象能力，较强的责任心和快速学习能力；
・?热衷于产品研发和技术发展、具有强烈的责任意识、开放的心态、进取心及团队合作精神；思路清晰，善于思考和总结，能独立解决难题。"
"职位描述：
        
        1. 负责自动驾驶数据采集系统的设计、开发、测试和部署；
2.参与自动驾驶相关Lidar，摄像头、雷达、GPS、IMU等传感器的评估、选购、测试、校准等工作。
3. 参与数据采集车辆管理、工具和校准空间的实验室空间。
4.为传感器数据构建丰富的3D和2D可视化工具。
5.为内部其它团队提供必要的指导和文档说明，以便轻松利用数据；
6.创建用于数据管理、标记、分区和搜索的相关工具
7. 为定位或高清地图等功能特性提供相关数据采集支持

任职资格:
1. 本科、硕士或博士以上学历，机器人、软件工程或机器学习等相关专业毕业；
2.有自动驾驶或相关大型软件项目开发经验优先；具备机器人操作系统（ROS）或类似的大型开源项目的经验优先；
3.有汽车制造商OEM或Tier1供应商经验优先。
4.熟悉Linux开发环境；精通C++/JAVA/PYTHON等至少一门编程语言；熟悉并行计算平台或分布式计算优先；
5.熟悉自动驾驶及相关的Lidar、摄像头、雷达、GPS-IMU等传感器数据优先；
6.有强烈解决自动驾驶相关挑战的欲望。
7.适应创业公司氛围，自我驱动，简单直接沟通，团结合作，高效快速应对变化；
8.英文听说读写能力优秀者优先"
"职位描述：
        
        岗位职责：
1、参与小鹏汽车技术中台的大数据云平台产品建设，包括：实时计算处理平台、离线计算处理平台、调用链分析监控、日志处理平台；
2、分析系统瓶颈，处理、协调和解决基础框架中出现的技术问题；
3、大数据新技术研究和应用，并推动适合技术应用于生产；
任职要求：
1、计算机相关专业，本科或以上学历，五年以上开发工作经验，有基础架构开发经验优先；
2、熟练Java、Python服务端编程，有良好的编码习惯；
3、深入理解MapReduce，熟练使用Storm/Flink、Hadoop、Spark，并阅读部分源码；
4、熟练使用Hadoop、HDFS、HBase、Kafka、ElasticSearch；
5、具有自然语言处理、信息检索、机器学习、web挖掘、搜索引擎、推荐引擎等相关经验优先；
6、熟悉Docker容器及容器化技术，有Kubernetes实战经验者优先；
7、对新技术有执着追求，热爱编程。善于抽象、总结、思考，能及时关注和学习业界最新技术；
8、有较强的自学能力和钻研精神，具有良好的沟通能力和团队合作能力，综合能力强。"
"职位描述：
        
        工作职责:
1.数据统计分析：小鹏汽车业务用户行为数据统计与分析，产品效果评估与分析，为产品策略优化迭代提供强有力的数据支持
2.数据挖掘：从海量日志数据中发掘有价值的信息，建立多个维度上的模型，用于指导产品优化
职位要求:
1.数学、统计、金融、计算机或者相关专业本科以上学历
2.熟悉Java/Python，熟练掌握SQL，具有2年以上开发或者统计分析经验
3.了解HADOOP大数据平台架构，熟悉HDFS/HBase/Hive/MapReduce/Spark，熟练掌握HiveSQL、Mapreduce程序开发
4.对数据仓库系统架构具有良好的认知，熟悉数据仓库相关技术，如 ETL、报表开发，具备数据分析技术并具有相关项目经验
5.掌握常用的数据分析工具、数据挖掘、机器学习算法是加分项"
"职位描述：
        
        岗位职责1.?负责公司大数据平台的搭建和海量数据处理；2.?负责数据采集、清洗、加工、分类等方面的工作；3.?能够对大数据平台进行性能调优；4.?负责大数据平台的可用性、稳定性和可扩展性。岗位要求：?1.?熟悉linux操作系统，熟悉?shell、python?、scala、java?等至少一种语言；2.?熟悉分布式系统的架构，有分布式系统架构设计的经验，至少1个以上大型成熟项目的经验；??3.?熟悉?ELK?或??Hbase?体系架构，并有相当开发经验；4.?有数据挖掘及机器学习方面的经验优先。"
"职位描述：
        
        【职位描述】
1．基于大型分布式平台的数据仓库模型设计及实现；
2．ETL开发、优化、技术攻关；
3．负责数据项目的开发、推进和优化；
4．数据产品、工具的设计和技术实现；
5．协助建立数据模型，对数据进行挖掘、优化及统计。

【任职要求】
1．2-5年数据仓库实施经验，ETL实施经验，认可数据产生价值；
2．熟练掌握一门语言Java或者Scala，能够编写Mapreduce、Spark等应用程序，以及相关的性能优化方式；
3．理解数据库原理，熟练使用至少一种关系数据库管理系统，如Mysql、Oracle；理解Nosql；
4．精通一种或多种分布式平台，理解计算框架，如Hadoop，Mapreduce、Spark streaming、HBase，Zookeeper、Hive、Sqoop、elk、Kafka；熟练掌握相关组件的使用、原理实现、常用的性能优化方案；
5．熟悉常用的数据结构和算法，有在业务或分布式系统中解决负载均衡，数据一致性保证的经验尤佳；
6．熟悉Linux系统，熟练掌握 Shell、Python、Perl 或其它任何一门脚本语言；
7. 有快速和持续学习的能力，动手能力强，有进取心、责任心强。"
"职位描述：
        
        【岗位职责】
1、小赢大数据平台的设计及数据分析挖掘平台的开发；
2、数据平台的ETL和数据统计分析、价值挖掘、数据可视化洞察系统的开发和维护；
3、协助营运、开发和管理团队进行日常数据提取与分析模型完善。

【任职资格】
1、熟悉Mac/Linux操作系统，了解Hadoop/Hbase/Hive/Spark等目前主流大数据平台的特性，并有相应系统安装和优化维护经验，有MapReduce程序开发经验；
2、熟悉数据的仓库模型的设计，了解Geenplum／Teradata等OLAP数据分析平台，有Druid等数据库使用经验者优先；
3、熟悉Mysql/Postgres等主流数据库的开发和使用，熟悉不同平台的数据迁移和导入/导出；
4、精通python/java等开发语言，熟悉SQL语句性能优化，对可视化的图表有深入的理解和图表组件的使用经验，有一定的web开发能力；
5、有用户画像、推荐系统和大数据机器学习方面经验者优先考虑；
6、良好的学习沟通协调能力和能严谨的面对数据，具备较好的技术执行力，计算机相关专业本科以上学历。"
"职位描述：
        
        ?
【应聘条件】：1）大专以上学历，计算机（网络）、电子信息、软件工程、（电气）自动化、测控、生仪、机电、英语、数学等相关专业往应届生，对编程感兴趣者。2）有计算机语言基础者优先考虑，如：JAVA、.C语言、C++、C#、Net、PHP等。
3）有十分明晰的IT职业发展规划，钻研精神和学习能力，团队合作能力，学习能力强的。
【职业背景】
1、Java+大数据――Java 已经连续21年位居热门编程语言之首。在薪酬待遇方面，远高于其他程序员。Java+大数据开发工程师，待遇更高，入职轻松起薪10k.2、人工智能+ Python――已经走进我们的生活，来得有些突然，以至于目前国内大学还没有开设人工智能专业，一名入门级的AI工程师月薪轻松就可以拿到15K，中、高级工程师，企业更是给出30万到150万的年薪；Python非常适合AI开发，它更接近自然语言，编程简单, 速度超快，它能够把各种模块很轻松地联结在一起,开发人员不必重复造轮子，像搭积木一样就可以完成绝大部分工作， 非常适合初学编程者。　　　未来将是人工智能的天下，越来越多的工作都将被人工智能替代！如果你够睿智，就算是壮士断腕，也要毅然决然地走进“人工智能”，四年后，当第一期AI大学生进入这一领域时，你已经年薪百万，已经是他们的总监、是他们的CEO了。人工智能时代刚刚拉开帷幕，现在加入，你就是下一个技术时代的王者。【福利待遇】：
1、签订正式《合同》。
2、入职首年二次调薪，年薪不低于10万元，高不封顶。
【发展空间及职业规划】：程序员----开发工程师----高级架构师----技术经理（CTO）----首席执行官（CEO）"
"职位描述：
        
        工作职责：1、负责广告产品核心业务模块数据仓库的构建；2、负责数据模型的设计，ETL实施、ETL性能优化、ETL数据监控以及一系列技术问题的解决；任职要求：1、计算机、数学相关专业，本科及以上学历，三年以上大数据开发工作经验，数据挖掘和BI分析领域优先；2、熟练掌握Hive/SQL，熟悉Spark/Map-Reduce/MPI分布式计算框架，熟悉大数据的离线和实时处理，可以进行海量数据模型的设计、开发；3、有产品sense，主动思考基于业务场景下的数据体系建设，而不单单只会做执行；4、工作认真，负责，良好的团队合作精神和解决问题分析能力，钻研技术克服困难，勇于挑战；5、有数据分析经验优先。"
"职位描述：
        
        【工作职责】
1. 负责数据分布式存储、计算系统；
2. 高水平团队，有 Ownership 的推动数据系统迭代；
3. 从架构到业务，支持公司快速发展；
4. 支持 CRM、搜索、机器学习平台等应用的底层数据架构。
?
【职位要求】
1. 掌握分布式系统原理，对存储、离线计算、实时计算中的一项或多项有深入的理解和认
识；
2. 很强的系统设计&编码能力，追求优雅的设计和优秀的代码质量，高标准，快速行动；
3. 思路清晰，具备生产系统快速 trouble-shooting 的经验和能力，擅长分析更深层次的原
因；
4. 对 HDFS, RocksDB, LevelDB, Memcache, Redis, MySQL, HBase, Kafka 的一项或多项有开发
经验；
5. 了解 Kafka、 MQ 等消息系统；
6. 对 Spark, Druid, Flink, OLAP 的一项或多项有经验者优先；
7. 拥抱新技术，有很强的学习能力。"
"职位描述：
        
        工作职责：
1. 负责数据分布式存储、计算系统；
2. 高水平团队，有 Ownership 的推动数据系统迭代；
3. 从架构到业务，支持公司快速发展；
4. 支持 CRM、搜索、机器学习平台等应用的底层数据架构。
?
职位要求：
1. 掌握分布式系统原理，对存储、离线计算、实时计算中的一项或多项有深入的理解和认识；
2. 很强的系统设计&编码能力，追求优雅的设计和优秀的代码质量，高标准，快速行动；
3. 思路清晰，具备生产系统快速 trouble-shooting 的经验和能力，擅长分析更深层次的原因；
4. 对 HDFS, RocksDB, LevelDB, Memcache, Redis, MySQL, HBase, Kafka 的一项或多项有开发经验；
5. 了解 Kafka、 MQ 等消息系统；
6. 对 Spark, Druid, Flink, OLAP 的一项或多项有经验者优先；
7. 拥抱新技术，有很强的学习能力。"
"职位描述：
        
        工作职责:
?
1. 负责小红书实时数据云平台，数据仓库建设；
2. 负责小红书Feed流，推荐实时数据Pipeline建设；
?
职责要求:
1. 计算机或相关专业本科以上学历；
2. 熟悉Linux，熟悉Scala/Java，熟悉常用脚本语言Shell、python等；
3. 有Storm/Spark Streaming/Flink等大规模实时框架经验；
4. 熟悉常用算法和数据结构，熟悉网络编程、多线程；
5. 熟悉分布式系统，有大规模系统设计和工程实现经验；
6. 熟悉Hbase/Redis/HDFS/MySQL等, 熟悉使用Kafka/RabbitMQ等消息中间件；
7. Team Player，良好的沟通能力。"
"职位描述：
        
        工作职责:
?
1. 负责小红书实时数据云平台，数据仓库建设；
2. 负责小红书Feed流，推荐实时数据Pipeline建设；
?
职责要求:
1. 计算机或相关专业本科以上学历；
2. 熟悉Linux，熟悉Scala/Java，熟悉常用脚本语言Shell、python等；
3. 有Storm/Spark Streaming/Flink等大规模实时框架经验；
4. 熟悉常用算法和数据结构，熟悉网络编程、多线程；
5. 熟悉分布式系统，有大规模系统设计和工程实现经验；
6. 熟悉Hbase/Redis/HDFS/MySQL等, 熟悉使用Kafka/RabbitMQ等消息中间件；
7. Team Player，良好的沟通能力。"
"职位描述：
        
        工作职责：
1.???????? 构建数据仓库，设计数据结构存储海量的产品数据，同时用技术手段解决灵活的，多层级的数据查询需求；
2.???????? 构建和优化数据处理流程，支撑处理海量数据规模；
3.???????? 利用机器学习技术，为业务部门建立数据分析和预测模型；
4.???????? 支持产品，运营、销售对业务上相关的数据需求，提供数据驱动和决策。
任职要求：
1.???????? 2 年Scala大数据开发经验，计算机相关专业本科及以上学历；
2.???????? 熟悉 MapReduce, Hadoop, Spark 等分布式相关的技术及组件；
3.???????? 熟悉 Spark Streaming 和 Spark MLlib 的相关开发；
4.???????? 熟悉 NoSQL（HBase/Redis），有过 HBase/Hive 调优优先；
5.???????? 有系统设计经验；
6.???????? 很强的自我驱动力、结果导向并极具责任感，有良好沟通能力和团队协作精神。"
"职位描述：
        
        工作职责:1、根据公司业务现状，挖掘业务痛点，研发稳定、易用、高效的中间件产品及基础服务平台，并持续优化；2、了解业务当前在技术上遇到的困难，帮忙业务方解决技术问题，用技术推动业务发展；3、在保障系统稳定性前提下，优化系统，降低企业成本。任职资格:1、软件工程/计算机科学/电子工程相关专业本科以上学历；2、熟悉Java常用框架，熟悉JVM，具备扎实的Java基础知识；3、熟悉知名开源中间件的实现原理；4、有强大的自驱力，勇于不断自我提升。"
"职位描述：
        
        工作职责：
1、参与海量数据的运营数据分析体系搭建, 数据量化运营效果,支持产品快速迭代；
2、开发各种数据分析工具, 支持产品效果优化；
3、负责数据接入, 数据清洗, 业务数据建模等工作。
任职要求：
1、统招本科或以上学历（硕士优先），985/211院校优先,计算机或相关专业毕业；
2、扎实的编程能力，熟练掌握Java/Scala编程；
3、熟悉算法和数据结构，熟悉计算机的基础理论；
4、深入理解MapReduce，Storm，Spark等大数据框架，并阅读部分源代码；
5、有数据数据实时处理经验, 熟悉Druid, Kylin等框架并有使用经验者优先；
6、掌握一种数据库技术，例如oracle、db2、mysql等，熟练使用sql进行数据处理；
7、工作细致、责任心强，具备较强的学习能力及理解能力，有良好的沟通能力和团队协作能力；
8、有分布式系统、大规模线上系统开发或者大规模数据处理经验的优先。"""
"职位描述：
        
        岗位职责：
1.参与小米IoT业务超大规模实时/离线数据计算框架，存储、查询、可视化解决方案的设计及研发
2.参与PB级实时/离线数据仓库建设

岗位要求：
1.计算机专业本科及以上，3年以上相关岗位工作经验
2.扎实的编程能力，熟悉算法和数据结构，熟悉计算机的基础理论
3.精通一种或多种分布式计算、存储、调度框架或工具（Hadoop/Hive/MapReduce/Spark/Hbase/Flink/Hbase等），有分布式系统的开发经验者优先。
4.有分布式OLAP系统开发应用经验者优先，对基于KV的分布式存储查询系统(Palo/Kylin/Presto)有过深入研究者优先
5.业务理解力强，对数据、新技术敏感，能基于对复杂业务逻辑的抽象，快速解决问题
6.积极乐观、诚信、有责任心，具备强烈的进取心、求知欲及团队合作精神"
"职位描述：
        
        工作职责：
1、负责海量数据分析平台的建设，保障数据方便快捷的被业务部门使用
2、负责数据存储和查询性能的优化，保障海量数据的结果能够高性价比、稳定、快速输出

任职要求：
1、计算机相关专业本科以上学历，一年以上大数据底层系统的开发经验
2、熟悉服务器软硬件体系结构，精通Linux和大数据的存储和计算模型，有相关经验
3、精通一种开发语言（Python、Scala、Java、C等），并具有快速学习其他开发语言的能力
4、熟悉Hadoop(HDFS/MapReduce/Hive/HBase)、Spark、Kafka的使用，熟悉Mysql等关系型数据库和NoSql技术
5、对数据敏感，能熟练预估数据量以及数据项之间关系，善于从数据中发现问题
6、具有良好的沟通协作能力，具有较强的分享意愿"
"职位描述：
        
        数据研发工程师
工作职责：
1、支持资讯, 电商, 小说等内容产品的精细化运营工作；
2、负责上述内容产品的数据仓库建设；
3、参与海量数据的运营数据分析体系搭建, 数据量化运营效果,支持产品快速迭代；
4、开发各种数据分析工具, 支持产品效果优化；
5、负责数据接入, 数据清洗, 业务数据建模等工作。
?
任职要求：
1、本科或以上,计算机或相关专业毕业；
2、扎实的编程能力，熟练掌握Java/Scala编程；
3、熟悉算法和数据结构，熟悉计算机的基础理论；
4、深入理解MapReduce，Storm，Spark等大数据框架，并阅读部分源代码；
5、有数据数据实时处理经验, 熟悉Druid, Kylin等框架并有使用经验者优先；
6、掌握一种数据库技术，例如oracle、db2、mysql等，熟练使用sql进行数据处理；
7、工作细致、责任心强，具备较强的学习能力及理解能力，有良好的沟通能力和团队协作能力；
8、有分布式系统、大规模线上系统开发或者大规模数据处理经验的优先。"
"职位描述：
        
        岗位职责：1、理解线上业务和数据，设计和实现大规模数据统计挖掘等工作。2、对海量数据进行处理，涉及Hadoop，Spark，Kafka，Hbase等技术组件；3、对数据进行挖掘建模，分析影响系统的关键因素，规划、设计和实现新的解决方案，评估并优化模型。任职要求：1.熟悉java/scala/python等任意一种编码语言。2.熟悉常用开源分布式系统，两年以上Hadoop及大数据生态圈产品实践经验，如Kafka/HBase/Presto/YARN/Spark等3.有大规模分布式系统开发、维护经验，有故障处理能力，源码级开发能力4.熟悉数据仓库原理，并有大型数据系统建设经验5.能使用Spark mllib,sklearn等开源框架实现常用的统计和算法模型。加分项:1、了解Lr,Gbdt，Bayes,Svm等机器学习算法，有过相关的实际项目或者比赛项目经验更佳。2、了解凸优化、概率论、统计、矩阵分析等数学原理更佳。3、有大规模数据集处理经验，具有丰富的特征工程经验更佳。"
"职位描述：
        
        工作职责：
1、参与海量数据的运营数据分析体系搭建, 数据量化运营效果,支持产品快速迭代；
2、开发各种数据分析工具, 支持产品效果优化；
3、负责数据接入, 数据清洗, 业务数据建模等工作。
任职要求：
1、统招本科或以上学历（硕士优先），985/211院校优先,计算机或相关专业毕业；
2、扎实的编程能力，熟练掌握Java/Scala编程；
3、熟悉算法和数据结构，熟悉计算机的基础理论；
4、深入理解MapReduce，Storm，Spark等大数据框架，并阅读部分源代码；
5、有数据数据实时处理经验, 熟悉Druid, Kylin等框架并有使用经验者优先；
6、掌握一种数据库技术，例如oracle、db2、mysql等，熟练使用sql进行数据处理；
7、工作细致、责任心强，具备较强的学习能力及理解能力，有良好的沟通能力和团队协作能力；
8、有分布式系统、大规模线上系统开发或者大规模数据处理经验的优先。"""
"职位描述：
        
        岗位职责：
1. 负责新服务Feeds、NewHome等产品线的个性化推荐系统的研发
2. 负责收集和分析用户行为数，设计合理的推荐模型。
3. 通过对用户行为数据的挖掘，对用户建模、精准刻画用户特征。
任职要求：
1.计算机相关专业本科及以上学历，具备扎实的计算机理论基础；
2. 具备扎实的编程基础, 熟悉算法和数据结构，熟悉计算机的基础理论；
3. 对数据敏感，善于发现数据中的潜在规律，了解业界最近动态。
4. 有强烈的上进心，自我驱动，学习适应能力强，乐观自信，能挑战自我不断追求卓越；
5.有强烈的责任心和团队精神，善于沟通和合作。
6. 有推荐系统、算法相关系统的开发经验者优先。"
"职位描述：
        
        岗位职责：1、 负责整个公司的数据收集、清洗工作，进行相关数据产品的开发工作；2、 建设、完善公司级用户画像,建设数据质量体系；3、 利用技术手段赋能新零售、广告、金融、小爱同学、手机等业务。任职要求：1、 精通至少一门编程语言(Java/Scala/Python/C/C++)，透彻理解常见的核心算法；2、 熟练掌握概率统计、数据挖掘、机器学习相关理论知识；3、 对Hadoop、Spark等工具拥有实践经验；4、 大数据新技术探索,技术攻坚。有以下经验者优先:1.有数据仓库,用户画像等研究经历或者工作经历2.工作踏实认真,有较强的学习能力和良好的团队沟通协作能力"
"职位描述：
        
        工作职责
1、负责智能硬件数据采集、校验、提取和统计的相关工作
2、负责设备数据分析和预测、应用数据预估和关联挖掘、应用内使用数据统计等工作
3、探索和研究有效的机器学习/深度学习模型，为公司其他部门或项目提供决策支持

任职要求：
1、数据挖掘、统计学、数学、计算机相关专业本科以上学历，一年以上大数据开发经验
2、熟悉主流机器学习、数据挖掘基本算法和数学模型，并有实际的项目经验
3、精通一种开发语言（Python、Scala、Java、C等），并具有快速学习其他开发语言的能力
4、熟悉Hadoop(HDFS/MapReduce/Hive/HBase)、Spark、Kafka的使用，熟悉Mysql等关系型数据库和NoSql技术
5、对数据敏感，能熟练预估数据量以及数据项之间关系，善于从数据中发现问题
6、具有良好的沟通协作能力，具有较强的分享意愿"
"职位描述：
        
        岗位职责：
1、参与小米IoT业务的数据分析，捕捉业务洞见；
2、参与小米IoT业务的数据探索和挖掘，为部门产品技术创新提供算法支持。

岗位要求：
1、计算机、数学及相关专业本科及以上学历；
2、熟练掌握机器学习/深度学习化学习基本理论知识，熟练掌握机器学习/深度学习算法；
3、熟练掌握C/C++/Java/Python等一门或多门编程语言；
4、.熟悉常见大数据基础组件的使用，如Hadoop/Hive/Hbase/Impala/Spark/Kafka/Flume/Sqoop/Redis/Flink等
5、熟练使用Scikit-Learn/TensoFlow等一种或多种机器学习/深度学习框架；
6、宽泛的技术视野、创造性思维、富有想象力；
7、强烈的责任心和团队精神，善于合作，愿意致力于新技术的探索和研究。"
"职位描述：
        
        工作职责：
1、负责海量数据分析平台的建设，保障数据方便快捷的被业务部门使用
2、负责数据存储和查询性能的优化，保障海量数据的结果能够高性价比、稳定、快速输出
任职要求：
1、计算机相关专业本科以上学历，一年以上大数据底层系统的开发经验
2、熟悉服务器软硬件体系结构，精通Linux和大数据的存储和计算模型，有相关经验
3、精通一种开发语言（Python、Scala、Java、C等），并具有快速学习其他开发语言的能力
4、熟悉Hadoop(HDFS/MapReduce/Hive/HBase)、Spark、Kafka的使用，熟悉Mysql等关系型数据库和NoSql技术
5、对数据敏感，能熟练预估数据量以及数据项之间关系，善于从数据中发现问题
6、具有良好的沟通协作能力，具有较强的分享意愿"
"职位描述：
        
        岗位职责：

 负责互娱各项业务日常运营数据报表的提取和分析
 ?负责部门各条业务线的BI相关产品的开发
 参与部门大数据引擎后台的设计和开发工作

任职要求：
1. 计算机相关专业，本科及以上学历，2~4年以上Hadoop相关开发经验；2. 熟悉主流的云计算、大数据产品（hadoop、spark、flume等）和数据分析技术（机器学习)并具有相关项目经验；3. 精通算法设计/数据结构，精通JAVA，python，scala语言编程；4. 熟悉Linux/Unix平台上的开发环境；5. 思路敏捷清晰，良好的表达和理解能力，良好的学习能力，强烈的创新意识；"
"职位描述：
        
        岗位职责：
1、 负责相关核心业务的数据挖掘与算法研发工作；
2、 利用机器学习算法解决相关业务问题，并优化算法模型与架构；
3、 从事机器学习算法模型相关方向的前沿性研究工作。

任职要求：
1、 精通Java、R/Python等常用语言，熟悉数据结构并拥有算法设计能力；
2、 拥有扎实的数学基础，深刻理解机器学习、深度学习、自然语言处理等领域的算法原理；
3、 熟悉常见的数据挖掘、数据建模方法，拥有较强的技术落地与变现能力；
4、? 参与过机器学习项目的相关工作，在广告、搜索、行为预测等方面拥有相关经验。"
"职位描述：
        
        岗位职责：1、负责数据平台相关产品的软件开发及架构设计，保证系统稳定性、性能优化等相关工作；2、保持技术前瞻性，持续推动系统架构的合理性；3、探索并应用大数据前沿技术，如海量数据的即席查询、微服务等。任职要求：1、JAVA基础扎实，包括JVM、IO、多线程、并发、网络，深刻理解面向对象、设计原则、封装抽象等；2、熟练使用常用的Java技术框架，并对java web的各种开源框架如Spring、Struts、Hibernate等有深入的应用和优化经验，掌握它的原理和机制；3、学习能力强，有较强的问题分析和处理能力，具有团队合作精神"
"职位描述：
        
        岗位职责：1、 负责整个公司的数据收集、清洗工作，进行相关数据产品的开发工作；2、 建设、完善公司级用户画像,建设数据质量体系；3、 利用技术手段赋能新零售、广告、金融、小爱同学、手机等业务。任职要求：1、 精通至少一门编程语言(Java/Scala/Python/C/C++)，透彻理解常见的核心算法；2、 熟练掌握概率统计、数据挖掘、机器学习相关理论知识；3、 对Hadoop、Spark等工具拥有实践经验；4、 大数据新技术探索,技术攻坚。有以下经验者优先:1.有数据仓库,用户画像等研究经历或者工作经历2.工作踏实认真,有较强的学习能力和良好的团队沟通协作能力"
"职位描述：
        
        岗位职责：
1.?负责大数据系统平台或者业务数据仓库开发与管理?
2.?负责大数据开发和查询平台建设，包括数据ETL，权限，调度，主数据，元数据，报表系统和Adhoc查询系统等，API服务接口
3.?提供数据化运营工具，构建丰富多样的大数据应用?
4.?管理岗职责：改进流程和规范，code review，项目驱动，员工激励、培训/招聘/淘汰。

任职要求：
1.?良好的java编程能力，熟悉java开发工具和调试工具?；
2.?熟悉Spring MVC框架，Hibernate或Mybatis持久层，Bootstrap，Node JS, AngularJS2等前端框架?
3.?熟悉Web Service/SOA/Redis/消息队列等技术
4.?熟悉linux系统，熟练使用shell或者python脚本处理工具?
5.?熟悉hadoop / hive /spark / storm等开源大数据系统的原理和使用?
6.?有良好的产品思维，能够根据用户需要设计简单，易用的产品?
7.?有良好的逻辑思维及解决问题的能力
?
有如下经验/能力者优先，但不是必须：
1.?熟悉爬虫和反爬虫技术
2.?在开源社区有影响力，有专利或者知名技术权威杂志有发表论文"
"职位描述：
        
        岗位职责：
1、负责数据分析工作
2、参与报表开发

岗位要求：
1、本科及以上学历，至少3年以上数据岗位经验，互联网在线教育行业优先。
2、精通SQL编写技能，能根据报表需求编写复杂SQL
3、熟悉数据分析，业务分析，两年以上分析经验
4、熟悉数据分析算法以及使用场景，如决策树，逻辑回归，随机森林等，根据业务分析结果生成分析报告。
5、擅长通过数据发掘业务价值优先"
"职位描述：
        
        工作职责：?
1． 建设数据仓库，参与或负责数据仓库设计、建模、研发等 ；
2． 参与或负责数据平台相关数据管理工作，如研发规范、质量规范、保障规范的制定与推动实施落地 ；
3． 支持公司相关业务的数据分析 ；
4． 支持业务团队的数据建设工作。

岗位要求:?
1． 统计学、数学、计算机专业等背景,从事数据仓库领域至少3年以上，熟悉数据仓库模型设计与ETL开发经验 ，掌握常用数据建模设计方法，具备海量数据加工处理（ETL）相关经验；?
2． 掌握Mysql数据库开发技术，灵活运用SQL实现海量数据ETL加工处理 ；
3． 熟悉Linux系统常规shell处理命令，灵活运用shell做的文本处理和系统操作 ；
4． 从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验着优先，重点考察Mapreduce、Hive ；
5． 熟练掌握一门或多门编程语言，并有大型项目建设经验者优先，重点考察Java、Python、Perl ；
6． 熟悉数据仓库领域知识和技能者优先，包括但不局限于：数据开发测试工具与方法、数据质量。"
"职位描述：
        
        工作职责:1.根据业务产品特性，针对数据仓库进行设计和开发工作； 2.负责海量数据的处理、分析和挖掘工作； 3.负责多业务数据仓库的设计、构建和ETL工作。任职资格:1.熟练掌握数据仓库设计，开发工作。能够根据业务设计并开发数据仓库，具备复杂业务需求梳理能力；2.熟悉数据仓库建模理论，了解数据仓库数据分层架构和多维数据模型设计；3.精通Java/Python/Shell至少一种，熟悉Linux环境开发及AWS相关服务组件；4.熟练SQL开发，熟悉Hadoop/Hive/Spark/Storm/Flink/HBase/Redis中的一项或多项大数据开发技术;5.有实际数据仓库项目开发经验者优先。"
"职位描述：
        
        职责描述：
根据业务需求进行数据模型的调研、设计、开发工作，并持续进行模型的优化；
持续对系统技术架构改进和优化，提升性能及用户体验；
任职要求：
1. 计算机或相关专业，5年以上工作经验；
2. 熟练掌握java/scala语言，对多线程有深入研究；
3. 熟练掌握oracle、mysql等主流数据库；
4. 熟练掌握shell、python、perl等脚本语言中的一种；
5. 熟练掌握hbase、redis、elasticsearch等存储,针对不同业务建模；
6. 熟悉storm,spark,flink中的一种。
加分项：
1. 有海量大数据开发经验
2. 对hadoop,storm,elasticsearch源码有深入研究"
"职位描述：
        
        岗位职责：1、负责开发数据应用平台，如报表平台、多维度分析工具、调度平台、流平台等研发；2、数据平台上数据治理、用户画像等数据服务产品的研发；3、参与公司业务数据处理、实时计算开发；
岗位要求：1、计算机相关专业，1年以上的大数据平台开发经验；2、精通Java/Python/Scala至少一种，掌握网络原理、数据结构与算法；3、熟悉Hadoop、Hive、Tez、Spark、Flink、HBase、Kafka等大数据技术的原理，有大数据平台开发经验者优先；4、在开源社群活跃并有积极贡献者优先；5、思维敏捷，有较强的钻研学习能力；6、较好的沟通能力、团队合作；"
"职位描述：
        
        岗位职责：1、负责数据采集、清洗、分析、转换、统计等工作；2、基于业务场景进行多维度专题分析，为业务决策和产品方案提供数据支撑；3、深入理解业务的需求，设计和构建数据仓库模型的各个数据层和视图；
岗位要求：1、本科以上学历，计算机、数理统计相关专业，1年以上数据分析工作经验；2、丰富的Python开发经验，熟悉Java、Scala更优；3、精通SQL，有一定SQL性能优化经验，熟悉HIVE/MYSQL等开源数据库，有Hadoop/Spark等平台经验更佳；4、对数据分析和算法设计有比较强烈的兴趣，具有统计学、运筹学、数据分析、推荐等相关知识和工作经验优先考虑；5、较好的沟通能力、团队合作；"
"职位描述：
        
        职位描述：
职位描述：?
1、根据不同的业务场景，构建业务指标体系，建立和完善日常业务报告体系，能够及时、准确、完整的披露公司整体及各项目的运作情况 ；
?2、参与数据仓库架构设计与数据开发，建设共享数据仓库 ；?
3、通过专项分析，输出专项分析报告，为业务模块的决策和产品方向提供数据支持 ；?
4、参与数据底层的工具、平台、部署流程等技术体系建设的研发工作

职位要求：?
1、本科以上学历，两年及以上大数据相关工作经验；?
2、熟悉数据仓库模型设计方法论，并有实际模型设计及ETL开发经验 ；?
3、掌握大型数据库开发技术，如Hive SQL、Mysql等等掌握至少一种，灵活运用SQL实现海量数据ETL加工处理与查询性能调优；?
4、熟悉Hadoop / Spark / Hive / Hbase 等， 有相关源码有研究更佳
5、熟悉常用的数据挖掘、分析的工具和方法，有数据挖掘工作经验；熟悉linux平台，精通shell/python等脚本语言的一种或多种，编码基本功扎实 ；?
6、具备快速学习能力、沟通协调能力及团队精神，有较强的责任心和学习积极性。"
"职位描述：
        
        一、岗位职责：
1.负责大数据平台研发，实现大数据分析与查询任务的管理与调度；
2.负责自动报表系统研发；
3.不断提升大数据平台的性能和使用效率。
二、任职要求：
1.2年以上工作经验，本科及以上学历，计算机相关专业，基础扎实，有较强的自驱力和责任心，具备良好的沟通和协作、文档能力；
2.熟练掌握包括但不限于 Python，Go，Java，Scala 的一门或多门开发语言；
3.熟练掌握Hadoop、Spark、Storm、Hive、HBase、Flume、Flink、Kafka等相关组件的使用和优化；
4.熟练掌握Redis、MySQL，MongoDB，ElasticSearch等系统的使用和优化；
5.有微服务、数据仓库、分布式系统开发经验优先。"
"职位描述：
        
        职位描述：
参与建设和开发公司的数据平台，结合实际业务进行技术选型；
支持和理解业务需求，实现数据采集、清洗入库、统计计算、展示；

岗位要求：
1. 2年以上大数据平台建设维护和相关开发经验；
2. 基础知识扎实，熟悉大数据和 OLAP 相关 Hadoop/HDFS/Spark/Druid 等技术栈；
3. 熟悉数据采集、清洗入库、统计计算、展示核心要点，可实现指标计算需求；
4. 对技术有热情可以持续投入技术研究，有前瞻性的思维；
5. 做事积极主动，有较强的执行能力和和较好的沟通能力。

加分项：
1. 其他编程语言经验，如 Scala / Python / R；
2. 阅读过主流框架类库的源码；
3. 参与或发起过开源项目。"
"职位描述：
        
        从事大数据平台下的数据挖掘、机器学习等任务，主要涉及NLP、推荐系统、知识发现等内容。
要求：本科以上学历，接受硕士以上的实习生。
hadoop和spark等大数据框架下的数据挖掘；
熟悉java或者scala编程语言，有实际项目经验；
熟悉常用的数据结构和算法
有数据挖掘、机器学习、自然语言处理经验者优先。
能够独立工作，热爱编程
接受硕士以上的实习生。"
"职位描述：
        
        岗位职责：
1、参与大数据平台的优化
2、协助改造目前的大数据平台
3、与业务平台对接开发与测试


任职要求：
1.计算机或数学相关专业，两年以上年工作经验
2.熟练操作linux，有python/shell/java/scala开发能力
3.熟悉整个大数据处理，能使用并优化hadoop/spark/spark sql/spark streaming/storm/kafka等大数据平台及组件，拥有完成实时数据处理业务的能力
4.具备海量数据处理以及性能优化的能力
5.有mysql数据库调优及运维经验优先（重点加分项）
6、有cdh使用经验优先
7、有推荐系统，用户画像等工作经验优先"
"职位描述：
        
        岗位职责：
1.?负责公司项目涉及大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；
2.?负责Hadoop、HBase、Hive、Spark、Kafka等集群的维护、优化工作；
3.?负责公司产品TSDB，MPP，及业务系统的运行维护。协助解决问题。
4.?深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；
5.?了解产品业务，加入产品从原型设计到正式上线的整个过程，基于对产品的理解，从技术架构的角度给予持续的优化意见；
6.?开发大数据自动化运维、监控、故障处理工具，监控所有基础设施组件、应用程序，提供紧急应急措施；
7.?持续的创新和优化能力，提升产品整体质量，改善用户体验，控制系统成本；
?
任职要求：
1.?深入理解linux系统，运维体系结构，精于容量规划、架构设计、性能优化，专家优先；
2.?具备一定的开发能力，精通一门以上脚本语言(shell/perl/python等)，熟悉java/C/C++等开发语言一种及以上；
3.?具备很强的ownership，故障排查能力，有很好的技术敏感度和风险识别能力；
4.?熟悉Hadoop、HBase、Kafka、Hive、Spark等组件的工作原理，并有2年以上Hadoop生态系统维护与调优经验；
5.?熟悉greenplum,druid相关技术，或者有强烈的学习欲望。
6.?熟悉分布式系统设计范型，有大规模系统设计和工程实现的了解者优先；
7.?了解docker，云计算相关技术，或者有强烈的学习欲望；
8.?良好的服务意识，善于团队协作，项目管理，主动思考，自我驱动力强；
9.?能适应经常出差，满足项目的需求；能够承受较大的工作压力，以结果和行动为准则，努力追求成功。"
"职位描述：
        
        岗位描述：
1、负责设计实现时序数据存储和分析系统功能
2、负责设计与实现大数据分析平台相关API及服务
3、负责搭建，实施和部署大数据分析系统
岗位要求：
1、计算机科学或相关专业本科或以上学历
2、熟悉Python/Java/Scala 等任一门语言
3、熟悉Kafka/Spark
4、有互联网后端项目开发经验,?熟悉高并发网络编程,?熟悉分布式理论基础
5、热爱程序设计,?能快速学习,?有独立解决问题的能力
具备以下资格优先：
1、精通Python， 用过py4j
2、熟悉Kafka源码， 有kafka streaming开发经验
3、熟悉大规模数据处理、高并发或分布式系统相关知识，熟悉JVM性能优化,?有后端服务优化相关经验
4、熟悉?MongoDB / Druid / Redis 等数据库系统
5、熟悉大规模数据处理、高并发或分布式系统相关知识，熟悉JVM性能优化,?有后端服务优化相关经验"
"职位描述：
        
        岗位职责：
1.?负责公司项目涉及大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；
2.?负责Hadoop、HBase、Hive、Spark、Kafka等集群的维护、优化工作；
3.?负责公司产品TSDB，MPP，及业务系统的运行维护。协助解决问题。
4.?深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；
5.?了解产品业务，加入产品从原型设计到正式上线的整个过程，基于对产品的理解，从技术架构的角度给予持续的优化意见；
6.?开发大数据自动化运维、监控、故障处理工具，监控所有基础设施组件、应用程序，提供紧急应急措施；
7.?持续的创新和优化能力，提升产品整体质量，改善用户体验，控制系统成本；
?
任职要求：
1.?深入理解linux系统，运维体系结构，精于容量规划、架构设计、性能优化，专家优先；
2.?具备一定的开发能力，精通一门以上脚本语言(shell/perl/python等)，熟悉java/C/C++等开发语言一种及以上；
3.?具备很强的ownership，故障排查能力，有很好的技术敏感度和风险识别能力；
4.?熟悉Hadoop、HBase、Kafka、Hive、Spark等组件的工作原理，并有2年以上Hadoop生态系统维护与调优经验；
5.?熟悉greenplum,druid相关技术，或者有强烈的学习欲望。
6.?熟悉分布式系统设计范型，有大规模系统设计和工程实现的了解者优先；
7.?了解docker，云计算相关技术，或者有强烈的学习欲望；
8.?良好的服务意识，善于团队协作，项目管理，主动思考，自我驱动力强；
9.?能适应经常出差，满足项目的需求；能够承受较大的工作压力，以结果和行动为准则，努力追求成功。"
"职位描述：
        
        工作内容描述 :
1 负责大数据项目的平台架构设计
2 负责大数据项目的数据集成数据清洗和数据加工实施工作

岗位要求：1，本科生及以上学历，2年以上相关开发经验；2，精通java开发，具有丰富的开发经验；熟悉Linux下开发，熟练使用shell/python；3，熟悉大数据相关技术hadoop/flume/kafka/storm/Spark等；4，针对业务系统数据需求，能够设计合理的数据收集、处理方案；5、工作踏实、认真负责，具备一定的钻研精神和持续学习的意愿，具有团队合作沟通交流意识；
加分项：1，有大规模数据收集，处理经验；2，有实时工业传感数据收集处理经验；3，有实际大数据项目开发经验；4，深入研究过大数据框架的运行机制、实现原理、源码者；"
"职位描述：
        
        工作内容描述 :
1 负责大数据项目的平台架构设计
2 负责大数据项目的数据集成数据清洗和数据加工实施工作

岗位要求：1，本科生及以上学历，2年以上相关开发经验；2，精通java开发，具有丰富的开发经验；熟悉Linux下开发，熟练使用shell/python；3，熟悉大数据相关技术hadoop/flume/kafka/storm/Spark等；4，针对业务系统数据需求，能够设计合理的数据收集、处理方案；5、工作踏实、认真负责，具备一定的钻研精神和持续学习的意愿，具有团队合作沟通交流意识；
加分项：1，有大规模数据收集，处理经验；2，有实时工业传感数据收集处理经验；3，有实际大数据项目开发经验；4，深入研究过大数据框架的运行机制、实现原理、源码者；"
"职位描述：
        
        岗位职责：
1 负责大数据产品及项目的平台架构设计及搭建；
2 负责大数据产品及项目的研发及实施工作。

任职要求：
1.具有5年以上数据仓库，大数据工程项目开发经验，主导或者作为核心人员参与至少一个集团数据分析或数据产品项目，熟悉数据库概念和大数据项目的实施流程；
2.至少精通Hadoop核心组件原理，Hive，Spark，NiFi 等大数据组件使用及开发，熟悉Hadoop 性能优化优先；
3.熟悉任意一种ETL开发工具和成熟BI工具，熟悉数据处理流程；
4.熟悉一种数据仓库平台，例如Teradata、Oracle、Greenplum等；
5.具备较强的数据处理及分析能力；
6.熟悉linux 操作系统，熟悉一种脚本语言shell/phython/java/R语言优先；
7.具备数据治理体系理论。"
"职位描述：
        
        工作职责:1 参与公司基于大数据平台的数据仓库的设计和开发，设计大数据平台的基础服务组件。2 负责数据模型架构的构建，建立数据抽取、清洗、校验等数据加工流程规范及OLAP多维数据分析模型；3 持续对系统的技术架构进行改进和优化，提升海量数据的查询性能和用户体验。4 参与数据仓库中ETL设计和开发，解决系统实施过程中的技术问题。任职资格:1 ?统招本科或以上学历，计算机、数据挖掘、统计类等相关专业，工作至少3年以上；2 ?熟悉Java开发，有脚本语言（shell,python)开发经验者优先,具有Linux下的开发经验。具有golang的开发经验，对分布式程序设计和开发具有一定的经验为加分项。3 ?熟悉Hadoop(HDFS/MapReduce/Hive)、Spark、Storm、Kafka、Flume等类框架技术，具有大数据产品开发、报表平台研发、数据仓库建设经验；4 ?掌握HBase、Redis、Mongodb、等开源数据存储技术，并能结合不同的业务场景深入使用；5 ?具有关系数据库的开发经验，比如oracle、db2、mysql，对SQL的优化和运行原理具有一定的理解。6 ?掌握数据仓库的ETL设计和开发经验，参与过大新BI项目的建设，能够解决系统实施过程中的技术问题。7. 具有设计和开发对外API接口经验和能力,具有面对大规模海量查询解决方案的经验；8 ?对解决具有挑战性的问题充满激情，具有良好的分析问题和解决问题的能力，9 ?具有良好的沟通，团队协作、计划和创新的能力；10 有优秀的业务理解能力，能够清楚业务并进行合理的平台演进和架构设计。11 具有较强的源代码阅读能力，对开发具有较高热情。"
"职位描述：
        
        岗位职责：
1、参与AI服务平台的架构和建设，负责大数据平台的架构设计与开发实现；
2、参与公司AI平台、量化交易平台底层的开发、优化，提升系统计算性能和资源使用效率；
3、匹配业务场景，使用机器学习、文本挖掘等技术，设计数据算法建模解决方案，对业务数据进行分析、算法设计及验证，并负责各类AI数据挖掘算法的开发、应用、监控优化，支撑公司数据挖掘落地； 4、开展数据挖掘分析算法和工具研究工作，研发创新方法解决业务问题，并组织相应方法/工具的引入，技术规范制定和推广。
?
任职要求：
1、2年以上大规模的数据处理/媒体、媒介处理经验；
2、2年以上涉及过云服务、发展的经验； 3、2年以上掌握 C++、Java、C语言、 Spark (或者相似的计算机语言经验)
4、有过Ali-cloud / containerized development /tensorflow/ computer vision/ NLP/speech经验者优先。"
"职位描述：
        
        任职资格：?
1. 至少2年的ETL方面的开发或维护工作经验?
2. 至少参加过1个数据仓库项目?
3. 有过开发和维护ETL工作流程和数据仓库的经验?
4. 熟悉Oracle，或MySQL， PostgreSQL?
5. 熟悉SQL和存储过程?
6. 沟通和理解能力强?

工作职责：?
1. 设计科学的数据抽取、转换、加载的工作流程?
2. 保证数据及时、正确、无误的抽取到数据仓库中?
3. 调查OMS, WMS等业务系统的业务，梳理数据在业务系统的流转?
4. 根据业务分析需求，将抽取到数据仓库的业务数据进行转换，使业务数据变成分析数据?
5. 负责安排ETL工作流程的调度时间，并保证ETL工作流程在安排的时间内成功执行?
6. 编写系统设计和接口文档?
7. 维护ETL流程和数据仓"
"职位描述：
        
        工作职责：
在数据仓库架构师的带领下，完成
1） 企业级数据仓库架构设计、建模以及ETL开发，构建可扩展的数据仓库解决方案；
2） 构建基于Hive的数据仓库和数据集市的架构设计与优化;
3） 对海量数据处理的业务需求进行评估和方案设计，以及脚本开发；对慢查询进行诊断，给出优化方向并进行优化；
4） 协助大数据平台搭建、研发及后续运维工作；

职位要求：
1） 计算机相关专业，本科及以上，要求实习时间在半年以上；
2） 熟练掌握SQL，有一定的SQL性能优化经验；
3） 熟悉Java或Python开发语言，并能够使用语言进行常用的大数据程序的开发；
4） 较好的沟通理解能力和优秀的学习能力，态度踏实上进；
5） 有过ETL的开发及海量数据处理相关经验者优先；
6） 熟悉数据仓库领域数据模型设计方法，并有相关设计经验者优先；
7） 了解Hadoop、HIVE、HBase、Sparkstreaming、Kafka、 Flume、Spark等开源框架者优先；"
"职位描述：
        
        岗位职责：
1、从事大数据分布式存储/应用服务的设计和开发，挑战大规模、高并发、易运维的分布式系统设计构建； 2、负责大数据应用产品的开发工作（营销、推荐、搜索、分析统计等），包括系统/算法的设计及实现；3、解决海量数据高效处理、交互式查询、流式分析等技术难点，对现有系统的不足进行分析，难点攻关；4、跟踪评估数据产品线上效果，参与各业务部门的产品设计讨论，促进大数据产品的广泛落地各产品线；5、梳理当前团队技术瓶颈、技术栈短板评估，业务线大数据需求技术预判相关技术预研。
岗位要求：
1、统招本科学历，互联网金融行业背景，工作稳定性强；
2、必须精通Java/Python服务端设计开发经验；
3、必须具备成熟的系统设计架构能力，丰富的高并发、分布式的系统设计经验；
4、必须熟悉业界先进的大数据生态组件（MR/Spark/HBase/ElasticSearch/ClickHouse）；
5、具备知识图谱、算法平台、实时多维分析、搜索可视化经验者优先；
6、有大数据产品线上大型系统设计开发/线上算法设计实践经验者优先。"
"职位描述：
        
        
1.?基于大数据平台结合保险领域，负责BI、画像、数据仓库的开发和应用；2.?基于海量用户行为数据，建立、评估、持续优化数据模型，包括但不限于：用户价值评分、用户风险评分、用户偏好预测?、用户画像构建等等，产出用户标签；3.?结合公司的业务场景，进行数据产品设计，解决业务痛点，提升用户体验，探索新的商业模式；

任职资格

1.?本科及以上学历，计算机或数学相关专业，工作3-6年及以上；2.?思维清晰敏捷，逻辑分析能力强，具有良好的语言和书面表达能力；3.?精通hive?sql，有海量数据处理的调优经验；4.?熟悉spark优先；5.?用户画像构建和应用实战经验的优先；6.?有数据挖掘实践经验，擅长从海量数据中发现有价值的规律的优先；7.?有大型互联网公司或保险行业背景优先，有带领团队，具有管理经验的优先；"
"职位描述：
        
        1． 负责公司大数据项目实施与管理，包含项目售前与售后支持工作；
2．与行业咨询经理对接，获取数据需求，负责所承担项目的数据需求分析、数据处理工艺流程制定、成本预估等；
3．负责对接生产团队进行数据项目实施，具体工作包括：数据处理需求沟通，制定数据生产计划、进度管理、技术支持、质量管理等数据项目管理工作；
4．负责数据验收、数据成果提交、数据项目总结等工作；
6．完成领导交办的其他工作。?
背景
1、GIS、测绘与地理信息系统、计算机、统计类等相关专业，大学硕士以上毕业，从事该专业1年及以上工作经验；
2、熟悉Arcgis等通用地理信息系统平台，有独立带项目及相关gis工作经验者优先；
3、熟悉使用python进行数据处理分析相关工作；
3、熟悉空间数据的实施和管理流程，熟悉项目需求调研方法，善于挖掘、分析和整理项目需求,有数据分析、统计和数据挖掘背景者优先；
4、具备创新精神，良好的文档编写和沟通表达能力，逻辑思维清晰严谨，认真踏实；
5、具有较强的责任感、独立思考能力和合作精神。"
"职位描述：
        
        1． 负责公司数据项目实施与管理，包含项目售前与售后支持工作；
2．与项目经理对接，获取数据需求，负责所承担项目的数据需求分析、数据处理工艺流程制定、成本预估等；
3．负责对接生产团队进行数据项目实施，具体工作包括：数据处理需求沟通，制定数据生产计划、进度管理、技术支持、质量管理等数据项目管理工作；
4．负责数据验收、数据成果提交、数据项目总结等工作；
6．完成领导交办的其他工作。?
背景
1、GIS、测绘与地理信息系统、计算机、统计类等相关专业，大学本科及以上毕业，从事该专业1年及以上工作经验；
2、熟悉Arcgis等通用地理信息系统平台，有独立带项目及相关gis工作经验者优先；
3、熟悉使用python进行数据处理分析相关工作；
3、熟悉GIS项目数据的实施和管理流程，熟悉项目需求调研方法，善于挖掘、分析和整理项目需求,有数据分析、统计和数据挖掘背景者优先；
4、具备创新精神，良好的文档编写和沟通表达能力，逻辑思维清晰严谨，认真踏实；
5、具有较强的责任感、独立思考能力和合作精神。"
"职位描述：
        
        Job Summary工作内容:
?
l? 与Product Owner和项目经理进行需求和项目讨论，提供技术和业务的解决方案
l? 根据实际业务需求，负责公司大数据平台及应用系统的架构设计与开发，技术改进与性能优化
l? 指导和培训开发人员，解决系统开发、运行中出现的各种问题，同时保证交付质量
l? 建立大数据智能分析工作的流程、规范和方法
l? 参与和帮助团队的敏捷实施和持续改善
l? 积极学习和掌握保险相关的业务和系统知识
l? 完成主管安排的其他工作。
?
????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
?
Job Requirements (Knowledge/Skills/Competencies) 录用条件:
?
l? 计算机相关专业本科及以上学历，4年以上工作经验，其中包含2年或以上的大数据开发实施经验
l? 精通Java语言，熟悉常见应用框架（如Spring、MyBatis等）和设计模式
l? 熟悉Linux环境，能够熟练使用至少一种脚本语言（如Shell、Python等）
l? 熟悉Hadoop/Yarn/Hbase/Hive//Flume/Spark/Kafka等常用大数据组件
l? 熟悉MS SQL Server/Oracle/MySQL/Redis/MongoDB等常见存储和缓存系统
l? 熟悉Git 等代码版本控制技术
l? 较强的分析和解决问题能力，对攻关疑难问题具有浓厚兴趣
l? 良好的团队合作精神、沟通能力和学习能力
l? 有大数据平台建设经验者优先录用
l? 有金融行业背景经验更佳
l? 有Web开发经验更佳"
"职位描述：
        
        职位描述：
为平台业务，进行相关算法模块的设计，开发及优化工作1 负责搜索场景的查询扩展，纠错，召回排序等模块的开发及优化2 负责主页、商详页、购物车等页面的商品、店铺推荐3 负责平台业务CPS广告系统的设计和开发4 负责平台业务商品，店铺，消费者画像构建SaaS服务方向：围绕提供给商家SaaS服务的核心交易链路，进行相关算法模块的设计，开发及优化工作；? 使用算法挖掘工具，分析商家店铺内商品结构是否合理，并给出优化建议； 负责商家首页、购物车加购页面、商详页等其他页面的商品个性化推荐，商品组合推荐，购物车凑单推荐等推荐场景负责进行商品销量／利润预测，判断商品未来的销售趋势；??? 营销活动、销售渠道效果等的分析及预测工作。
职位要求：1、机器学习、数据挖掘、统计学、计算机科学等相关专业硕士学位或以上学历 2、熟悉Mysql，ES， HBase， Redis等存储引擎的数据存储及使用方法3、熟悉Java，Python，Scala等一种或一种以上编程语言4、熟悉Hive，Spark，Flink等大数据工具的使用5、对数据分析和算法设计有比较强烈的兴趣，有搜索、推荐、计算广告等相关工作经验优先考虑 6、有零售、电商业务经验优先考虑"
"职位描述：
        
        1.本科及以上学历，计算机、软件工程、信息系统、数学等相关专业；
2.掌握SQL基本技能，熟练掌握数据库开发技能，熟悉数据仓库建设方法；
3.具有较强的学习能力和业务理解能力；
4.有良好的沟通能力和团队合作精神，能接受出差工作。"
"职位描述：
        
        岗位职责
1、参与金融行业大型数据仓库项目需求ETL开发、程序优化、项目部署工作；2、参与数据平台架构的设计、开发、流程优化及解决ETL相关技术问题；3、负责项目中的关键模块开发、项目实施跟踪 、客户培训、相关文档编写等工作；
4、负责与实施项目组沟通及产品技术支持。

岗位要求
1、全日制本科及以上学历，计算机相关专业，两年以上Oracle开发工作经验；2、掌握数据仓库基础理论知识，了解数据仓库模型设计和ETL设计技术；3、具有良好的SQL语言开发技能，了解掌握存储过程、函数等开发技术， 了解Oracle，Mysql，sql server等数据库，熟悉最少一种数据库；4、掌握Kettle、Informatica等工具开发技术者优先；5、有金融业务知识优先；6、良好的沟通和团队协作能力，乐观向上，有一定抗压能力。

【员工福利】
1、做五休二：周末双休，工作+娱乐两不误；
2、五险一金：入职即购买五险一金；
3、节日礼品：生日礼品、节庆礼品等；
4、员工活动：提供不定期员工活动，活动筋骨；
5、丰富补贴：享有电脑补贴、餐补、出差补助等；
6、假期种类：法定假期、年假、三八节假、儿童节假等；
7、慰问福利：婚庆慰问金、生育慰问金、住院慰问金等；
8、其他福利：技术培训、免费咖啡、下午茶、国内国外游等着你来。"
"职位描述：
        
        【岗位职责】
1、参与金融行业数据应用系统的需求分析工作；
2、负责数据应用产品需求实施、测试及部署工作；
3、负责产品相关文档编写工作；
4、配合上级完成其他日常工作。

【任职资格】
1、全日制本科及以上学历，计算机、统计学、金融学等相关专业优先；
2、有基金或其他金融行业知识优先；
3、了解数据库、数据仓库基础理论知识，对数据库开发有浓厚兴趣，对数据敏感；
4、具有良好的SQL语言开发技能，熟悉oracle、sql server、My SQL其中一种数据库；
5、精通Excel，了解主流BI报表工具，如BusinessObjects、MSTR、Oracle BIEE、Tableau、帆软、SmartBI等；
6、良好的沟通和团队协作能力，有较强的抗压能力，有很强的学习能力。

*实习期间补贴：2000-4000元/月；表现优秀者可提供转正机会喔。

【转正员工享受以下福利】
1、做五休二：周末双休，工作+娱乐两不误；
2、五险一金：入职即购买五险一金；
3、节日礼品：生日礼品、节庆礼品等；
4、员工活动：提供不定期员工活动，活动筋骨；
5、丰富补贴：享有电脑补贴、餐补、出差补助等；
6、假期种类：法定假期、年假、三八节假、儿童节假等；
7、慰问福利：婚庆慰问金、生育慰问金、住院慰问金等；
8、其他福利：技术培训、免费咖啡、下午茶、国内国外游等着你来。"
"职位描述：
        
        岗位要求：
1.熟练掌握Hadoop、zookeeper、kafka大数据相关技术
2.有实时流开发相关的经验，至少使用过flink、spark、storm任意一种流计算平台
3.深入了解大数据行业解决方案应用架构?
4.有CEP相关开发经验的，优先考虑
5.熟悉ElasticSearch、Lucene优先
6.有过海量数据系统开发经验者优先
7.有深厚的计算机功底及架构规划能力，良好的编码能力
8.熟悉jvm相关原理，具有性能调优经验，能够对产品性能瓶颈进行排查和解决"
"职位描述：
        
        岗位职责
1.大数据产品的设计和开发；
2.在深入理解大数据产品系统基础上，不断追求高性能、低价格、高可用、高可靠；
3.编写详细设计、用户手册等相关文档。
任职要求
1.有至少2年以上大数据项目研发经验，处理过TB级以上的海量数据
2.熟悉Linux操作系统下程序开发，起码对一种以上的大数据工具有代码分析和bug修复经验；
3.熟悉spark/hbase架构，熟练掌握scala/JAVA/hbase等一种以上的大数据编程语言."
"职位描述：
        
        职位信息
1.???? 负责基于客户需求的用户研究及数据分析工作，交付人群画像数据或报告；
2.???? 管理并持续优化用户洞察工作，包括数据处理、多维度分析、用户画像等；
3.???? 创建大数据平台的数据库，设计架构；
?
任职要求：
1.本科以上学历，计算机或数据分析相关专业优先；
2.熟悉SQL数据查询、统计、分析，熟练掌握SqlServer/MySQL数据库；
3.具备大数据分析，市场营销知识（统计学知识（决策树、逻辑回归、ARMA、随机森林、神经网络），有相关建模经验者优先；
4.熟悉常见分布式计算框架和技术原理，如Hadoop 、Spark、Storm等；熟悉Linux环境开发，熟悉常用SHELL命令；
5.有在大数据计算平台（Hadoop/Spark/Storm）上部署、实施、及项目开发，大数据分布式存储、大数据计算系统设计、实现和优化的相关经验者优先。"
"职位描述：
        
        岗位职责：
负责大数据平台的研发工作，基于Hadoop数据平台基础组件研发（hadoop生态圈个组件），基于Hadoop平台的数据挖掘、数据流处理。
职位要求：
1、大学本科学历以上，熟悉大数据开发的专业知识；
2、自我驱动，热爱编程，认为编程是不可剥夺的权利，对技术和产品充满热情，极致追求。
3、有Hadoop/Spark/Storm等开源社区经营，掌握数据挖掘算法和相关软件，精通Java/R语言者优先。
4、了解Hadoop，HDFS，Hive等分布式大数据技术、能够独立开发功能者优先考虑
5、追求高品质产品的精神与热情，对行业动态有足够洞察力及敏锐度；
6、具有优秀的表达、沟通与协调能力、团队合作精神、保密意识。"
"职位描述：
        
        工作职责：
1. 负责数据仓库应用产品设计和开发??
2. 负责数据仓库建模、数据预处理子系统的设计和开发。
3、负责数据仓库ETL流程的优化及解决ETL相关技术问题?

职位要求：
1、计算机相关专业本科及以上学历；
2、在用户行为日志采集、海量数据处理、数据建模、业务理解方面有丰富经验；?
3、精通Hadoop/MapReduce/hive ,有一定的hql/sql性能调优经验；
4、熟悉java/Python/php/mysql，有相关开发经验；?
5、熟悉Linux/Unix环境以及常用命令；
6、至少熟练使用shell、python、perl等脚本语言之一；?
7、有较好的沟通交流能力,善于主动思考和行动,乐于解决具有挑战性的问题；?
8、有较好的逻辑思维能力，较强的抽象、概括、总结能力；
9、对数据敏感、对新技术敏感、对数据产品设计有想法者优先。"
"职位描述：
        
        工作职责：
1. 负责数据仓库应用产品设计和开发 ?
2. 负责数据仓库建模、数据预处理子系统的设计和开发。
3、负责数据仓库ETL流程的优化及解决ETL相关技术问题?
职位要求：
1、计算机相关专业本科及以上学历；
2、在用户行为日志采集、海量数据处理、数据建模、业务理解方面有丰富经验；?
3、精通Hadoop/MapReduce/hive ,有一定的hql/sql性能调优经验；
4、熟悉java/Python/php/mysql，有相关开发经验；?
5、熟悉Linux/Unix环境以及常用命令；
6、至少熟练使用shell、python、perl等脚本语言之一；?
7、有较好的沟通交流能力,善于主动思考和行动,乐于解决具有挑战性的问题；?
8、有较好的逻辑思维能力，较强的抽象、概括、总结能力；
9、对数据敏感、对新技术敏感、对数据产品设计有想法者优先。"
"职位描述：
        
        工作职责：
1、负责大数据相关软件产品的规划，包括市场调研、需求分析、产品定位、产品架构以及细节功能的设计；
2、关注大数据在企业及互联网方向的应用研究，将数据成果快速产品化、商品化
3、跟踪产品的开发、测试、上线、优化；管理完整的产品生命周期；

职位要求：
1、本科及以上学历，2年以上大数据相关工作经验，数学或计算机相关专业；
2、熟悉常用机器学习和数据挖掘算法，包括但不限于熟悉聚类分析、关联分析、回归分析、决策树，系统过滤，神经网络等；"
"职位描述：
        
        职位描述：
岗位职责：1：参与大数据清洗平台的开发2：负责构建多种数据源文件的清洗、去重流程3：负责数据字典的建立4：负责清洗过程的优化任职要求：?1：精通java/scala/python至少一门编程语言，熟悉2种及以上优先2：熟悉Linux各项操作，掌握python/shell至少一个脚本语言3：熟悉Kafka/Hadoop/Hive/Spark/Hbase/Flink等大数据系统进行海量数据分析与计算4：熟悉parquet、OCRFile、CarbonData等文件格式和特点5：有良好的HiveSQL功底6：做过数据仓库,对数据治理、数据标准及元数据有很好理念及实施经验的优先7：良好的沟通能力和团队精神,具备创新意识9：2-3年大数据开发经验"
"职位描述：
        
        任职要求：
1、熟悉Java，具备Java开发经验，对数据结构、算法有深刻的理解；
2、了解大数据架构，熟练掌握常见大数据框架和技术 spark,hadoop,hbase/redis/MongoDB,flume,mahout,zookeeper等技术?
3、参与过大数据相关的大型项目，积累丰富的异常问题处理经验，并作为主要开发人员者优先；
4、独自搭建过大数据环境者优先考虑；
5、熟悉linux系统，熟悉常用shell命令；
6、良好的沟通理解能力、团队协作意识、学习能力、执行力，并热爱技术研发工作。

岗位职责：
1、负责系统架构整体设计，技术架构选型
2、主导功能模块设计、数据结构设计、对外接口设计，持续对现有软件框架进行改进。

福利待遇 ：
1、提供高弹性的薪酬模式！
2、公司员工享有双休、五险一金、法定假日、带薪假等！
3、公司员工享有法定假日礼品、每月团建活动、生日福利、公费旅游等！
4、公司每月准时发薪，每年均有调薪机会！
5、公司内部员工均有培训晋升机会。公司定期或不定期举行技能、技术、管理等一系列培训，公司内部有管理岗位空缺皆会优先采用内部提拔制,晋升空间广阔！

工作时间：
朝九晚六 周末双休 法定节假日休息

工作地点：
武汉市洪山区珞瑜东路4号慧谷时空21楼2101

武汉海云健康科技股份有限公司期待您的加入，共创未来！"
"职位描述：
        
        职位职责：
1、负责头条广告变现核心业务模块标准化cube数据的开发建设；
2、负责数据模型的设计，etl实施，etl性能优化，etl数据监控以及相关技术问题的解决；
3、负责面向业务的olap，报表，数据提取等工作。

职位要求：
1、本科及以上学历，计算机相关专业，每周实习4天以上优先；
2、灵活、主动，热爱数据，对数据具备较好的敏感性；
3、熟悉数据库相关知识，具有较强的学习能力、沟通能力和团队合作精神； 
4、有较强的独立工作能力和解决问题能力，积极主动、责任心强，能承受工作压力； 
5、有mapreduce、hive、spark等经验者优先；
6、熟悉Linux开发环境，熟悉至少一种开发语言优先（python，java）。"
"职位描述：
        
        职位职责：
1、负责海量用户行为数据的统计分析； 
2、参与数据平台的建设；
3、参与用户画像系统建设。

职位要求：
1、对至少一项分布式计算平台有使用经验，如 Hadoop，Spark，Hive，Storm等；
2、对数据敏感，善于从数据中发现问题，提出假设并使用数据进行验证；
3、善于沟通，具备优秀的技术与业务结合能力。"
"职位描述：
        
        职位职责：
1、 负责抖音/火山等多个业务线内大数据平台架构的落地实施；
2、搭建可配置化计算引擎，实现1000W/s条流式数据挑战下实时精准计算，落地储存；
3、负责流式数据的实时传递，清洗，转换，计算，并对外提供查询服务；
4、负责实时及离线特征抽取、融合，为数据挖掘及策略平台提供特征服务；
5、负责大数据能力在产品功能上的落地，推动产品数据化和智能化。

职位要求：
1、计算机等相关专业，硕士及以上学历；
2、熟悉HiveHadoopSparkFlinkClickHouseDruid等大数据开发技术；
3、有良好的业务和产品sense，执行力、推动力强优先；
4、优秀的理解沟通能力，每周可实习4天以上，持续3个月以上，20届应届生优先。"
"职位描述：
        
        职位职责：
1、负责数据收集、清洗和规约等工作；
2、提供面向业务的数据服务，完成数据指标的统计、多维分析和展现；
3、根据业务和产品情况，抽象业务逻辑，搭建和开发大数据平台。

职位要求：
1、统招本科及以上，大三及研二学生优先；
2、可以保证每周不低于4天的工作时间投入，能保证5天的优先；
3、精通SQL，有较好的SQL性能调优经验，了解Hive/MySQL的基本原理和调优策略；
4、熟悉常用的数据挖掘、分析的工具和方法，熟悉linux平台，精通Shell/Python/Golang等语言的一种或多种，编码基本功扎实 ；
4、良好的沟通和应变能力，细致认真；
5、可尽快入职，实习期3个月起，可长期实习者优先。"
"职位描述：
        
        职位职责：
1、负责今日头条海量用户行为数据的处理，在分布式计算平台基础上建立高效、实时的数据 pipeline； 
2、负责推荐系统、广告系统的数据分析，发现模式与规律，为实验解释、系统改进提供数据支持； 
3、负责 Hadoop，Spark 等大数据基础设施和平台的改进，解决大规模生产环境集群可用性和性能优化问题。

职位要求：
1、热爱计算机科学和互联网技术，优秀的编码能力，乐于快速学习和尝试新技术、新工具； 
2、对数据敏感，掌握量化分析方法，善于从数据中发现问题，提出假设并使用数据进行验证； 
3、对至少一项分布式计算平台有使用经验，例如 Hadoop，Spark，Hive，Storm，Kafka 等； 
4、有参与开源项目对社区有贡献的经历，有互联网公司实习经历，有大数据处理或用户行为数据分析经验者优先。
5、本科及以上学历，计算机相关专业，19年毕业的同学优先，有相关实习经验的同学优先，实习时间3个月及以上，每周至少4天。"
"职位描述：
        
        职位职责：
1、负责字节跳动旗下的所有产品线风控数据仓库架构设计、建模和OLAP开发；
2、参与数据治理工作，提升数据易用性及数据质量；
3、理解并合理抽象业务需求，发挥数据价值，与业务团队紧密合作；

职位要求：
1、熟悉Linux操作系统及开发环境；
2、扎实的计算机软件基础知识：数据结构，操作系统等;
3、熟悉 C/C++、Java、Python 等任意一门编程语言；
4、对数据敏感，认真细致，善于从数据中发现疑点；
具备以下条件者优先
1、研究过开源项目；
2、参加过 ACM 或者其他类型的软件开发大赛。
3、有风控研发实习经验者优先。"
"职位描述：
        
        职位职责：
1、负责数据收集、清洗和规约等工作；
2、提供面向业务的数据服务，完成数据指标的统计、多维分析和展现；
3、根据业务和产品情况，抽象业务逻辑，搭建和开发大数据平台。

职位要求：
1、统招本科或以上学历在读学生；
2、精通SQL，有较好的SQL性能调优经验，了解Hive/MySQL的基本原理和调优策略；
3、熟悉常用的数据挖掘、分析的工具和方法，熟悉linux平台，精通Shell/Python/PHP等脚本语言的一种或多种，编码基本功扎实 ；
4、精通Java开发，熟悉大数据处理相关技术，有Hadoop开发经验，掌握MapReduce；
5、一周可实习三天及以上。"
"职位描述：
        
        职位职责：
1、负责字节跳动海量用户行为数据的处理，在分布式计算平台基础上建立高效、实时的数据 pipeline； 
2、参与推荐系统、广告系统的数据分析，发现模式与规律，为实验解释、系统改进提供数据支持； 
3、参与 Hadoop，Spark 等大数据基础设施和平台的改进，解决大规模生产环境集群可用性和性能优化问题。

职位要求：
1、本科及以上学历，计算机相关专业；
2、热爱计算机科学和互联网技术，优秀的编码能力，乐于快速学习和尝试新技术、新工具；
3、对数据敏感，掌握量化分析方法，善于从数据中发现问题，提出假设并使用数据进行验证；
4、有互联网公司实习经历，有大数据处理或用户行为数据分析经验者优先；
5、实习时间每周三天及以上，四个月及以上者优先。"
"职位描述：
        
        职位职责：
1、支持业务对海量数据的分析和运用；??
2、支持业务数据的流式处理、用户行为分析等；?
3、分析与挖掘数据中各种潜在关联，不断优化业务效果，提高投入产出比。

职位要求：
1、本科及以上学历，计算机相关专业，每周可实习4天以上，持续3个月以上；
2、扎实的编程能力，有优秀的设计和代码品位，对解决具有挑战性问题充满激情；??????
3、精通至少一门编程语言，熟练运用各种常用算法和数据结构，有独立的实现能力 ；???
4、熟悉常用的开源组件：Hadoop/Hive/Spark/Storm，了解其特性和使用场景；
5、熟悉机器学习、数据挖掘、数据分析、分布式计算至少某一领域，有较深的理论研究和实践经验优先；?
6、优秀的沟通理解能力，能快速理解业务，用数据解读业务；???
7、有数据分析、推荐、机器学习、数据挖掘相关的开发工作优先。"
"职位描述：
        
        职位职责：
1、负责字节跳动旗下在上海多条产品线的数据仓库建设，包括但不限于抖音（海外版），泡芙社区，半次元等；
2、与业务团队紧密合作，深入理解并抽象业务需求，产出数据工具/应用，发挥数据价值。

职位要求：
1、精通数据仓库实施方法论、深入了解数据仓库体系，并支撑过实际的互联网业务场景；
2、具备较强的编码能力，对hadoop生态的大数据基础设施有较强理解，包括但不限于hive/spark/flink/kafka等，有数据工具的研发经验者优先；
3、善于沟通，具备优秀的技术与业务结合能力；
4、有PB级以上海量数据处理经验者优先；
5、有团队管理经验者优先。"
"职位描述：
        
        职位职责：1、广告各类在线业务的离线数据加工与在线数据服务开发与维护2、数据服务接口及产品需求研发迭代，代码review、bug修复及日常服务运维3、针对海量数据处理和查询需求，设计适应业务变化的合理的多维数据分析系统架构，满足多样性的需求4、海量日志清洗加工，并抽象出可以多业务复用的数据模型职位要求：1、熟悉Hadoop架构和工作原理，精通MapReduce编程；精通Hive，有HQL优化经验2、有web服务开发经验，具备独立完成模块开发能力，具备大规模分布式服务设计能力和经验3、理解基本的设计模式，能将业务需求快速理解成技术需求4、熟练使用Mysql，熟练使用ElasticSearch、Druid者优先；熟悉其原理者优先5、善于沟通，工作积极主动，责任心强，具备良好的团队协作能力6、具备良好的问题分析与解决能力，有较强学习能力和逻辑思维能力"
"职位描述：
        
        职位职责：
1、负责字节跳动海量用户行为数据的处理，在分布式计算平台基础上建立高效、实时的数据 pipeline； 
2、负责推荐系统、广告系统的数据分析，发现模式与规律，为实验解释、系统改进提供数据支持； 
3、负责 Hadoop，Spark 等大数据基础设施和平台的改进，解决大规模生产环境集群可用性和性能优化问题。

职位要求：
1、本科及以上学历，计算机相关专业，每周可实习4天以上，持续3个月以上；
2、热爱计算机科学和互联网技术，优秀的编码能力，乐于快速学习和尝试新技术、新工具；
3、对数据敏感，掌握量化分析方法，善于从数据中发现问题，提出假设并使用数据进行验证；
4、对至少一项分布式计算平台有使用经验，例如 Hadoop，Spark，Hive，Storm，Kafka 等；
5、有参与开源项目对社区有贡献的经历，有互联网公司实习经历，有大数据处理或用户行为数据分析经验者优先。"
"职位描述：
        
        职位职责：
1、负责字节跳动海量用户行为数据的处理，在分布式计算平台基础上建立高效、实时的数据 pipeline； 
2、负责推荐系统、广告系统的数据分析，发现模式与规律，为实验解释、系统改进提供数据支持； 
3、负责 Hadoop，Spark 等大数据基础设施和平台的改进，解决大规模生产环境集群可用性和性能优化问题。

职位要求：
1、本科及以上学历，计算机相关专业，每周可实习4天以上，持续3个月以上，19届校招生优先；
2、热爱计算机科学和互联网技术，优秀的编码能力，乐于快速学习和尝试新技术、新工具；
3、对数据敏感，掌握量化分析方法，善于从数据中发现问题，提出假设并使用数据进行验证；
4、对至少一项分布式计算平台有使用经验，例如 Hadoop，Spark，Hive，Storm，Kafka 等；
5、有参与开源项目对社区有贡献的经历，有互联网公司实习经历，有大数据处理或用户行为数据分析经验者优先。"
"职位描述：
        
        职位职责：
1、负责通用数据平台和分析型产品，服务于今日头条全公司的数十个用户产品线；
2、面向PB级超大规模数据问题，每天处理千亿增量的用户行为数据；
3、为大数据的全生命周期提供服务，覆盖数据产生，传输，建模，统计分析，实验评估，可视化的全流程；
4、构建设计良好的数据流、数据仓库、调度系统、查询引擎，数据服务、分析系统、流程规范，数据工具/产品，降低数据的使用门槛，保证系统稳定高效运行，以实现数据的最大价值；

职位要求：
1、计算机相关专业，基础扎实，编码能力强悍，对新技术有强烈的学习热情；
2、有大数据相关工具/框架经验者优先，e.g. Hadoop, Mapreduce, Hive, Storm, Spark, kylin，scribe, kafka, hbase, canal，sqoop etc；
3、实习时间满足3个月*5天以上，能够长期实习并有转正意向的优先；"
"职位描述：
        
        职位职责：1、负责通用数据平台和分析型产品，服务于今日头条商业产品线；2、面向PB级超大规模数据问题，每天处理千亿增量的用户行为数据；3、为大数据的全生命周期提供服务，覆盖数据产生，传输，建模，统计分析，实验评估，可视化的全流程；4、构建设计良好的数据流、数据仓库、调度系统、查询引擎，数据服务、分析系统、流程规范，数据工具/产品，降低数据的使用门槛，保证系统稳定高效运行，以实现数据的最大价值；职位要求：1、计算机相关专业，基础扎实，编码能力强悍，对新技术有强烈的学习热情；2、有大数据相关工具/框架经验者优先，e.g. Hadoop, Mapreduce, Hive, Storm, Spark, kylin，scribe, kafka, hbase, canal，sqoop etc；3、实习时间满足3个月*5天以上，能够长期实习并有转正意向的优先；"
"职位描述：
        
        职位职责：
1、负责通用数据平台和分析型产品，服务于今日头条全公司的数十个用户产品线；
2、面向PB级超大规模数据问题，每天处理千亿增量的用户行为数据；
3、为大数据的全生命周期提供服务，覆盖数据产生，传输，建模，统计分析，实验评估，可视化的全流程；
4、构建设计良好的数据流、数据仓库、调度系统、查询引擎，数据服务、分析系统、流程规范，数据工具/产品，降低数据的使用门槛，保证系统稳定高效运行，以实现数据的最大价值。

职位要求：
1、计算机相关专业，基础扎实，编码能力强悍，对新技术有强烈的学习热情；
2、有大数据相关工具/框架经验者优先，e.g. Hadoop, Mapreduce, Hive, Storm, Spark, kylin，scribe, kafka, hbase, canal，sqoop etc；
3、实习时间满足3个月*5天以上，能够长期实习并有转正意向的优先。"
"职位描述：
        
        职位职责：
1、参与数据接入、内容集成、优化数据处理流程
2、参与平台化服务建设，满足各业务团队的数据诉求

职位要求：
1、对技术有热情、既有高远目标，也能脚踏实地
2、有扎实的数据结构和算法功底，强悍的编码能力
3、熟悉Linux环境，熟悉至少一门高级语言：C/C++/Python
4、理解http、计算机网络，熟悉HTML、DOM、XPath优先"
"职位描述：
        
        职位职责：
1、负责公司级的通用数据平台和分析型产品，服务于今日头条全公司的数十个用户产品线；
2、面向PB级超大规模数据问题，每天处理千亿增量的用户行为数据；
3、为大数据的全生命周期提供服务，覆盖数据产生，传输，建模，统计分析，实验评估，可视化的全流程；
4、构建设计良好的数据流、数据仓库、调度系统、查询引擎，数据服务、分析系统、流程规范，数据工具/产品，降低数据的使用门槛，保证系统稳定高效运行，以实现数据的最大价值。

职位要求：
1、熟悉多项大数据处理/分析相关的工具/框架，e.g. Hadoop, Mapreduce, Hive, Storm, Spark, kylin，scribe, kafka, hbase, canal，sqoop etc；
2、强悍的编码能力，生产环境快速 trouble-shooting能力，对新技术有强烈的学习热情；
3、优秀的理解沟通能力，能快速理解业务背景，对数据敏感，崇尚数据说话，深信数据在驱动业务、支撑决策上的价值，有web应用开发能力者优先。"
"职位描述：
        
        职位职责：
1、打造业界领先的存储、计算等分布式系统；
2、为海量数据和大规模业务系统提供可靠的基础设施。

职位要求：
1、掌握分布式系统原理，对存储、计算、消息队列、集群管理中的一项或多项有深入的理解和认识；
2、乐于挑战没有明显答案的问题，能快速理解业务场景，从具体问题中抽象出通用的解决方案；
3、存储方向：对 HDFS, RocksDB, LevelDB, memcache, redis, MySQL, HBase, Kafka 的一项或多项有经验者优先；
4、计算方向：对 Spark, MapReduce, Storm, Hive, Presto, Impala 的一项或多项有经验者优先；
5、集群管理方向：对 YARN, Mesos 的一项或多项有经验者优先；
6、向开源社区贡献过 patch 者优先，请在简历上说明。"
"职位描述：
        
        职位职责：
1、打造业界领先的存储、计算等分布式系统；
2、为海量数据和大规模业务系统提供可靠的基础设施。

职位要求：
1、掌握分布式系统原理，对存储、计算、消息队列、集群管理中的一项或多项有深入的理解和认识；
2、乐于挑战没有明显答案的问题，能快速理解业务场景，从具体问题中抽象出通用的解决方案；
3、存储方向：对 HDFS, RocksDB, redis, MySQL, HBase, Kafka 的一项或多项有经验者优先；
4、计算方向：对 Spark, MapReduce, Flink, Hive, ClickHouse 的一项或多项有经验者优先；
5、Developer Infrastructure方向：对 OpenTSDB, InfluxDB, Mesos, Kubernetes 的一项或多项有经验者优先；
6、向开源社区贡献过 patch 者优先，请在简历上说明。"
"职位描述：
        
        职位职责：
1、打造业界领先的通用数据平台，包括实时数据流、数据仓库、调度系统、查询引擎，用户行为分析，abtest 实验系统等，降低数据的使用门槛，实现数据的最大价值
2、打造业界领先的存储、计算等分布式系统，为海量数据和大规模业务系统提供可靠的基础设施

职位要求：
1、熟悉多项大数据领域的开源框架，e.g. Hadoop, Hive, Presto, Storm, Spark, Kafka, HBase, Redis, RocksDB, ElasticSearch, Druid, etc.
2、强悍的编码和 troubleshooting 能力
3、乐于挑战没有明显答案的问题，对新技术有强烈的学习热情"
"职位描述：
        
        职位职责：
1、负责财经业务的数据平台研发，建设数据集市；
2、负责金融BI指标体系、数据模型的构建；
3、制定统一的数据规范，负责数据质量，元数据的监控，整合；
4、理解并合理抽象不同业务需求，做较通用和系统性的支持；

职位要求：
1、本科及以上学历，计算机、通信等相关专业；
2、熟悉数据库、数据仓库，有海量数据处理经验，熟练使用mysql和hsql；
3、有扎实的编程能力, 熟悉python，hadoop, hive，spark等；
4、对数据敏感，善于从数据中发现疑点；
5、有金融背景或者金融数据仓库建设者优先；
6、积极乐观，责任心强，工作认真细致，有良好的团队沟通和协作能力。"
"职位描述：
        
        职位职责：
1、支撑DMP人群包计算的业务需求，参与服务端代码开发；
2、支撑DMP标签的技术升级，参与数据产出流程性能优化；
3、支持DMP大规模数据的计算和分析。

职位要求：
1、本科及以上学历，计算机、通信等相关专业，1-2年相关工作经验；
2、有良好的数据结构、算法基础和扎实的编程能力；
3、熟悉Python/Java/C++/Scala其中任意一门或者多门语言;
4、熟悉hadoop/kafka/spark/storm/flink/HIVE其中的若干技术；
5、具有良好的团队沟通意识和快速学习能力;
6、加分项: 熟悉大数据处理或者DMP业务."
"职位描述：
        
        职位职责：
1、负责品牌广告业务平台及其相关系统的研发
2、负责现有系统的问题分析和改进，提高系统性能，保证系统稳定性
3、持续改进系统架构、核心算法或者核心技术等，保证系统高性能、高可用性和高可扩展性
4、新技术预研，完成项目的选型和设计，难点公关

职位要求：
1、本科及以上学历，一年以上大数据系统开发经验
2、熟悉python语言， 熟练使用Linux
3、对常用的redis、kafka等工具系统有一定的了解
4、有大数据集、分布式计算工具(Hadoop，Spark，Hive，Storm, ES)等应用开发经验优先
5、有良好的团队合作精神，较强的沟通能力
6、愿意深入了解业务知识，并能敏锐的发现业务痛点
7、有品牌广告系统、DMP、舆情、指数平台方向开发经验者优先"
"职位描述：
        
        职位职责：
1、负责字节跳动旗下的所有产品线风控数据仓库架构设计、建模和OLAP开发；
2、参与数据治理工作，提升数据易用性及数据质量；
3、理解并合理抽象业务需求，发挥数据价值，与业务团队紧密合作；

职位要求：
1、精通数据仓库实施方法论、深入了解数据仓库体系，并支撑过实际业务场景；
2、具备较强的编码能力，熟悉sql，python，hive，spark，kafka，flink, druid中的多项，有至少TB以上级大数据处理经验；
3、对数据敏感，认真细致，善于从数据中发现疑点；
4、善于沟通，具备优秀的技术与业务结合能力。；
5、有风控研发经验者优先，对风控行业有自己思考的优先。"
"职位描述：
        
        职位职责：
1、负责字节跳动所有产品线风控方向的数据流和相关数据服务；
2、面向超大规模数据问题，每天处理千亿增量的用户行为数据；
3、负责流式数据的实时传递，清洗，转换，计算，并对外提供查询服务；
4、负责相同数据集的批处理功能。

职位要求：
1、有至少TB以上级大数据处理经验，编码能力强悍，具备生产系统快速 trouble-shooting 的经验和能力；
2、熟悉大数据处理工具/框架中的一项或多项，包括但不限于Hadoop, Mapreduce, Hive, Storm, Spark, Druid, kafka, hbase, canal，ES等；
3、对开源社区有过贡献者优先，请在简历上说明。"
"职位描述：
        
        职位职责：
1、参与数据产品的设计与开发；
2、优化前端数据展示的性能；
3、与后端工程师协作，高效完成产品的数据交互、动态信息展现。

职位要求：
1、扎实的前端基本功，包括但不限于HTML/CSS/JS等；
2、对视觉、交互有着深刻理解，有能力精确还原设计、实现交互；
3、至少熟悉一门非前端的语言（如Java/PHP/C/C++/Python/Ruby），并有实践经验；
4、熟悉nodejs，通过nodejs (如express/koa) 搭建web服务器；
5、熟悉数据可视化库，如ECharts/D3.js/HighCharts/G2等；
6、具有数据类产品和数据可视化的工作经验者优先；
7、熟悉可视化渲染引擎、图形学、几何学相关算法者优先；
8、对前端技术有持续的热情，个性乐观开朗，逻辑性强，善于和各种背景的人合作。"
"职位描述：
        
        职位职责：
1、带领数据团队，构建业务指标体系，建立和完善日常业务报告体系，能够及时、准确、完整地披露业务的运作情况 ；
2、参与数据仓库架构设计与数据开发，建设共享数据仓库 ；
3、通过专项分析，输出专项分析报告，为业务模块的决策和产品方向提供数据支持 ；
4、参与数据底层的工具、平台、部署流程等技术体系建设的研发工作。

职位要求：
1、统招本科及以上学历，计算机相关专业；
2、熟悉数据仓库模型设计方法论，并有实际模型设计及ETL开发经验 ；
3、掌握大型数据库开发技术，如Oracle、Teradata、DB2、Mysql等等掌握至少一种，灵活运用SQL实现海量数据ETL加工处理与查询性能调优；
4、熟悉常用的数据挖掘、分析的工具和方法，有数据挖掘工作经验，熟悉linux平台，精通shell/c(c++)/php/python/等脚本语言的一种或多种，编码基本功扎实 ；
5、有团队组建经验和管理经验。"
"职位描述：
        
        职位描述：
1、打造业界领先的通用数据平台，包括实时数据流、数据仓库、调度系统、查询引擎，用户行为分析，abtest 实验系统等，降低数据的使用门槛，实现数据的最大价值2、打造业界领先的存储、计算等分布式系统，为海量数据和大规模业务系统提供可靠的基础设施
职位要求：
1、熟悉多项大数据领域的开源框架，e.g. Hadoop, Hive, Presto, Storm, Spark, Kafka, HBase, Redis, RocksDB, ElasticSearch, Druid, etc.2、强悍的编码和 troubleshooting 能力3、乐于挑战没有明显答案的问题，对新技术有强烈的学习热情"
"职位描述：
        
        职位职责：
1、打造业界领先的通用数据平台，包括实时数据流、数据仓库、调度系统、查询引擎，用户行为分析，abtest 实验系统等，降低数据的使用门槛，实现数据的最大价值；
2、打造业界领先的存储、计算等分布式系统，为海量数据和大规模业务系统提供可靠的基础设施。

职位要求：
1、熟悉多项大数据领域的开源框架，e.g. Hadoop, Hive, Presto, Storm, Spark, Kafka, HBase, Redis, RocksDB, ElasticSearch, Druid, etc.；
2、强悍的编码和 troubleshooting 能力；
3、乐于挑战没有明显答案的问题，对新技术有强烈的学习热情。"
"职位描述：
        
        职位职责：
1、负责在全球互联网下头条系产品短视频用户体验的持续优化；
2、构建短视频相关数据仓库，分析和报表系统；
3、设计并优化视频播放QoS数据上报机制，构建面向用户体验的APM系统；
4、通过建设实时数据分析，构建智能播放调度策略和自动报警归因系统。

职位要求：
1、本科及以上学历，计算机、通信等相关专业，两年及以上全职工作经验； 
2、有扎实的编程能力，有优秀的设计和代码品位，有独立的代码实现能力 ； 
3、深刻理解计算机原理，有良好的数据结构和算法基础；
4、熟悉数据采集、清洗入库、统计计算、Web展示核心要点，可实现指标计算需求；
5、熟悉至少一个分布式框架，如 Hadoop/YARN、Hive、Spark、Storm、Kafka 等，有Flink实时处理经验优先；
6、优秀的理解沟通能力，能快速理解业务背景，责任心强，具有良好的团队沟通与协作能力；
7、有大数据处理、数据平台、数据仓库经验者或数据挖掘算法优先。"
"职位描述：
        
        职位职责：
1、支持业务需求，基于海量数据实现数据采集、清洗入库、统计计算、Web展示。
2、主要负责流式实时计算分析和离线数据统计分析
3、主要实现编程语言为Scala/Java/Python；

职位要求：
1、本科及以上学历，计算机、通信等相关专业，两年及以上全职工作经验； 
2、有扎实的编程能力，有优秀的设计和代码品位，有独立的代码实现能力 ； 
3、深刻理解计算机原理，有良好的数据结构和算法基础；
4、熟悉数据采集、清洗入库、统计计算、Web展示核心要点，可实现指标计算需求；
5、熟悉常用的开源组件：Hadoop/Hive/Spark/Storm/Flink，并了解其特性和使用场景优先；
6、优秀的理解沟通能力，能快速理解业务背景，对数据敏感，崇尚数据说话，深信数据在驱动业务、支撑决策上的价值，有数据挖掘、数据分析、分布式计算、业务推荐开发能力者优先
7、积极乐观，责任心强，工作认真细致，具有良好的团队沟通与协作能力；"
"职位描述：
        
        职位职责：
1、负责核心业务数据a品的架构设计和实施，紧跟业务发展，推动规范的制定和落实
2、负责大数据产品的模型提出&优化、系统设计、开发和维护，和产品、分析师等紧密合作，让数据充分发挥价值
3、针对复杂的业务场景，探索和实施新的技术方案，与业务团队一起发现、解决数据流及相关技术问题

职位要求：
1、热爱计算机科学和互联网技术，乐于快速学习和尝试新技术、新工具，良好的沟通和理解能力;
2、具备强悍的编码能力，熟悉 linux 开发环境，熟悉 Python 语言优先；
3、具备在复杂业务场景中发现和解决数据&业务问题的能力，不被固有方案限制，对解决有挑战性的问题充满激情;
6、熟悉数据挖掘算法，包括数据清洗.统计学习.分类聚类算法，并能够验证算法效果，将算法应用在教育鼍爸校
4、熟悉至少一个分布式框架，如 Hadoop/YARN、Hive、Spark、Storm、Kafka 等;
5、有大数据处理、数据平台、数据仓库经验者优先;"
"职位描述：
        
        职位职责：
1、 负责抖音/火山等多个业务线内大数据平台架构的规划与设计，并带领团队落地实施；
2、搭建可配置化计算引擎，实现1000W/s条流式数据挑战下实时精准计算，落地储存；
3、负责流式数据的实时传递，清洗，转换，计算，并对外提供查询服务；
4、负责实时及离线特征抽取、融合，为数据挖掘及策略平台提供特征服务；
5、负责大数据能力在产品功能上的落地，推动产品数据化和智能化。

职位要求：
1、计算机等相关专业，硕士或以上学历，3年以上大数据、人工智能相关经验；
2、熟悉HiveHadoopSparkFlinkClickHouseDruid等大数据开发技术；
3、有良好的业务和产品sense，执行力、推动力强优先；
4、有丰富的行业经验，丰富的专业知识，独特的行业见解，有战略视野和规划能力优先；
5、优秀的理解沟通能力，崇尚数据说话，深信数据在驱动业务、支撑决策上的价值优先。"
"职位描述：
        
        职位职责：
1、 负责抖音/火山等多个业务线内大数据平台架构的规划与设计，并带领团队落地实施；
2、搭建可配置化计算引擎，实现1000W/s条流式数据挑战下实时精准计算，落地储存；
3、负责流式数据的实时传递，清洗，转换，计算，并对外提供查询服务；
4、负责实时及离线特征抽取、融合，为数据挖掘及策略平台提供特征服务；
5、负责大数据能力在产品功能上的落地，推动产品数据化和智能化。

职位要求：
1、计算机等相关专业，硕士或以上学历，3年以上大数据、人工智能相关经验；
2、熟悉HiveHadoopSparkFlinkClickHouseDruid等大数据开发技术；
3、有良好的业务和产品sense，执行力、推动力强优先；
4、有丰富的行业经验，丰富的专业知识，独特的行业见解，有战略视野和规划能力优先；
5、优秀的理解沟通能力，崇尚数据说话，深信数据在驱动业务、支撑决策上的价值优先。"
"职位描述：
        
        职位职责：
1、负责头条广告变现核心业务模块标准化cube数据的开发建设；
2、负责数据模型的设计，etl实施，etl性能优化，etl数据监控以及相关技术问题的解决；
3、负责面向业务的olap，报表，数据提取等工作。

职位要求：
1、本科及以上学历，精通至少一门编程语言，如Java、Python；具有很强的开发与动手能力；
2、深入理解常用的数据建模理论，可独立把控数据仓库的各层级设计；有数据挖掘，机器学习，推荐相关经验优先；
3、两年以上etl开发经验，熟悉hive、hadoop、spark等大数据技术；
4、对mysql，nosql数据库有一定的了解和使用经验；
5、踏实，好学，较强的沟通能力，良好的团队协作精神，对海量数据处理与分析有热情。"
"职位描述：
        
        职位职责：
1、负责头条广告变现核心业务模块标准化cube数据的开发建设；
2、负责数据模型的设计，etl实施，etl性能优化，etl数据监控以及相关技术问题的解决；
3、负责面向业务的olap，报表，数据提取等工作。

职位要求：
1、本科及以上学历，精通至少一门编程语言，如Java、Python；具有很强的开发与动手能力；
2、深入理解常用的数据建模理论，可独立把控数据仓库的各层级设计；有数据挖掘，机器学习，推荐相关经验优先；
3、二年以上etl开发经验，熟悉hive、hadoop、spark等大数据技术；
4、对mysql，nosql数据库有一定的了解和使用经验；
5、踏实，好学，较强的沟通能力，良好的团队协作精神，对海量数据处理与分析有热情。"
"职位描述：
        
        职位职责：
1、负责创新工具核心业务模块数据仓库的构建；
2、负责数据模型的设计，ETL实施、ETL性能优化、ETL数据监控以及一系列技术问题的解决；
3、负责构建用户主题、各业务线主题、推荐主题、企业BI门户系统；
4、负责全产品线数据字典维护，提升数据资产质量。

职位要求：
1、计算机、数学相关专业本科及以上学历，三年以上大数据开发工作经验，数据挖掘和BI分析领域优先；
2、熟练掌握Hive/SQL，熟悉Spark/Map-Reduce/MPI分布式计算框架，熟悉大数据的离线和实时处理，可以进行海量数据模型的设计、开发；
3、有产品sense，主动思考基于业务场景下的数据体系建设；
4、工作认真，负责，良好的团队合作精神和解决问题分析能力。钻研技术克服困难，勇于挑战；
5、有数据分析经验优先。"
"职位描述：
        
        职位职责：
1、负责创新工具核心业务模块数据仓库的构建；
2、负责数据模型的设计，ETL实施、ETL性能优化、ETL数据监控以及一系列技术问题的解决；
3、负责构建用户主题、各业务线主题、推荐主题、企业BI门户系统；
4、负责全产品线数据字典维护，提升数据资产质量。

职位要求：
1、计算机、数学相关专业本科及以上学历，三年以上大数据开发工作经验，数据挖掘和BI分析领域优先；
2、熟练掌握Hive/SQL，熟悉Spark/Map-Reduce/MPI分布式计算框架，熟悉大数据的离线和实时处理，可以进行海量数据模型的设计、开发；
3、有产品sense，主动思考基于业务场景下的数据体系建设；
4、工作认真，负责，良好的团队合作精神和解决问题分析能力。钻研技术克服困难，勇于挑战；
5、有数据分析经验优先。"
"职位描述：
        
        职位职责：
1、负责今日头条的一条或多条核心产品线的数据仓库建设，例如，火山，抖音，西瓜，国际化，问答等；
2、参与数据治理工作，提升数据易用性及数据质量，与数据工具团队紧密合作
3、深入业务，理解并合理抽象业务需求，发挥数据价值，与业务团队紧密合作。

职位要求：
1、精通数据仓库实施方法论、深入了解数据仓库体系，并支撑过实际业务场景；
2、具备较强的编码能力，熟悉sql，python，hive，spark，kafka，storm中的多项；
3、善于沟通，具备优秀的技术与业务结合能力；
4、有PB量级数据处理经验者优先；
5、有团队管理经验者优先。"
"职位描述：
        
        职位职责：
1、面向全球互联网络持续优化头条系产品视频播放体验；
2、设计优化的视频播放QoS数据上报机制，开发数据Pipeline，分析和报表系统，不间断监测平台的直播点播体验；
3、通过建设实时数据分析，实现智能的CDN调度策略和精细化报警策略；
4、建立一体化的CDN质量解决方案，和CDN共同提升视频播放体验；

职位要求：
1、计算机、网络、通信等相关专业本科以上学历
2、数据大数据系统构建，深入理解大数据处理的Lambda架构；有Storm/Spark/Flink应用经验者优先；
3、具有扎实的计算机网络基础，深入理解流媒体相关协议标准，有互联网络拓扑优化、小运营商优化经验者优先；
4、积极乐观，责任心强，工作认真细致，具备良好的服务意识，具有良好的团队沟通与协作能力"
"职位描述：
        
        职位职责：
1、面向全球互联网络持续优化头条系产品视频播放体验；
2、设计优化的视频播放QoS数据上报机制，开发数据Pipeline，分析和报表系统，不间断监测平台的直播点播体验；
3、通过建设实时数据分析，实现智能的CDN调度策略和精细化报警策略；
4、建立一体化的CDN质量解决方案，和CDN共同提升视频播放体验；

职位要求：
1、计算机、网络、通信等相关专业本科以上学历
2、数据大数据系统构建，深入理解大数据处理的Lambda架构；有Storm/Spark/Flink应用经验者优先；
3、具有扎实的计算机网络基础，深入理解流媒体相关协议标准，有互联网络拓扑优化、小运营商优化经验者优先；
4、积极乐观，责任心强，工作认真细致，具备良好的服务意识，具有良好的团队沟通与协作能力"
"职位描述：
        
        职位职责：1、基于每日百亿级展现数据，搭建大数据处理平台;实现流式事件的实时计算，落地储存。对于离线数据完成数据仓库的建立，为数据挖掘提供有效的数据。 2、使用用户行为数据，广告投放数据，挖掘数据层次关系，利用机器学习算法，解决媒体、流量、充分竞价等对优化广告投放流程，3、数据分析，挖掘，模型具体的产品化；了解广告业务能，和PM合作，基于数据驱动持续优化数据产品。职位要求：1、熟悉C++、JAVA、python中的一种或多种编程技术，编程能力强，熟悉大数据处理技术，善于学习应用业界领先数据架构和技术。 2、熟悉数据挖掘算法，包括数据清洗、统计学习、分类聚类算法，并能够验证算法效果，将算法应用在广告业务中。 3、善于学习，有想要折腾的想法。有广告调优背景优先，对广告行业有自己思考的优先。"
"职位描述：
        
        职位职责：
1、负责创作工具类产品的业务模块数据仓库和数据产品的构建；
2、负责创新工具的推荐架构的开发，支持千万级的推荐流量；
3、负责创新工具实时流的开发，搭建实时数据仓库；
4、负责全产品线数据质量体系的构建，保证数据资产质量。

职位要求：
1、计算机、数学等相关专业本科及以上学历，三年以上大数据开发工作经验，有数据挖掘和BI分析领域优先；
2、熟练掌握Hive/SQL，熟悉Spark/MR/Flink分布式计算框架，熟悉大数据的离线和实时处理，可以进行海量数据模型的设计、开发；
3、有产品和分析sense的优先，主动思考基于业务场景的数据产品构建和分析价值落地；
4、工作认真，负责，良好的团队合作精神和解决问题分析能力，钻研技术克服困难，勇于挑战。"
"职位描述：
        
        职位职责：
1、 对业务问题进行合理抽象和设计，设计和开发高质量的底层数据体系，驱动业务快速健康发展；
2、在数据仓库内实施收集，清洗和规约等工作；
3、提供面向业务的数据服务，完成数据指标的统计，多维分析和展现；
4、根据业务和产品情况，抽象业务逻辑，搭建和开发大数据平台；
5、参与数据平台架构设计，核心开发任务。

职位要求：
1、 熟悉SQL/HQL/PLSQL之一，有SQL性能调优经验者优先；
2、 熟悉Mysql/Oracle等至少一种关系型数据库；
3、 了解数据仓库，学习过主题建模、维度建模理论者优先；
4、 了解MapReduce/Hive，熟悉Hadoop生态者优先；
5、 有互联网，电信，金融等行业应用经验者优先；
6、 具备优秀的逻辑思维能力，对解决挑战性问题充满热情，善于解决问题和分析问题；
7、 责任心强，具备良好的沟通技能，团队合作能力和承受压力的能力。"
"职位描述：
        
        职位职责：1、参与合作数据接入、内容集成，优化数据处理流程2、参与平台化服务建设，满足各业务团队的数据诉求职位要求：1、具备良好的编码能力，有扎实的数据结构和算法功底 2、熟悉linux开发环境，掌握至少一门高级语言：C/C++/Python3、理解http、计算机网络，熟悉HTML、DOM、XPath等4、工作认真细致踏实，较强的学习能力、分析解决问题能力"
"职位描述：
        
        职位职责：
1、负责协作&创作工具类产品核心业务模块数据仓库的构建；
2、负责数据模型的设计，ETL实施、ETL性能优化、ETL数据监控以及一系列技术问题的解决；
3、负责构建用户主题、各业务线主题、推荐主题、企业BI门户系统；
4、负责全产品线数据字典维护，提升数据资产质量。

职位要求：
1、计算机、数学相关专业，本科及以上学历，三年以上大数据开发工作经验，数据挖掘和BI分析领域优先；
2、熟练掌握Hive/SQL，熟悉Spark/Map-Reduce/MPI分布式计算框架，熟悉大数据的离线和实时处理，可以进行海量数据模型的设计、开发；
3、有产品sense，主动思考基于业务场景下的数据体系建设，而不单单只会做执行；
4、工作认真，负责，良好的团队合作精神和解决问题分析能力，钻研技术克服困难，勇于挑战；
5、有数据分析经验优先。"
"职位描述：
        
        职位职责：
1、打造业界领先的apm数据系统；
2、为公司所有app提供报表，监控，分析，计算等解决方案。

职位要求：
1、掌握分布式系统原理，对存储、计算、消息队列、集群管理中的一项或多项有深入的理解和认识；
2、乐于挑战没有明显答案的问题，能快速理解业务场景，从具体问题中抽象出通用的解决方案；
4、有深厚的代码功底，熟悉常见的算法和数据结构；
5、对 HDFS, RocksDB, redis, MySQL, HBase, Kafka 的一项或多项有经验者优先；
6、具有spark，MapReduce，clickhouse等有相关使用经验，并了解他们的运作原理；
7、具有druid使用经验者优先；
8、向开源社区贡献过 patch 者优先，请在简历上说明。"
"职位描述：
        
        职位职责：
1、基于海量数据，支持业务对数据的分析和使用：
2、支持业务处理数据的流式处理、构建数据仓库、分析用户行为等。

职位要求：
1、有扎实的编程能力，有优秀的设计和代码品位，对解决具有挑战性问题充满激情；
2、对大数据处理有丰富的经验和广阔的视野；
3、熟悉常用的开源组件：Hadoop/Hive/Spark/Storm，并了解其特性和使用场景；
4、优秀的沟通理解能力，能快速理解业务，用数据解读业务；
5、推荐或机器学习相关的开发工作优先。"
"职位描述：
        
        职位职责：
1、打造业界领先的存储、计算等分布式系统；
2、为海量数据和大规模业务系统提供可靠的基础设施。

职位要求：
1、掌握分布式系统原理，对存储、计算、消息队列、集群管理中的一项或多项有深入的理解和认识；
2、乐于挑战没有明显答案的问题，能快速理解业务场景，从具体问题中抽象出通用的解决方案；
3、存储方向：对 HDFS, RocksDB, LevelDB, memcache, redis, MySQL, HBase, Kafka 的一项或多项有经验者优先；
4、计算方向：对 Spark, MapReduce, Storm, Hive, Presto, Impala 的一项或多项有经验者优先；
5、向开源社区贡献过 patch 者优先，请在简历上说明。"
"职位描述：
        
        职位职责：
1、打造业界领先的存储、计算等分布式系统；
2、为海量数据和大规模业务系统提供可靠的基础设施。

职位要求：
1、掌握分布式系统原理，对存储、计算、消息队列、集群管理中的一项或多项有深入的理解和认识；
2、乐于挑战没有明显答案的问题，能快速理解业务场景，从具体问题中抽象出通用的解决方案；
3、存储方向：对 HDFS, RocksDB, LevelDB, memcache, redis, MySQL, HBase, Kafka 的一项或多项有经验者优先；
4、计算方向：对 Spark, MapReduce, Storm, Hive, Presto, Impala 的一项或多项有经验者优先；
5、向开源社区贡献过 patch 者优先，请在简历上说明。"
"职位描述：
        
        职位职责：
1、根据不同的业务场景，构建业务指标体系，建立和完善日常业务报告体系，能够及时、准确、完整的披露公司整体及各项目的运作情况 ；
2、参与数据仓库架构设计与数据开发，建设共享数据仓库 ；
3.、通过专项分析，输出专项分析报告，为业务模块的决策和产品方向提供数据支持 ；
4、参与数据底层的工具、平台、部署流程等技术体系建设的研发工作；

职位要求：
1、统招本科以上学历；
2、熟悉数据仓库模型设计方法论，并有实际模型设计及ETL开发经验 ；
3、掌握大型数据库开发技术，如Oracle、Teradata、DB2、Mysql等等掌握至少一种，灵活运用SQL实现海量数据ETL加工处理与查询性能调优；
4、熟悉常用的数据挖掘、分析的工具和方法，有数据挖掘工作经验；熟悉linux平台，精通shell/c(c++)/php/python/等脚本语言的一种或多种，编码基本功扎实 ；
5、具备快速学习能力、沟通协调能力及团队精神，有较强的责任心和学习积极性。"
"职位描述：
        
        职位职责：
1、参与打造业界领先的存储、计算、消息队列等分布式系统
2、为海量数据及其上的大规模数据挖掘、数据分析、机器学习业务系统提供可靠、高效的支持
3、深入了解业务需求，利用存储技术支持关键业务场景

职位要求：
1、掌握分布式系统原理，对存储、计算、消息队列的一项或多项有深入的理解和认识
2、乐于挑战没有明显答案的问题，能快速理解业务场景，从具体问题中抽象出通用的解决方案
3、有较好的沟通能力；有良好的团队合作精神"
"职位描述：
        
        职位职责：
1、为海量数据和大规模业务系统提供可靠的基础设施；
2、优秀的数据挖掘分析处理能力；
3、参与数据接入、集成、优化等处理流程；
4、参与平台化服务建设，满足业务的数据诉求；

职位要求：
1、掌握分布式系统原理，对存储、计算、消息队列、集群管理中的一项或多项有深入的理解和认识；
2、乐于挑战没有明显答案的问题，能快速理解业务场景，从具体问题中抽象出通用的解决方案；
3、熟悉多项大数据处理/分析相关的工具/框架，e.g. Hadoop, Mapreduce, Hive, Storm, Spark, kafka
4、熟悉Python和Go语言优先；"
"职位描述：
        
        职位职责：
1、负责业务相关数据挖掘核心技术的研发；
2、负责多渠道内容处理Pipeline的设计与开发，实现相关业务的实体的关键字抽取、正则化、聚类、Topic等基础特征，为后续处理提供数据；
3、负责大数据基础设施和平台改进，解决生产环境可用性和性能优化问题；
4、参与数据底层的工具、平台和部署流程等研发工作。

职位要求：
1、良好的设计和编码品味，热爱写代码，有代码洁癖更佳；
2、动手能力强，喜欢折腾，有解决复杂问题的能力与兴趣；
3、精通 SQL，有较好的 SQL 性能调优经验，熟悉 Hive/MySQL 的基本原理和调优策略；
4、熟悉数据仓库实施方法论、深入了解数据仓库体系，并支撑过实际业务场景；
5、编程语言不限，有Python或c++经验更佳；
6、较好的产品意识，关注数据，以产品为工作的驱动因素。"
"职位描述：
        
        职位职责：
1、负责字节跳动海量用户行为数据的处理，在分布式计算平台基础上建立高效、实时的数据 pipeline； 
2、负责推荐系统、广告系统的数据分析，发现模式与规律，为实验解释、系统改进提供数据支持； 
3、负责 Hadoop，Spark 等大数据基础设施和平台的改进，解决大规模生产环境集群可用性和性能优化问题；
4、持续改进系统架构、核心算法或者核心技术等，保证系统高性能、高可用性和高可扩展性。

职位要求：
1、本科及以上学历，一年以上大数据系统开发经验；
2、对至少一项分布式计算平台有使用经验，例如 Hadoop，Spark，Hive，Storm，Kafka 等；
3、热爱计算机科学和互联网技术，优秀的编码能力，乐于快速学习和尝试新技术、新工具； 
4、对数据敏感，掌握量化分析方法，善于从数据中发现问题，提出假设并使用数据进行验证；
5、有良好的团队合作精神，较强的沟通能力；
6、愿意深入了解业务知识，并能敏锐的发现业务痛点；
7、 有品牌广告系统、DMP、舆情、指数平台方向开发经验者优先；
8、 有参与开源项目对社区有贡献的经历，有互联网公司实习经历，有大数据处理或用户行为数据分析经验者优先。"
"职位描述：
        
        职位职责：
1、负责字节跳动海量用户行为数据的处理，在分布式计算平台基础上建立高效、实时的数据 pipeline；?
2、负责推荐系统、广告系统的数据分析，发现模式与规律，为实验解释、系统改进提供数据支持；?
3、负责 Hadoop，Spark 等大数据基础设施和平台的改进，解决大规模生产环境集群可用性和性能优化问题。
4、北京、上海均有需求

职位要求：
1、2019届毕业，本科及以上学历，计算机相关专业； 
2、热爱计算机科学和互联网技术，优秀的编码能力，乐于快速学习和尝试新技术、新工具； 
3、对数据敏感，掌握量化分析方法，善于从数据中发现问题，提出假设并使用数据进行验证； 
4、对至少一项分布式计算平台有使用经验，例如 Hadoop，Spark，Hive，Storm，Kafka 等； 
5、有参与开源项目对社区有贡献的经历，有互联网公司实习经历，有大数据处理或用户行为数据分析经验者优先。"
"职位描述：
        
        职位职责：
1、研发业界领先的灰度实验/abtest系统，面向头条全公司的所有产品线；
2、建立通用的用户行为指标体系，探索性发掘新指标，研究业界领先的个性化评估方法；
3、从PB级超大规模的用户行为数据中挖掘信息，并设计实验验证假设，为策略/产品改进提供支持。

职位要求：
1、熟悉多项大数据处理/分析相关的工具/框架，e.g. Hadoop, Mapreduce, Hive, Storm, Spark, kylin，scribe, kafka, hbase, canal，sqoop etc；
2、强悍的编码能力，生产环境快速 trouble-shooting能力，对新技术有强烈的学习热情；
3、优秀的理解沟通能力，能快速理解业务背景，对数据敏感，崇尚数据说话，深信数据在驱动业务、支撑决策上的价值，有web应用开发能力者优先。"
"职位描述：
        
        职位职责：
1、为海量数据和大规模业务系统提供可靠的基础设施；
2、优秀的数据挖掘分析处理能力；
3、参与数据接入、集成、优化等处理流程；
4、参与平台化服务建设，满足业务的数据诉求；

职位要求：
1、掌握分布式系统原理，对存储、计算、消息队列、集群管理中的一项或多项有深入的理解和认识；
2、乐于挑战没有明显答案的问题，能快速理解业务场景，从具体问题中抽象出通用的解决方案；
3、熟悉多项大数据处理/分析相关的工具/框架，e.g. Hadoop, Mapreduce, Hive, Storm, Spark, kafka
4、熟悉Python和Go语言优先；"
"职位描述：
        
        职位描述：
1、为海量数据和大规模业务系统提供可靠的基础设施；2、优秀的数据挖掘分析处理能力；3、参与数据接入、集成、优化等处理流程；4、参与平台化服务建设，满足业务的数据诉求；
职位要求：
1、掌握分布式系统原理，对存储、计算、消息队列、集群管理中的一项或多项有深入的理解和认识；2、乐于挑战没有明显答案的问题，能快速理解业务场景，从具体问题中抽象出通用的解决方案；3、熟悉多项大数据处理/分析相关的工具/框架，e.g. ?Hadoop, Mapreduce, Hive, Storm, Spark, kafka4、熟悉Python和Go语言优先；"
"职位描述：
        
        职位职责：
1、负责公司级的通用数据平台和分析型产品，服务于今日头条全公司的数十个用户产品线；
2、面向PB级超大规模数据问题，每天处理千亿增量的用户行为数据；
3、为大数据的全生命周期提供服务，覆盖数据产生，传输，建模，统计分析，实验评估，可视化的全流程；
4、构建设计良好的数据流、数据仓库、调度系统、查询引擎，数据服务、分析系统、流程规范，数据工具/产品，降低数据的使用门槛，保证系统稳定高效运行，以实现数据的最大价值。

职位要求：
1、熟悉多项大数据处理/分析相关的工具/框架，e.g. Hadoop, Mapreduce, Hive, Storm, Spark, kylin，scribe, kafka, hbase, canal，sqoop etc；
2、强悍的编码能力，生产环境快速 trouble-shooting能力，对新技术有强烈的学习热情；
3、优秀的理解沟通能力，能快速理解业务背景，对数据敏感，崇尚数据说话，深信数据在驱动业务、支撑决策上的价值，有web应用开发能力者优先。"
"职位描述：
        
        职位职责：
1、负责公司级的通用数据平台和分析型产品，服务于字节跳动全公司的用户产品线；
2、面向PB级超大规模数据问题，每天处理千亿增量的用户行为数据；
3、为大数据的全生命周期提供服务，覆盖数据产生，传输，建模，统计分析，实验评估，可视化的全流程；
4、构建设计良好的数据流、数据仓库、调度系统、查询引擎，数据服务、分析系统、流程规范，数据工具/产品，降低数据的使用门槛，保证系统稳定高效运行，以实现数据的最大价值。

职位要求：
1、熟悉多项大数据处理/分析相关的工具/框架，e.g. Hadoop, Mapreduce, Hive, Storm, Spark, kylin，scribe, kafka, hbase, canal，sqoop etc；
2、强悍的编码能力，生产环境快速 trouble-shooting能力，对新技术有强烈的学习热情；
3、优秀的理解沟通能力，能快速理解业务背景，对数据敏感，崇尚数据说话，深信数据在驱动业务、支撑决策上的价值，有web应用开发能力者优先。"
"职位描述：
        
        职位职责：
1、负责公司级的通用数据平台和分析型产品，服务于今日头条全公司的数十个用户产品线；
2、面向PB级超大规模数据问题，每天处理千亿增量的用户行为数据；
3、为大数据的全生命周期提供服务，覆盖数据产生，传输，建模，统计分析，实验评估，可视化的全流程；
4、构建设计良好的数据流、数据仓库、调度系统、查询引擎，数据服务、分析系统、流程规范，数据工具/产品，降低数据的使用门槛，保证系统稳定高效运行，以实现数据的最大价值。

职位要求：
1、熟悉多项大数据处理/分析相关的工具/框架，e.g. Hadoop, Mapreduce, Hive, Storm, Spark, kylin，scribe, kafka, hbase, canal，sqoop etc；
2、强悍的编码能力，生产环境快速 trouble-shooting能力，对新技术有强烈的学习热情；
3、优秀的理解沟通能力，能快速理解业务背景，对数据敏感，崇尚数据说话，深信数据在驱动业务、支撑决策上的价值，有web应用开发能力者优先。"
"职位描述：
        
        职位职责：
1、负责公司级的通用数据平台和分析型产品，服务于字节跳动全公司的用户产品线；
2、面向PB级超大规模数据问题，每天处理千亿增量的用户行为数据；
3、为大数据的全生命周期提供服务，覆盖数据产生，传输，建模，统计分析，实验评估，可视化的全流程；
4、构建设计良好的数据流、数据仓库、调度系统、查询引擎，数据服务、分析系统、流程规范，数据工具/产品，降低数据的使用门槛，保证系统稳定高效运行，以实现数据的最大价值。

职位要求：
1、熟悉多项大数据处理/分析相关的工具/框架，e.g. Hadoop, Mapreduce, Hive, Storm, Spark, kylin，scribe, kafka, hbase, canal，sqoop etc；
2、强悍的编码能力，生产环境快速 trouble-shooting能力，对新技术有强烈的学习热情；
3、优秀的理解沟通能力，能快速理解业务背景，对数据敏感，崇尚数据说话，深信数据在驱动业务、支撑决策上的价值，有web应用开发能力者优先。"
"职位描述：
        
        职位职责：
1、负责公司级的统一数据平台和分析型产品的研发，服务于今日头条全公司的数十个用户产品线；
2、设计和实现Web后端和关键数据服务，用数据衡量产品并驱动产品演进。

职位要求：
1、熟悉互联网产品和服务的开发过程，熟悉后端技术架构，具备良好的系统设计能力；
2、扎实的计算机基础，对技术有热情，愿意不断尝试新技术和业务挑战；
3、熟悉Python和Go语言优先；
4、有大数据集、分布式计算工具(Hadoop，Spark，Hive，Storm)等应用开发经验优先；
5、有产品sense，兼具pm技能者优先。"
"职位描述：
        
        职位职责：
1、负责数据仓库架构设计、建模和ETL开发，服务于今日头条全公司的数十个用户产品线；
2、制定和推行全公司的统一数据规范，负责数据质量，元数据的监控，整合；
3、理解并合理抽象不同业务需求，做较通用和系统性的支持。

职位要求：
1、精通数据仓库实施方法论、深入了解数据仓库体系，并支撑过实际业务场景；
2、具备强悍的编码能力，熟悉sql，python，hive，spark，kafka，storm中的多项，有至少TB以上级大数据处理经验；
3、对数据敏感，善于从数据中发现疑点，有用户行为分析经验者优先；
4、善于沟通，具备优秀的技术与业务结合能力。"
"职位描述：
        
        职位职责：
1、参与计算框架和服务的定制和改进，为公司批处理和流式计算能力提供支撑；
2、深入理解业务场景，解决性能瓶颈，实现业务目标；
3、计算、存储和网络方面基础技术的探索和储备。

职位要求：
1、精通各种性能分析和调试工具，高效进行分析；
2、熟练的 C/C++/Java 开发能力，代码质量高；
3、熟悉网络、linux、Hadoop 等系统，能够灵活解决新问题；
4、较好的团队协作和沟通能力。"
"职位描述：
        
        职位职责：
1、基于每日百亿级展现数据，搭建大数据处理平台; 实现流式事件的实时计算，落地储存。对于离线数据完成数据仓库的建立，为数据挖掘提供有效的数据； 
2、面向超大规模数据问题，每天处理千亿增量的用户行为和模型预估数据； 
3、负责流式数据的ETL，统计报表及展示； 
4、数据分析，基于数据驱动产品及算法优化。

职位要求：
1、有至少TB以上级大数据处理经验，编码能力强悍，具备生产系统快速 trouble-shooting 的经验和能力； 
2、熟悉C++、JAVA、python中的一种或多种编程技术，编程能力强，熟悉大数据处理技术，善于学习应用业界领先数据架构和技术； 
3、对大数据开源组件有使用经验，对hadoop/hive/spark/ES/druid 其中一项精通； 
4、善于学习，思维活跃，善于从数据中发现、思考并解决问题。"
"职位描述：
        
        职位职责：
1、研发业界领先的交互式数据分析系统，服务于今日头条全公司的数十个用户产品线；
2、面向超大规模数据问题，每天千亿增量的用户行为数据，秒级处理PB级别的数据计算；
3、善于理解和抽象业务问题，支撑多样的海量数据分析场景。

职位要求：
1、理解分布式系统，思路清晰，具备生产系统快速 trouble-shooting 的经验和能力，擅长分析深层次的原因；
2、对市面上常见的 OLAP 系统设计与源码有深入研究，给 Hive/Kylin/Presto/Spark/Tez 等项目提交过 patch者优先。"
"职位描述：
        
        职位职责：
1、研发业界领先的交互式数据分析系统，服务于今日头条全公司的数十个用户产品线；
2、面向超大规模数据问题，每天千亿增量的用户行为数据，秒级处理PB级别的数据计算；
3、善于理解和抽象业务问题，支撑多样的海量数据分析场景。

职位要求：
1、理解分布式系统，思路清晰，具备生产系统快速 trouble-shooting 的经验和能力，擅长分析深层次的原因；
2、对市面上常见的 OLAP 系统设计与源码有深入研究，给 Hive/Kylin/Presto/Spark/Tez 等项目提交过 patch者优先。"
"职位描述：
        
        职位职责：
1、研发业界领先的交互式数据分析系统，服务于今日头条全公司的数十个用户产品线；
2、面向超大规模数据问题，每天千亿增量的用户行为数据，秒级处理PB级别的数据计算；
3、善于理解和抽象业务问题，支撑多样的海量数据分析场景。

职位要求：
1、理解分布式系统，思路清晰，具备生产系统快速 trouble-shooting 的经验和能力，擅长分析深层次的原因；
2、对市面上常见的 OLAP 系统设计与源码有深入研究，给 Hive/Kylin/Presto/Spark/Tez 等项目提交过 patch者优先。"
"职位描述：
        
        职位职责：
1、打造业界领先的通用数据平台，包括实时数据流、数据仓库、调度系统、查询引擎，用户行为分析，abtest 实验系统等，降低数据的使用门槛，实现数据的最大价值
2、打造业界领先的存储、计算等分布式系统，为海量数据和大规模业务系统提供可靠的基础设施

职位要求：
1、熟悉多项大数据领域的开源框架，e.g. Hadoop, Hive, Presto, Storm, Spark, Kafka, HBase, Redis, RocksDB, ElasticSearch, Druid, etc.
2、强悍的编码和 troubleshooting 能力
3、乐于挑战没有明显答案的问题，对新技术有强烈的学习热情"
"职位描述：
        
        职位职责：
1、负责企业级大数据平台的研发，服务于今日头条公司内外的几十条产品线；
2、不局限于按部就班的研发工作，有强烈的产品sense，对用户体验敏感，能够综合运用技术/产品/运营方案，提升终端用户体验；
3、平台产品包括但不限于：用户行为分析，查询中心，BI报表，元数据管理，abtest系统，数据开发套件等；

职位要求：
1、计算机等相关专业优先，本科及以上学历；
2、复合型人才，有研发能力的pm，或有产品运营能力的研发等均可投递；
3、做事积极主动，优秀的组织协调，推进执行能力，思路手段灵活，对用户体验负责；有数据分析，大数据研发，数据产品设计，售前售后等经验之一者，优先考虑；"
"职位描述：
        
        职位职责：
1、广告各类在线业务的离线数据加工与在线数据服务开发与维护；
2、数据服务接口及产品需求研发迭代，代码review、bug修复及日常服务运维；
3、针对海量数据处理和查询需求，设计适应业务变化的合理的多维数据分析系统架构，满足多样性的需求；
4、海量日志清洗加工，并抽象出可以多业务复用的数据模型。

职位要求：
1、计算机相关专业本科及以上学历，熟悉Hadoop架构和工作原理，精通MapReduce编程；精通Hive，有HQL优化经验；
2、熟悉JAVA，python等多种编程技术，编程能力强，有web服务开发经验，具备独立完成模块开发能力；
3、理解基本的设计模式，能将业务需求快速理解成技术需求；
4、熟练使用Mysql，熟练使用ElasticSearch、Druid者优先；熟悉其原理者优先；
5、善于沟通，工作积极主动，责任心强，具备良好的团队协作能力；
6、具备良好的问题分析与解决能力，有较强学习能力和逻辑思维能力。

额外加分项:：
Github等开源社区贡献者；
具备大规模分布式服务设计能力和经验。"
"职位描述：
        
        职位职责：
1、负责广告业务平台及其相关系统的研发；
2、负责现有系统的问题分析和改进，提高系统性能，保证系统稳定性；
3、持续改进系统架构、核心算法或者核心技术等，保证系统高性能、高可用性和高可扩展性；
4、新技术预研，完成项目的选型和设计，难点公关。

职位要求：
1、本科及以上学历，一年以上大数据系统开发经验；
2、熟悉python语言， 熟练使用Linux；
3、对常用的redis、kafka等工具系统有一定的了解；
4、有大数据集、分布式计算工具(Hadoop，Spark，Hive，Storm, ES)等应用开发经验优先；
5、有良好的团队合作精神，较强的沟通能力；
6、愿意深入了解业务知识，并能敏锐的发现业务痛点；
7、有品牌广告系统、DMP、舆情、指数平台方向开发经验者优先。"
"职位描述：
        
        职位职责：
1、研发业界领先的大数据计算引擎，服务于今日头条全公司的数十个用户产品线；
2、面向超大规模数据问题，每天千亿增量的用户行为数据，秒级处理PB级别的数据计算；
3、善于理解和抽象业务问题，支撑多样的海量数据分析场景。

职位要求：
1、强悍的系统设计&编码能力，追求优雅的设计和优秀的代码质量，高标准，快速行动；
2、对Hive/Kylin/Presto/Spark/Tez/Impala 的一项或多项有深入研究者优先；
3、有PB规模的数据处理经验者优先/4、开源项目commiter或贡献过patch 者优先，请在简历上说明。"
"职位描述：
        
        职位职责：
1、研发业界领先的大数据计算引擎，服务于今日头条全公司的数十个用户产品线；
2、面向超大规模数据问题，每天千亿增量的用户行为数据，秒级处理PB级别的数据计算；
3、善于理解和抽象业务问题，支撑多样的海量数据分析场景。

职位要求：
1、强悍的系统设计&编码能力，追求优雅的设计和优秀的代码质量，高标准，快速行动；
2、对Hive/Kylin/Presto/Spark/Tez/Impala 的一项或多项有深入研究者优先；
3、有PB规模的数据处理经验者优先/4、开源项目commiter或贡献过patch 者优先，请在简历上说明。"
"职位描述：
        
        职位职责：
1、研发业界领先的大数据计算引擎，服务于今日头条全公司的数十个用户产品线；
2、面向超大规模数据问题，每天千亿增量的用户行为数据，秒级处理PB级别的数据计算；
3、善于理解和抽象业务问题，支撑多样的海量数据分析场景。

职位要求：
1、强悍的系统设计&编码能力，追求优雅的设计和优秀的代码质量，高标准，快速行动；
2、对Hive/Kylin/Presto/Spark/Tez/Impala 的一项或多项有深入研究者优先；
3、有PB规模的数据处理经验者优先/4、开源项目commiter或贡献过patch 者优先，请在简历上说明。"
"职位描述：
        
        1、掌握分布式系统原理，对存储、计算、消息队列、集群管理中的一项或多项有深入的理解和认识； ? ?2、强悍的 system 设计&编码能力，追求优雅的设计和优秀的代码质量，高标准，快速行动； ? ?3、思路清晰，具备生产系统快速 trouble-shooting 的经验和能力，擅长分析更深层次的原因；"
"职位描述：
        
        1、掌握分布式系统原理，对存储、计算、消息队列、集群管理中的一项或多项有深入的理解和认识； ? ?2、强悍的 system 设计&编码能力，追求优雅的设计和优秀的代码质量，高标准，快速行动； ? ?3、思路清晰，具备生产系统快速 trouble-shooting 的经验和能力，擅长分析更深层次的原因；"
"职位描述：
        
        职位职责：
1、掌握分布式系统原理，对存储、计算、消息队列、集群管理中的一项或多项有深入的理解和认识；
2、强悍的 system 设计&编码能力，追求优雅的设计和优秀的代码质量，高标准，快速行动；
3、思路清晰，具备生产系统快速 trouble-shooting 的经验和能力，擅长分析更深层次的原因；

职位要求：
1、掌握分布式系统原理，对存储、计算、消息队列、集群管理中的一项或多项有深入的理解和认识；
2、强悍的 system 设计&编码能力，追求优雅的设计和优秀的代码质量，高标准，快速行动；
3、思路清晰，具备生产系统快速 trouble-shooting 的经验和能力，擅长分析更深层次的原因；
4、存储方向：对 HDFS, RocksDB, LevelDB, memcache, redis, MySQL, HBase, Kafka 的一项或多项有经验者优先；
5、计算方向：对 Spark, MapReduce, Storm, OLAP 的一项或多项有经验者优先；
5、集群管理方向：对 YARN, Mesos 的一项或多项有经验者优先；
6、向开源社区贡献过 patch 者优先，请在简历上说明"
"职位描述：
        
        职位职责：
1、掌握分布式系统原理，对存储、计算、消息队列、集群管理中的一项或多项有深入的理解和认识；
2、强悍的 system 设计&编码能力，追求优雅的设计和优秀的代码质量，高标准，快速行动；
3、思路清晰，具备生产系统快速 trouble-shooting 的经验和能力，擅长分析更深层次的原因；

职位要求：
1、掌握分布式系统原理，对存储、计算、消息队列、集群管理中的一项或多项有深入的理解和认识；
2、强悍的 system 设计&编码能力，追求优雅的设计和优秀的代码质量，高标准，快速行动；
3、思路清晰，具备生产系统快速 trouble-shooting 的经验和能力，擅长分析更深层次的原因；
4、存储方向：对 HDFS, RocksDB, LevelDB, memcache, redis, MySQL, HBase, Kafka 的一项或多项有经验者优先；
5、计算方向：对 Spark, MapReduce, Storm, OLAP 的一项或多项有经验者优先；
5、集群管理方向：对 YARN, Mesos 的一项或多项有经验者优先；
6、向开源社区贡献过 patch 者优先，请在简历上说明"
"职位描述：
        
        职位职责：
1、负责字节跳动旗下的用户产品线的数据仓库架构设计、建模和ETL开发；
2、参与数据治理工作，提升数据易用性及数据质量，与数据工具团队紧密合作；
3、理解并合理抽象业务需求，发挥数据价值，与业务团队紧密合作。

职位要求：
1、精通数据仓库实施方法论、深入了解数据仓库体系，并支撑过实际业务场景；
2、具备较强的编码能力，熟悉sql，python，hive，spark，kafka，storm中的多项，有至少TB以上级大数据处理经验；
3、对数据敏感，认真细致，善于从数据中发现疑点；
4、善于沟通，具备优秀的技术与业务结合能力。"
"职位描述：
        
        职位职责：
1、负责今日头条的用户产品线的数据仓库架构设计、建模和ETL开发；
2、参与数据治理工作，提升数据易用性及数据质量，与数据工具团队紧密合作；
3、理解并合理抽象业务需求，发挥数据价值，与业务团队紧密合作。

职位要求：
1、精通数据仓库实施方法论、深入了解数据仓库体系，并支撑过实际业务场景；
2、具备较强的编码能力，熟悉sql，python，hive，spark，kafka，storm中的多项，有至少TB以上级大数据处理经验；
3、对数据敏感，认真细致，善于从数据中发现疑点；
4、善于沟通，具备优秀的技术与业务结合能力。"
"职位描述：
        
        职位职责：
1、负责头条垂直项目数据平台的建设；
2、负责处理头条垂直项目每日用户行为数据分析和报表生成；
3、为大数据的全生命周期提供服务，覆盖数据产生、传输、建模、统计分析、实验评估、可视化的全流程；
4、构建设计良好的数据流、数据仓库，维持每日数据任务稳定性，降低数据的使用门槛。

职位要求：
1、1年及以上工作经验，计算机相关专业，对新技术有强烈的学习热情；
2、熟练使用C++/Java/python/Go/PHP语言中的一种或者多种，有良好的编程习惯；
3、熟练使用SQL语言，至少熟悉MySQL，Oracle，DB2等常见关系型数据库中的一种；
3、有大数据相关工具/框架经验者优先，e.g. Hadoop, Mapreduce, Hive, Storm, Spark, kylin，scribe, kafka, hbase, canal，sqoop etc。"
"职位描述：
        
        职位职责：
1、面向公司的大数据开发套件产品设计与研发，包括大数据任务建设平台，元数据管理系统，数据质量监控平台，任务运维平台等
2、参与需求调研与用户技术支持
3、追求极致，构建业内领先的数据平台产品

职位要求：
1、精通java/scala语言，包括JVM、类装载、线程、并发、IO资源管理、网络
2、扎实的计算机基础，对技术有热情，愿意不断尝试新技术和业务挑战
3、精通SOA架构和微服务架构
4、有 IDE 开发经验者优先考虑
5、熟悉前端技术的全栈开发工程师优先
6、熟悉hadoop ecosystem常用开源框架者优先，例如hadoop/flink/spark等"
"职位描述：
        
        职位职责：
1、面向公司的大数据开发套件产品设计与研发，包括大数据任务建设平台，元数据管理系统，数据质量监控平台，任务运维平台等
2、参与需求调研与用户技术支持
3、追求极致，构建业内领先的数据平台产品

职位要求：
1、精通java/scala语言，包括JVM、类装载、线程、并发、IO资源管理、网络
2、扎实的计算机基础，对技术有热情，愿意不断尝试新技术和业务挑战
3、精通SOA架构和微服务架构
4、有 IDE 开发经验者优先考虑
5、熟悉前端技术的全栈开发工程师优先
6、熟悉hadoop ecosystem常用开源框架者优先，例如hadoop/flink/spark等"
"职位描述：
        
        职位描述：
1.负责创新工具核心业务模块数据仓库的构建2.负责数据模型的设计，ETL实施、ETL性能优化、ETL数据监控以及一系列技术问题的解决3.负责构建用户主题、各业务线主题、推荐主题、企业BI门户系统4.负责全产品线数据字典维护，提升数据资产质量。
职位要求：
1.计算机、数学相关专业本科及以上学历，三年以上大数据开发工作经验，数据挖掘和BI分析领域优先；2.熟练掌握Hive/SQL，熟悉Spark/Map-Reduce/MPI分布式计算框架，熟悉大数据的离线和实时处理，可以进行海量数据模型的设计、开发。3.有产品sense，主动思考基于业务场景下的数据体系建设，而不单单只会做执行。4.工作认真，负责，良好的团队合作精神和解决问题分析能力。钻研技术克服困难，勇于挑战5.有分析经验的优先"
"职位描述：
        
        职位职责：
1、负责数据收集、清洗和规约等工作；
2、提供面向业务的数据服务，完成数据指标的统计、多维分析和展现；
3、根据业务和产品情况，抽象业务逻辑，搭建和开发大数据平台。

职位要求：
1、统招本科或以上学历；
2、精通SQL，有较好的SQL性能调优经验，了解Hive/MySQL的基本原理和调优策略
3、熟悉常用的数据挖掘、分析的工具和方法，熟悉linux平台，精通Shell/Python/PHP等脚本语言的一种或多种，编码基本功扎实 ；
4、精通Java开发，熟悉大数据处理相关技术，有Hadoop开发经验，掌握MapReduce。"
"职位描述：
        
        职位职责：
1、基于海量数据，支持业务对数据的分析和使用； 
2、支持业务处理数据的流式处理、分析客户行为等。

职位要求：
1、精通至少一门编程语言，熟练运用各种常用算法和数据结构，有独立的实现能力 ； 
2、熟悉常用的开源组件：Hadoop/Hive/Spark/Storm，并了解其特性和使用场景优先；
3、熟悉机器学习、数据挖掘、数据分析、分布式计算至少某一方面，有较深的理论研究和实践经验优先； 
4、数据分析、推荐、机器学习、数据挖掘相关的开发工作优先。"
"职位描述：
        
        职位职责：
1、负责数据收集、清洗和规约等工作；
2、提供面向业务的数据服务，完成数据指标的统计、多维分析和展现；
3、根据业务和产品情况，抽象业务逻辑，搭建和开发大数据平台。

职位要求：
1、统招本科或以上学历；
2、精通SQL，有较好的SQL性能调优经验，了解Hive/MySQL的基本原理和调优策略
3、熟悉常用的数据挖掘、分析的工具和方法，熟悉linux平台，精通Shell/Python/PHP等脚本语言的一种或多种，编码基本功扎实 ；
4、精通Java开发，熟悉大数据处理相关技术，有Hadoop开发经验，掌握MapReduce。"
"职位描述：
        
        职位职责：
1、基于海量数据，支持业务对数据的分析和使用：???
2、支持业务处理数据的流式处理、分析用户行为等；
3、通过海量数据，分析与挖掘各种潜在关联，从而不断优化火力补贴效果，提高投入产出比。

职位要求：
1、计算机相关专业，本科及以上学历；??
2、有扎实的编程能力，有优秀的设计和代码品位，对解决具有挑战性问题充满激情；??????
3、精通至少一门编程语言，熟练运用各种常用算法和数据结构，有独立的实现能力 ；???
4、熟悉常用的开源组件：Hadoop/Hive/Spark/Storm，并了解其特性和使用场景优先；
5、熟悉机器学习、数据挖掘、数据分析、分布式计算至少某一方面，有较深的理论研究和实践经验优先；?
6、优秀的沟通理解能力，能快速理解业务，用数据解读业务；???
7、数据分析、推荐、机器学习、数据挖掘相关的开发工作优先。"
"职位描述：
        
        职位职责：
1、负责财经业务的数据平台研发，建设数据集市；
2、负责金融BI指标体系、数据模型的构建；
3、制定统一的数据规范，负责数据质量，元数据的监控，整合；
4、理解并合理抽象不同业务需求，做较通用和系统性的支持；

职位要求：
1、本科及以上学历，计算机、通信等相关专业；
2、熟悉数据库、数据仓库，有海量数据处理经验，熟练使用mysql和hsql
3、有扎实的编程能力, 熟悉python，hadoop, hive，spark等；
4、对数据敏感，善于从数据中发现疑点；
5、有金融背景或者金融数据仓库建设者优先；
6、积极乐观，责任心强，工作认真细致，有良好的团队沟通和协作能力。"
"职位描述：
        
        职位职责：
1、负责ElasticSearch/Druid平台化建设相关设计、研发、运维工作；
2、深入理解ElasticSearch或Druid的技术原理、架构和使用场景，为业务方提供技术指导。

职位要求：
1、JAVA基础扎实，熟悉ElasticSearch或Druid源代码优先；
2、有丰富的数据平台开发或使用经验，能够高效挖掘技术团队需求痛点并提供解决方案；
3、有较强的沟通能力，可以和相关技术业务部门进行有效沟通；
4、善于学习新的知识，有进取心，对解决具有挑战性问题充满激情。"
"职位描述：
        
        职位职责：
1、负责直播端及服务端海量用户行为数据的加工处理，数据洞察驱动业务优化；
2、打造业界领先的大数据平台，支撑数据采集，加工，建模，分析，实验，可视化的全流程；
3、打造业界领先的分布式计算，存储系统，解决大规模生产环境集群可用性和性能优化问题。

职位要求：
1、热爱计算机科学和互联网技术，优秀的编码能力，乐于快速学习和尝试新技术、新工具；
2、对开源大数据系统有相关经验者优先，包括但不限于Hadoop/Spark/Hive/Flink/Kafka/Druid 等；?
3、对数据敏感，掌握量化分析方法，善于从数据中发现问题者优先。"
"职位描述：
        
        职位职责：
1、负责海量用户行为数据的加工处理，数据洞察驱动业务增长；
2、打造业界领先的大数据平台，支撑数据采集，加工，建模，分析，实验，可视化的全流程；
3、打造业界领先的分布式计算，存储系统，解决大规模生产环境集群可用性和性能优化问题。

职位要求：
1、2019届本科及以上学历应届毕业生，计算机、相关专业；
2、热爱计算机科学和互联网技术，优秀的编码能力，乐于快速学习和尝试新技术、新工具；
3、对开源大数据系统有相关经验者优先，包括但不限于Hadoop/Spark/Hive/Flink/Kafka/Druid 等； 
4、对数据敏感，掌握量化分析方法，善于从数据中发现问题者优先。"
"职位描述：
        
        职位职责：
1、负责海量用户行为数据的加工处理，数据洞察驱动业务增长；
2、打造业界领先的大数据平台，支撑数据采集，加工，建模，分析，实验，可视化的全流程；
3、打造业界领先的分布式计算，存储系统，解决大规模生产环境集群可用性和性能优化问题。

职位要求：
1、2019届本科及以上学历应届毕业生，计算机、相关专业；
2、热爱计算机科学和互联网技术，优秀的编码能力，乐于快速学习和尝试新技术、新工具；
3、对开源大数据系统有相关经验者优先，包括但不限于Hadoop/Spark/Hive/Flink/Kafka/Druid 等； 
4、对数据敏感，掌握量化分析方法，善于从数据中发现问题者优先。"
"职位描述：
        
        职位职责：
1、负责字节跳动海量用户行为数据的处理，在分布式计算平台基础上建立高效、实时的数据 pipeline； 
2、负责推荐系统、广告系统的数据分析，发现模式与规律，为实验解释、系统改进提供数据支持； 
3、负责 Hadoop，Spark 等大数据基础设施和平台的改进，解决大规模生产环境集群可用性和性能优化问题。

职位要求：
1、2019届毕业，本科及以上学历，计算机相关专业；
2、热爱计算机科学和互联网技术，优秀的编码能力，乐于快速学习和尝试新技术、新工具；
3、对数据敏感，掌握量化分析方法，善于从数据中发现问题，提出假设并使用数据进行验证；
4、对至少一项分布式计算平台有使用经验，例如 Hadoop，Spark，Hive，Storm，Kafka 等；
5、有参与开源项目对社区有贡献的经历，有互联网公司实习经历，有大数据处理或用户行为数据分析经验者优先。"
"职位描述：
        
        职位职责：
1、负责数据收集、清洗和规约等工作；
2、提供面向业务的数据服务，完成数据指标的统计、多维分析和展现；
3、根据业务和产品情况，抽象业务逻辑，搭建和开发大数据平台。

职位要求：
1、统招本科或以上学历；
2、精通SQL，有较好的SQL性能调优经验，了解Hive/MySQL的基本原理和调优策略
3、熟悉常用的数据挖掘、分析的工具和方法，熟悉linux平台，精通Shell/Python/PHP等脚本语言的一种或多种，编码基本功扎实 ；
4、精通Java开发，熟悉大数据处理相关技术，有Hadoop开发经验，掌握MapReduce。"
"职位描述：
        
        职位职责：
1、负责基于业务分析需求的数据仓库的架构设计、开发和维护；
2、负责基于Spark/Hadoop的海量数据的处理、分析、统计、挖掘工作；
3、根据需求进行数据处理、查询、统计等工作；
4、作为公司整体业务分析的技术合作伙伴，参与对核心业务问题进行深入分析和数据建模，为公司运营决策、产品方向、销售策略提供数据支持。

职位要求：
1、研究生及以上学历，计算机相关专业优先，掌握扎实的统计学，数据挖掘，机器学习理论基础； 
2、两年以上数据仓库相关工作经验；
3、良好的分析问题及解决问题的能力，良好的沟通意识、团队协作、学习进取精神。"
"职位描述：
        
        职位职责：
1、负责今日头条用户行为大数据的分析、建模和评估；
2、负责abtest实验分析，用户满意度分析，探索新的量化指标，和相关工具的研发。

职位要求：
1、计算机，统计学，应用数学等相关专业本科及以上学历，一年以上互联网数据工作经验；
2、精通python，R，SQL等的一种或多种，有大数据处理经验者优先；
3、热爱数据分析工作、具有高度的数据敏感性与洞察力，高效的团队协作及沟通能力；
4、喜欢挑战开放性问题，能综合运用计算机，统计学，心理学等知识，开创性解决问题。"
"职位描述：
        
        职位职责：
1、负责字节跳动所有产品线风控方向的数据流和相关数据服务；
2、面向超大规模数据问题，每天处理千亿增量的用户行为数据；
3、负责流式数据的实时传递，清洗，转换，计算，并对外提供查询服务；
4、负责相同数据集的批处理功能。

职位要求：
1、有至少TB以上级大数据处理经验，编码能力强悍，具备生产系统快速 trouble-shooting 的经验和能力；
2、熟悉大数据处理工具/框架中的一项或多项，包括但不限于Hadoop, Mapreduce, Hive, Storm, Spark, Druid, kafka, hbase, canal，ES等；
3、对开源社区有过贡献者优先，请在简历上说明。"
"职位描述：
        
        岗位职责：
1、构建数据仓库，设计数据结构存储海量的产品数据，同时用技术手段解决灵活的，多层级的数据查询需求；
2、构建和优化数据处理流程，支撑处理海量数据规模；
3、参与大数据平台构建，大数据相关项目的研发工作；
4、支持产品、运营和销售对业务上相关的数据需求，提供数据驱动和决策。

岗位要求：
1、1年以上Scala/Java 大数据开发经验，计算机相关专业本科及以上学历；
2、熟悉 HDFS，Yarn，Zookeeper，Flume，Kafka，MapReduce，Spark 等分布式相关的技术及组件；
3、熟练运用Spark Streaming，Flink等实时计算框架，并有实际项目经验
4、熟悉 NoSQL（HBase/Redis），有过 HBase/Hive 调优优先；
5、熟悉Linux环境及脚本开发(shell或python)
6、很强的自我驱动力、结果导向并极具责任感，有良好沟通能力和团队协作精神。"
"职位描述：
        
        大数据开发经理? 45-75K/M
岗位职责：
1、参与计算框架和服务的定制和改进，为公司批处理和流式计算能力提供支撑；
2、基于业务需求和应用场景，设计和实现公司大数据相关产品；
3、负责设计，开发，优化数据接入、数据存储、数据计算服务框架；
4、负责优化分布式框架，解决大并发下的各种问题；
5、为公司所有业务线提供数据支持和服务。

任职要求：
1、本科或以上学历，计算机专业，5年以上大数据项目开发经验；
2、具有Hadoop/Spark开发与应用经验，有较大规模的项目经历并应用在生产环境；
3、具有独立完成从方案选型设计到原型系统开发实现的能力；
4、有较好的团队管理和沟通能力，较强的责任心和事业心。"
"职位描述：
        
        职位描述：
岗位职责：
1、全面了解互联网行业数据，结合公司实际业务情况进行技术选型及大数据底层架构的战略规划；
2、参与大数据基础架构和技术体系的规划建设，包括数据采集平台、数据资产管理与治理平台、数据质量及稳定性保障体系、数据处理智能化和自动化体系的建设；
3、负责架构优化及系统关键模块的设计开发，协助团队解决开发过程中的技术难题；
4、研究未来数据模型和计算框架的创新与落地，包括但不限于以下领域：大规模数据实时化、研发模式敏捷化、数据计算框架轻量化、数据模型组织方式业务化等方面,参与制定并实践团队的技术发展路线。

任职要求：
1、有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关开发经验，有Spark/Storm的开发经验尤佳；
2、较为丰富的数据仓库及数据平台的架构经验，精通数据仓库建模及ETL设计开发；有较为系统的海量数据性能处理经验；在大数据资产管理与治理有一定成功产品化经验；
3、具备大型互联网日志采集系统设计或架构经验，具备较扎实的理论基础和工程能力，并且有基于日志对用户行为进行分析和画像构建的经验；
4、算法基础扎实，熟悉常见的数据结构，深入理解分布式算法，具备机器学习算法能力尤佳。"
"职位描述：
        
        职位职责
1、大数据平台开发, 满足日益增长的数据计算需求, 提高小伙伴的工作效率。
2、离线计算/实时计算开发, 为线上业务提供数据支撑
职位要求
1、扎实的计算机基础, 至少3年大数据平台相关经验
2、熟练掌握如下最少一门语言: Java/Go/Python
3、熟练掌握如下最少一个组件:Hadoop/Spark/Kafka/Presto 等, 具备问题定位/解决能力, 有 HBase/Cassandra 等分布式存储相关经验加分, 有开源社区贡献的加分, AWS/阿里云 相关经验优先
4、乐于沟通, 敢于担当, 具备良好的沟通和团队协作能力

PS，大数据开发，数据平台，数据仓库方向接可，尤需实时计算方向。"
"职位描述：
        
        职位描述：
1、数据分析平台的设计和开发，为数据分析和运营等人员搭建友好高效的数据产品；
2、核心实时指标、离线指标、图计算指标开发；
3、其它大数据平台技术相关的技术工作。

岗位要求：
1、熟悉分布式系统的基础理论知识，了解大数据处理的常用算法；
2、熟悉Java或Scala语言，有扎实的开发功底；
3、熟悉Spark/Hadoop，Hbase，Storm，Kafka等大数据处理框架；
4、有图计算经验和大数据平台开发经验优先。"
"职位描述：
        
        岗位职责：
1、支持业务需求，基于海量数据实现数据采集、清洗入库、统计计算，包括运营报表/仪表盘开发；2、协助策略落地实现，提供高可靠数据服务；3、对业务和数据进行梳理，设计大数据模型，构建相关应用，用数据推动业务发展；4、主要负责流式实时计算分析和离线数据统计分析。
任职要求：
1、本科及以上学历，3年及以上大数据相关工作经验；2、具备成熟的系统设计架构能力，丰富的高并发、分布式的系统设计经验；3、熟悉业界先进的大数据生态组件（MR/Spark/HBase/ElasticSearch/ClickHouse/Hadoop/Hive），有成熟的系统设计应用经验；4、熟悉Mysql/Redis/MongDB等系统原理机制以及线上应用经验原则；5、对新技术保持求知欲，熟悉数据采集、清洗入库、统计计算、Web展示核心要点，可实现指标计算需求；6、具有优秀的代码治理经验，良好的表达能力和团队协作精神；7、具有顽强的拼搏精神、奉献精神、敬业精神,有英文读写和交流能力者优先。"
"职位描述：
        
        岗位职责:

1、 负责开发并维护各数据系统；2、负责新数据挖掘与数据产品开发，例如数据ETL系统，流处理架构；3、支持运营业务需求，提供数据驱动和决策的能力； 
任职资格:

1、2年以上大数据系统/平台相关工作经验，能够完成数据模型的设计与开发；2、熟悉大数据相关技术: Kafka/Hadoop/Spark/Flink/MapReduce/Hive/Sqoop等；3、熟悉Linux系统，熟悉Golang/Python/JavadeJs等至少一门语言；4、 熟悉各类型存储，如Mysql/MongoDB/Elasticsearch/Redis/GFS/HBase/HDFS等；5、有数据挖掘经验。加分项1、 熟悉电竞(DOTA2/CS:GO/LOL等)；2、 熟悉TCP/IP, HTTP等协议，并有设计与开发API经验。"
"职位描述：
        
        岗位职责:?
1、 负责开发并维护各数据系统；2、负责新数据挖掘与数据产品开发，例如数据ETL系统，流处理架构；3、支持运营业务需求，提供数据驱动和决策的能力。
任职资格:?1、熟悉大数据相关技术: Kafka/Hadoop/Spark/Flink/MapReduce/Hive/Sqoop等；2、熟悉Linux系统，熟悉Golang/Python/JavadeJs等至少一门语言；3、 熟悉各类型存储，如Mysql/MongoDB/Elasticsearch/Redis/GFS/HBase/HDFS等；4、有数据挖掘经验。"
"职位描述：
        
        【岗位职责】
1、负责数据产品线团队的搭建、管理和绩效考核。
2、负责设计、建立、数据挖掘、分析的产品架构和运营模式；
3、指导产品的研发管理和迭代计划，协调开发进度，推动数据平台的建设；
4、组织实现公司内部和外部对大数据服务的需求，和相关产品推广、咨询、支持、培训等工作；
5、跟踪大数据应用动向，创新产品应用；
6、提出产品提升建议与发展方向。

【任职要求】
1、计算机、数学相关专业，本科或硕士以上学历（硕士、博士）。
2、8年以上分布式系统、大数据相关工作经验，5年以上团队管理经验。
3、熟悉Hadoop、Hive、HBase等开源项目和社区，至少3年以上产品项目应用研发经验。
4、熟悉Hadoop/Spark等系统，有hands-on的产品设计、性能调优、开发经验。有MongoDB、Hadoop/Hbase/Cassandra/Storm/Spark/Hive?等多系统的开发经验者优先。
5、有以下其中之一者，更加优先：
(1)精通或者熟悉数据库设计，熟悉Oracle／MySQL/MySQL?集群等数据库，并具有较好的?SQL?编写及优化能力；熟悉NoSQL?者优先。?
(2)具有较强的数据挖掘、优化理论、机器学习的理论基础和实际项目经验，精通数据分析与各种算法与模型，例如分类、聚类、Boosting、SVM、神经网络中的至少一种。?
(3)?极强的系统设计和系统架构能力或者项目经验；必要的产品管理意识。
(4)对分布式系统和云计算尤其是互联网云计算要有深刻的理解，最好有相关技术经验。"
"职位描述：
        
        【岗位职责】
1、负责海量数据的分析处理和数据统计系统的研发；
2、参与个性化推荐系统的开发和优化；
3、针对海量用户行为数据进行数据挖掘和构建模型。

【岗位要求】
1、本科及以上学历，计算机等相关专业；
2、精通Linux操作系统下Python开发，具备shell脚本开发能力；
3、有良好的编程习惯，能够撰写良好的技术文档；
4、有较强的分析问题与独立解决问题的能力，良好的沟通能力及团队合作精神；
5、有Spark、Hadoop、HBase、Hive等经验优先；
6、有文本挖掘、用户画像、自然语言处理、推荐系统、机器学习等研究经历或工作经历优先；
7、有大规模高并发分布式系统开发经验优先；"
"职位描述：
        
        岗位职责：
1、负责公司负责大数据服务平台产品的规划和设计，保证架构的可持续性发展，并具备对需求变更的应变能力；
2、负责大数据平台核心技术问题的攻关，解决项目应用过程中的技术难题；
3、负责新型大数据技术的引入评估和落地；
4、负责海量数据处理，业务数据体系的设计、数据统计、分析及数据建模；
5、对开发团队进行技术指导和培训。
任职资格：
1、计算机相关专业本科以上学历，8年以上工作经验，4年以上大数据相关经验；
2、具有扎实的大数据和数据仓库的理论功底，负责过大数据平台或数据仓库设计与开发；
3、对基于Hadoop的大数据体系有深入理解，具备相关产品（Hadoop、 Hive、 HBase、 Spark、 Storm、 Flume、Kafka、K8S、ES等）项目应用研发经验，有Hadoop、Spark集群搭建和管理经验，读过hadoop、Spark源码；
4、算法基础扎实，熟悉常见的数据结构，深入理解分布式算法和以上提到的分布式系统；
5、必须具有实际大数据相关产品或项目研发经验能力，具有较强的设计开发能力；
6、具有团队管理经验。
7、有汽车金融领域数据经验、大数据风控或征信经验者优先考虑。"
"职位描述：
        
        岗位职责：

1、负责开发大数据工具，如报表平台、多维度分析工具、ETL平台的研发；

2、负责数据仓库的建设，数据接入、数据建模、数据服务等工作；

3、负责大数据平台核心技术问题的攻关，解决项目应用过程中的技术难题；



任职资格：

1、计算机相关专业本科以上学历，3年以上大数据相关经验；

2、具有扎实的大数据和数据仓库的理论功底，负责过大数据平台或数据仓库设计与开发；

3、对基于Hadoop的大数据体系有深入理解，具备相关产品（Hadoop、 Hive、 HBase、 Spark、 Storm、 Flume、Kafka、K8S、ES等）项目应用研发经验；

4、算法基础扎实，熟悉常见的数据结构，深入理解分布式算法和以上提到的分布式系统；

5、具有实际大数据相关产品或项目研发经验能力，具有较强的设计开发能力；

6、有汽车金融领域数据经验、大数据风控或征信经验者优先考虑。"
"职位描述：
        
        职位职责：?
1、负责教育用户的数据仓库架构设计、建模和ETL开发，构建可扩展的数据仓库和分析解决方案；?
2、负责分析和解释产品试验，市场运营活动等结果，为产品改进，推广等提供数据支持；?
3、负责建立用户数据分析模型，针对用户行为进行数据监控和统计，发现用户行为模式与规律，为改进推荐系统提供支持。?
职位要求：?
1、热爱计算机科学和互联网技术，乐于快速学习和尝试新技术、新工具；?
2、具备强悍的编码能力，熟练使用 SQL，熟悉 Python或R语言的优先；?
3、优秀的分析问题和解决问题的能力，对解决具有挑战性问题充满激情；?
4、熟悉至少一项分布式计算平台，例如Hadoop，Spark，Hive，Storm，Kafka 等；?
5、有参与开源项目对社区有贡献的经历，有大数据处理或用户行为数据分析经验者优先。"
"职位描述：
        
        岗位职责:
1、负责直播云上亿级别流量日志实时及离线处理、流量计费数据开发工作；
2、根据具体业务进行数据建模，重难点模块的功能设计和难点攻坚；
3、负责核心系统性能调优；
4、对数据体系建设提供架构导引、技术监督和风险预判。

岗位要求:
1、具备数学、计算机科学或相关专业领域大学本科及以上学历，3~5年工作经验；
2、熟悉Linux环境，熟悉常用的命令；
3、熟练使用ELK/FLUME/Filebeat等相关工具，并了解各项参数意义；
4、熟练Scala语言、熟悉Hadoop生态环境，掌握Spark SQL/Spark Streaming/Flink开发经验；
5、有比较丰富的海量日志实时及离线处理经验；
6、有较强的业务理解能力和领域建模能力，良好的模型抽象能力沟通能力和技术文档撰写能力。"
"职位描述：
        
        岗位职责：1、大数据平台的维护；2、基于大数据平台进行周边功能开发。任职要求：1、1年以上Java开发工作经验；2、熟练掌握java，仔细阅读过jdk源码尤佳； 3、具有hadoop或者spark的开发经验；4、熟悉Linux环境，掌握Linux常用命令，操作系统配置；5、做事积极主动，有较强的学习能力，理解能力，沟通能力，表达能力"
"职位描述：
        
        岗位职责：
-负责业务报表的开发和维护，并能及时响应业务部门数据分析的要求
-运用Python或者SQL编写脚本,实现跨库数据整合,提高数据拉取效率，支持业务部门的常规抽取或临时数据分析需求;
-基于Python开发报表的定时邮件发送系统;
-维护网站网页的埋点方案，针对不同的渠道和业务需求更新埋点系统
-设计、开发和维护公司内部数据系统,包括数据报表可视化,实时数据拉取等;
-维护用户画像标签体系,为营销推广和投放提供数据支持;
-维护Hadoop集群，进行大数据平台开发。
?
任职要求：
本科以上学历，计算机，统计，信息或者软件工程等相关专业
3年以上相关工作经验
熟悉Hadoop平台，数据库Hbase，MySQL，HDFS，InfluxDB，MongoDB
熟悉Python，Spark开发语言
熟练其他工具Kafaka，Flume，Hive，Hue，Excel
了解数据展示工具Zepplin，SuperSet
有大数据的技术管理开发经验
对数据敏感，能够发现数据的内在价值以及业务的相关性
认同公司发展，有创业精神，勇于开拓，能够承受工作压力"
"职位描述：
        
        工作内容
1. 参与需求调研与业务沟通，负责数据指标体系的建设
2. 负责数据仓库模型（实时与离线）的设计、开发与维护
3. 基于大数据平台（Hadoop/Spark/Flink），设计与实现ETL流程
4. 负责数据管理策略，保障数据的正确性、有效性以及安全性
5. 管理数据仓库与指标集市的口径与质量，提供一致性解释
岗位要求
1、大学本科以及上学历，有5年以数据仓库项目工作经验，3年以上编程开发经验；
2. 精通关系型数据与非关系型数据库设计理论，数据仓库的架构与设计理论，数据项目实施理论
3、熟练掌握SQL/Python/Java中的至少两种编程语言，熟悉Hive/Spark/Flink/HBase/Kafka至少3种组件
4. 能熟练应用至少一种主流数据库（Oracle/Greenplum/MySQL等)，有TB级数据处理经验
5. 熟悉多种ETL工具，能对ETL流程进行设计和优化
6、主导或全程参与过大型项目，具有较强的组织协调能力及沟通交流能力
7. 学习能力强，拥有优秀的逻辑思维能力，强烈的责任心和团队合作精神"
"职位描述：
        
        工作内容：
参与智能机器人开发工作
岗位要求：
1.熟悉Oracle数据库及MPP架构数据库
2.熟悉BI、ETL、SAS、NoSQL、据仓库设计经验
3.有深入使用开源项目、机器学习经验者优先
4.至少熟练掌握Java/Python一门语言，熟悉Linux操作系统
5.积极主动、学习能力强、沟通能力强、肯吃苦耐劳"
"职位描述：
        
        工作内容
1.负责大数据平台的设计、开发与维护；
2.参与数据运营平台的需求与设计过程，负责各子系统的开发实施
3.解决数据平台的技术问题，推进技术平台的技术演化
4.负责大数据平台技术组件调优与维护
岗位要求
1.大学本科及以上学历，5年工作经验，3年以上大数据平台开发经验
2.熟悉Hadoop技术生态体系，有Spark/Hive/Flink/HBase等组件的应用和调优经验
3.熟悉Java技术体系，掌握多线程、网络协议及服务器编程能力
4.有良好的编码习惯及文档习惯，有独立承担系统设计的经验
5.主导或全程参与过大型项目，具有较强的组织协调能力及沟通交流能力 ?
6.学习能力强，拥有优秀的逻辑思维能力，强烈的责任心和团队合作精神"
"职位描述：
        
        岗位描述:
1.?根据公司的海量数据，为大数据营销、BI提供数据支持
2.?对数据处理的需求场景进行抽象，形成自动化工具，提升工作效率
3.?设计和实现对行为，交易等不同类型数据的海量存储，计算，挖掘的整体方案
?
岗位要求:
1.?熟悉hadoop生态系统（HDFS、MR、SPARK、HIVE）或者熟悉ELK生态系统。
2.?有数据处理的经验，对于数据建模，数据分析挖掘有兴趣
3.?熟练掌握PYTHON/JAVA/GO其中至少一种以上
4.?熟悉mysql数据库，熟练使用SQL
5.?熟悉数据结构，算法
?
具有以下经验者优先考虑：
1.?具有互联网金融-大数据方向经验者优先
2.?有大数据平台开发经验者优先考虑 ，
3.?有丰富后端开发经验，对于数据工作有热情的优先"
"职位描述：
        
        岗位职责： ?负责游戏大数据平台的建设：1.负责大数据的建设和发展。2.负责整体ETL设计和开发以及重点问题处理、及核心复杂业务代码的设计和研发。3、负责Hadoop/Spark/图数据库/流处理/搜索引擎产品的设计和开发。4、负责Hadoop/Spark生态圈组件维护。岗位要求：1、计算机或数学相关专业，有3年以上的工作经验，熟悉数据仓库相关知识和理论 。2、有分布式软件开发经验，熟悉Hadoop/Spark/HBase/Hive/Flink/Elasticsearch中至少几个组件。3、精通Hbase、hive，熟悉Hql的性能优化方法，熟悉MySql数据库，熟悉sql的性能优化方法。4、熟悉数据仓库ETL开发和流程，能根据业务需求设计整体的ETL方案和开发。 5、熟悉java或scala语言，对分布式、网络、高并发有自己的理解，对中型java项目有架构能力,具备linux环境开发经验。6、有效沟通能力强，乐观开朗，思路清晰，解决问题能力强。"
"职位描述：
        
        岗位职责：
1、?负责公司大数据平台的建设与维护工作；
2、?负责构建Spark/HDFS大数据处理架构，不断研究、改进分布式微服务架构的功能、性能等问题；
3、?跨部门/团队协作，协同分析并解决各类大数据平台相关的运行或数据问题。
?
职位要求：
1、?计算机、数学相关专业本科以上学历；1年以上大数据相关经验；
2、?至少掌握Java/Scala/Python其中一种语言；
3、?有大数据分布式计算平台开发经验,熟悉Hadoop,?Spark，MapReduce，Hive等原理及应用；
4、?熟悉linux?或macOS开发环境，熟悉linux系统基本操作，能编写shell或python脚本；
5、?至少掌握一种大数据存储相关数据库，如：MongoDB、Cassandra、hbase；了解elasticsearch全文检索引擎的优先考虑；
6、?工作认真、负责、仔细，有良好的团队合作精神，良好的分析能力、沟通技巧。"
"职位描述：
        
        1. More than 5 years working experience in development of .Net or JAVA technology stack;
2. At least 2 years of experience in cloud application and services deployment and development with AWS or Azure;
3. Experience in restful API or Web Services development;
4. At least one project experience with Micro Services architecture, Experienced with Docker or k8s will be a plus;?
5. Proven solid project experience in CI/CD to support automatic deployment? in Azure or AWS platform;
6. Knowledge and working experience on varies database such as Oracle, MSSQL, MySql; Experience in redis development; Experience in noSQL such as mongoDB, HBase is a plus;
7. Good software engineering knowledge and good communication skills, customer awareness and teamwork spirit;
8. Good capacity in analyzing and solving problem, such as security and performance issue;
9. Good oral and written communication skills in English."
"职位描述：
        
        1. More than 5 years working experience in development of .Net or JAVA technology stack;
2. At least 2 years of experience in cloud application and services deployment and development with AWS or Azure;
3. Experience in restful API or Web Services development;
4. At least one project experience with Micro Services architecture, Experienced with Docker or k8s will be a plus;?
5. Proven solid project experience in CI/CD to support automatic deployment? in Azure or AWS platform;
6. Knowledge and working experience on varies database such as Oracle, MSSQL, MySql; Experience in redis development; Experience in noSQL such as mongoDB, HBase is a plus;
7. Good software engineering knowledge and good communication skills, customer awareness and teamwork spirit;
8. Good capacity in analyzing and solving problem, such as security and performance issue;
9. Good oral and written communication skills in English."
"职位描述：
        
        1. More than 1 year working experience in development of .Net or JAVA technology stack.
2. Participant to an actual project with cloud application and services deployment and development, such as AWS, Azure, etc.
3. Experience in restful API or Web Services development.
4. Knowledge and working experience on RDMS database such as Oracle, MSSQL, MySql.
5. Work experience with Git version control tool;
6. Experience with major CI/CD technologies like Jenkins;
7. Good capacity in analyzing and solving problem, such as security and performance issue;
8. Good communication skills and teamwork spirit;"
"职位描述：
        
        1. More than 1 year working experience in development of .Net or JAVA technology stack.
2. Participant to an actual project with cloud application and services deployment and development, such as AWS, Azure, etc.
3. Experience in restful API or Web Services development.
4. Knowledge and working experience on RDMS database such as Oracle, MSSQL, MySql.
5. Work experience with Git version control tool;
6. Experience with major CI/CD technologies like Jenkins;
7. Good capacity in analyzing and solving problem, such as security and performance issue;
8. Good communication skills and teamwork spirit;"
"职位描述：
        
        职位描述：1. 完善和优化现有实时流计算系统和存储系统，编写核心开发框架；
2. 善于发现系统的性能瓶颈、设计缺陷，提出改进方案并实施；
3. 对现有系统进行宏观的思考，规划形成统一的框架、平台或组件；
4. 能够与产品经理、管理团队进行良好的沟通合作，按时保质保量完成开发任务。任职要求：1. 计算机科学或相关技术学科的学士、硕士学位（或同等学历）；
2. Java相关开发经验3年以上，熟悉多线程，高并发处理，有实际项目开发经验； 同时熟悉Python/Scala更佳
3. 精通分布式数据处理底层技术，包括但不限于：hadoop/Flink/Spark/elasticsearch/hbase/kafka/flume等，用过mysql，redis，hbase等开源存储，懂druid.io佳；
4. 熟悉ETL流程，使用过Hive，Impala处理数据作业， 有Kudu经验者更佳
5. 能够主动去分析数据，发现数据异常，不符合业务逻辑的问题，并推动解决
6. 具有强烈的责任心，良好的沟通、学习能力，良好的团队合作意识，勇于接受技术挑战；"
"职位描述：
        
        岗位描述:
1. 根据360金融业务和集团的海量数据，为风控、BI提供数据支持；
2. 对数据处理的需求场景进行抽象，形成自动化工具，提升工作效率；
3. 基于日常的需求场景，构建安全、高效、稳定的大数据平台，为业务提供更有效的数据支撑

岗位要求:
1.属性Linux操作系统，熟悉Shell编程语言；
2.大数据处理经验丰富，熟悉hadoop map/reduce编程；有Hbase、Spark、Storm的应用开发经验；
3.熟悉其它分布式存储相关技术，包括HDFS，Hive、Redis、mongodb、 Flume、Kafaka、Sqoop、Zookeeper、ElasticSearch等。

具有以下经验者优先考虑：
1. 具有海量数据调优、数据倾斜调优经验者优先考虑；
2. 有大数据平台开发经验者优先考虑；
3. 具有SQL优化经验优先考虑；
4. 熟悉REDIS使用的优先考虑。"
"职位描述：
        
        岗位描述:
1. 根据360金融业务和集团的海量数据，为风控、BI提供数据支持
2. 对数据处理的需求场景进行抽象，形成自动化工具，提升工作效率
3. 基于日常的需求场景，构建安全、高效、稳定的大数据平台，为业务提供更有效的数据支撑

岗位要求:
1.属性Linux操作系统，熟悉Shell编程语言
2.大数据处理经验丰富，熟悉hadoop map/reduce编程；有Hbase、Spark、Storm的应用开发经验
3.熟悉其它分布式存储相关技术，包括HDFS，Hive、Redis、mongodb、 Flume、Kafka、Sqoop、Zookeeper、ElasticSearch等

具有以下经验者优先考虑：
1. 具有海量数据调优、数据倾斜调优经验者优先考虑
2. 有大数据平台开发经验者优先考虑
3. 具有SQL优化经验优先考虑
4. 熟悉REDIS使用的优先考虑"
"职位描述：
        
        岗位职责：
1、负责整体大数据平台体系的建设工作。
2、负责带领团队完成基于大数据平台的业务项目的开发、实施和维护工作。
3、负责解决大数据平台建设过程中的技术难点和性能调优工作。
4、负责指导和培训团队成员，共同提升大数据技能。
任职要求：
1、计算机相关专业，至少5年以上大数据开发经验；
2、熟悉大数据、数据仓库，分布式架构技术理论，具有大数据整体系统架构设计和实战经验，，有从无到有建设大数据平台经验者优先；
3、熟悉大数据生态圈技术，不限于Hadoop、HDFS、Hive、HBase、Spark、Storm、Flume、sqoop、kylin等，阅读过底层源码者优先；
4、熟悉至少一种编程语言，Python，Java，Scala等，精通SQL；
5、2年以上技术团队管理经验，有阿里，百度，腾讯，滴滴，美团等互联网大数据工作经验者优先；
6、逻辑思维清晰，具备高度的责任感和良好的沟通协调能力，遇事积极主动。"
"职位描述：
        
        工作职责：1.负责大数据平台的设计与开发实现2.负责大数据应用相关产品需求分析、架构设计以及开发实现3.负责数据产品的服务接口开发和维护岗位要求:1.本科及以上学历，2年及以上大数据相关技术背景2.熟练使用java开发语言3.熟悉spring boot、mbatis、dubbo等开发框架，熟悉前后端分离开发流程4.有大数据平台开发经验，包括但不限于离线开发平台、数据质量中心、元数据管理、数据资产管理等5.熟悉hadoop大数据相关技术体系，包括但不限于Hive、HDFS、Kafka、Flume、Spark等6.具备良好的沟通能力以及团队合作精神"
"职位描述：
        
        岗位要求:
? ? 1. 参与或负责数据中台项目需求分析、数据建模、ETL开发以及项目管理;
? ? 2. 参与或负责内部的大数据产品的开发
? ? 3. 参与或负责大数据相关的海量数据处理技术研究,技术突破,线上性能优化,技术框架的研究;
? ? 4. 能保证每周4天及以上时间工作学习,实习期3个月以上

职位要求：
? ? 1. 本科及以上学历，计算机、数学、统计相关的专业
? ? 2. 熟悉主流的数据库mysql/pg等,有java功底,熟悉springmvc,mybatis等框架
? ? 3. 了解数据仓库理论,比如kimball
? ? 4. 有分词,搜索,排序算法实际经验者优先?
? ? 5. 了解大数据hadoop生态各个组件,对Hadoop/Hbase/Spark/Flink产品熟悉的优先
? ? 6. 具有良好的沟通协作能力，具有较强的分享意愿，对业务有很好的理解能力
? ? 7. 过去有实习经历或者主导过项目的优先"
"职位描述：
        
        
具体要求：
1.熟悉C/Java编程，掌握主流数据结构和基本算法，有良好的编码习惯和技术文档撰写习惯；
2.熟悉电力基本知识和电力数据采集行业业务流程，熟悉采集终端和电表的技术规范、开发流程和调试方
法；
3.熟悉电力能效监测系统技术规范、国网用电信息采集系统技术规范、电能表技术规范和行业标准；
4.熟悉国网用电信息采集系统Q/GDW1376.1-2013通讯协议、Modbus通讯协议，环保HJ212协议；
5.具备良好的工程思维，能根据项目实施场景，解决问题、优化效率；
6.具备电力、环保采集协议开发经验者优先；
7.211、985院校毕业优先考虑。
主要职责：
1.负责376.1-2013通讯协议、Modbus通讯协议、环保HJ212协议的应用开发；
2.负责数据采集软件的开发工作；"
"职位描述：
        
        工作职责：(1)负责软件系统代码的实现，编写代码和开发文档(2)负责进行系统的功能定义,程序设计(3)根据设计文档或需求说明完成代码编写、调试、测试与维护(4)分析并解决软件开发过程中的问题(5)配合技术经理完成相关任务目标任职资格：(1) 计算机相关专业全日制本科及以上学历；(2) 3年以上工作经验，其中至少2年大数据开发经验，熟悉Hadoop大数据处理系统的开发,搭建及部署(3) 精通JAVA语言，熟悉Linux开发环境(4) 熟悉hadoop生态系统项目的使用（hdfs、hive、hbase、spark、zookeeper,yarn等）(5) 学习和理解能力强，具有一定的系统分析能力，及独立解决问题的能力(6) 具备良好的团队合作精神和承受压力的能力(7) 拥有金融类产品开发经验者优先。"
"职位描述：
        
        工作职责1. 开发数据生产、管理流程和框架，监控数据实时性和准确性；2. 开发模型分析数据，为决策提供依据；3. 为策略开发搜集整理并清洗数据，评估类似数据有效性；4. 维护管理数据库，管理数据权限；5. 与公司各部门协调，开发构建数据链配合金融数据需求和结算。

任职要求

  熟悉分布式数据管理和计算方法；
 精通编程，熟悉 python 语言；
 精通数据库操作和维护；
 熟悉数据类统计模型和方法，熟悉数据清洗概念和方法
 掌握前端编程，了解数据展示方法；
 具备编写爬虫的能力；"
"职位描述：
        
        岗位职责：
1、负责大数据平台相关组件的设计和开发工作；
2、负责医疗相关的数据仓库的模型标准制定和数据处理；
3、负责大数据平台的日常管理与维护；
4、参与大数据平台的设计和开发工作；
5、参与研究大数据管理和分析新技术，应用于实际商业场景；
6、完成上级领导交办的其他工作。

任职要求:
1、全日制大学本科及以上学历，计算机或相关专业；
2、具有3年以上大数据平台建设和数据管理的经验；
3、熟悉面向数据仓库和数据集市的数据建模技术和工具；
4、熟悉大数据平台技术的应用和开发，对大数据平台技术有深入的认识和理解；
5、熟悉Spark/HDFS/Hive/Mapreduce/Kylin/HBase等技术，能独自部署开发；
6、熟悉分布式系统概念、架构，有大规模分布式系统设计、实现、部署等经验；
7、思维清晰敏捷，逻辑分析能力强，具有良好的语言和书面表达能力和沟通能力。"
"职位描述：
        
        1、本科2年以上数据开发经验，专科4年以上开发经验，有一定的数据库、ETL等开发经验，具有金融或银行业开发经验人员优先；
2、熟悉Oralce、TereData、GP等数据库；
3、熟悉存储过程开发、ETL开发、BI等应用开发经验；
4、熟悉Perl、Shell等脚本开发；
5、熟悉Linux、Unix等操作系统环境及常用命令；
6、有良好的编码规范与文档编辑能力"
"职位描述：
        
        工作职责:1.主导数据仓库基础架构的建设，以满足数据仓库对时效性、正确性、可扩展性和易用性的要求；2.通过分析相关系统，梳理潜在的数据源和日志清洗需求，并设计合适的、可扩展的数据模型；3.开发并维护数据流水线，挖掘数据中的有价值信息，发挥大数据价值，帮助各个部门用数据驱动决策。任职资格:1.熟练掌握以下一种或多种语言Java/Python/C++/C/；2.计算机等相关专业本科及以上学位；3.熟悉Spark, Hadoop/YARN, Hive, HBase, Storm等技术一种或多种；4.对数据敏感，善于从数据中发现疑点，有用户行为分析经验。"
"职位描述：
        
        友情提示：我想让你更了解我（天眼查）是谁，投递简历前可以先下载【天眼查】app或者浏览网页端进行产品体验。

我们需要你
1.主导数据仓库基础架构的建设，以满足数据仓库对时效性、正确性、可扩展性和易用性的要求；
2.通过分析相关系统，梳理潜在的数据源和日志清洗需求，并设计合适的、可扩展的数据模型；
3.开发并维护数据流水线，挖掘数据中的有价值信息，发挥大数据价值，帮助各个部门用数据驱动决策。

我们希望你
1.熟练掌握以下一种或多种语言：Java/Python/C++/C/；
2.计算机等相关专业本科及以上学位；
3.熟悉Spark, Hadoop/YARN, Hive, HBase, Storm等技术一种或多种；
4.对数据敏感，善于从数据中发现疑点，有用户行为分析经验。


不可错过的福利待遇
1、国家高新科技企业，优秀员工有机会申请《北京市工作居住证》；
2、可为明星员工、硕士以上学历留学生解决北京市户口；
3、全年13+N薪，完善的五险一金；
4、一年两次涨薪机会；
5、大小周休息制，享有加班加时薪资补偿；
6、加班福利：提供多种口味免费晚餐，并享有额外饭补，9点以后打车全额报销，保障你的安全；
7、高标准的年度体检福利；
8、5A级别办公区，地铁出站口即是；
9、行业内领先的技术团队，千万量级用户产品，给你更优质的发展平台；
10、不定期团建活动，加入我们，让你不再孤单！"
"职位描述：
        
        岗位职责：
1、负责数据平台架构、数据处理、java研发；
2、负责集团数据湖(离线、实时)平台建设、开发和维护；
3、负责据开发框架落地，推进质量、采集、智能运维等数据仓库系统平台的落地。
4、负责数据开发团队的开发规范.
任职要求：
1、基础知识扎实，熟悉常用的算法和数据结构，熟练使用;
2、精通Hive及HBase等组件的使用及性能调优;
3、熟悉hadoop生态相关组件及其他数据平台相关产品项目;
4、扎实的编程基础，精通java开发语言，熟悉jvm、缓存，分布式架构、消息中间件等核心技术；
5、具备shell、python等一种脚本语言开发能力。
4、有数据仓库经验以及数据工具平台开发经验优先；
5、熟悉分布式计算优先，或有海量数据应用经验者优先 ；
6、良好的沟通表达能力和团队协作能力，对自己有较高的要求，喜欢有挑战的工作。"
"职位描述：
        
        岗位职责：
云端基础支撑平台数据服务开发：
1. 在已有平台的基础上，配合项目需求进行数据存储、处理、访问服务的集成开发；
2. 配合项目需求参与云平台端数据存储模式、组织形式设计；
3. 在完成数据服务逻辑流程的基础上，进行数据服务系统高并发访问优化。
任职要求：
1.?全日制本科及以上学历，计算机科学与技术相关专业；
2.?具有计算机专业英文技术文档阅读能力，具有借助相关英文技术文档解决技术问题的能力；
3.?为人踏实认真，能为完成工作积极学习补充新知识，有克服工作中遇到困难的拼搏和进取精神；
4. 熟悉高并发数据库设计与开发，熟悉至少一种数据库（如Mysql）的应用于程序编写；
5.?具备C++、Java、Python等编程语言软件开发经验，熟悉Linux操作系统基本使用；
6.?有相关数据服务或机器学习系统开发经验者优先，熟悉容器（如Docker）和容器编排系统（如Kubernetes）及其程序开发者优先。"
"职位描述：
        
        公司注册在上海，目前正在筹备中，职位暂时由其他公司代发。
我们的要求：
硬实力
1. 3年以上大数据工作经验，需要掌握的基本技术和语言相信不用多说，你一定是精通的。
2.能处理亿级数据灵活检索与聚合、亿级明细数据存储等问题，有图计算经验优先。
3. 本科以上学历，计算机、数学相关专业
软实力
1. 不要玻璃心（能妥善处理工作中产生的一些负面情绪）
2. 喜欢沟通，善于协作（能求助，及时暴露问题）
3. 对自己有要求（随时都在思考有没有更好的解决方案）
4. 勤于记录和复盘

你要做的：
1. 基于运营商数据，负责清洗、存储、处理、分析等场景的开发，完成高质量的代码编写。
2. 构建各种算法模型
2. 带新人
3. 会有出差的工作

你能得到的：
1. 还不错的薪资福利待遇（我们会把大多数利润作为绩效回馈给员工）
2. 持续不断的挑战（每天都会有进步，真正的大数据环境）
3. 有不少的优秀合作伙伴和你一起

公司背景:
我们是一家通信和互联网相结合的高科技公司，以移动大数据融合分析引擎为技术核心，构建全域覆盖的数据服务网络，实现在线、实时、真实的数据服务网络闭环分析处理。核心团队由来自华为、通信科研等拥有多年丰富经验的人员组成。（成都的产品研发团队及办公地点还在筹备中）"
"职位描述：
        
        成都的产品研发团队及办公地点还在筹备中，职位暂时代发（面试地点可能会在某咖啡馆）
**我们的要求：**
硬实力
1. 1-3年大数据相关工作经验
2. 有构建海量数据存储、离线/实时计算、实时查询，大数据平台、BI平台等项目的实战经验。有图计算经验优先
3. 本科以上学历，计算机、数学相关专业
软实力
1. 不要玻璃心（能妥善处理工作中产生的一些负面情绪）
2. 喜欢沟通，善于协作（能求助，及时暴露问题）
3. 对自己有要求（随时都在思考有没有更好的解决方案）
4. 勤于记录和复盘

**你要做的：**
1. 基于运营商数据，负责清洗、存储、处理、分析等场景的开发，完成高质量的代码编写。
2. 构建各种算法模型
3. 会有出差的工作

**你能得到的：**
1. 还不错的薪资待遇（我们会把大多数利润作为绩效回馈给员工）
2. 持续不断的挑战（每天都会有进步，真正的大数据环境）
3. 有不少的优秀合作伙伴和你一起

**公司背景:**
我们是一家通信和互联网相结合的高科技公司，以移动大数据融合分析引擎为技术核心，构建全域覆盖的数据服务网络，实现在线、实时、真实的数据服务网络闭环分析处理。核心团队由来自华为、通信科研等拥有多年丰富经验的人员组成。（成都的产品研发团队及办公地点还在筹备中）"
"职位描述：
        
        岗位描述： 
1、负责应用机器学习算法对用户数据进行分析和挖掘，包括但不限于反欺诈策略及模型、授信模型、信用评分模型、催收评分模型等； 
2、负责风控模型的开发，跟进模型上线； 
3、负责模型验证及回测，进行线上模型迭代优化； 
4、对接外部第三方公司，开展数据测试及联合建模； 
岗位要求： 
1、?统计学、数学、计算机等相关专业大学本科以上学历； 
2、?掌握数据挖掘基本方法，有较强的数据敏感度； 
3、?熟悉逻辑回归、决策树、SVM等常用算法的理论及建模流程，有实际项目经验； 
4、?熟悉Python语言，至少熟练使用一种python机器学习库； 
5、?有较强的适应性及压力承受能力，重视团队合作，工作态度积极，责任心强，有较强自我学习能力。"
"职位描述：
        
        职位描述：
1.参与构建数据中心基础设施的设计与开发。
2.参与数据仓库的建设，ETL开发。
3.参与完成数据挖掘、机器学习相关的技术工作。

任职资格:
1、丰富的Java研发经验，精通Java，熟悉Python/Scala中的一种；
2、熟悉Mysql，熟悉网络编程及并发技术，熟悉安全解决方案；
3、有丰富后端服务系统的设计和实现经验，有独立的系统级设计能力；
4、扎实的计算机基础，熟悉常用的数据结构和算法，熟悉Linux系统环境；
5、熟悉大数据技术栈，对Hadoop、Hive、Spark、Hbase、Kafka、ELK等开源组件有使用及优化经验者优先；
6、简单、真诚、负责、主动。"
"职位描述：
        
        岗位职责：
1. 使用大数据技术栈进行POC测试、实施并进行数据迁移；
2. 负责根据需求进行大数据服务的开发和部署；
3. 负责大数据的应用开发及优化。
任职要求：
1.? 理解大数据生态（优先FI HD产品）架构及企业版概览；
2.? 熟悉大数据主要组件特性（HDFS、MapReduce、Hive、HBase、Spark、Kafka、Solr、 Redis、Flink、Flume、Oozie）；
3.? 具备大数据产品现场POC测试与实施的能力；
4.? 具有FusionInsight HD实际项目经验者优先；
5.? 有ETL实施经验者优先；
6.? 四年以上大数据开发经验，其中两年以上大数据实施经验；
7.? 二本以上学历
8.? 取得OCP 或 DB2 证书者优先。"
"职位描述：
        
        【职位描述】
岗位职责
1、 负责数据产品需求分析、数据建模，主导完成相关设计及编码；
2、 完善现有数据产品，优化现有产品数据体系；
3、 深入理解业务需求，能从数据角度推动业务发展，开发相应数据产品及工具
【岗位要求】
1. 计算机、数据等相关专业本科以上学历，工作2年以上；?
2. 熟悉数据仓库和数据集市的框架结构，具备数据仓库与数据集市的架构设计能力；?
3. 精通SQL，熟悉Oracle、MySQL等关系型数据库；
4. 熟悉HiveSQL/MapReduce/Spark等数据开发技术；
5. 有一定的Java/python开发能力，熟悉linux/Shell；
6. 在数据统计、机器学习上有一定基础的优先；
7. 沟通与交流能力强，业务理解能力强，具有一定的业务建模能力"
"职位描述：
        
        岗位职责：
1、参与大数据平台的建设及开发
2、负责产品/项目的需求调研、数据分析、商业分析及数据挖掘建模等工作
3、构建基于大数据的数据产品和应用
?
岗位要求：
1、计算机相关专业，4年及以上工作经验
2、对Hadoop有实战经验，对基于hadoop、Spark、Storm、MapReduce、HDFS、YARN等技术开发大数据处理引擎有深入了解
3、熟悉Linux开发环境及Java开发，具有良好的编程基础及编程习惯
4、对数据结构和算法设计具有深刻的理解，熟悉常用数据挖掘算法，并有一定的算法实现调优经验
5、有良好的数据分析意识和产品意识，能够从海量数据中发现有价值的规律
6、具备良好沟通能力和团队合作精神，工作认真细致，责任心强
7、具备较强的分析解决问题的能力，以及优秀的逻辑思维能力，对有挑战的问题充满激情
8、有团队管理经验优先"
"职位描述：
        
        一、岗位职责:
1、负责带领大数据团队制定合理的大数据开发市场发展战略与大数据服务策略，并带领团队有效执行，确保目标的达成；
2、负责海量数据处理和高性能分布式计算的架构设计，深入研究大数据业务相关运维技术；3、负责大数据处理和分析的核心模块的研发，完成平台搭建、调试、集成及实施；4、设计实现分布式集群的运维、监控和管理平台；对Hadoop生态组件及相关技术组件的性能调优；制定Hadoop整体集群使用规范，规范Hadoop平台开发及应用；5、参与公司大数据平台整体规划, 支撑公司不同业务线对数据收集、整理、统计和学习等需求；6、完善和优化公司大数据采集、处理、分析和建模等流程。
7、有较好的团队管理和沟通能力，较强的责任心和事业心。任职资格:1、本科及以上学历，4年以上工作经验，至少一个完整的大数据规划项目经验；2、熟悉Hadoop体系结构、对Hadoop生态系统有较全面了解，具有大型hadoop平台（项目）开发和实施经验；3、擅长hadoop生态系统各个组件的运用和调优， 如Spark、hadoop、hbase、hive、flume、sqoop等，具备海量数据处理经验，熟悉HBase/Hive/MR开发及优化，熟悉storm/spark steaming等流式计算架构；4、具有优秀的团队合作精神，富有激情和创造力，善于沟通协调，能够有效地组织和推进跨职能、跨团队的合作项目。"
"职位描述：
        
        职位描述:1、参与大数据平台的建设及开发2、负责产品/项目的需求调研、数据分析、商业分析及数据挖掘建模等工作3、构建基于大数据的数据产品和应用
任职要求:1、计算机相关专业，2年以上工作经验2、对Hadoop有实战经验，对基于hadoop、Spark、Storm、MapReduce、HDFS、YARN等技术开发大数据处理引擎有深入了解3、熟悉Linux开发环境及Java开发，具有良好的编程基础及编程习惯4、对数据结构和算法设计具有深刻的理解，熟悉常用数据挖掘算法，并有一定的算法实现调优经验5、有良好的数据分析意识和产品意识，能够从海量数据中发现有价值的规律6、具备良好沟通能力和团队合作精神，工作认真细致，责任心强7、具备较强的分析解决问题的能力，以及优秀的逻辑思维能力，对有挑战的问题充满激情"
"职位描述：
        
        岗位职责：
1、参与和负责数据仓库基础设施和平台的搭建、开发及维护工作；
2、优化数据存储和计算平台，确保数据平台的可靠运行；
3、搭建和维护BI报表系统，参与ETL开发；
4、了解运营数据业务需求，提出解决方案，制定开发计划并执行；
5、解决海量数据不断增长面临的挑战，提高数据仓库性能，减少业务运营工作人员的工作量，解决业务运营需求。
?
岗位要求：
1、具有数据仓库、数据集市架构设计、开发实施经验；
2、有海量数据处理经验，熟悉分布式计算和大规模数据处理的相关技术；
3、熟悉ETL开发实施流程和原理，具有ETL程序开发能力；
4、熟练使用Linux系统，有Shell/Python/Ruby等一种以上脚本编程经验；
5、扎实的Java/php开发技术功底，熟悉Java/PHP领域内的主流开源项目优先；
6、熟练应用主流关系型数据库，精通SQL，有一定的SQL编写和优化调优经验。"
"职位描述：
        
        岗位职责：
1、? 基于内部大数据平台进行开发工作；
2、? 负责大数据平台的基础数据服务接口开发，包括数据提取、分析与结果整理；
3、? 负责分布式数据平台框架下的数据架构设计与开发；
4、? 完成领导交办的其他任务。
?
任职要求：
1、? 全日制统招本科及以上学历，计算机相关专业，3年以上大数据开发经验；
2、? 在文本分类、实体识别、关键词抽取、知识图谱、爬虫等文本分析、日志类分析相关领域从事过数据挖掘、大数据处理相关工作；
3、? 有大规模分布式计算平台（Spark、Hadoop）的使用和并行算法开发经验；
4、? 熟悉常用的数据挖掘和机器学习算法，对分类、聚类、深度学习等NLP有实践经验；
5、? 能熟练调用现有深度机器学习框架者优先考虑（TensorFlow、Theano、Scikit―Learn，Deeplearning4j等）"
"职位描述：
        
        1、负责大数据服务项目实施过程中，相关需求分析、架构设计、方案编制及数据开发工作；
2、负责大数据平台运维服务过程中，相关系统优化、问题处理等；
3、协助产品经理完成产品开发，负责产品技术路线规划以及系统架构、应用架构、技术架构分析和设计；
4、协助数据分析团队完成分析工作；协助数据治理团队完成相关治理工作；
5、领导交办的其他相关工作。
任职要求：
1、计算机相关专业全日制本科及以上学历，5年以上工作经验，2年以上大数据相关经验，能独立带领团队完成项目工作；
2、熟悉Java或Scala语言，熟悉Spark，Hadoop，Kafka，Hive，HBase，ZooKeeper等大数据相关技术；
3、精通SQL语句并对Redis，Mongodb等NoSQL数据库有一定经验；
4、对于高并发、高可用性、高性能有过实际项目产品经验者优先；
5、责任心强，工作踏实，有团队协作精神。沟通能力强者优先。
公司福利：
六险一金、各项补贴、专业培训、绩效奖金、定期体检、弹性工作、商业保险、不定期团建及聚餐、定期生日会、福利多多，快来加入我们吧~"
"职位描述：
        
        岗位要求：
熟悉机器学习相关算法以及深度学习模型
1、能够基于机器学习开源架构，快速上手解决业务问题。
2、紧密关注数据变化，及时发现业务背后原因
3、用户行为大数据分析，用户画像，用户分层，提出业务发展建议
4、新营销业务场景快速建模
加分项：
+分布式编程、pyspark熟练应用
+对于卷积神经网络相关算法有深入理解
任职资格：
1、数学或者计算机专业，985、211院校本科及以上学历；
2、具有数据质量意识，工作认真、细致、有耐心，有良好的团队协作意识 ，乐于接受挑战，思路清晰，善于钻研思考；
3、精通Python，具备良好的代码书写规范和文档编写能力"
"职位描述：
        
        1、深入掌握目前业务大数据建设所需MPP、Hadoop、sparkstreaming、storm及云计算等开源技术
2、精通Hadoop下Flume、Spark、Strom、Kylin等平台和工具应用
3、精通Python、R、Java等程序设计语言
4、熟悉深度学习模型并参与过一个以上类似数据分析产品的开发或运营"
"职位描述：
        
        岗位职责：

1、大数据相关项目及整体平台解决方案的产品化输出；
2、负责数据调研、数据接入、数据建模、数据清洗、数据映射、数据可视化等工作；
3、负责对数据进行分析，为项目组提供大数据技术指导及分析手段支撑；
4、负责大数据平台的性能监控和持续优化；
5、针对需求提供大数据分析技术解决方案。

任职资格：

1、3年以上工作经验，
2、扎实的Java基础；熟悉Spring、Mybatis等框架，了解实现原理；
3、熟悉大数据相关技术栈，包括但不限于Hadoop、Hbase/Spark/Flink等相关技术框架；
4、熟悉业内的常见数据应用，如推荐引擎、用户画像等，熟悉分布式理论与原理；
5、优秀的独立解决能力；较好的逻辑思维能力，工作态度端正积极，有团队合作意识；良好的规范意识；
6、拥有相关项目管理经验者优先。"
"职位描述：
        
        职责描述：
1. 参与金融大数据处理系统的设计与研发工作。
2. 负责大数据工具的部署运维。
3. 根据投研需求，完成大数据处理程序的开发与调试。

任职要求：
1. 全日制本科及以上学历，计算机相关专业毕业。
2. 具有扎实的程序设计基础，精通Java/Scala，熟悉常用的数据结构与算法。
3. 具有2年以上Spark大数据处理程序开发经验，深入理解分布式大数据处理的常用方法。
4. 精通Python，熟悉常用的数据处理工具包，如Pandas等。
5. 热爱程序设计，对IT充满激情，愿意面对挑战。
6. 有独立解决问题的能力，也有团队工作的经验。
7. 有如下经验者优先： Hadoop/Hive/Impala等大数据生态圈经验，Spark运维，机器学习。"
"职位描述：
        
        岗位职责：
1、负责核心业务模块数据仓库的构建；
2、负责数据模型的设计，ETL实施、ETL性能优化、ETL数据监控以及一系列技术问题的解决；
3、负责构建用户主题、各业务线主题、推荐主题、企业BI门户系统；
4、负责全产品线数据字典维护，提升数据资产质量。
任职资格：
1、计算机、数学相关专业本科及以上学历，三年以上大数据开发工作经验，数据挖掘和BI分析领域优先；
2、熟练掌握Hive/SQL，熟悉Spark/Map-Reduce/MPI分布式计算框架，熟悉大数据的离线和实时处理，可以进行海量数据模型的设计、开发；
3、有产品sense，主动思考基于业务场景下的数据体系建设，而不单单只会做执行；
4、工作认真，负责，良好的团队合作精神和解决问题分析能力，钻研技术克服困难，勇于挑战；
5、有数据分析经验优先。"
"职位描述：
        
        1、研发大数据处理系统，处理用户日志、支持公司搜索及推荐业务；
2、带领数据团队，构建业务指标体系，建立和完善日常业务报告体系，能够及时、准确、完整地披露业务的运作情况 ；?
3、参与数据系统架构设计与数据开发，建设运营数据支撑体系 ；?
4、通过专项分析，输出专项分析报告，为业务模块的决策和产品方向提供数据支持 ；?
5、参与数据底层的工具、平台、部署流程等技术体系建设的研发工作。
?
岗位要求：
1、熟悉Hadoop/HBase/Flink/Spark/Airflow等开源大数据技术；
2、具备电商行业，或者有交易/订单产生的业务经验的优先；
3、具有大规模Hadoop集群运维管理经验者优先 ；
4、熟悉常用的数据挖掘、分析的工具和方法，有数据挖掘工作经验，熟悉linux平台，精通shell/c(c++)/php/python/等脚本语言的一种或多种，编码基本功扎实 ；?
5、技术背景深厚，熟悉分布式计算技术理论，具有架构和设计实践经验，对现有行业主要产品的相关技术有深刻研究和了解；
6、具备较强的数据敏感性，善于从大数据中挖掘价值
7、3年以上相关工作经验"
"职位描述：
        
        工作内容：1.?? ?编程实现大数据采集、清洗等业务逻辑2.?? ?通过数据建模实现用户需要的数据分析和挖掘功能3.?? ?开发数据分析和挖掘相关的用户界面岗位要求：1.?? ?数学、计算机、生物信息等相关专业硕士以上学历2.?? ?良好的算法和数理统计相关理论基础，对数据敏感3.?? ?熟悉Hadoop，HBase，Hive，Kylin，Kafka，Storm等数据处理相关技术，了解数据采集、清洗、建模、分析、挖掘等流程4.?? ?掌握至少一种编程语言5.?? ?良好的团队合作精神"
"职位描述：
        
        岗位职责：1. 负责PB级别用户数据实时/离线计算的架构设计和开发；2. 构建推荐模型、排序优化系统的设计和开发3. 构建数据管理平台,用于存储、计算、分析、挖掘用户行为、用户交易等日志数据处理和分析；4. 对大数据相关的前沿技术进行预研，利用挖掘技术分析用户偏好特征，构建用户画像、精细化运营等业务的数据基础；任职要求：1. 本科及以上学历，计算机或者数学等相关专业；2. 熟练掌握Java以及Scala/Python(2者任意一种)语言，熟练Linux开发环境以及Shell、Python常用脚本语言；3. 5年以上大数据开发经验，熟练使用flink,Hadoop，Spark，Storm，Hive，Hbase，ES，MongoDB等开源技术；4. 在实时计算、流计算、多维度olap分析方面有实践经验；5. 对技术有执着的热情。6. 优秀的问题分析解决能力，严谨，踏实的工作态度，强烈的责任心和进取心态7. 优秀的学习，沟通能力和团队合作精神8. 有推荐、广告、NLP、机器学习等相关经历和背景者优先"
"职位描述：
        
        【工作职责】
1、负责游戏数据体系的搭建；
2、负责数据应用系统指标的算法设计以及实现；
3、负责数据仓库、用户画像体系的设计与开发；
4、负责即时OLAP系统的设计以及开发；
【职位要求】
1、本科以上学历，3年以上数据分析、数据开发经验，熟练使用标准SQL语言，以及scala、java等；
2、有hadoop，hive，spark，hbase等大数据生态圈开发经验优先；
3、熟悉kudu,presto等工具优先；
4、有数据仓库项目或者用户画像项目成功实施的经验优先；
5、工作积极主动，有创新精神，能主动学习新技术。

该职位只接受招聘官网投递简历，请您进入我司官网招聘地址（http://hr.duoyi.com/）选择对应职位进行投递，我们将认真查看您的简历并作回复，感谢您对多益的关注！
(1)根据投递岗位（数据开发工程师）及工作地点，点击进入详细页面；
(2)点击“投递岗位”、“注册帐号”并填写邮箱和电话号码后点击“确认注册”；
(3)将简历信息填写完整，点击“保存并提交”即可。"
"职位描述：
        
        岗位职责：
 围绕新零售商品从供应链到销售，整个商品生命周期
 建设新零售商品数据集市、画像特征。
 深入商品选品模型、销量预估、定价模型建设，指导采销工作。
 深入零售业品类优化、增汰品策略建设，指导零售商。
 深入商品货货关系分析、指导零售商卖场陈列优化策略，提升销量。
 挖掘商品数据，通过产品创新，场景化赋能新零售商品运营工作。?
岗位要求
 熟悉python，以及numpy，pandas，scikit 等库
 熟悉机器学习各种概念，算法，部署方式
 熟悉数据探索技术，数据可视化
 了解深度学习概念
 了解大数据处理技术 包括 Hive， Spark等
 加分项：有相关零售业工作经验。"
"职位描述：
        
        岗位职责
1、负责数据产品的整体评估、设计与工程落地，如数据集市、精准营销、个性化推荐等；
2、寻求数据层面的业务价值，利用数据推动产品优化。
岗位要求
1、对Hadoop的大数据体系有深入认识，对Hadoop、Hive、Impala、HBase、Spark、ES等有实际应用研发经验，对大数据的某一技术领域有深入了解；
2、很强的学习、分析和解决问题能力，良好的团队意识和协作精神，有较强的内外沟通能力；
3、对数据有足够的敏感度，具备必要的产品管理意识与产品设计能力，对互联网用户端产品有良好的感觉；
4、精通Java，有良好的面向对象思想，熟悉Python/R编程等语言优先；
5、有大数据项目、数据仓库、数据分析及数据挖掘等经验者优先。"
"职位描述：
        
        岗位职责：
1、负责并参与新零售领域数据相关系统架构设计、技术选型、开发、优化、重构，根据业务规划制定技术实现方案；
2、负责并参与海量用户行为数据埋点与收集、数据集市建设等数据中台研发；
3、负责并参与用户画像、智能营销、个性化推荐、零售企业赋能数据产品等相关系统研发。
岗位要求：
1、人靠谱，责任心强，有自信；
2、充满好奇心，热爱技术，享受coding，学习能力强，有代码洁癖；
3、4 年以上 java工作经验，java基础扎实，熟悉io、多线程，熟悉分布式、缓存、消息机制、jvm调优等；
4、熟悉Dubbo、MQ、spring boot、Mybatis、Redis、ElasticSearch、zookeeper等常用技术，在某一技术领域有较深入研究；
5、项目经验丰富，对业务有良好理解；
6、对数据有足够的敏感度，具备必要的产品意识，对互联网产品有良好的感觉。
加分项
具备大型互联网公司背景
有大型分布式、电商系统研发经验
了解一定的大数据技术（如Hadoop、Hive、Impala、HBase、Spark、Storm、Kafka、Kylin、Kudu、ES等之一）
面向有丰富工作经验，期望转型大数据的高级Java工程师"
"职位描述：
        
        职位描述：
岗位职责：
1、负责新零售数据相关系统架构设计、研发、优化、重构，根据业务规划落地相关技术方案；
2、负责海量用户行为数据埋点与收集、数据集市建设等数据中台研发；
3、负责用户画像、智能营销、个性化推荐、零售企业赋能数据产品等相关系统研发。
岗位要求：
1、大数据平台建设、数据治理与数据仓库建设、数据中台建设、用户数据精细化运营、用户画像、新零售数据应用等方向均有中高级HC，高级别薪资可谈；
2、热爱技术，喜欢接触新事物，有自驱力，责任心强，有自信；
3、3?年及以上?java工作经验，java基础扎实，熟悉io、多线程，熟悉分布式、缓存、消息机制、jvm调优等；
4、熟悉Dubbo、MQ、spring boot、Mybatis、Redis、ElasticSearch、zookeeper等常用技术，在某一技术领域有较深入研究；
5、对数据有足够的敏感度，具备必要的产品意识，对互联网产品有良好的感觉。
6、不限于是否具备大数据技术经验，欢迎期望转型的优秀java工程师?
加分项
具备大型互联网公司背景
具备电商业务研发经验
了解一定的大数据技术（如Hadoop、Hive、Impala、HBase、Spark、Kafka、Kylin、Kudu、ES等）"
"职位描述：
        
        职位描述：
1.??? 负责各种数据源的采集入库。
2.??? 负责医疗数据的加工处理，在分布式计算平台基础上建立高效、实时的数据 pipeline，数据洞察驱动业务增值。
3.??? 打造业界领先的医疗大数据平台，支撑数据采集，加工，建模，分析，实验，可视化的全流程；
4.??? 打造业界领先的分布式计算，存储系统，解决大规模生产环境集群可用性和性能优化问题。
职位要求：
1. 本科及以上学历，计算机相关专业，三年以上相关工作经验；
2. 熟悉包括不限于hadoop、hbase、hive、spark、flume、Flink、Kafka、Druid、zookeeper等技术，并了解其基本原理。
3. 熟悉CDH，TDH框架；
4. java基础扎实，熟悉jvm原理，熟悉并发编程。
5. 熟悉sql编程，对编写高性能sql代码和sql优化有一定的心得。
6. 熟悉linux系统。
7. 对技术充满热情，喜欢钻研新技术，挑战技术难题。"
"职位描述：
        
        1、负责LIS相关产品的需求分析，撰写技术方案，以及核心代码的研发工作； ? ?
2、与产品经理、实施人员进行紧密沟通、协作，制定合理的项目开发计划； ? ?
3、主导开发高性能、高可用性的分布式区域级检验数据平台； ? ?
4、跟踪并汇报项目执行进度，协助团队解决技术难题； ? ?
1、全日制本科以上学历，计算机或相关专业毕业，8年以上相关医疗系统行业或医院系统研发或LIS云等岗位工作经验； ? ?
2、熟悉各种检验数据交互标准，有行业内主流检验设备对接或实施经验； ? ?
3、对区域级医疗平台有深入的了解； ? ?
4、有很强的业务分析能力，能够根据需求快速的给出技术方案； ? ?
5、有很强的技术编程能力，精通JAVA，以及主流的技术框架，如Spring, MyBatis, ? Dubbo等；"
"职位描述：
        
        1.Hadoop实际项目使用经验2.Java平台开发经验3.英语能力好"
"职位描述：
        
        【我们的目标】
?打造中国第一的连锁餐饮管理平台
?完成云平台的用户体系、统一服务、物流等核心系统
?为以上目标提供技术支持，卓越的平台造就卓越的你

岗位职责
1. 参与基础数据平台、数据仓库的设计、研发;
2. 根据各业务需求，进行数据ETL的设计与开发，建立数据标准化; 3. 配套管理设施的设计与开发。

任职要求
1. 数据大数据平台架构常用组件(Hadoop、Spark、Hive、Hbase、Kafka等)，可熟练使 用Pyt hon、Java、Scala任一语言进行开发，熟悉基本原理，有一定的性能调优能力;
2. 熟悉Unix/Linux管理，可熟练编写Shell、Python脚本;
3. 熟悉ElasticSearch、MySQL、MongoDB等一种或几种的使用;
4. 精通Python、Java、Scala至少一种或几种;
5. 工作负责，追求卓越，对代码质量有较高追求。

【我们提供你】
丰厚待遇，法定节假日及亲子假期
入职即缴纳五险一金
无限量茶点及五星级大厨级免费的一日三餐
错开早高峰，弹性工作时间
开放的团队氛围，开放的办公环境。"
"职位描述：
        
        岗位职责：1、参与公司大数据平台的技术选型和架构设计2、负责公司大数据核心业务的设计、开发和优化，对项目开发中的技术难点进行攻关3、为公司所有业务线提供数据支持，助力业务成长任职资格：1、本科以上学历，熟练掌握Java语言编程，有3年以上大数据项目开发经验2、熟悉Hadoop生态链，包括Hadoop、HBase、Hive、Kafka、Flume、ElasticSearch、Spark、Storm、Flink等3、深刻理解分布式数据处理技术原理，具有独立完成从方案选型设计到原型系统开发实现的能力4、熟悉Linux基本操作，熟悉Python/Shell等至少一种脚本语言有以下经验者优先：1、有海量数据存储处理项目经验2、有批处理计算和实时流计算处理开发经验3、有数理统计、机器学习、自然语言处理背景知识及算法"
"职位描述：
        
        岗位职责：
1、负责分布式数据平台建设，数据仓库各子系统开发，数据仓库的研发、设计与维护；
2、负责海量数据处理与开发工作，满足各类数据应用需求；
3、系统的性能分析与系统优化，不断提高系统运行效率；
4、基于海量数据,开发设计高可扩展/高并发/高效的数据挖掘、机器学习、统计分析、图等算法，挖掘用户风险行为特征；

5、利用数据挖掘、机器学习、AI等技术的应用、以及对技术的创新和设计识别风险行为及场景；

6、为公司运营提供数据支撑，不定期进行专题分析，根据业务需要进行数据挖掘，建立模型并推动落地；

7、使用机器学习算法建模，结合金融数据推动模型落地，并解决实际运行中出现的问题；?

8、开发基于金融行业大数据的人工智能应用系统和平台。


任职资格：
1、必须全日制国内外重点大学计算机、数学、统计、运筹学等相关专业的本科和硕士，博士优先；
2、1年以上分布式数据处理系统开发经验，1年以上大数据开发经验；
3、具有扎实的数据结构和算法功底，精通Java/PythonJava／Python/JavaScript/Shell等高级编程语言；
4、熟悉至少一种主流数据库系统，精通SQL、存储过程，有较好的SQL性能调优经验，有大数据分布式计算平台开发经验，熟悉Hadoop原理，熟练使用hadoop/hive/spark优先（包括hdfs, yarn, hbase, impala, storm, kafka, flume等)；
5、精通Map/Reduce编程，有源代码阅读经验者优先，有实际开发经验优先；
6、有增量算法实施经验，熟悉大规模数据挖掘、机器学习、分布式计算等技术优先；
7、有文本挖掘、用户画像、自然语言处理、推荐系统、Spark MLlib或Mahout等研究经历或工作经历优先；
8、有TB-PB级数据处理实际工作经验者或实时数据平台开发经验优先；
9、具有优秀的沟通能力，能够结果导向，协同团队快速迭代完成任务；
10、能够接受创业型公司的节奏。"
"职位描述：
        
        职位描述：
岗位职责：
1. 使用阿里云大数据产品及开源大数据产品进行项目中的数据仓库、数据指标及接口开发工作；
2. 负责数据项目基于数仓的数据开发、治理、运维工作；
3. 进行数据链路搭建、维护，完成数据接入工作；
4. 工作地点杭州。

数据开发技能要求：
1. 计算机类相关专业，本科及以上学历；
2. 熟练掌握SQL关系型数据开发，有数据仓库设计开发经验以及有阿里云ODPS、流计算产品开发经验优先；
3. 具备Spark及Hive等开源大数据平台开发经验者优先，有数据库相关认证以及阿里云ACP大数据专业认证者优先；
4. 熟悉Linux环境及常用指令，掌握Shell、Python脚本开发，能够独立承担数据处理工作以及数据接口服务开发等工作；
5. 有良好的学习能力，有意愿学习阿里云数据产品及公司自研数据产品，有责任心、对待工作态度积极，有一定抗压能力；
6. 工作经验：1-4年。"
"职位描述：
        
        岗位职责：
1、参与项目或者运营服务过程中的数据抽取，处理，分析等相关工作；2、参与项目或者运营服务过程中的数据接入及需求对接；3、参与项目或者运营服务过程中的日常运维工作，并负责开发相应的数据接口或脚本辅助运维。

任职要求：

1、3年以上大数据开发经验，精通数据结构、Java，有互联网/人工智能/大数据公司工作经验者优先；2、技术基础扎实，熟悉主流技术框架，熟练掌握RPC、分布式、OLAP等相关技术栈；3、熟悉大数据生态圈技术，Hadoop、HDFS、Hive、HBase、Spark、Storm、Flume、sqoop、kylin等，阅读过源码或做过二次开发者优先。4.熟悉kylin并了解过源码的优先。5.熟悉odps，并有开发经验的优先。6、对大数据感兴趣，对技术感兴趣，责任心强，具备较强的团队合作精神，勇于开拓，有创业精神，适应互联网公司氛围"
"职位描述：
        
        岗位职责：
1.负责数据平台的设计、开发、维护、优化，提升数据部门开发和自动化效率，平台输出能力，更好地支撑各部门数据需求；
2.参与大数据平台各类基础系统架构设计和工具开发，性能调优，技术难点攻关；
3.负责自助BI分析平台、日志监控平台、数据管理平台等搭建设计，开发和维护工作；
岗位要求：
1、3年以上相关工作经验
2、熟悉一种或者多种大数据生态技术（Flume，Kafka、Hive、Hbase、Spark、Storm、Hadoop、Flink等），熟悉源码者优先；
3、对Java语言基础有良好的掌握，熟练运用spring,mybatis等主流的开发框架；
4、熟悉阿里云数加平台、日志服务的优先；"
"职位描述：
        
        岗位职责：
1.参与实时计算平台和上下游完整体系的建设，向公司输出实时计算服务能力；
2.以实时计算平台为支撑，串联公司线上业务核心流程，支持包括但不限于营销，推荐，流量分配等业务场景；
3.负责线上系统的技术支持工作，保障系统稳定运行。
岗位要求：
1、.熟悉至少一种大数据处理引擎，例如Hadoop、Storm、Spark、Flink等，熟悉Flink sql的优先；
2、3年以上大数据相关领域开发和工作经验，
3、有成熟中大型互联网公司数据应用平台和产品从业经验者优先。"
"职位描述：
        
        工作职责
?1. 开发自动驾驶领域数据的存储、处理、分析平台工具，承载感知自动标注、分布式预处理、算法输出结果的交互式分析等功能；
?2. 负责平台中数据实体的管理，数据集成，以及面向业务的数据分析等任务；
?3. 负责数据库/大数据集群性能监控与优化，故障处理，数据备份及恢复；
?4. 负责数据库/大数据集群管理，包括数据库日常维护，系统数据安全以及故障处理、日常错误情况处理等。

任职资格：
?1. 计算机、数学、通信等相关专业；
?2. 对至少一门常用语言（比如 C/C++、Java、Python）有良好的开发调试经验，熟练使用常用的数据结构与算法, 熟悉Linux；
?3. 熟悉数据库实现原理，熟悉存储过程和事务；
?4. 具备数据库设计、SQL优化能力，能根据业务需求，提供高可用、高性能、可扩展、稳定可靠的数据库解决方案；
?5. 良好的团队合作能力，沟通能力和学习能力。

优先条件:
?1. 有Web后端开发, 基于大数据进行数据挖掘/分析的经验；
?2. 有深度学习图像感知算法开发和使用经验；
?3. 有Hadoop/Hbase/Phoenix/Kafka/Spark/ElasticSearch相关经验。"
"职位描述：
        
        岗位职责:

1、 针对业务数据的特点，选择合适的存储、计算、分析的解决方案；2、 对数据存储、计算平台进行优化与封装，使业务开发更加便捷；3、 能够使用数据挖掘与机器学习算法完成业务对数据价值的发现；4、 能够根据业务需求与数据特点，设计数据接入、存储、计算等平台架构； 
任职资格:

1、 精通数据存储组件的原理、适应场景与使用优化，包括结构化存储、对象存储等，如hdfs、hbase、ceph、mongodb、elasticsearch、mysql等。2、 至少熟悉一种实时计算框架，并有相关的开发经验，如storm、spark streaming、hadoop streaming、flink等；3、 至少数据一种离线计算框架或ETL工具，如spark sql、mapreduce、hive、flink等。4、 有亿级以上数据处理经验者优先，有数据挖掘与机器学习开发项目经验者优先；5、 至少对一个开源数据框架或工具有原代码级的研读，有二次开发或定制开发者加分；6、 精通python/golang/php/java任一语言，有完整的互联网或软件项目开发迭代经验；7、 计算机及相关专业本科以上学历，两年以上工作经验"
"职位描述：
        
        岗位职责：
1、 针对业务数据的特点，选择合适的存储、计算、分析的解决方案；
2、 对数据存储、计算平台进行优化与封装，使业务开发更加便捷；
3、 能够使用数据挖掘与机器学习算法完成业务对数据价值的发现；
4、 能够根据业务需求与数据特点，设计数据接入、存储、计算等平台架构；
?
岗位要求：
1、 精通数据存储组件的原理、适应场景与使用优化，包括结构化存储、对象存储等，如hdfs、hbase、ceph、mongodb、elasticsearch、mysql等。
2、 至少熟悉一种实时计算框架，并有相关的开发经验，如storm、spark streaming、hadoop streaming、flink等；
3、 至少数据一种离线计算框架或ETL工具，如spark sql、mapreduce、hive、flink等。
4、 有亿级以上数据处理经验者优先，有数据挖掘与机器学习开发项目经验者优先；
5、 至少对一个开源数据框架或工具有原代码级的研读，有二次开发或定制开发者加分；
6、 精通python/scala/C++/java任一语言，有大数据平台开发与数据处理经验；
7、 ?计算机及相关专业本科以上学历，两年以上数据开发工作经验；"
"职位描述：
        
        岗位职责：
1、流式计算平台的整体架构设计；
2、负责技术攻关和创新技术引用，开发具有数据分析、数据挖掘能力的创新型产品；
3、负责提升基于Hbase数据存储集群的高可用性、高性能、高扩展特性；
4、负责设计和建立基于Storm或Spark实时数据处理框架；
5、研究Hadoop/Spark/Hbase/Hive等开源项目，对线上任务进行调优，并开发通用组件；
6、维持实时大数据平台高效稳定。
?
任职要求：
1、本科及以上，计算机、软件工程、统计学、数据挖掘、机器学习等相关专业，2年以上大数据架构经验；
2、扎实的Java、Scala语言基础，对JVM运行机制有深入了解；熟悉Hadoop、Spark并有丰富的开发经验；?
3、熟练使用java语言，并掌握spring、mybatis等开源J2EE框架。使用java、scala、python等开发语言中的一种，有python和scala实际使用经验更佳；?4、有hadoop和spark实际开发经验。了解大数据组件的使用限制和应用场景，如hdfs,yarn,hbase,hive,flume,kafka,zk,impala,kylin,kudu,ES,Storm、MongoDB等。
5、熟悉mysql、ElasticSearch、Redis等关系型或NoSQL数据库，了解应用场景和使用限制。有实际调优经验者更佳。
6、熟悉linux常用命令，有实际CDH或HDP或apache版本的hadoop部署经验者优先；?
7、熟悉并行计算或者分布式计算，熟悉Spark框架,熟练掌握RDD，SQL, Streaming, MLLIB，SparkR编程；
8、英文文档阅读无障碍、熟练掌握常用设计模式、熟练使用maven、git；
9、有深入研究过Hadoop/Spark源码者优先；
10、深入理解MapReduce工作原理，HDFS分布式文件系统架构；熟练掌握Hadoop/Hive/HBASE的运维和调优方法；?
11、掌握或使用过Storm、Spark、flume、kafka等工具；"
"职位描述：
        
        【职位描述】
1、负责大数据平台的搭建、功能设计、及核心模块的开发；
2、负责指导团队成员开发，对代码质量进行监控、保证代码的可读性、易维护性，确保开发质量；
3、负责大数据平台新技术的调研及技术选型。
?
【任职资格】
1、计算机相关专业全日制本科及以上学历，5年以上开发工作经验；
2、5年以上大数据开发经验，熟悉各个大数据组件，尤其对HBase，Hive，Spark，Kafka、HDFS、Yarn等能够熟练编写代码，对大数据各个组件原理有清晰深刻理解
3、3年以上Java开发经验，熟悉JAVA开发，数据库设计，web框架搭建，restful API设计等"
"职位描述：
        
        岗位职责：
1、参与开发平台核心功能模块，能独立进行需求分析和设计开发工作；
2、能够发现和解决系统的框架问题、流程问题、数据问题、运维问题；
3、主要负责机器学习算法工程化工作；
职位要求：
1、本科或以上学历，计算机、软件工程等相关专业；
2、3年以上工作经验，精通JAVA、scala、python等至少一种开发语言，有常用开源框架使用经验；
3、熟练使用Hadoop、Spark、hive、Hbase、Redis等大数据技术框架；
4、拥有机器学习算法工程化（如时间序列算法、XGBoost、逻辑回归算法等）实践经验者优先；
5、拥有电商平台开发设计经验者优先；
6、学习领悟能力强，具备高度的责任心及团结协作精神，善于沟通交流。"
"职位描述：
        
        岗位职责：1、参与构建大数据平台；2、负责数据分析需求设计与开发，构建数据集市；3、负责数据平台在公司内的推广、培训，不断提升其应用能力；；4、需求基于平台，完成集团的各项指标的建设任务；
5、完成日常数据分析查询需求，通过大数据挖掘用户；
任职要求：1、熟悉主流大数据平台，了解前沿技术和潮流方向，具有3-5年以上大数据系统客户需求研究、软件架构设计、项目集成部署等实际项目经验，熟练使用大数据平台产品至少完成2个以上项目交付；2、了解Hadoop/Hbase/HIVE/Spark等数据平台，熟悉大规模数据并行计算/传输/处理系统架构；精通常用的数据分析工具，熟悉商业智能系统，熟悉数据仓库，熟悉数据集市，深入理解Lucene，ElasticSearch，Solr等，有优化经验者优先；3、具备3年以上大客户业务开拓能力及独立行业解决方案能力；4、至少熟悉并精通一款商用大数据平台产品，熟悉基于平台产品之上大数据应用产品设计及解决方案设计，具备优秀的方案制作能力，行业大数据产品设计能力，并有实施落地经验；5、具备优秀的文档能力，清晰明了地表达架构意图，能够熟练编写各类技术文档；6、良好的沟通、协调及资源整合能力，具备优秀的表达能力，思路清晰、逻辑缜密。"
"职位描述：
        
        岗位职责：
1、参与大数据平台的架构和设计；2、研究设计基于大数据数据挖掘解决方案，负责大数据处理的实现，以及数据挖掘的实现和优化；3、应用大数据技术，将模型转化为具体的实现逻辑；4、负责大数据新技术的研究与落地；5、参与数据清洗，数据结构设计与重构。

任职要求：
1、本科及以上学历，计算机或数学专业毕业，具有2年以上大数据开发和处理经验；2、有扎实的计算机和数学理论，对数据结构和算法有一定基础，并在项目中使用优化经验；3、熟悉数据仓库，数据建模方法和理论；4、熟悉Hadoop生态圈及其他相关组件和框架，例如：Spark，Hive，HBase，Flink，ZK，sqoop等；5、有机器学习和数据挖掘的相关经验，了解常用的机器学习：线性回归，决策树等，有文本分析，情感分析经验；6、掌握深度学习框架（Caffe，Tensorflow，Torch等）。"
"职位描述：
        
        岗位职责：1.?结合公司背景以及项目背景，配合产品经理，负责挖掘用户/行业需求，在技术上对产品提供支持2.?以数据挖掘、机器学习等为基础，促进产品改进，探索新业务3.?学习最新算法和大数据行业趋势，了解AI最新发展方向，并进行技术预研，实践，并探索形成产品化4.?形成并优化公司现有产品算法，并测试评估算法精准度，运行效率，资源消耗等参数5.?编写相应的核心代码，算法文档6.?具备极强的自我驱动能力、学习能力和执行力，能够在压力下工作7.?良好的团队沟通能力，善于分享和总结?任职要求：1.?本科及以上学历，计算机、数学、或统计专业毕业。有3年以上算法实际工作经验2.?精通python，R 语言，了解Scala，Java，C++ 任意一门编程语言3.?项目实际涉及过图像识别，自然语言处理，推荐算法，预测等业务4.?掌握TensorFlow，Caffe，OpenCv等框架技术5.?熟悉机器学习算法：CNN，朴素贝叶斯，因子分析，分类，回归，文本挖掘等6.?熟悉Linux操作系统7.?良好的沟通配合能力，与数据清洗以及系统研发一起配合工作"
"职位描述：
        
        岗位职责：1.?结合公司背景以及项目背景，配合产品经理，负责挖掘用户/行业需求，在技术上对产品提供支持2.?以数据挖掘、机器学习等为基础，促进产品改进，探索新业务3.?学习最新算法和大数据行业趋势，了解AI最新发展方向，并进行技术预研，实践，并探索形成产品化4.?形成并优化公司现有产品算法，并测试评估算法精准度，运行效率，资源消耗等参数5.?编写相应的核心代码，算法文档6.?具备极强的自我驱动能力、学习能力和执行力，能够在压力下工作7.?良好的团队沟通能力，善于分享和总结?任职要求：1.?本科及以上学历，计算机、数学、或统计专业毕业。有3年以上算法实际工作经验2.?精通python，R 语言，了解Scala，Java，C++ 任意一门编程语言3.?项目实际涉及过图像识别，自然语言处理，推荐算法，预测等业务4.?掌握TensorFlow，Caffe，OpenCv等框架技术5.?熟悉机器学习算法：CNN，朴素贝叶斯，因子分析，分类，回归，文本挖掘等6.?熟悉Linux操作系统7.?良好的沟通配合能力，与数据清洗以及系统研发一起配合工作"
"职位描述：
        
        岗位职责：
1.根据产品需求、项目需求，进行软件架构设计；2.根据项目及产品设计需求进行产品和项目的开发；3维护平台系统的日常运行，确保各个程序稳定高效运转；4.配合运维、配合产品测试人员提供修改方案和技术支持；5.对项目成员进行相应的技术指导；6.对前沿的大数据技术进行研究探索。
任职要求：
1.本科及以上学历，必须为计算机相关专业, 2年以上开发相关经验；2.熟练掌握及应用Java EE相关技术，熟悉Spring, Mybatis、MVC等开源框架；3.具有丰富的后台服务开发经验，对系统架构设计与性能调优有经验;4.熟练掌握NOSQL、Hive、MapReduce、hadoop 、Spark、Storm等大数据技术，并有相关的使用、开发经验，熟悉源码者优先；5、精通python,scala任意语言者优先；6、熟悉liunx系统，能进行shell文件编写；7.熟练掌握消息中间件技术，如KAFKA、RabbitMQ等，有应用于实际大数据项目经验。"
"职位描述：
        
        岗位职责：
1、根据产品需求、项目需求，进行软件架构设计，制定项目计划、技术方案、技术架构；
2、根据产品需求、项目需求进行产品和项目的开发；
3、负责团队技术架构的设计与规划，对团队成员进行技术指导，提升团队整体技术能力；
4、负责大数据相关基础数据的技术规划，编制相关规范文档；
5、负责大数据相关技术发展方向的预研；
6、参与业务需求调研，根据需求及行业特点设计大数据解决方案并跟进具体实施项目；
7、参与制定大数据平台汇总数据质量、业务质量监控及管理方案。
?
职位要求：?
1、全日制本科或以上学历，计算机、软件、数学等相关专业背景，5年以上大数据开发工作经验；
2、熟悉并掌握大数据相关算法（机器学习算法、深度学习算法、神经网络算法相关）；
3、具有Hadoop、Storm、Spark、ES等大数据技术的开发经验；
4、具有Oracle、HBase、Hive、Redis等主流数据库的相关开发和调优实战经验；
5、精通Java、Scala、Python中的一种或多种语言，熟悉Linux环境下编程，熟悉常用的shell命令工具；
6、有R、Python、SAS、SPSS等数据分析和挖掘经验者优先；
7、深刻理解大数据处理、流计算、分布式计算、分布式文件系统、分布式存储等相关技术和实现方法，有架构和设计实践经验优先；
8、具有优秀的表达、沟通与协调能力、团队合作精神、保密意识。"
"职位描述：
        
        工作职责:1、理解国泰产险业务，与业务同学紧密合作，了解业务对数据的诉求；2、负责国泰产险产品经营过程的业务分析，与蚂蚁金服同学的沟通，通过数据模型帮助业务运营及实施；3、负责国泰产险的数据中台问题的解决，保障其稳定运行；4、能够从用户的角度思考问题，通过数据分析，找出用户痛点，完善用户体验；5、探索数据产品化的机会，让数据在业务中发挥更大的价值。任职资格:1、熟练使用SQL，并且具有良好的数据建模能力；2、熟悉Java或Pathon，有优秀的编程能力；3、熟悉hadoop生态系统，如hive、spark、hbase、ES等；4、拥有良好的沟通能力和团队协作能力，勇于接受挑战，自我驱动，具备较强的学习能力、创新应用能力； 5、良好的逻辑思维和批判性思维能力；6、计算机、统计、数学、信息技术等本科及以上学历，有互联网相关数据分析工作经历优先，优秀的应届毕业生亦可。"
"职位描述：
        
        工作职责:1、深入理解国泰产险业务，与业务及运营同学紧密合作，通过分析/挖掘数据，探索业务机会点并能贡献自己对业务的独特见解；2、负责国泰产险产品经营过程的业务分析，与蚂蚁金服同学的沟通，通过数据模型帮助业务运营及实施；3、负责国泰产险的数据中台规划与落地，参与数据建模、数据工程的构建；4、能够独立推动数据项目，为产品运营决策、网站运营、策略提供数据决策支持；5、能够从用户的角度思考问题，通过数据分析，找出用户痛点，完善用户体验；6、探索数据产品化的机会，让数据在业务中发挥更大的价值。任职资格:1、掌握数据建模语言，并且具有良好的建模能力；熟悉hadoop生态系统，熟练应用hive、spark、hbase、ES等；熟练使用SQL，以及SAS/R/Python等中的一种；2、有分布式大数据平台开发经验，对CDH/HDP等大数据集群的应用、运维和调优有相当的经验；3、拥有良好的沟通能力和团队协作能力，勇于接受挑战，自我驱动，具备较强的学习能力、创新应用能力； 4、良好的逻辑思维和批判性思维能力；5、计算机、统计、数学、信息技术等本科及以上学历，有互联网相关数据分析工作经历；五年以上相关工作经历；6、三年及以上海量数据的数据挖掘、机器学习算法建模经验，具有较强的数据整合，数据分析/挖掘和解决业务问题的能力；有互联网用户growth分析经验者优先。"
"职位描述：
        
        【工作职责】
1、负责公司数据分析、加工、清理、处理程序的开发工作；
2、从事研究相关的数据分析、挖掘相关工作；
3、负责数据相关平台的搭建、开发、维护、优化工作；
4、配合投研平台开发及策略开发等工作；
【职位要求】
1、熟练使用python，理解基本的数据结构和使用场景，对python语言的本质和底层有一定了解。有基本的工程师思维，和基本的代码实现能力，能够运用python解决现实中的问题，并有至少一两个python相关的工程项目经历，1000行代码以上为佳。
2、熟练掌握pandas，熟练掌握pandas的常用用法，以及熟悉pandans的高级用法，如groupby、rolling、multiindex，merge。
3、有过相关数据分析经历，处理过非结构化数据，理解数据分析的基本图表形式，包括但不限于柱状图、饼状图、Box、Kde 等
4、熟悉sql语句，能进行基本的增删改查，merge等操作。了解sql语句的高级用法如，rank over、partitionby等。
5、有基本的统计学知识，概率分布、统计检验，参数估计，相关知识，熟悉线性回归。
6、有过相关的数据挖掘经历，有一定的特征工程经历，对特征工程中的技术有自己的理解，了解基本的机器学习算法。
7、有一定的投资经历为佳，包括但不限：股票、期货、债券、外汇、基金、数字货币等。
8、对宏观经济，金融市场运行机制有一定的见解。

【我们将为你提供】
1、有竞争力的薪酬体系：
工资+绩效奖+年终奖，让你的每一分努力都收获满意的回报；
2、完善的福利体系：
五险一金，补充医疗，带薪年假，年度出国旅行，节日福利，免费体检，福利多多，让你感受到无微不至的人文关怀；
3、健全的职业通路：
全面深入的职业培养计划和完善的内部晋升体系，根据您的特征做不同的职业发展辅导，实行1+1的带教制度，只要付出，必有收获；
4、和谐的企业文化：
扁平化的管理，不定期团建，我们为每个人都提供了自由绽放的的机会和平台！

【公司荣誉】
? 中国证券报第八届金牛奖：多策略金牛私募管理公司；
? 中国基金报中国私募基金英华榜：中国私募基金综合实力50强（复合策略）/三年期复合策略最佳私募基金（因诺天跃）/一年期复合策略最佳私募基金/一年期套利策略最佳产品；
? 上海证券报第八届金阳光奖：年度成长私募公司奖（量化对冲）；
? 证券时报金长江奖 ：年度优秀私募基金经理/收益明星私募基金产品/快速成长私募基金公司；
? 中国私募证券投资研究中心：2018中国最佳私募证券投资经理TOP50；
? 私募排排网：最值得信赖私募基金管理人（复合策略）；
? 财经生活频道及华林证券中华好私募：套利策略产品奖、“全明星”团队奖；
? 东方财富风云榜：最受欢迎股票量化策略私募基金产品；
? 中国量化投资风云榜：最佳复合策略奖；
? 亿信伟业第二届金亿奖：最佳复合策略奖；
? 国金证券：年度最佳奖（量化对冲策略）；
? 财视中国：Top10量化投研团队；
? 排排网百舸奖：最佳相对价值策略、最佳复合策略、最受投资者喜爱私募基金经理；
? 资管网：最佳股票对冲策略基金；
? 格上财富招商证券金樟奖：最佳套利策略私募基金、最佳量化复合策略私募基金；
? 好买财富：十大新基金；
? 朝阳永续中国私募基金风云榜：对冲类套利策略季军；
? 智道金服第一届金梧桐：最佳管理期货；
? 金斧子首届私募大会：至尊新锐奖、最受投资者信赖奖；
? 东方财富风云榜：最受欢迎私募基金公司；
? CCTV证券资讯频道央证私募风云榜：最佳相对价值策略；
? 全球量化金融峰会中国量化投资风云榜金矿奖：最佳套利策略、最佳复合策略、最具潜力量化投资公司；
? 朝阳永续年度中国私募基金风云榜：最具潜力私募；
? 资管网年度：最佳套利策略基金；"
"职位描述：
        
        【工作职责】
1、负责公司数据分析、加工、清理、处理程序的开发工作；
2、从事研究相关的数据分析、挖掘相关工作；
3、负责数据相关平台的搭建、开发、维护、优化工作；
4、配合投研平台开发及策略开发等工作；
【职位要求】
1、熟练使用python，理解基本的数据结构和使用场景，对python语言的本质和底层有一定了解。有基本的工程师思维，和基本的代码实现能力，能够运用python解决现实中的问题，并有至少一两个python相关的工程项目经历，1000行代码以上为佳。
2、熟练掌握pandas，熟练掌握pandas的常用用法，以及熟悉pandans的高级用法，如groupby、rolling、multiindex，merge。
3、有过相关数据分析经历，处理过非结构化数据，理解数据分析的基本图表形式，包括但不限于柱状图、饼状图、Box、Kde 等
4、熟悉sql语句，能进行基本的增删改查，merge等操作。了解sql语句的高级用法如，rank over、partitionby等。
5、有基本的统计学知识，概率分布、统计检验，参数估计，相关知识，熟悉线性回归。
6、有过相关的数据挖掘经历，有一定的特征工程经历，对特征工程中的技术有自己的理解，了解基本的机器学习算法。
7、有一定的投资经历为佳，包括但不限：股票、期货、债券、外汇、基金、数字货币等。
8、对宏观经济，金融市场运行机制有一定的见解。"
"职位描述：
        
        岗位职责： 1. 深入理解业务，建立完善的BI数据开发和分析体系。 2. 对接业务方数据分析需求，提供分析结果和结论。 3. 通过数据分析洞察业务或市场规律，监测产品或运营状况，提出和推进落实改造方案。 4. 负责数据提(爬)取、处理、分析和展示等数据相关工作。

岗位要求：
1. 本科及本科以上学历，3年以上数据开发或分析相关工作经验。 2. 熟练使用scrapy爬虫框架、redis、mysql等数据处理语言或工具。 3. 熟练使用kylin等大数据分析OLAP平台。 4. 熟悉Hadoop、HDFS、HIVE、HBASE等大数据组件。 5. 能独立完成从数据提(爬)取、处理、分析到报告产出整个分析流程工作。 6. 具备优秀的需求分解能力及沟通表达能力。 7. 拥有Superset类似应用经验的优先。"
"职位描述：
        
        
数据开发工程师
岗位职责：
1、负责公司大数据基础平台的部署、运维管理和优化，保障平台稳定可靠高效运行，提升数据处理效率
2、提炼数据产品需求，设计数据分析思方法，协作并推动数据产品和数据分析的落地?
3、与数仓团队协作进行数据建模工作，推动业务部门的数据化运营?
任职资格:
1、丰富的Java研发经验，熟悉Python，Linux Shell，精通Hive SQL开发
2、熟悉大数据技术栈，对Hadoop、Hive、Spark、Hbase、Kafka、ELK等开源组件有使用及优化经验者优先；
3、有后端服务系统的设计和实现经验，有独立的微服务开发能力；
4、扎实的计算机基础，熟悉常用的数据结构和算法，熟悉Linux系统环境；"
"职位描述：
        
        职位诱惑：
融洽的工作氛围、百万项目奖金
职位描述：
岗位职责：
1、 参与部门大数据产品的需求分析，模块架构设计；
2、 参与系统的结构分析、数据库、接口设计；
3、 能独立完成JAVA后台程序的设计工作，负责模块核心代码编写；
4、 对大数据生态圈集群有深刻的理解，能基于大数据平台完成应用产品的开发，并对出现的大数据平台相关问题进行故障解决和优化；
5、 根据业务需求，提出最优的技术解决方案；分解详细的开发任务；
6、 对高可用、可扩展、调度器等概念有一定的理解。
任职要求：
1、 计算机相关专业毕业，本科或以上学历，4年以上Java开发工作经验，1年以上Hadoop等大型平台项目开发经验优先；
2、 精通Java研发，有扎实的软件理论基础，深刻理解面向对象编程，良好的面向对象分析设计能力；
3、 熟悉Spark/HBase/Hive/Redis等大数据技术；
4、 熟悉J2EE主流技术框架，对Spring MVC/Spring/dubbo/Mybatis等开源框架有应用实际经验，精通关系型数据库及SQL语言，熟悉NoSQL/JSON/XML；
5、 具备使用Spark Streaming、kafka等流式技术框架进行开发的经验优先，对大数据量下的数据存储和查询具备一定的开发和设计经验优先；
6、具有较强成就动机、创新精神、抗压能力。
?
公司地址：成都市高新区科园三路四号火炬时代C座2楼
薪资福利：月薪*12+年终奖（激励性强）；五险一金；免费工作餐
工作时间：9:00-18:00 或8:30-17:30；午休：12:00-13:30

我们是这样的团队：
1、融洽的团队氛围，给你家庭般的温暖
2、团队都是王者荣耀、麻将爱好者，玩得尽兴
3、团队属于高速发展期，机会多多
4、百万项目奖金，有能力就来拿"
"职位描述：
        
        职位描述：
1、负责大数据平台产品开发，主要为数据集成产品线的系统开发、参与文档编写等；
2、负责高并发、大存储的数据系统，实时计算处理系统的研发；
3、负责海量数据的处理、分析、挖掘。
任职要求：
1、2-3年java web开发经验,熟悉springmvc；
2、学习能力较强；
3、熟悉spark，flink开发；
4、根据分配的任务完成设计文档编写和开发工作
5、熟悉ETL流程，有DataX,flume,sqoop,Kettle开发经验优先"
"职位描述：
        
        应届毕业生或者1年左右经验的
计算机相关专业的，会编程
算法好，踏实，肯沉下心来学习的。"
"职位描述：
        
        岗位职责：1、负责公司数据平台的搭建维护，包括但不限于数据仓库、用户画像、营销分析、报表等数据产品的规范和开发；?2、负责大数据平台的开发和维护工作，贯彻落实性能、稳定性、可靠性等方面的优化，保障大数据平台的安全、平稳运行；?3、协助完善数据的分析挖掘流程体系。岗位要求：1、精通Linux/Unix环境，熟悉Java、Scala、Python开发，能作为技术担当，解决核心技术问题；?2、2年以上大数据项目实战经验，对大数据生态体系有较深的了解，有海量日志和数据处理经验;?3、熟悉Hadoop、HBase、Spark、Hive、Kafka、ES、Impala、Kylin等框架，并且有相关的调优经验；?4、熟悉Oracle、Mysql等关系型数据库；?5、熟悉整个大数据的处理流程（采集、清洗、预处理、存储、分析、数据可视化等）；?6、熟悉git、maven、junit等工具和开发，注重开发规划；?7、了解大数据相关算法，熟悉分布式系统原理，及微服务原理;?8、有金融支付领域工作经验优先，热爱编程和数据处理。"
"职位描述：
        
        岗位职责：
1.负责公司后台功能的设计、开发与维护；
2.参与数据库及系统模块设计与开发；
3.修正现有系统的故障和缺陷，维护软件的稳定性；
4.配合其他同事完成开发工作，满足其他部门的数据需求；

任职要求：
1.本科及以上学历，2年以上JavaWeb开发经验；
2.精通Java语言，熟练使用Eclipse，Tomcat开发工具；
3.精通sql server数据库和 SQL 查询语言，对Mysql等有一定了解；
4.熟练使用struts2、spring3、hibernate3等框架；
5.掌握良好的前端技能，包括JSP、Servlet、JavaScript、Ajax、Jquery；
6.熟悉Linux操作系统；
7.了解Kettle等ETL工具；"
"职位描述：
        
        工作内容：
1、??? 搭建维护hadoop、hbase、spark等集群并进行必要的troubleshooting，保障系统正常运行；
2、??? 提高集群的使用效率及稳定性，并对整个系统做合理分离，满足各种应用场景的使用；
3、??? 构建集群监控体系、可视化体系、调度系统，保障集群安全和数据安全；
4、??? 数据使用开放平台;
5、??? 各个业务线的数据接入及数据一致性建设。
?
任职要求：
1、??? 计算机相关专业统招本科及以上学历；
2、??? 熟悉linux平台shell/python脚本开发，并最少熟悉一门编程语言；
3、??? 熟悉hadoop系统，对hdfs、hbase、hive、spark等分布式体系有丰富的研究及实践；
4、??? 熟练书写常见的sql语句，并对常见的数据接入技术架构flume，kafka，sqoop等有丰富的经验；
5、??? 对服务器集群有较深的理解；
6、??? 有强烈的责任心和优秀的学习能力。"
"职位描述：
        
        职位描述：1、负责核心数据产品开发；?2、负责离线/实时数据计算的开发，维护；职位要求：?1、本科及以上学历；2、1年及以上JAVA开发经验，了解设计模式、数据结构；3、熟练掌握MySql，Redis等数据库的使用和优化；4、有hive、kylin,、spark、oozie、hue、impala、hbase开发经验者优先；5、严谨的逻辑思维，强烈的技术热情善于合作喜欢有挑战性的工作；"
"职位描述：
        
        职位描述：1、负责核心数据产品开发； 2、负责离线/实时数据计算的开发，维护；职位要求： 1、本科及以上学历；2、3年及以上JAVA开发经验，了解设计模式、数据结构；3、熟练掌握MySql，Redis等数据库的使用和优化；4、有Hive、Spark、Flink、hbase、ES、Druid开发经验者优先；5、有CDH集群运维经验优先；6、严谨的逻辑思维，强烈的技术热情善于合作喜欢有挑战性的工作；"
"职位描述：
        
        工作职责：1.后台数据仓库(实时/离线)开发设计2.大数据集群组件运维调优工作要求：1.统招本科及以上学历，计算机、软件工程等相关专业，3-5年左右大数据工作经验； 2.数据仓库维护开发经验，对业务非常敏感，有过出行数据仓库设计经验优先；3.熟悉大数据开发基本问题、工具和方法，熟悉并使用过各种大数据相关框架或组件如Kafka、Flink、Hadoop/Spark、Hive、HBase等，精通Java和ETL开发；4.对即席查询、OLAP引擎有使用、调优或源码阅读/修改经验。如presto、kylin、elasticsearch、druid等；5.算法基本功扎实，熟悉常用的数据结构，编码能力强；6.有实时数据仓库建设经验（加分项）"
"职位描述：
        
        职责描述：
1、建立质量数据管理体系,定义数据规则,数据库维护，数据需求开发；
2、业务数据挖掘与分析，提供数据指导及支持；体验核心指标体系完善及持续跟踪；
3、协助线下运营制定问题整改计划，并追踪整改进度；制定预案，控制尾部发生概率；
4、协调项目推进的相关资源；结合常见问题，推动改善项目；

任职要求：
1、本科以上学历，数学、统计学、计算机相关专业；
2、熟练操作EXCEL（常规函数、数据透视表、图标制作等），PPT撰写分析报告；
3、熟悉掌握MY-SQL、SQL Server等数据库，是使用相关分析工具进行数据分析，熟悉统计分析，数据挖掘相关方法；
4、拥有良好的跨部门沟通能力和业务理解能力，具有较强的数据敏感度和逻辑推理能力，有互联网行业应用经验者优先；"
"职位描述：
        
        职位描述：
1.??为海量数据的处理和分析提供高效解决方案
2.??研究Hadoop/Spark/Hbase/Hive等开源项目，对线上任务进行调优，并开发通用组件
3.??维持线上服务高效稳定，支撑业务和数据量的快速扩张
职位要求：
1.??扎实的计算机系统和算法基础知识；良好的英文阅读能力
2.??扎实的Java、Scala语言基础，对JVM运行机制有深入了解
3.??熟悉Hadoop、Spark并有丰富的开发经验
4.??对常见开源框架代码有研究
5.??熟悉SQL和noSQL的设计和开发
6.??熟悉企业应用设计模式、面向对象的分析和设计技术，包括设计模式、UML建模等
7.??善于思考，能独立分析和解决问题，热衷于互联网技术的研究和创新
8.??责任心强，具备良好的团队合作精神
9.??有深入研究过Hadoop/Spark源码者优先
10.??有OLAP系统设计经验者优先"
"职位描述：
        
        岗位职责：1、负责业务相关WEB平台设计和开发工作；?2、负责基础服务组件，解决实际需求，减少重复开发；?3、负责大数据相关的数据集成，数据处理，数据清洗等工作(PYTHON)。
任职资格：1、精通使用Python语言，有实际Python?Web项目经验，至少有tornado、Django、flask框架之一的开发经验；?2、熟练使用数据处理,以及机器学习相关，如Pandas,numpy,Scipy，Scikit-Learn，Matplotlib等；3、了解常用的xboost等机器学习算法优先；4、熟悉Spark相关技术，至少有1年pySpark开发经验；?5、熟悉自动化配置管理工具如saltstack、Ansible，了解Serverless并对AWS?Lambda有实践经验?；?6、熟悉MySQL/Redis/MongoDB/hive/hbase等，熟练编写SQL以及改写优化；?7、熟悉Linux/Unix操作系统，熟练shell编程；?8、熟悉JavaScript,jQuery,HTML,CSS等前端技术，有react、vue开发经验者优先；?9、具备较强的学习能力和责任心，良好的沟通能力、文档编写能力，有github开源项目者优先；10、喜欢钻研开源技术及自动化技术，具有较强的分析、解决应用问题的能力。"
"职位描述：
        
        这是一个为商业人工智能领域构建实时大数据分析平台的工作机会。我们希望您具备计算机科学或者相关专业领域的专业背景，并拥有构建分布式可扩展数据处理及大数据存储方面的丰富经验。您将担任跨职能的团队中的重要角色。我们希望您斗志昂扬，注重结果，积极主动，具备推动产品的增长和成功的成功经验。
?
工作职责

 在云端或者本地集群上构建可扩展的实时数据处理流水线，收集、转换、加载并管理各类数据源
 构建可扩展的分布式数据存储
 确保所构建的数据处理管道具有高质量并可审计
 开发相关工具以优化数据的提取、分析及可视化效率
 评估数据工程领域的新技术，并开发原型，以持续改善工作
 与框架和其他团队合作，确保系统运行符合设计预期

?
工作要求

 全日制硕士以上学历，计算机相关专业，CET6
 具备大数据相关技术例如Spark, Kafka, Hadoop, HBase, Hive等的丰富经验
 具备五年以上Java、Scala、Python相关工作经验，MySQL， Redshift等SQL相关经验
 具备三年以上可扩展实时ETL开发经验
 熟悉Azure/AWS/GCP相关工具与知识
 良好的书面/口头沟通技巧
 具备机器学习算法方面工作经验者优先"
"职位描述：
        
        岗位职责：
1. 负责公司项目应用监测数据，分析软件大数据平台的代码开发；
2. 负责大数据体系架构设计和应用产品的研究；
3. 负责大数据平台及应用场景的构建、部署、测试；
4. 编写软件研发相关技术文档；
5. 编写产品研发相关任务单计划，阶段性代码、技术方案和软件产品及时提交至配置管理理库；
6. Spark程序的研发，sqoop脚本开发和商家用户行为等离线分析数据；
7. kudu，kylin等技术调研，编写软件研发相关技术文档；
8. SUNMI数仓设计架构以及ETL流程开发；
9. 建立多维度，多体系的用户标签体系以及用户行为数据库。

岗位要求 ：
1. 本科以上学历，4年以上?工作经验，2年以上Hadoop平台的相关研发经验，具有良好的需求分
析，方案设计，架构设计，程序编写、测试能力；
2. 熟悉J2EE或Python平台开发，有良好的Java或Python语言功底；
3. 了解Linux/Unix操作系统，了解脚本编程(Shell/Python其中一种）；
4. 具备数据中心资源管理（YARN）、监控（ClouderaManage）、调度（Azkaban）等系统研发经验者优先，具备分布式系统研发经验者优先；
5. 熟悉hadoop以及其?生态圈系统上的hive、hbase、sqoop、spark、spark-streaming等技
术，懂hadoop源码者优先；
6. 熟悉Kylin有OLAP平台设计和开发经验优先；
7. 具有应用大数据技术处理TB级以上数据的项目开发经验者优先；
8. 有较清晰的代码编写规范，逻辑性强，工作态度认真，良好沟通能力和团队合作精神。"
"职位描述：
        
        工作职责：
1.?通过大数据建模，分布式并行计算，机器学习等技术，结合业务需求，研发创新产品和技术平台
2.?参与产品架构讨论，影响产品路线图，强责任意识实现项目目标
基本要求：
1. 3年以上大数据相关项目经验，包括但不限于大规模时序数据存储和计算，分布式向量检索聚类等相关应用
2. 3年以上大数据相关技术应用经验，包括但不限于Spark/Hadoop/HBase/Elasticsearch等相关技术
3.?熟悉使用Python实现预定的算法逻辑，建立评估测试体系，并进行调优工作
4.?熟悉Linux系统原理及分布式技术，熟练把握算法准确率，IO及计算性能之间的平衡
满足以下条件者优先：
1.?有和研究员合作经历的优先
2.?有大数据基础平台建设经历的优先
3.?熟悉GPU体系结构，有Nvidia CUDA开发经验
4.?开源项目贡献者和维护者"
"职位描述：
        
        岗位描述：1. 基于分布式技术构建数据平台，解决海量视觉数据的存储、计算需求2. 将人工智能与分布式计算相结合，构建高性能的视觉数据处理流程和系统3. 构建多元化的数据分析解决方案，实现海量视频、图像与业务数据的分析和挖掘任职资格：1. 本科或以上学历，计算机相关专业，2年以上相关工作经验2. 熟悉Linux开发环境，熟练掌握C++/Java/Scala/Python等任一编程语言，算法基础扎实，编码能力优秀3. 了解分布式系统的基本原理，具有分布式存储、计算平台（Hadoop、Spark等）的开发和实践经验，熟悉相关系统的运维、调优方法4. 有一线互联网公司大数据处理、数据仓库建设、及数据安全等方面工作经验者优先5. 有图像处理、深度学习相关研发经验者优先6. 责任心强，具有良好的学习能力、沟通能力和团队合作精神"
"职位描述：
        
        工作职责:1. 负责企业级数据仓库建设和管理，包括但不限于数据质量、数据模型、数据安全相关标准的制定2. 负责数据仓库设计，构建面向应用场景的数据模型和数据集市3. 负责数据规范定义和实施，包括但不限于数据采集/回收，用户标识，标签体系，存储模型等4. 深入理解数据业务，管理公司全域数据资产，构建业务模型，提升数据的易用性任职资格:1. 本科及以上学历，计算机、数学、统计等相关专业，四年以上相关工作经验2. 拥有良好的编程能力，熟练掌握Hive/Scala/Python/Java中至少两种编程语言，算法基础扎实，编码能力优秀3. 拥有数据仓库模型设计与ETL开发经验，建设过复杂业务数据仓库者优先4. 拥有数据仓库领域知识和技能，包括但不局限于：元数据管理、仓库模型、数据开发测试工具与方法、数据质量5. 熟练掌握开源大数据处理技术栈，有Hadoop/storm/hive/spark等计算框架使用经验，深入阅读或修改过源码者优先6. 责任心强，具有良好的学习能力、沟通能力和团队合作精神"
"职位描述：
        
        工作职责:1、负责公司大数据平台技术架构设计、平台建设， 大数据应用开发。2、对海量数据进行挖掘分析，构建数据模型及监控体系；3、将数据分析能力应用于业务进行实践落地。任职资格:1、本科以上学历，统计学、数据挖掘、机器学习的相关理论基础扎实；2、3年以上的海量数据处理工作经验，对主流大数据技术有深入了解，如hadoop、hbase、spark、flink等等；3、熟悉常用的分类、回归、聚类等算法及应用场景，并有相关实战经验；4、有互联网、人工智能行业数据分析经验优先；5、热爱技术，认真严谨，对系统运行质量、性能有苛刻的自我要求。"
"职位描述：
        
        岗位职责：
1、理解业务，基于大数据平台，进行业务指标开发和维护，对业务需求部门进行数据支持
2、根据业务部门需求，充分利用现有数据资源，进行数据提取、整理和挖掘(ETL)
3、建立及优化和维护大数据平台数据仓库，解决技术问题
4、要求完成开发工作和相关文档编写
要求：
1、熟悉Linux常用操作
2、熟悉Oracle sql，了解Hive，Shell，Java
3、善于沟通，工作细心、负责
4、代码习惯良好，文档书写清晰"
"职位描述：
        
        工作职责?
1. 负责推荐系统核心算法设计与优化（社群，Feed）；?
2.具体技术方向包括但不限于推荐排序模型优化、召回模型优化、用户意图建模等；?
3. 负责某个业务方向，带领团队与产品经理有效沟通，推进算法在业务中的应用，以技术驱动业务发展；?
岗位要求:?
1. 计算机、数学相关专业，3年以上互联网公司工作经验；?
2. 有多年推荐方向算法研发经验；?
3. 深入理解常用的推荐算法，熟悉机器学习的前沿技术和业界动态；?
4. 优秀的领导力、推动力和沟通能力；?
5. 有知名互联网公司工作经历；?
6. 有阿里云推荐工具使用经验优先；"
"职位描述：
        
        职位描述：
1、负责HDFS/Yarn/Spark/Hive的故障分析，性能改进和功能扩展。2、负责处理大数据平台Hadoop/Hive/Spark的疑难问题，为Hadoop开发者提供可靠的技术支持。
3、确保Hadoop关键作业及时完成，保持作业稳定运行。职位要求1、计算机软件相关专业，Java3年以上开发经验。
2、对技术有追求，能够刨根问底的搞定技术问题。3、熟悉Hadoop/Spark/Hive等开源项目，精通其中一种源码，有patch源码经验者优先。
4、大规模集群调优有经验者优先。"
"职位描述：
        
        职位描述：
1、负责HDFS/Yarn/Spark/Hive的故障分析，性能改进和功能扩展。2、负责处理大数据平台Hadoop/Hive/Spark的疑难问题，为Hadoop开发者提供可靠的技术支持。
3、确保Hadoop关键作业及时完成，保持作业稳定运行。职位要求1、计算机软件相关专业，Java3年以上开发经验。
2、对技术有追求，能够刨根问底的搞定技术问题。3、熟悉Hadoop/Spark/Hive等开源项目，精通其中一种源码，有patch源码经验者优先。
4、大规模集群调优有经验者优先。"
"职位描述：
        
        岗位职责：
1、负责电商搜索领域的数据挖掘、日志分析工作。
2、搭建数据管理平台，数据流的维护和优化。
3、负责电商搜索相关数据指标的统计和监控。
职位要求：
1、计算机相关专业，本科以上学历；
2、熟悉Linux开发环境，熟悉shell、scala、python等脚本语言开发；
3、熟练使用Hadoop、Hive、Storm、Spark、Spark-streaming等大数据平台工具与
4、具有大规模数据收集、日志处理、实时数据收集处理等项目经验；
5、工作认真细心，对数据敏感；
6、具有优秀的沟通能力和团队合作精神。"
"职位描述：
        
        工作职责：
1. 唯品会数据体系综合建设及运营，不断提高离线/准实时数据体系运转&应用的时效性与稳定性
2. 业务&流量&归因等核心数据模型的开发及迭代，保障数据模型面对业务变化的快速适应
3. 统计&分析型数据产品线的建设及运营，降低信息不对称，打破有限理性，提高决策效率
4. 聚焦数据及业务，通过机器学习，以智能化产品为依托，增加价值创造，提升综合运营水平
?
岗位要求：
1. 计算机相关专业本科及以上学历
2. 熟悉hive、spark、presto中1~2种常用的大数据处理技术
3. 掌握数据统计分析相关知识
4. 做事认真细致，有良好的逻辑思维及沟通能力
5. 热爱互联网及电商行业，善于学习和总结分析
6. 有机器学习、算法应用经历者优先
7. 有海量数据开发或分析相关经验者优先"
"职位描述：
        
        工作职责：
1、主导大数据平台的设计与开发，解决海量数据面临的挑战；
2、管理、优化并维护Hadoop、Spark、Storm、Hbase等集群，保证集群规模持续、稳定；
3、负责HDFS/Hive/HBase/Storm的功能、性能和扩展，解决并实现业务需求；
4、协助建立数据模型，对数据进行挖掘、优化及统计。
职位要求：
1、本科及以上学历，2年以上java web或java后端开发经验，外加2年及以上大数据平台开发经验；
2、熟悉并理解Hadoop/HBase/Spark/Storm/Hive/Zookeeper/Azkaban/Oozie/Hue等大数据开源框架，熟悉数据挖掘策略与算法；
3、熟悉微服务架构和实现技术，熟练掌握spring boot、spring cloud等框架。
精通主流开源应用架构和技术，如spring、mybatis、struts2、dubbo等
4、熟悉分布式系统设计范型，有大规模系统设计和工程实现的经验；
5、熟悉消息队列ActiveMQ、RabbitMQ、Kafka等；熟悉Redis、Memcached等缓存技术；熟悉MongoDB、Hbase等Nosql技术;
6、熟悉MySQL等关系型数据库以及数据库调优、SQL优化；
7、数据控，善于发现问题、解决问题，对新兴技术有好奇心，有利用技术解决实际问题的热情，开源社区积极参与者优先。"
"职位描述：
        
        工作职责：
1. 参与数据中台建设，包括数据查询平台基础建设、实时和离线大数据计算及交互式查询分析等
2. 参与大数据基础架构和技术体系的规划建设，包括数据采集平台、数据质量及稳定性保障体系、数据处理智能化和自动化体系的建设。

任职要求
1，本科以上学历，计算机相关专业，工作经验5年及以上，3年以上大数据相关开发经验；
2，熟悉Linux，精通Java/Scala语言中的一种或多种，熟悉Java技术栈；
3，熟悉大数据领域的技术栈，如Spark/Flink/Hadoop/Hive等,尤其对spark执行原理及使用调优有深入见解者优先；
4，具有数据平台/数据产品的完整搭建经验，实时大数据经验，大规模并发请求经验；
5，熟悉数据库，有 MySQL或TiDB调优经验者优先，有一定的数据敏感度和安全意识;
6，具备线上系统性能优化经验，生产系统快速 trouble-shooting 的能力，擅长分析更接近本质的原因；
7，良好的人际沟通和团队协作能力，有责任心
?
行业标杆，高速成长， 团队活跃，平台广阔，交通便利！前景，专注于本地生活最大的领域――餐饮O2O；晋升，广阔的职业发展空间，越努力你就越幸运；氛围，那是年轻人的世界，公司营造各种交流机会，帅哥MM你懂的；环境，舒适高大上的办公环境，西直门地标建筑二十二层，没有雾霾还可看见西山落日。哗啦啦（www.hualala.com）期待你的加入！"
"职位描述：
        
        工作职责：
1、负责直播数据部门整体技术规划；
2、根据业务需求变动，推进持续迭代数仓、数集建设；
3、推进用户画像持续完善；
4、推进大数据上层应用持续迭代，包括?BI自助平台、业务/技术分析报告、直播风控系统、直播推荐系统等。

职位要求:
1、本科及以上学历，计算机基础扎实；
2、5年以上互联网开发经验，3年以上数据相关工作经验；
3、熟悉Java/scala编程，熟悉?Hadoop/Spark?相关技术，有大中型数据仓库实践经验、用户画像实践经验；
4、业务敏感，有强数据驱动意识；
5、具备优秀的团队协作、沟通能力，有强责任心和强执行力；
6、有算法策略经验者优先。"
"职位描述：
        
        工作职责：
1、负责大数据平台产品的设计研发，完成产品的核心功能、公共核心模块的代码编写；
2、负责应用规划及架构设计，能够出具完成的应用实施解决方案，包括：系统架构设计、接口规范制定、技术文档编写等；
3、具备良好的沟通表达能力，协同他人并组织跨团队协作，保证项目质量与进度。

职位要求：?
1、3年以上的开发经验；
2、扎实的Java编程基础，熟悉各种设计模式，熟练掌握；Spring/Struts或其他主流Java框架，对代码质量有追求；
3、具备大数据处理的架构经验，熟悉典型业务场景下的数据架构方式，有关系型数据库、NOSQL数据库及内存数据库的综合运用经验；
4、了解常见的分布式计算平台Hadoop、Hive或Storm等优先；
5、具备良好的沟通技能及团队协作意识，有能力针对特定场景或要求给出合理的技术解决方案，并跨部门协调完成；
6、具有灵活解决问题能力和抗压能力。"
"职位描述：
        
        工作职责：
1、负责大数据底层组件(hadoop,spark,presto,hbase,kafka)的troubleshoot
2、基于大数据底层组件的定制开发工作


职位要求：
1、全日制本科及以上学历，计算机相关专业，两年年以上工作经验；
2、有一定的研究、实验的能力，沟通能力强，优秀的分析问题和解决问题的能力；
3、熟练掌握Java语言，掌握基本的分布式理论
4、熟悉Hadoop、Hbase、Hive、Spark等大数据处理平台和工具者
5、有过大数据生态底层源码开发经验优先"
"职位描述：
        
        工作职责：
1、广告产品的DMP用户画像平台搭建
2、广告产品的商业智能BI系统搭建
3、数据产品基础设施的架构、研发、优化
职位要求：
1、5年以上大数据及分布式计算研发经验，对海量数据、数据仓库技术具有浓厚的兴趣；
2、熟悉Oracle 、Mysql等关系型数据库，能独立完成数据仓库结构设计、ETL设计和开发；
3、熟悉Hadoop 、Spark、Storm、Flink、Kafka、Redis等分布式计算架构体系；
4、熟悉Impala、Druid等实时OLAP大数据查询和分析系统；
5、熟悉Linux 环境，熟悉 Shell脚本开发，能进行分布式环境的搭建、日常维护和问题处理；
6、热衷开源社区，有开源作品者优先；有优秀技术博客者优先。"
"职位描述：
        
        【岗位职责】
1、负责数据统计与分析的研发与维护；
2、根据产品经理和运营团队等的统计需求，进行开发实现；
3、负责对用户行为数据的深度挖掘，以数据指导产品改善；
【任职要求】
1、全日制本科及以上学历，3年以上工作经验；
2、Java基础扎实，熟悉Netty、IBatis等开源框架，懂JVM调优更佳；
3、熟悉HBase、Spark/Storm、MapReduce等数据框架；
4、熟悉Kafka、LogStash、Redis等数据中间件；
5、良好的SQL语句功底，熟悉MySQL、PostgreSQL、Oracle数据库中的一种；
6、有日志收集相关经验或者数据仓库建设和BI经验优先；
7、逻辑清晰，快速的学习能力及良好的沟通能力。"
"职位描述：
        
        工作职责:1.在深刻理解公司业务的基础上，利用开发的数据产品及时发现定位线上业务出现的问题；2.为实现部门沟通及业务质量的提升开发数据平台，搭建数据桥梁；3.负责满足常用业务需求的数据开发，支持研发及运营部门的数据需求；
任职资格:1.3年以上开发经验，熟练使用编程语言，Scala/Python/Go/Java中的至少两种开发语言；2.有实时任务，搜索引擎，规则引擎，spark/flinkml等在线项目的第一手开发经验；3.熟练使用SQL并精通SQL调优；4.熟悉常用分布式框架的原理、架构、调优；5.熟悉数仓维度建模建设方法，及常用数据库（Mysql，Postgrepsql）技术；6.有良好的团队协作能力，强烈的责任心和自我驱动力。"
"职位描述：
        
        职位描述：
1.??????负责核心业务模块数据仓库的构建；
2.??????负责数据模型的设计，ETL实施、ETL性能优化、ETL数据监控以及一系列技术问题的解决；
3.??????负责全产品线数据字典维护，提升数据资产质量。
4.??????负责大数据产品的整体架构设计；
5.? ? ?负责大数据相关的技术进行前瞻性研究，为团队提供长远的技术储备。
人员任职要求：
1.??????计算机、数学相关专业本科及以上学历，三年以上大数据开发工作经验；
2.??????熟练掌握Hive/SQL，熟悉Spark/Map-Reduce分布式计算框架，
3.??????熟悉大数据的离线和实时处理，可以进行海量数据模型的设计、开发；
4.??????熟悉ElasticSearch,HBase优先;
5.??????工作认真，负责，良好的团队合作精神和解决问题分析能力。钻研技术克服困难，勇于挑战；
有数据分析经验优先。"
"职位描述：
        
        工作职责：
1.参与构建适用于亿级交易规模的商业数据产品；2.参与超大规模实时/离线数据计算框架，存储、查询、可视化解决方案的设计、研发。"
"职位描述：
        
        岗位职责：
1. 负责原始处理，包括关键词提取、主题分析、类目预测、质量打分等；
2. 负责海量用户行为的分析研究，挖掘优化用户画像，包括人口属性，用户标签，用户兴趣等；
3. 负责推荐引擎算法的开发，包括各类推荐算法的实现、特征和参数调优、用户体验优化等；
4. 负责数据营销广告平台策略的开发，包括用户洞察、行业指数趋势预测、各类精准定向算法的实现和优化等。
岗位要求：
1. 本科及以上学历，计算机、应用数学、模式识别、人工智能、统计学等专业；
2. 具备数据挖掘、NLP、机器学习、深度学习等算法原理知识背景；
3. 具备推荐系统、精准营销、信息检索等方面的工作经验优先；
4. 具备大规模分布式计算平台的使用和并行算法的开发经验；
5. 熟练掌握至少一种编程语言，Java、Scala、C++、R、Python；
6. 熟练掌握至少一种机器学习库，Scikit Learn、Spark MLlib， Tensorflow。"
"职位描述：
        
        职位描述：
负责公司大数据平台项目的存储、计算等框架的系统开发。
任职要求：
1、三年以上大数据工作经验，5年以上工作经验；
2、熟悉Java，Scala开发；
3、熟悉Shell、Python中的一种；
4、熟悉大数据生态技术，有Spark、Hadoop、Hive实际项目经验；
5、熟悉常用关系数据库、NoSQL数据库，熟悉结构化和非结构化建模，具有丰富的数据库设计经验；
6、熟悉分布式系统的设计和应用，熟悉负载均衡和高可用机制的实现；
7、能够解决线上的疑难问题，并能给初步开发者指导和帮忙；
8、有较强的沟通的能力和理解能力，有较强的抗压能力。
9、有大数据生态圈底层开发经验或对Spark源码有深入研究者优先。"
"职位描述：
        
        技能要求：
Spark，Hive，Hadoop,?Java/Scala，MySQL，Shell
职位描述：
1.负责数据抽取标准、规范；
2.负责需求分析，数据建模，清洗，数据质量校验；
3.负责前瞻性技术预研，团队分享；
4.负责数据仓库的日常管理和维护；
职位要求：
1.具备2年及以上大数据开发相关工作经验；
2.熟练掌握Java或者Scala一种语言；
3.熟悉Oracle,mysql等主流数据库；熟练掌握标准SQL语言及大数据SQL语言；
4.熟悉主流开源大数据处理平台，如Spark，Hdaoop，Hive等两种或多种；
5.熟悉Linux系统，熟悉Shell，Python等脚本语言，能快速根据业务需求开发ETL脚本；
6.具备良好的语言沟通和表达能力和自我驱动能力。"
"职位描述：
        
        能力要求：
1、计算机科学与技术或相关专业本科及以上学历；
?
2、4年以上相关工作经验，了解数据可视化技术，熟悉BI数据展现；
?
3、精通一种前端框架如angular、 react、 vuejs等，精通ds.js、three.js、echarts 等至少一个数据可视化框架或类库。
?
4、学习能力强，有较强的问题分析和处理能力，具有团队合作精神；
?
5、精通svg、canvas、webgl、GoJS等web前端绘图技术及标准者优先。
?
?
职位描述：
1、负责大数据查询分析、商业智能决策、核心业务策略等大数据系统的可视化平台建设工作；
?
2、负责大数据相关平台可视化页面和前端交互的开发和优化；"
"职位描述：
        
        职位描述：
1、数据分析平台的设计和开发，为数据分析和运营等人员搭建友好高效的数据产品；
2、核心实时指标、离线指标、图计算指标开发；
3、其它大数据平台技术相关的技术工作。

岗位要求：
1、熟悉分布式系统的基础理论知识，了解大数据处理的常用算法；
2、熟悉Java或Scala语言，有扎实的开发功底；
3、熟悉Spark/Hadoop，Hbase，Storm，Kafka等大数据处理框架；
4、有图计算经验和大数据平台开发经验优先。"
"职位描述：
        
        岗位职责：
1. 负责云控基础平台大数据处理系统的设计、开发和优化；
2. 参与云控大数据平台架构的设计工作；
3. 跟踪、研究和应用相关前沿技术；
4. 对相关项目提供技术支撑。
技能要求：
1. 熟悉消息队列的原理，熟练使用Kafka等常用的消息队列；
2. 熟悉Spark、Storm等计算和数据处理引擎的环境搭建、开发和管理；
3. 熟练掌握Redis/Memcached等内存数据库，有过相关使用经验；
4. 掌握数据分析的基本流程，擅长数据采集、清洗、分析等环节，；
5. 熟练掌握Linux的操作和使用。"
"职位描述：
        
        任职要求：
1.大学本科以上学历，计算机、软件相关专业优先；
2.熟悉MySQL，对MySQL的较大量数据存储、优化有丰富的经验；
3. 一年以上基于hadoop、hive、spark等分布式计算环境进行大数据处理经验优先；
4. 熟练使用Linux，熟悉一种以上脚本语言（Shell、Perl、Python等）；
5.对常见的数据分析模型有一定的了解，有海量数据分析项目经验、数据挖掘项目经验尤佳；
6.优秀的解决问题、抗压能力，具有较强的数据分析能力
7.有较强的抗压能力；
岗位职责：
1. 负责数据采集、清洗、存储、展现、监控工具的开发；
2. 参与数据基础架构和处理流程的设计和优化；
3. 为商务智能、运营决策提供可靠稳定的数据平台服务；"
"职位描述：
        
        工作职责
1、负责大数据平台的设计、维护、优化工作；
2、负责数据的实时和离线采集、清洗、计算等工作。
职位要求
1、计算机相关专业全日制统招本科及以上；
2、3年以上大规模数据集处理经验；
3、至少熟练掌握一种主流编程语言（Java、Scala等）；
4、具有Hadoop、Spark等大数据集群部署开发经验；
5、学习能力强，喜欢研究新技术，有团队观念，具备独立解决问题的能力。"
"职位描述：
        
        1.负责大数据架构相关组件的开发、维护和优化
2.负责大数据平台运维管理工具系统的设计和实现
3.确定大数据架构的整体技术路线和架构走向，新技术的调研和落地"
"职位描述：
        
        1.负责大数据平台相关系统产品的设计和研发，包括数据传输平台、数据开发平台、数据治理平台等
2.与数据架构、数据仓库、BI、数据服务等团队合作，构建准确、高效、安全的数据平台"
"职位描述：
        
        【岗位职责】
?1、负责业务系统中数据库相关的任务开发；?
?3、基于商业目标对业务系统中的数据进行分析和挖掘。
【岗位要求】
1、本科及以上学历，3年及以上相关工作经验，英文读写无障碍，能英语口语交流；
2、了解ORACLE/MYSQL/GREENPLUMN等常用数据库，至少熟悉Greenplumn、Oracle其中之一，具有较强的SQL语言功底，有较好的SQL性能调优经验，能独立完成业务方数据需求；
3、熟悉数据仓库各类建模理论，以及数据仓库数据层级关系，具备大模型设计和处理性能调优等相关经验；
4、掌握主流ETL工具使用，熟悉各类主流服务器操作系统windows、linux等。
5、至少熟悉一种以上的主流ETL工具。
6、有hadoop hdfs、hive等相关数据处理经验优先"
"职位描述：
        
        工作职责:1. 利用离线、在线数据，根据业务需求构建图，并进行社团发现与推断等，将获取的知识进行提取、分析与存储2. 对现有的存量数据和实时数据进行入库（neo4j/hdfs/hbase）处理，服务于业务任职资格:1. 本科及以上学历，计算机、数学相关专业，有2年以上的相关经验；2. 计算机基础知识扎实，熟悉图论基础知识；3. 熟悉图数据库的编程接口，熟练掌握python，熟练使用shell、scala等一门脚本语言，有python net-workx开发经验者优先；4. 熟悉spark/hadoop/hive等大数据处理技术，熟练进行图计算数据建模，具有spark graphx / GraphFrames + neo4j开发经验优先；5. 对图数据库neo4j有深入理解，熟练使用cypher语言对图数据库进行模式匹配查询；6. 业务理解能力强、优秀的团队合作能力和沟通能力。"
"职位描述：
        
        工作职责:1、负责数据安全管理，制定数据安全标准及相关指引和流程2、负责Hadoop大数据平台(CDH)安全相关运维工作3、负责数据安全方案和产品中数据脱敏、数据加密等相关模块的技术支撑和落地实现4、追踪前沿数据安全相关技术，有效实现技术转移落地任职资格:1、本科及以上学历，3年以上相关工作经验，精通sql，熟悉Linux基本操作，熟练使用shell，python等脚本工具；2、精通Hadoop生态，具备Kerberos等技术经验；3、熟悉掌握常用的安全协议和组件服务，对Hadoop各组件的权限、安全、Kerberos进行配置管理。熟悉LDAP、SSL、ACL、Kerberos等安全规范与原理和在大数据环境场景的使用；4、参与过中大性大数据项目的架构和设计的优先考虑；"
"职位描述：
        
        工作职责:1、负责Hadoop大数据平台各类数据业务抽象及模型化；2、负责数据仓库ETL设计、开发及自动化工作3、负责Spark的功能扩展和性能优化，使用海量数据解决并实现业务需求，4、设计或配合算法工程师实现算法，解决实体识别、情感分析等相关问题5、使用Hive、Spark进行数据处理，协助建立数据模型；任职要求：1、本科及以上学历。2年以上相关工作经验，精通SQL，精通Java、scala，Python其中至少一门语言，2、熟悉数据库/数据仓库设计3、熟悉Hive、Spark、kafka，Sqoop、hdfs，HBase4，熟悉linux开发环境，掌握shell编程5，参与过中大性大数据项目的架构和设计的优先考虑6、有nlp相关经验者优先考虑任职资格:1、本科及以上学历。2年以上相关工作经验，精通SQL，精通Java、scala，Python其中至少一门语言，2、熟悉数据库/数据仓库设计3、熟悉Hive、Spark、kafka，Sqoop、hdfs，HBase4，熟悉linux开发环境，掌握shell编程5，参与过中大性大数据项目的架构和设计的优先考虑6、有nlp相关经验者优先考虑"
"职位描述：
        
        工作职责:职责:1. ?负责构建大数据分析平台，支持数据分析和挖掘工作2. ?数据分析模块功能开发及维护岗位要求:1. ?计算机相关专业，有扎实的计算机理论基础2. ?熟悉Java/Python等编程语言，熟练使用SQL，有良好的编码习惯3. ?熟悉hadoop、hive、spark、ES等分布式计算和存储平台4. ?技术视野开阔，有强烈的上进心和求知欲，善于学习和运用新知识5. ?善于沟通和逻辑表达，良好的团队合作精神和积极主动的沟通意识任职资格:职责:1. ?负责构建大数据分析平台，支持数据分析和挖掘工作2. ?数据分析模块功能开发及维护岗位要求:1. ?计算机相关专业，有扎实的计算机理论基础2. ?熟悉Java/Python等编程语言，熟练使用SQL，有良好的编码习惯3. ?熟悉hadoop、hive、spark、ES等分布式计算和存储平台4. ?技术视野开阔，有强烈的上进心和求知欲，善于学习和运用新知识5. ?善于沟通和逻辑表达，良好的团队合作精神和积极主动的沟通意识"
"职位描述：
        
        工作内容： ? 负责不同应用场景下的互联网数据采集、解析、清洗、计算，为数据挖掘和机器学习提供支持 ? 负责分布式数据处理平台和服务的开发 ? 参与数据仓库分层设计与开发 ? 参与数据融合、数据统计分析、数据可视化等工作 ? 与团队共同积累和分享新技术、工具岗位要求： ? 本科及以上学历, 有良好的计算机专业基础知识和扎实的编程功底 ? 熟悉Linux平台开发，精通Python/Java/Go三种编程语言中的至少一种 ? 精通一种开源爬虫框架，如scrapy、webmagic、nutch、heritrix等 ? 熟悉常用的分布式计算工具，如Spark、Hive、Flink；  ? 强烈的责任感，优秀的分析问题和解决问题的能力，对解决具有挑战性问题充满激情加分项：  ? 有爬虫框架开发经验  ? 有数据仓库相关开发和使用经验  ? 有机器学习相关应用经验"
"职位描述：
        
        大数据工程师
岗位职责：
1.?? 参与公司数据仓库的建设，负责数据清洗、ETL等工作
2.?? 深入理解公司业务场景，提供准确完善的数据
3.?? 关注开源技术动态，并将最新的大数据计算框架应用到业务场景中。
?
岗位要求：
1.?? 本科及以上学历，计算机、机器学习等相关专业
2.? ?5年以上大数据相关工作经验；
3.?? 精通HQL，熟练编写批次与流式数据处理调度与程序；
4.?? 熟练使用java或者python等对数据进行分析和处理
5.?? 熟练使用大数据相关组件和工具，Hive、Spark、Hbase、GreenPlum、Kafka等等
6.?? 有Spark-Streaming/Storm/Flink中一种或多种实时计算框架使用经验者优先
7.?? 优秀的分析问题和解决问题的能力，对解决具有挑战性问题充满激"
"职位描述：
        
        岗位职责：
1.?? 参与公司数据仓库的建设，负责数据清洗、ETL等工作
2.?? 深入理解公司业务场景，提供准确完善的数据
3.?? 关注开源技术动态，并将最新的大数据计算框架应用到业务场景中。
?
岗位要求：
1.?? 本科及以上学历，计算机、机器学习等相关专业。
2.?? 3年以上大数据相关工作经验；
3.?? 精通HQL，熟练编写批次与流式数据处理调度与程序；
4.?? 熟练使用java或者python等对数据进行分析和处理
5.?? 熟练使用大数据相关组件和工具，Hive、Spark、Hbase、GreenPlum、Kafka等等
6.?? 有Spark-Streaming/Storm/Flink中一种或多种实时计算框架使用经验者优先
7.?? 优秀的分析问题和解决问题的能力，对解决具有挑战性问题充满激"
"职位描述：
        
        岗位描述
1、负责大数据集群中各个子系统的开发运维工作；
2、负责大数据基础技术的调研和选型升级；
3、结合需求设计高扩展、高性能、高可用的技术系统；
任职要求
1、本科或以上计算机相关专业学历；
2、至少精通一种大数据技术，熟悉主流的大数据技术
3、熟悉Java及web应用开发，了解分布式、多线程及高性能的设计与编码及性能调优， 熟悉使用常用关系型数据库，了解SQL优化方法；
4、至少会使用一种脚本语言，包括但不局限于Shell、Ruby、Groovy、Python，能够在日常工作中使用脚本简化工作
5、 熟悉Linux日常工作环境，熟悉掌握常用命令和调优监控手段优先
6、大数据相关开源技术贡献者优先；"
"职位描述：
        
        1.负责负责大数据平台的战略规划、架构规划、团队管理
2.基于历史数据进行平台统计、分析（离线和实时）；
3.基于线上海量日志数据的用户行为分析；?
4.维护现有数据平台正常运行
5.负责整个数据平台系统的优化；
6.负责大数据平台开发变现；
7.负责数据中心大数据方面的其他应用开发。
任职资格：
1、熟悉Hadoop、HBase、Hive、Spark、Mapreduce、Druid、Kafka、Storm或Jstorm、ETL等相关技术或者工具至少3个以上；
2、?熟练掌握基础算法和数据结构和linux开发环境；
3、熟悉hadoop、hbase、spark的源码的优先；
4、精通Java、Python，了解数据挖掘、机器学习、并行计算相关理论；
5、有风控、推荐、人群画像等领域模型构建和调优工作经验者优先；
6、学习能力强，喜欢研究新技术，有团队观念，具备独立解决问题的能力；"
"职位描述：
        
        【工作职责】
1、负责大数据基础服务平台搭建、调试、优化、运维工作，维护平台稳定性；
2、负责大数据平台产品类功能设计、开发；
3、配合数据分析、BI、数据仓库工作，提供数据应用平台功能支持；
4、探索大数据前沿技术发展、引入合适的技术为业务提供服务；
?
【任职资格】
1、计算机相关专业，本科及以上学历；
2、5年以上工作经验，3年以上大数据平台开发、维护经验；
3、精通Hadoop、Hive远离，熟悉大数据生态技术，如Impala、Sqoop、Klein、Flink、Kafka、Zookeeper等，有大规模集群架构、开发及运维经验，能根据业务场景设计合适的技术栈完成需求；
4、熟练掌握SQL语言，掌握Mysql、Oracle、Postgresql等一种或多种关系型数据库使用，有一定的SQL调优经验；
5、至少熟练掌握Shell、Java、Scala、Python等编程语言中的两种；
6、具备良好的团队合作精神，良好的沟通能力；"
"职位描述：
        
        【工作职责】
1、负责大数据基础服务平台搭建、调试、优化、运维工作，维护平台稳定性；
2、负责大数据平台产品类功能设计、开发；
3、配合数据分析、BI、数据仓库工作，提供数据应用平台功能支持；
4、探索大数据前沿技术发展、引入合适的技术为业务提供服务；
【任职资格】
1、计算机相关专业，本科及以上学历；
2、5年以上工作经验，3年以上大数据平台开发、维护经验；
3、精通Hadoop、Hive远离，熟悉大数据生态技术，如Impala、Sqoop、Klein、Flink、Kafka、Zookeeper等，有大规模集群架构、开发及运维经验，能根据业务场景设计合适的技术栈完成需求；
4、熟练掌握SQL语言，掌握Mysql、Oracle、Postgresql等一种或多种关系型数据库使用，有一定的SQL调优经验；
5、至少熟练掌握Shell、Java、Scala、Python等编程语言中的两种；
6、具备良好的团队合作精神，良好的沟通能力；"
"职位描述：
        
        岗位描述：1，?负责数据仓库与集市建模，数据ETL的设计、开发与性能优化2，负责业务需求的需求理解、数据探查和分析，进行业务产品的数据研发， 参与数据产品、数据平台的架构设计岗位要求：1，具有数据仓库相关开发经验，了解Oracle/DB2/Teradata等主流数据库编程，有较好的SQL性能调优经验；?2，熟悉Java或Scala语言，有扎实的开发功底；?3，熟悉Spark/Hadoop，Cassandra/Hbase，Storm，Kafka等大数据处理框架；?4，良好的语言沟通与表达能力和自我驱动动力"
"职位描述：
        
        职位描述：
1、数据分析平台的设计和开发，为数据分析和运营等人员搭建友好高效的数据产品
2、数实时计算平台的设计和开发，为实时风险评估和报表展示等提供最核心的指标计算
3、其它大数据平台技术相关的技术工作

岗位要求：
1、熟悉分布式系统的基础理论知识，了解大数据处理的常用算法
2、熟悉Java或Scala语言，有扎实的开发功底
3、熟悉Spark/Hadoop，Cassandra/Hbase，Storm，Kafka等大数据处理框架
4、热爱技术，有参与过开源系统、或研究过上述系统源代码、或有技术博客者优先"
"职位描述：
        
        岗位职责：1、3年以上linux经验，至少1年hadoop运维经验；有Java/python开发经验；有良好的计算机和网络基础，熟悉linux文件系统、内核、性能调优，TCP/IP、HTTP等协议2、对hadoop原理有深刻认识，具备相关产品（hadoop、Hive、Presto、Sqoop、Kafka、Flume、Zookeeper、hue、spark、storm等）的运维经验；3、熟悉JAVA语言，熟练使用shell、python等脚本语言开发相关运维管理工具。任职资格：1、负责Hadoop集群的日常维护、监控、异常处理等工作，保障集群稳定运行；对Hadoop平台运维不断优化，提升数据产品的质量和响应速度；2、探索海量数据不断增长的解决方案，解决快速增长的业务需求；负责集群服务器网络的配置、管理工作；3、负责离线调度任务的发布和维护，负责相关应用服务器的维护，系统，软件安装，配置调试。"
"职位描述：
        
        职位描述
岗位描述
1.负责事业群业务开发，包括：支付、结算、资金业务的数据架构、数据模型规划及业务开发、数据质量保障；2.负责事业群业务的分析，能够独立完成较复杂的数据统计、数据分析和挖掘工作，能够结合业务场景提出科学的、有效的分析结论，包括：多维度分析、波动分析和异常分析等，同时负责可视化开发

职位要求
1. 有从事分布式数据存储与计算平台应用开发经验，有较为丰富的数据仓库及数据平台的架构经验，精通数据仓库建模及ETL设计开发；有较为系统的海量数据性能处理经验；在大数据资产管理与治理有一定成功产品化经验；
2、具备丰富的大型互联网日志采集系统设计或架构经验，具备较扎实的理论基础和工程能力
3、熟练的JAVA、Python、SQL语言的开发能力，具备机器学习算法能力尤佳；
4、良好的思维逻辑性、语言表达能力5、有HR、财务、行政等相关企业运营相关业务经验尤佳"
"职位描述：
        
        工作职责

1.?基于大数据平台结合领域，负责BI/画像/数据仓库的开发和应用；2.?基于海量用户行为数据，建立、评估、持续优化数据模型，包括但不限于：用户价值评分、用户风险评分、用户偏好预测?、用户画像构建等等，产出用户标签；3.?结合公司的业务场景，进行数据产品设计，解决业务痛点，提升用户体验，探索新的商业模式；""

任职资格

1.?本科及以上学历，计算机或数学相关专业，工作3-6年及以上；2.?思维清晰敏捷，逻辑分析能力强，具有良好的语言和书面表达能力；3.?精通hive?sql，有海量数据处理的调优经验尤佳；4.?熟悉spark尤佳；7.?有大型互联网公司行业背景先，有带领团队，具有管理经验的尤佳；"
"职位描述：
        
        岗位职责：
1、负责数据采集、数据存储、数据查询、数据计算等平台基础能力的设计和开发工作
2. 利用Hadoop、Spark等大数据技术对海量数据进行处理
3. 负责离线/实时的数据存储和加工处理
4. 负责海量数据的清洗、处理和挖掘工作，支持数据分析师和算法工程师的数据需求
5. 对数据敏感，基于海量数据进行业务分析
6. 研究前沿技术，解决实际场景中的业务问题，优化离线/实时大数据计算任务的性能

任职要求：
1. 熟悉Hadoop,MR,Hbase, Spark等大数据技术，并能够基于上述项目开发大数据相关应用；?
2. 熟悉基本数据挖掘方法和技术
3. 熟悉大数据组件的开发、搭建、维护以及调优
4. 较强的开发能力，掌握相关开发语言(Java、Python、Scala等)、框架、数据库、Linux等相关知识，能够独立完成并领导团队完成大数据相关的工程化应用实现
5. 熟悉MongoDB等NoSQL数据库，具备NoSQL数据库实际工作经验
6. 有大数据处理、数据挖掘等领域开发经验"
"职位描述：
        
        岗位职责：?1.负责数据加工、清理、分析、处理等程序的开发；??2. 负责用户实时行为，历史行为等相关系统的开发；?3. 负责数据相关平台的搭建、开发、维护、优化。???任职要求：?1.熟悉主流开发语言包括但不限于 Java，Scala，Python，精通SQL及其他常用数据库操作；?2.了解各种常用集群的搭建及性能调优Hadoop集群，spark集群；??3.熟悉数据仓库建设的理论及模型，3年以上相关领域实践经验；?4.能够进行复杂业务逻辑的数据处理工作，具备海量数据处理以及性能优化的能力；?5.思路清晰，具备良好的沟通能力和理解能力，较强的学习能力以及快速解决问题的能力。"
"职位描述：
        
        岗位职责：
1、参与需求调研和需求分析，撰写相关技术文档；?
2、搭建系统开发环境，完成功能模块相关代码的编写；?
3、项目概要设计、详细设计、开发计划等标准文档的编制；?
4、独立完成单元测试，解决开发过程中的技术问题；?
5、有平台开发经验者优先；有接口开发及文档撰写能力者优先；?

任职资格:?
1、国家统招全日制大学本科及以上学历，计算机相关专业；
2、熟悉Java编程和面向对象程序设计，对设计模式有了解，熟悉JavaEE；
3、熟悉JSP、Freemarker、Servlet等WEB基础知识；?
4、熟悉及熟练应用各种框架，包括但不限于：Spring cloud，Spring MVC，Spring，Mybatis，Struts2等；?
5、具有较强的学习和沟通能力，良好的团队协作精神，极强的责任心，工作踏实、勤恳，有钻研精神，乐于分享自己的成果，乐于帮助团队中其它成员进行提高；?
6、在校有获奖经历者优先；?
7、有CC开发经验者优先；"
"职位描述：
        
        工作职责：?
1、负责基于Hadoop和OLAP框架的海量数据平台建设 :
2、负责分布式数据平台框架下数据系统开发与新数据应用开发架构研究?
3、理解用户数据统计、分析和挖掘应用场景，抽象为数据产品需求，不断完善基础数据平台的建设
4、负责大数据实施过程中相关技术问题解决，包含数据接入，数据规范，建模等；
5、完成与工作相关的技术文档编写工作。

?职位要求：?
1、具备较强的数据敏感度以及数据抽象能力?
2、精通Java/Scala之一，具备良好的coding素养和习惯?
3、熟练掌握至少一种脚本语言，如Python、Shell等?
4、2年以上Hadoop项目实际研发经验，如Zookeeper/HDFS/Hive/HBase/Spark/Impala/Gobblin/Flume/Kafka等其中一个或多个?
5、1年以上ETL/Adhoc query/OLAP等实践经验?
6、强烈的责任心和主动Push能力"
"职位描述：
        
        岗位职责
1、依据业务模型，负责游戏大数据计算平台的架构设计，以及核心功能的开发，满足实时、离线计算的需求。
2、负责游戏大数据平台的设计和开发，为个性化推荐、用户价值评估、实时运营数据分析等提供数据支持。
?
任职要求
1、本科以上学历，扎实的计算机专业基础，有3年以上大数据平台开发经验，1年以上的大数据计算/存储设计经验。
2、熟练掌握Hadoop、Spark、Flink、HBase的原理特性以及适用场景，具备大规模数据集的实际开发经验。
3、有大规模数据计算平台的架构设计经验，且精通大规模数据集的存储方案设计优先。
4、具备用户问题的定位及解决能力，善于归纳总结，对数据敏感。
5、思维活跃、敢于担当、乐于沟通，具有良好的团队合作精神，积极主动，能承受一定的工作压力。
6、有游戏大数据经验优先。"
"职位描述：
        
        职位描述
1.理解并梳理大数据平台的核心流程；
2.整合开源和自研的机器学习计算框架，进行产品化接入；
3.负责大数据场景下，报表平台、自助取数平台、BI平台等核心业务模块的开发；
4.研究分析产品提出的数据需求，持续改进产品功能，并提供技术方案；
5.提升数据平台的安全性、兼容性、可维护性、可扩展性；
6.团队管理能力强，能够带10+人技术团队
?
任职要求
1.计算机相关专业，本科或以上学历；
2.精通Java语言，熟练掌握至少一种脚本语言；
3.有5年以上编程经验，独立完成过中等规模的项目；
4.有良好的数据结构和算法设计基础；
5.熟悉Linux系统原理、熟练运用Linux命令与脚本；
6.熟悉关系型数据库原理及SQL语言；
7.理解敏捷开发流程。
?
加分项
1.熟悉java web端框架，如spring/spring mvc/mybatis等；
2.熟悉分布式系统原理，有分布式系统设计和开发；
3.熟悉主流大数据处理技术（hadoop/spark等）；
4.熟悉 Python，掌握一种 python web 框架；"
"职位描述：
        
        工作职责：
1.大规模分布式数据仓库搭建
2.海量日志和业务数据的采集和分析
3.实时可视化统计平台的数据开发

任职资格：
1.本科及以上学历，有5年以上大数据相关开发或运维经验
2.要求有良好的沟通和理解能力，善于学习，熟悉电商业务优先
3熟悉hadoop/hive/hbase等开源工具的使用和原理，有实际生产环境的优化或搭建经验优先
4.有linux系统java/shell/python等语言的开发经验，有框架或架构开发经验优先
5.理解数据仓库ETL，有高可靠性系统构建经验优先
6.有hive源码修改经验优先"
"职位描述：
        
        工作职责:1、为AI团队提供有力的数据技术支撑。2、负责分析挖掘业务线对大数据产品的需求（应用场景），利用数据分析结论提升客户业务能力。3、数据支撑平台系统分析、设计，并主导完成详细设计和编码任务，确保项目进度和质量。任职资格:1、三年及以上海量数据下机器学习和算法实施相关工作经验，具有较强的数据整合，数据分析/挖掘，和解决业务问题的能力；2、熟练掌握Scala、JAVA、Python之中的一种；3、良好的数据敏感度,能从海量数据提炼核心结果，有丰富的数据分析、挖掘、清洗和建模的经验，至少熟悉一种关系型数据库如Oracle、mysql等；4、熟练掌握Hive/SQL，熟悉Hadoop/Spark/MPI分布式计算框架，有海量数据处理经验者优先；5、了解回归分析模型、关联规则挖掘、分类和聚类算法、协同过滤算法等数据统计模型和挖掘算法优先，了解完整的数据挖掘过程方法论，并有独立完整的建模实践经验优先。"
"职位描述：
        
        工作职责:1.负责大数据处理和数据仓库的设计开发；2.负责数据清洗、转换和加载过程的设计开发；3.负责数据分析、统计和数据可视化的设计开发。任职资格:1.扎实的编程基础，至少熟悉java、python语言；2.熟悉大数据相关开源工具,包括hadoop、hive、hbase、spark等；3.熟悉数据仓库、多维分析、数据可视化技术；4.熟练掌握数据结构和算法；5.熟悉elasticsearch，有ELK经验者优先；6.良好的沟通表达和较强的学习能力。"
"职位描述：
        
        工作职责:1、基于大数据驱动构建企业数据模型EDW以及面向应用产品与分析的应用层模型设计开发。2、参与大数据平台的数据研发，发掘数据商业价值，打造极致体验的数据平台。3、负责构建基于hadoop，Hive的数据仓库和数据集市的架构设计与优化；4、对海量数据处理的业务需求进行评估和方案设计；5、对慢查询进行诊断，并给出优化方向；6、了解行业前沿的大数据处理方法和框架；
任职资格:1、5年（含）以上数据仓库开发和管理经验，熟悉数据仓库模型设计与ETL开发经验 ，掌握维度建模设计方法，具备海量数据加工处理（ETL）相关经验 ；2、熟悉Hadoop、Hive、Hbase、Storm、Spark、kafaka、zk，flume的工作原理；3、熟悉Hadoop, HBase, Spark, Storm, Redis, Elastic Search技术及其生态圈；4、掌握JAVA/Python/Shell/Tcl/Perl等一门以上语言；5、具有高度的责任感，思路清晰，有良好的沟通能力；"
"职位描述：
        
        工作职责：1、负责游戏运营对接开发；2、负责后台管理系统的功能开发及日常维护；3、负责后台数据统计，数据分析。岗位要求：1、1年以上后台开发经验；2、精通mysql、redis、memcache、nginx等常用web开发技术；3、熟悉数据库性能调优方案，熟练掌握MySQL数据库的高可用及分库、分表的水平扩展方案；4、熟悉?Linux?操作系统，精通python，lua脚本；5、有高并发、大用户量应用系统开发经验者优先。
?
福利：五险一金+带薪年假+法定节假日+每日下午茶零食+每月生日会+节日礼品+定期团建~"
"职位描述：
        
        1、工作职责：
??? 1）构建维护良好的数据批量处理及实时处理架构，为大数据全生命周期提供稳定、高效的基础平台支撑服务；
??? 2）制定平台运营管理规范，并设计开发工具进行闭环运营，保障平台可持续高效、稳定运行；
??? 3）基于大数据平台进行项目技术攻关和调优，并形成案例进行内部分享；
??? 4）及时跟进开源社区更新及新技术，阅读文档，验证特性，持续提升平台的性能与稳定性，并保持架构一定的先进性。
?
2、能力要求：
??? 1）熟悉Linux平台操作，掌握C/C++/Java/Python之一的编程；
??? 2）对大数据理论、数据仓库理论、行业应用有一定的认识与研究，熟悉大数据相关技术，精通CDH集群管理环境的安装部署及运维；
??? 3）良好的数据敏感度，能从海量数据提炼核心结果，有丰富的数据分析和建模的经验；
??? 4）熟悉分布式系统设计范型，有大规模系统设计和工程实现的经验，能独立开发分布式计算应用者优先，掌握统计学习方法和机器学习算法者优先；
??? 5）善于总结，积极主动学习新技术，热爱大数据工作，直面困难敢于承担责任，有较强的沟通的能力和理解能力。"
"职位描述：
        
        1、工作职责
?1）负责企业数据仓库架构设计和研发；
?2）运用数据挖掘、统计分析和运筹优化等算法，挖掘数据价值，解决业务难题。
2、能力要求
?1）精通Oracle、DB2等关系型数据库的SQL开发，具备编写和优化存储过程的能力；
?2）掌握数据仓库建模方法和工具，有航空业数据建模经验者优先；
?3）熟悉大数据平台生态环境，具备大数据平台Hive、Spark、MapReduce、HBase、Impala等常用组件的开发经验；
?4）掌握常用的数据分析挖掘算法，具备Python开发能力"
"职位描述：
        
        负责组建并领导一个大数据算法小组，支持一条产品线的算法工作并推进算法落地"
"职位描述：
        
        职位描述：
职位描述

 开发并维护数据基础设施
 数据产品开发，如推荐系统组件研发和架构优化
 支持运营业务需求，提供数据驱动和决策的能力


职位要求

 2年以上大数据系统/平台相关工作经验，能够完成数据模型的设计与开发
 熟悉大数据相关技术：Kafka/Storm/Hadoop/Spark/HBase 等
 熟练使用至少一门编程语言：Java/Python/Go/Scala/Node.js 等
 熟练使用至少一种关系型数据库和 SQL 编写及调优：PostgresSQL/MySQL/Oracle


加分项

 有实时流处理相关经验
 有数据挖掘/机器学习相关经验
 熟悉 HTTP 原理，掌握 HTTP API 的设计与开发"
"职位描述：
        
        职位描述

 负责即刻海量用户行为数据的处理，在分布式计算平台上建立高效且实时的数据 pipeline
 负责大数据基础设施和平台的研发和改进，解决大规模生产环境可用性和性能优化问题
 负责推荐系统、用户画像等核心数据系统的研发


职位要求

 1 年大数据平台相关工作经验
 对至少一项大数据处理技术有使用经验：例如 Kafka/Storm/Hadoop/Spark/Hive 等
 具有优秀的编程能力，快速 Trouble-Shooting 定位问题的能力，对新技术有强烈的学习热情
 熟练使用至少一门编程语言：Java/Python/Go/Scala 等


加分项

 有实时流处理/大规模数据处理/用户行为数据分析经验
 熟悉 HTTP 原理，掌握 HTTP API 的设计与开发，有一定 Web 应用开发能力
 有为开源项目贡献过代码的经验，有互联网公司实习经验"
"职位描述：
        
        工作职责：

组建和管理优秀高效的数据平台团队
搭建高可拓展性，高可靠性和高性能的数据管理系统，如数据湖、数据仓库等解决方案，以赋能业务部门实现灵活的，准确的和自助式的分析
主导系统和架构设计，以满足各业务部门现有和未来数据需求
合理规划数据平台建设，不断优化流程和采用最佳实践来设计、构建和发布数据结构和数据管道，达到可拓展性，稳定性和性能的要求
设计和实施与各种数据源的集成（包括与第三方数据源的集成）
与多个团队进行协作，共同交付端到端解决方案
协助增长和运营团队评估和部署数据基础设施，助力流程自动化，优化和分析
与分析，数据科学和产品技术团队合作评估、基准测试和整合最先进的开源数据框架、工具和技术
管理和维护数据平台并根据需要进行性能优化

任职资格：

计算机科学或相关专业本科及研究生，或同等经验 ???
5年以上软件开发经验, 至少2年大规模数据处理经验
有一定的团队管理经验和丰富的数据项目规划及管理经验
优秀的领导力和沟通技巧，主动开展和推动项目正向发展
熟悉Shell, Python和Java或类似语言
具备Hadoop体系相关的经验，比如Mapreduce，Spark，Hive，Tez，Presto等
有实时数据处理技术经验如Kafka，Fluentd，Flume，Spark Streaming, Flink等优先
熟悉关系型与非关系型数据库"
"职位描述：
        
        高级大数据开发工程师

工作地点：北京

工作职责：

搭建高可拓展性，高可靠性和高性能的数据管理系统，如数据湖、数据仓库等解决方案，以赋能业务部门实现灵活的，准确的和自助式的分析
设计和实施实时数据处理流
设计和实施与第三方数据源的集成
与多个团队进行协作，共同交付端到端解决方案
协助增长和运营团队评估和部署数据基础设施，助力流程自动化，优化和分析
与分析，数据科学和产品技术团队合作评估、基准测试和整合最先进的开源数据框架、工具和技术
管理和维护数据平台并根据需要进行性能优化

任职资格：

计算机科学或相关专业本科及研究生，或同等经验
至少2年以上软件开发经验并且有1年大规模数据处理经验
熟悉Shell, Python和Java或类似语言
具备Hadoop体系相关的经验，比如Mapreduce，Spark，Hive，Tez，Presto等
有实时数据处理技术经验如Kafka，Fluentd，Flume，Flink等优先
熟悉关系型与非关系型数据库
具有云计算经验特别是腾讯 QCloud 经验优先
能够清晰准确地解释复杂概念
愿意学习新技术，新工具和解决问题的新方法
具有敏锐的洞察力，具备快速发现问题根源和解决问题的能力"
"职位描述：
        
        岗位职责：

 支持大数据的批量、实时流转、清洗、转换和计算的设计和开发；

任职要求：
1.计算机、数学、软件工程或相关专业本科及以上学历 ；
2.熟悉大数据处理相关产品架构和技术（如Hadoop/Hive/HBase/Spark/Kafka/Storm/Flume等），了解内部组件实现机制；
3.熟练使用java、python等语言；
4.具有良好的沟通能力、组织能力及团队协作精神，有较强的分析和解决问题的能力。"
"职位描述：
        
        岗位职责：
1.基于海量供应链数据，研究相关挖掘算法及机器学习技术实现链上企业全方位评估、资产定价；
2.计算与动态调整各种金融抵押品质押率、监控与预警，并反映到授信额度；
3.支持分析与设计供应链金融产品，构建其背后的智能风控模型，支持核心业务拓展；
4.支持构建模型训练必备的训练集、样本集及回测应用；
5.参与基础数据收集、整理和特征工程建设。
任职要求：
1.计算机、数学、统计学或相关专业本科及以上学历，硕士博士优先 ；
2.具有3年以上数据挖掘、机器学习、深度学习、自然语言处理等的实战经验；
3.熟悉常用数据挖掘和机器学习算法以及一些常用判别模型；
4.了解分布式计算，能独立建模，数据探索与语义推理，包括算法选取、数据准备与预处理、特征抽取，以及模型回测与优化；
5.精通Python/SAS语言，熟练掌握关系型数据库和SQL， 以及HBase、Mongo 等常用工具的使用和开发；
6.具有供应链金融链上企业评价、资产定价及链上生态智能风控、供应链优化有经验的优先。"
"职位描述：
        
        岗位职责：
1.负责大数据相关平台产品、工具等开发；
2.参与产品的需求分析和功能设计过程并编码实现；；
3.持续改进当前产品的前、后端功能，优化性能，改善使用体验；
4.前端前沿新技术的调研与研发。
任职要求：
1.本科及以上学历，计算机相关专业，3年以上相关工作经验，具备良好的服务意识，责任心，团队沟通和协作能力、发现并解决问题的能力；
2.有扎实的前端技术和计算机基础，包括但不限于HTML/CSS/JavaScript/DOM/Http/数据结构等；
3.精通至少一门MVVM框架，如AngularJS/Vue/Bootstrap；
4.熟练掌握SVG/Canvas/WebGL等前端绘图技术及标准，至少使用过一个数据可视化类库，包括但不限于D3/G2/Three.js /ECharts/Highcharts，有一定计算机图形学基础的优先；
5.掌握至少一门服务端编程语言，并有实战经验, Python者优先,有过大数据产品（Hadoop/Hive/Spark等）相关开发经验者优先；
7.有移动端开发经验并且有实际性能优化案例者优先；
8.有自己的技术产品、开源作品或活跃的开源社区贡献者优先。"
"职位描述：
        
        岗位职责：
1.负责建设供应链大数据分析平台及数据仓库；
2.负责大数据的批量、实时流转、清洗、转换和计算的设计和开发；
3.负责基于大数据技术的海量数据的自动化分析处理和统计工作。
任职要求：
1.计算机、数学、软件工程或相关专业本科及以上学历 ；
2.具有3年以上大数据平台开发相关工作经验、具备大数据处理平台架构设计经验，熟悉DW/DM的设计与构建；
3.熟悉大数据处理相关产品架构和技术（如Hadoop/Hive/HBase/Spark/Kafka/Storm/Flume等），了解内部组件实现机制；
4.熟悉各种互联网常用开源软件（如Zookeeper/Redis/Dubbo等），有知名互联网/软件/通信厂商大型项目经验者优先；
5.熟练使用java、python，熟悉linux平台及shell脚本开发；
6.具有良好的沟通能力、组织能力及团队协作精神，有较强的分析和解决问题的能力。"
"职位描述：
        
        岗位职责：?
1. 负责大数据采集、存储、计算、分析等场景的通用架构设计和开发；?
2. 负责流式数据的实时传递、清洗、转换和计算（实时统计、分析等）的设计和开发；?
3. 负责大数据相关框架/工具/中间件的设计和开发；
4. 负责以上各种架构平台及相关基础技术组件的稳定性保障及源码级的bug修复；
5. 负责大数据相关解决方案的设计文档撰写。
任职要求：?
1. 本科以上学历，计算机相关专业；
2. 五年以上大数据平台相关开发及架构设计经验；
3. 深入使用Java，深入理解并熟练使用Java类库及框架，如多线程、并发处理、I/O与网络通讯；
4. 对Java虚拟机有较深了解，有运行态JVM分析及调优的实际经验；
5. 熟悉Linux系统，具备Shell、Python等脚本开发能力者优先；
6. 熟悉并使用过各种大数据相关框架或组件优先，如Kafka、Storm/JStorm、Hadoop/Spark、Hive、HBase、kylin、opentsdb、redis、flume等，具备源代码级问题解决和集群优化改造能力者优先；?
7. 具备丰富的数据处理和数据仓库建模的项目实践经验者优先；
8. 具有良好的语言表达和文档撰写能力，学习能力强，喜欢研究开源新技术，有团队观念，具备独立解决问题的能力；
9. 有一年以上大数据团队带领经验优先。"
"职位描述：
        
        岗位职责：
1、在工程师的帮助下负责软件产品的开发与维护；
2、根据产品需求完成架构和模块设计、编码、测试、调试工作；
3、能按照项目计划，按时提交高质量的代码，完成开发任务；
4、改善软件的易用性，提升用户使用体验；
5、对软件bug的修复，完成团队项目工作。
任职要求：
1、工作认真、细致、敬业，责任心强；
2、优秀应届毕业生或即将毕业在校生，计算机相关以及理科相关专业优先；
3、对计算机IT有浓厚的兴趣，熟练掌握java或其他编程语言；
4、有较高的学习能力，能够专注于技术工作."
"职位描述：
        
        1、负责数据的提取、BI设计和展示，以及数据运营分析平台的需求分析、设计和基础数据开发；
2、负责个性化内容推荐系统构建及优化，效果改进，持续提升产品体验；
3、负责海量数据的分析、开发、设计等工作；
任职要求：
1、精通Linux操作系统，熟练使用Java、Scala、python、Go中任意一种或者多种高级语言；
2、2年以上大数据实时查询、离线分析、数据存储开发经验，包括HDFS、HBase、Spark等；
3、2年以上大数据PB级海量数据分析、开发，包括 HDFS、HBase、Hive、Spark Sql等；
4、2年以上的流式计算集群开发、优化、运维经验，包括Storm、Spark Streaming、Flink、Kafka等；
5、具有一定分布式系统设计/开发经验者优先；
6、参与过开源项目，为开源社区贡献过代码的优先;
7、本科及以上学历，不少于3年的工作经验"
"职位描述：
        
        1、 大专以上学历，计算机相关专业，2年以上相关经验
2、?熟悉Hadoop生态圈，有相关hive库迁移以及丰富hql调优相关经验
3、 熟悉hive，spark，mapreduce，sqoop等开发经验
4、 熟悉python&shell脚本开发2年经验以上
5、 至少熟悉一种ETL工具
6、 有责任心及较强的学习能力，具有一定抗压力。"
"职位描述：
        
        岗位要求：
1、熟悉hdfs、hive、sqoop、oracle、mysql，以及sql性能调优;?
2、有较强的编程能力，熟悉掌握shell、java或python开发;?
3、熟悉数据仓库、数据集市模型设计方法论，并有实际模型设计及ETL数据治理开发经验;?
4、熟悉impala、hbase、spark、elasticsearch、redis等数据框架;?
5、熟悉git、jira、confluence工具的使用。"
"职位描述：
        
        岗位要求：
1、熟悉hdfs、hive、sqoop、oracle、mysql，以及sql性能调优;?
2、有较强的编程能力，熟悉掌握shell、java或python开发;?
3、熟悉数据仓库、数据集市模型设计方法论，并有实际模型设计及ETL数据治理开发经验;?
4、熟悉impala、hbase、spark、elasticsearch、redis等数据框架;?
5、熟悉git、jira、confluence工具的使用。"
"职位描述：
        
        1.?精通hdfs、hive、sqoop、oracle、mysql，以及sql性能调优;
2.?有较强的编程能力，熟悉掌握shell、java或python开发;
3.?熟悉数据仓库、数据集市模型设计方法论，并有实际模型设计及ETL数据治理开发经验;
4.?熟悉impala、hbase、spark、elasticsearch、redis等数据框架;
5.熟悉git、jira、confluence工具的使用。"
"职位描述：
        
        岗位描述：
1、负责各种源业务系统数据的采集、清洗、整合工作；
2、负责大数据的分布式存储和管理工作；
3、负责大数据项目的开发、维护工作；
4、负责大数据平台各组件的开发、维护工作；
5、负责部分设计、开发文档的编写工作。
?任职要求：
1、统招本科学历；2、两年以上大数据开发经验，熟悉JAVA语言；3、熟悉Hadoop生态体系，熟练使用常见的大数据工具，如. HDFS, YARN，Mapreduce, Hive, Storm, Spark, kafka；4、能够熟悉使用etl工具，如：kettle；5、掌握分布式系统原理，对存储、计算、消息队列、集群运维中的一项或多项有深入的理解和认识；6、熟悉基本的JAVA WEB开发；7、熟练使用Linux系统；8、此岗位需要适度出差。"
"职位描述：
        
        高级：
5年及以上大数据工作经验，可以设计各类功能模块；
精通Linux 的Shell编写，用户和权限管理思路清晰；
精通Hadoop MapReduce分布式计算框架或Spark框架，知晓原理，研究过组件源码；
精通流式数据处理，清楚知晓Spark stream, storm的各类API，清楚了解这些组件与Zookeeper, YARN的协同机制和配置管理，知道实时或者准实时处理数据的关键。
精通Flume和Sqoop做日志、关系型数据的收集，有其中之一的代码编写经验
精通使用1种基于大数据的外围查询挖掘组件，如Spark SQL, Impala, Elasticsearch、Hive, HBase或Mahout，有足够调优能力;
精通消息异步处理，如Kafka，熟练知晓组件API和应用策略
?
中级：
3~4年大数据工作经验；
熟悉Linux熟悉Shell编写；
熟悉Hadoop MR框架或Spark分布式计算框架，会熟练组合运用各组件；
足够大数据接入和处理经验，熟练使用Spark stream, storm的主要API，知道实时或者准实时处理数据的关键
能熟练运用Flume和Sqoop做日志、关系型数据的收集，有编码调优能力
能熟练安装使用1种基于大数据的外围查询挖掘组件，如Spark SQL, Impala, Elasticsearch、Hive, HBase或Mahout;"
"职位描述：
        
        1、二年以上开发经验，计算机相关专业本科毕业；
2、）熟悉Spring、Mybatis、Jquery，等常用的java开发框架有较好的了解和掌握；
3、熟悉数据仓库体系架构，熟悉Hadoop/Spark等开源大数据平台
4、熟悉Hadoop架构框架，掌握YARN及MapReduce算法与原理，具备大规模并发设计与? ?开发能力；?
5、熟悉ZooKeeper、HDFS、Hbase等分布式开源软件，具备系统优化与性能调优能力；精通SparkSQL，SparkStream使用与调优；"
"职位描述：
        
        1.3~4年大数据工作经验，可以为企业大数据生态打造做出合适的策略，可以指导开发人员
2.熟悉Hadoop分布式集群运维管理经验，可以从运维角度考虑设计
3.精通各类基于Hadoop生态的系统搭建，充分了解Spark分布式计算框架、Yarn集群资源管理和调度平台、HDFS分布式文件系统的工作原理；
4.对流行的大数据框架产品足够熟悉，如Spark、Cloudera、Hortonworks和MapR等其中之一，能够自行设计；
5.谙熟zookeeper分布式协作服务应用场景和配置机制，能够独立设计调度策略。
6.熟悉Spark Stream, Storm等配套组件的使用，知道批处理和实时处理的不同策略，有落地经验。
7.有一些云厂商收费大数据产品的落地经验。"
"职位描述：
        
        1、一年以上开发经验，计算机相关专业本科毕业；
2、）熟悉Spring、Mybatis、Jquery，等常用的java开发框架有较好的了解和掌握；
3、熟悉数据仓库体系架构，熟悉Hadoop/Spark等开源大数据平台
4、熟悉Hadoop架构框架，掌握YARN及MapReduce算法与原理，具备大规模并发设计与? ?开发能力；?
5、熟悉ZooKeeper、HDFS、Hbase等分布式开源软件，具备系统优化与性能调优能力；精通SparkSQL，SparkStream使用与调优；"
"职位描述：
        
        岗位职责：1、负责大数据平台、设计、开发及维护工作；2、负责大数据平台数据仓库数据分析挖掘工作；3、负责公司大数据挖掘项目的数据分析和算法实现；4、通过数据挖掘、机器学习等算法对生产过程的数据进行分析，对生成过程的参数进行优化；任职要求：1、应用数学、计算机、信息处理等相关专业本科及以上学历；2、数学基础扎实，熟悉高等数学、线性代数、概率论等等；3、熟悉常用的机器学习算法，KNN、Kmeans、朴素贝叶斯、线性回归、逻辑回归、SVM、Boosting、CNN、RNN等等；4、熟悉python或者scala语言；5、熟悉常用数据库的使用；5、具备良好的表达和沟通能力、学习能力，具备极强的团队合作精神，能够承受一定的工作压力。
加分项：物联网SAAS平台大数据经验热爱大数据开源技术基于spark的大数据算法开发经验有兴趣学习基于flink的实时计算方向发展"
"职位描述：
        
        岗位职责
1、负责机器学习计算平台的架构设计、技术选型、开发测试
2、负责构建Spark/HDFS大数据处理架构
3、持续地研究分析分布式微服务架构的功能、性能等问题，并设计、开发改进方案
4、跨部门/团队协作，协同分析并解决各类大数据平台相关的运行或数据问题
任职资格
1、本科或以上学历，数学类专业优先
2、5年或以上的工作经验，至少2年分布式高并发高可用系统架构工作经验
3、熟练掌握Java语言，掌握Scala或Python语言，有Java架构师经验优先
4、扎实的算法基础，熟悉常见的数据结构，了解分布式算法和分布式系统
5、精通分布式计算框架，如MapReduce/Spark/Storm等，并有丰富的实际开发、优化和应用经验
6、了解机器学习技术和常见算法，如LR/GBDT/DNN/CNN/RNN，有实际应用经验者优先
7、了解开源深度学习框架，如Tensorflow/MXNet/Caffe，有实际应用经验者优先


税前年薪（万元）：20-40"
"职位描述：
        
        岗位职责
1、负责机器学习计算平台的架构设计、技术选型、开发测试
2、负责构建Spark/HDFS大数据处理架构
3、持续地研究分析分布式微服务架构的功能、性能等问题，并设计、开发改进方案
4、跨部门/团队协作，协同分析并解决各类大数据平台相关的运行或数据问题
任职资格
1、本科或以上学历，数学类专业优先
2、5年或以上的工作经验，至少2年分布式高并发高可用系统架构工作经验
3、熟练掌握Java语言，掌握Scala或Python语言，有Java架构师经验优先
4、扎实的算法基础，熟悉常见的数据结构，了解分布式算法和分布式系统
5、精通分布式计算框架，如MapReduce/Spark/Storm等，并有丰富的实际开发、优化和应用经验
6、了解机器学习技术和常见算法，如LR/GBDT/DNN/CNN/RNN，有实际应用经验者优先
7、了解开源深度学习框架，如Tensorflow/MXNet/Caffe，有实际应用经验者优先


税前年薪（万元）：20-40"
"职位描述：
        
        南方报业传媒集团南方网技术中心因业务发展需要，现招募设计/研发/产品/项目经理等各类专业人士，主要从事互联网+政务、互联网+媒体等互联网产品线研发及发展工作。

职责描述：

 负责建立大数据平台的业务数据开发；
 负责大数据平台的业务流程开发；
 开发数据清洗，计算，存储等代码；

?
岗位要求：

 本科以上学历，计算机专业；
 精通Hadoop、Spark、kafka、Storm等， 熟悉大数据架构体系；精通掌握Python/Scala/Java语言；
 精通Hadoop的MapReduce，Spark的架构体系；熟悉大数据CDH平台，oozie调度等，写过大数据平台调度插件；
 精通数据结构和算法，了解Spark整个体系，对机器学习有所了解；参与设计过大规模的数据仓库底层设计的优先；
 具有强烈学习的欲望，和工作积极性，责任心；


欢迎加入我们，南方网为每一位人士提供充分发挥能力的空间与时间，提供一份过得去的薪酬（20-40K），有完善的福利制度（五险一金）；享受国家法定假期等。"
"职位描述：
        
        ?
集团信息技术部招聘启事
因发展需要，集团信息技术部现招聘大数据工程师。具体要求如下：?
岗位职责：参与集团数据和大数据相关项目的设计研发工作；负责集团数据采集、清洗、整合工作；负责集团大数据项目的数据开发工作，对服务相关功能、大数据组件及数据接口进行监控、管理、优化；参与数据和大数据系统运维；完成其他部门交办的工作。
岗位要求：
1. 2年相关工作经验，熟悉分布式系统原理及大数据平台组件，如hadoop、Spark、kafka、Elasticsearch、Redis等；
2. 有相关组件研发实战能力优先；有较强的研发能力，熟练掌握JAVA、Python其一开发，有良好的设计风格；
3. 熟悉Linux，能够熟练运维管理Linux服务器，有HDP/CDH平台运维经验优先；
4. 具有较强的责任心、安全意识和文档意识，具有良好的沟通能力及团队精神。
有意应聘者简历内请注明期望薪酬水平，合则约见。"
"职位描述：
        
        岗位职责：
1、参与大数据项目服务端程序的设计及开发工作；
2、负责大数据项目数据接入，清洗，处理，对接等工作；
3、解决ETL相关技术问题；
?
任职要求：
1、? 计算机相关专业，统招本科及以上学历；
2、? 熟练使用Java，3年以上Java开发经验，1年以上大数据开发经验；
3、? 熟悉分布式系统架构，对dubbo等分布式RPC框架有使用经验者优先；
4、? 精通各种网络通讯协议,熟悉Socket/TCP/UDP/IP/P2P等网络开发技术；
5、? 熟悉RMI、多线程并发编程，有实际的socket, nio, mina,netty等tcp/ip服务器端开发经验；
6、? 熟悉Flume、Logstash、Kettle、DataX等ETL工具，有二次开发经验者优先；
7、有ETL项目开发和实施经验，掌握数据仓库相关知识、ETL数据流程设计、模型设计等；具有大数据处理经验优先；
8、熟悉elasticsearch，kafka，Hadoop，redis；了解主流大数据处理技术，如：spark、Sqoop、Hbase、Hive等；
9、积极上进，责任心强，具备良好的团队合作精神；
10、熟悉Linux环境开发，熟悉常用SHELL命令。"
"职位描述：
        
        1、有大数据分析开发经验，精通hive，hadoop的使用，擅长使用Python语言。2、在大数据库风控、反欺诈、客户画像等方面有一定的研发经验；3、本科以上学历，计算机相关专业经验；4、有银行、金融行业开发经验优先；"
"职位描述：
        
        岗位职责：
1、熟练使用python完成后端程序开发，熟悉linux下各种环境搭建（在Docker上运行hyperledge、EOS等）
2、数据库设计和运维，
3、开发测试设计，测试用例编写
4、按要求输出设计文档，包括：系统架构图、UML图等

任职要求：
1、熟悉数据结构和算法，除python 外掌握1-2门编程语言（go语言最好）
2、掌握hadoop、spark等大数据分析工具和技术框架，能够进行大数据开发；
3、精通mysql、mongodb、hive等数据库中的一种；
4、熟悉开发工具使用，有过项目成功开发经验，理解项目管理。"
"职位描述：
        
        1、3年以上相关工作经验，良好的执行和沟通能力，负责过大型互联网产品开发者经验优先；

2、熟练掌握Linux操作系统，精通Scala/Java/Python语言的一种或多种；

3、熟悉主流大数据工具Hadoop、spark、Storm、ELK中两个及以上,并熟悉所使用工具的技术原理、主要特点；

4、熟练使用flume、Kafka、hbase、redis、mysql等常用工具；

5、能够承担对业务数据、生产日志的抽取、转储、检索等相关工作。

6、熟悉前端常用框架 Vue，并能独立进行前端开发。"
"职位描述：
        
        岗位职责?1.?负责大数据分析需求设计和开发工作，包括数据存储、预处理、查询、统计、实时分析、数据优化及配置等功能;?2.?对大数据分析系统存在的问题进行跟踪和定位并及时解决;?3.?负责上级交办的其他相关工作。岗位要求：?1.?本科以上学历，2年以上工作经验;?2. Java基础扎实，熟练使用Java IDE?进行代码编写和调试，熟悉JUnit单元测试框架;?3.?熟悉Linux操作系统，能在Linux上完成开发、调试工作;?4.?熟悉网络IO、多线程并发编程、集合等基础框架，精通数据结构和数据算法;?5.?参与过分布式高性能服务的设计开发过程，有大规模分布式系统的实践经验;?6.?熟悉数据库操作和使用的基本技能，熟练一种关系型数据库的使用;?7.?能独立编写详细设计文档;?8.?有大数据分析工具Hadoop、spark使用开发经验优先;?9.?具有团队精神与敬业精神，学习钻研能力强，具有良好的协调沟通能力。"
"职位描述：
        
        1、负责大数据的采集、清洗、存储、分析工作 ? ??
2、负责数据存储结构的设计，
3、三年以上java开发经验，有haddop、spark、hive等大数据工具的使用经验， ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 4、有千万级以上数据处理经验者优先，有政务大数据处理经验者优先，有数据挖掘经验者优先
5、接受阶段性出差"
"职位描述：
        
        掌握大数据相关技术
熟练掌握Mysql数据库设计、开发经验，熟练掌握SQL语法；
具备良好的编码习惯和注释习惯、注重细节处理；
编程基础扎实，熟悉各种数据结构，熟悉常用的设计模式和算法；
熟练使用hive，hbase，有es，codis，storm经验者；
熟悉使用Maven、GIT、SVN等工具；
熟悉 ?大数据处理套件TBDS
任职要求：
具有出色的软件工程交付任务汇报能力；
具有卓越的领导能力和团队管理经验；
具有出色的分析和解决问题的能力；
熟悉软件开发的流程和项目实施的过程，能够胜任项目管理工作，有大中型项目的开发和实施经验者优先；
具有良好的沟通能力，能够培训员工，带领技术队伍解决开发过程中遇到的难题；
主持项目日常开发工作、有大局观和整体把控项目的能力、需要适应出差；
?富有责任感、执行力强，有良好的团队协作精神及优秀的沟通技巧，具备较强的领导力，能承担一定工作压力；"
"职位描述：
        
        工作内容：1，针对部门大数据业务进行大数据分析、挖掘应用的开发；基于大数据平台针对业务进行开发；
2、负责大数据平台的安装调试、日常运行维护工作及撰写相关文档等工作；
3、负责大数据平台整体资源合理规划、性能优化、故障处理；
4、为项目开发人员提供大数据技术指导及解决大数据平台应用中遇到的技术难题
职位要求
1、应、往届计算机、信息、软件、电子技术、自动化、电子商务等相关专业及理工科的专、本科学生。
2、熟悉Oracle、Mysql等常用关系数据库，熟练编写SQL语句；有分布式nosql数据库应用经验优先；
3、熟悉Linux环境，能够熟悉使用shell脚本；熟练运维应用组件如tomcat、nginx等；
4、具有较强的文档编写能力，能够按照公司要求编写大数据架构设计文档；
5、对大数据技术有强烈兴趣，有志于往大数据处理方向发展；工作认真踏实，动手和学习新技术能力
福利待遇
1、朝九晚六，8小时工作制，双休。
2、国家法定节假日正常休息。"
"职位描述：
        
        岗位描述：1、负责大数据平台的规划、部署、监控、系统优化等工作；2、负责大数据平台的基础数据服务接口开发，包括数据提取、分析与结果整理；3、为线上服务高效稳定运行负责，支撑业务和数据量的快速扩张，发现并能解决重大故障及性能瓶颈；4、完成领导交办的其他任务。?任职资格:1、全日制统招本科及以上学历，计算机相关专业，3年以上大数据开发经验2、深度优化HADOOP平台MR作业/计算框架/存储技术，提升集群吞吐并降低成本；?? ?3. 具有CDH(或者HDP)/HDFS/YARN/HIVE/ES/Kylin/Hbase/Kafka/Spark/Storm/Flume/Impala/Hue/Kettle/Flink等大数据系统的架构经验3、有大规模分布式计算平台（Spark、Hadoop）的使用和并行算法开发经验4、较强的学习意识和学习能力"
"职位描述：
        
        南京佳泰得投资管理有限公司

公司简介：
佳泰得是一家专注于金融大数据挖掘、分析、以及软件平台研发的高科技公司。佳泰得集团旗下两间办公室：位于瑞士楚格州(Zug)的Drivetide Capital AG,?主要从事基于大数据分析的跨境产业整合的投资及咨询业务；位于中国南京的佳泰得投资管理有限公司，为佳泰得集团的研发中心，主导中国及欧洲产业企业的海量数据库搭建、产业链信息挖掘、金融分析及相关的投资业务。与此同时，佳泰得也自主管理量化私募基金将公司的前沿研究成果在金融投资领域直接应用。
?
佳泰得南京办公室核心研发团队是瑞士海归，为江苏省海外高端人才引进。佳泰得为兼备资本市场国际视野、及中国市场产业需求和本土特色的金融大数据高科技公司，是国际化的集科技研发、产业整合于一体的专业服务机构。

职位:
大数据算法工程师（储备经理），2名

工作地点:
南京

职位描述:
负责公司大数据平台的搭建，完成系统调试、集成与实施。
对海量的数据进行挖掘分析，发现数据和业务背后的规律，完成建模以及回测，并撰写相关报告。
负责对数据进行验证、清洗、确保数据有效性。

招聘要求:
有行业经验为佳。
有数据挖掘/机器学习/自然语言处理/推荐算法等方向丰富的工作经验。
熟悉Matlab/C,C++/Perl/Python/VBA或者MySql中的一种或者多种。
有机器学习项目经验者优先。
有网络爬虫项目经验者优先。
能承受一定的工作压力，有责任心和上进心。
佳泰得（中国）目前正致力于搭建中欧产业跨境大数据平台，业务发展迅猛，对于技术、新媒体运营、人力资源等各类人才极度渴求。
?
我们希望你，
1、对未知挑战充满好奇，能够适应创业节奏
2、学历高低不重要，但动手能力、学习能力很重要
3、人品、素质和本性一定要好
4、有长期职业发展规划
?
我们能够提供，
1、极富想象的发展空间，成长路线直至公司合伙人
2、非常公平的薪酬计划，按贡献分配，没有论资排辈
3、结构扁平的公司架构，没有效率低下的层层汇报
4、轻松愉快的公司氛围，崇尚简单纯粹有效的沟通
5、愿意传授的公司高管，不做指挥家，勇于承担带头冲锋
?
市场上很难找到我们这么开明且有理想的公司，所以请珍惜这次机会。如果这是你想参与的挑战，我给你与市场上最优秀的人一起工作和成长的机会。"
"职位描述：
        
        岗位职责：
1、参与大数据分析平台和数据仓库设计、建模、研发
2、对各源数据进行ETL与标准化
3、根据业务需求，开发相应数据产品
4、处理各类大数据系统平台的异常，确保系统平台能稳定运行

岗位要求：
?1、3年以上大数据开发工作经验，计算机相关专业本科及以上学历；?
?2、熟练使用Hadoop、Spark、Elastic Search等大数据框架，熟悉Kafka配置，熟悉基于Kafka的实时应用编程；
?3、有扎实的Java开发基础，熟悉Scala，HiveSQL等编程语言
?4、熟悉Linux操作系统和开发环境；
?5、熟悉MySQL数据库,熟练掌握sql的使用
?6、了解数据挖掘、机器学习的概念和算法；"
"职位描述：
        
        岗位职责：
1.?根据需求文档进行大数据相关的功能开发和测试；
2.?配合同事完成相应的技术文档、项目文档编写；
3.?协助完成大数据环境搭建与运维相关的工作；
4.?根据公司业务需求，参与或者主导机器学习算法实现；
5.?根据业务需求，开发大数据系统收集和分析用户行为数据；
6.?基于大数据分析，为公司数字化运营提供支撑和指导；
7.?指导其他初级中级的大数据库开发工程的技术工作，带领提升团队能力。
?
?
职位要求：
1.?985,211类大学计算机或相关专业本科以上学历；
2.?本科及以上学历，5年以上JAVA开发经验；
3.?熟悉java编程语言以及设计思想；
4.?熟悉linux操作系统以及shell常用命令；
5.?具备良好的团队合作精神，热爱学习，喜欢专研；
6.?熟悉java系统调优者优先考虑（包括CPU、内存、进程/线程、IO等资源）；
7.?熟练使用Hadoop、Spark、Elastic Search等大数据框架，熟悉Kafka配置，熟悉基于Kafka的实时应用编程熟悉分布式环境开发、部署和测试，有TB级以上的实时数据流处理开发经验优先；
8.?精通基于Spark的计算，包括RDD与SparkSQL，针对离线以及实时计算；
9.?熟悉Job系统及API接口开发，熟悉Redis、ElasticSearch者优先；
10.?对机器学习算法了解者优先考虑（有过机器学习相关领域经验，比如用户画像，个性化推荐，聚类算法、协同过滤算法，贝叶斯算法等。"
"职位描述：
        
        岗位描述：
1、参与公司大数据平台以及数据应用平台的开发与建设工作；
2、负责数据应用开发工作，如：数据开放平台、推荐平台、机器学习平台；
4、参与报表系统开发与维护工作以及NoSQL开发工作；
5、参与Hadoop生态系统、Spark Streaming等相关开发与优化工作。
任职资格：
1、本科或以上学历，计算机、通信、电子、应用数学等相关专业；
2、3年或以上Java开发相关经验，了解HadoopSpark，如：原理、M/R开发；
3、精通Java程序设计语言与Java EE体系架构，了解常用框架如Spring；
4、掌握OOA&D，了解UML与设计模式，了解Python或Linux；
5、热爱开发工作与技术研究，了解项目管理知识和开发流程；
6、具有良好的沟通能力，积极向上、乐观开朗；
7、具有团队精神和一定的抗压性，为人正直、诚信。"
"职位描述：
        
        【岗位职责】
1、负责大数据平台以及对外数据服务的调优和维护工作；
2、负责基于大数据平台的数据仓库的建模和数据治理工作；
3、负责实现为各业务方提供统计分析、数据挖掘以及图形化展示工作；
4、负责基于大数据平台的推荐和预测功能的算法设计和实现。
?
【任职要求】
1、本科及以上学历，计算机或数学相关专业，8年以上工作经验，6年以上大数据项目经验；
2、熟悉分类、聚类、回归等算法，并熟悉各种算法在推荐、预测场景下的应用，具备良好的数学功底，比如统计学、离散数学等；
3、熟练掌握PYHSON、R、SAS、SSPS等数据分析工具之一；
4、熟悉HADOOP等大数据系统和分布式系统的原理，并能够调优；
5、熟悉数据仓库知识，具备数据建模能力；
6、精通JAVA开发，熟练掌握MYSQL数据库，以及熟悉SSM开发框架；
7、具备快速的学习能力，乐观皮实，有强烈的责任心和团队精神，善于沟通和合作；
8、熟悉教育行业业务者优先，具备推荐、预测项目算法设计和实现经验者优先。

【我们的团队】
卓越教育集团（股票代码：03978.HK）是华南区最具规模的一家K12（中小学校外辅导培训）培训机构，正式员工5000多人，已涉足课外辅导，全日制教学，素能教育等领域。
卓越教育互联网管理中心于2016年成立，经过两年多的发展，已拥有80余IT精英，并呈加速发展态势。
卓越教育互联网管理中心致力于利用最尖端的大数据与智能学习技术，为各类教育机构提供自适应学习解决方案。目前中心业务涵盖教育行业软件研发、教育机构信息化建设、自适应学习系统研发等。
我们的目标和使命：科技让教育更快乐。我们希望通过教育+互联网，让学习更简单，教育更智慧，助飞孩子梦想，助飞中国教育，助力国家未来。
成员学历背景：北京师范大学、上海交通大学、同济大学、香港大学、中山大学等重点院校MBA/硕士/本科背景。
成员互联网公司背景：腾讯、网易、YY、IBM、汇丰、HP等。"
"职位描述：
        
        工作职责：

 大数据产品/组件研发 负责公司大数据产品/组件模块的设计、编码及测试； 配合产品、设计、测试人员，完成大数据产品持续优化； 基于产品/组件设计、研发体验，提出优化建议； 配合项目实施人员，解决现场实施中遇到的问题；
 大数据项目的实施 负责大数据项目功能模块的设计、编码及测试； 与项目团队合作，及时、高效交付项目功能； 能够快速定位并解决现网问题，提高客户满意度；
 技术跟踪及团队提升 指导大数据开发工程师及开发专员； 跟踪大数据技术发展方向，定期进行技术分享。



任职要求：

 本科或本科以上学历，计算机相关专业；
 具有五年以上JAVA项目经验；三年以上大数据项目经验；
 熟练使用Java语言编程，熟悉常用的中间件、开发框架等；
 熟悉大数据生态圈相关组件，熟悉HDFS、YARN、MapReduce原理，熟练使用Hive/Spark/Storm/HBase进行数据应用开发；
 熟悉常用的任务调度工具（oozie、Azkaban、kettle等）,熟悉Flume、Kafka/RabbitMQ、Redis等，熟悉Oracle/mysql 等数据库系统；
 熟悉流行的数据分析（Kylin）、可视化（Tableau、Hue）工具；
 熟悉数据仓库原理，具备BI项目实施经验。"
"职位描述：
        
        岗位职责：
1、负责大数据业务平台系统分析，参与架构设计，持续提升系统平台业务支撑能力；
2、进行具体业务领域问题分析、建模和方案设计；
3、进行相关平台实际的搭建、编码、测试及监测工作。

任职要求：
1、大学本科及以上学历，通信、计算机、应用数学等相关专业毕业；
2、3-5年以上大数据行业研发经验，精通Java或Python等至少一门语言；
3、熟悉主流应用服务器架构体系、MPP数据库及中间件技术，熟悉Hadoop/Hive/Spark/Storm/Kafka/Yarn等大数据分析处理工具；
4、熟悉大规模系统计算、网络、存储的高可用性设计和性能评估方法；
5、能独立思考，有良好的技术品味，动手能力强。"
"职位描述：
        
        【工作职责】
1. 负责数据分布式存储、计算系统；
2. 高水平团队，有 Ownership 的推动数据系统迭代；
3. 从架构到业务，支持公司快速发展；
4. 支持 CRM、搜索、机器学习平台等应用的底层数据架构。

【职位要求】
1. 掌握分布式系统原理，对存储、离线计算、实时计算中的一项或多项有深入的理解和认识；
2. 很强的系统设计&编码能力，追求优雅的设计和优秀的代码质量，高标准，快速行动；
3. 思路清晰，具备生产系统快速 trouble-shooting 的经验和能力，擅长分析更深层次的原因；
4. 对 HDFS, RocksDB, LevelDB, Memcache, Redis, MySQL, HBase, Kafka 的一项或多项有开发经验；
5. 了解 Kafka、 MQ 等消息系统；
6. 对 Spark, Druid, Flink, OLAP 的一项或多项有经验者优先；
7. 拥抱新技术，有很强的学习能力。"
"职位描述：
        
        【工作职责】
1. 负责数据分布式存储、计算系统；
2. 高水平团队，有 Ownership 的推动数据系统迭代；
3. 从架构到业务，支持公司快速发展；
4. 支持 CRM、搜索、机器学习平台等应用的底层数据架构。

【职位要求】
1. 掌握分布式系统原理，对存储、离线计算、实时计算中的一项或多项有深入的理解和认识；
2. 很强的系统设计&编码能力，追求优雅的设计和优秀的代码质量，高标准，快速行动；
3. 思路清晰，具备生产系统快速 trouble-shooting 的经验和能力，擅长分析更深层次的原因；
4. 对 HDFS, RocksDB, LevelDB, Memcache, Redis, MySQL, HBase, Kafka 的一项或多项有开发经验；
5. 了解 Kafka、 MQ 等消息系统；
6. 对 Spark, Druid, Flink, OLAP 的一项或多项有经验者优先；
7. 拥抱新技术，有很强的学习能力。"
"职位描述：
        
        工作职责：
1.基于AWS平台，面向全球；
2.负责卓动游戏运营数据云平台的建设；
3.负责海量数据的实时计算、离线计算、存储、查询；
4.参与数据平台自助化建设。
工作要求：
1.计算机相关专业，3年及以上相关工作经验,有扎实的计算机理论基础；
2.熟练Java服务端编程，有良好的编码习惯；熟悉scala、Python的优先；
3.对Hadoop相关生态体系有所了解，要求实际使用过
4.Mapreduce或者Spark等进行数据处理，有实际使用经验者优先；
5.对机器学习算法，增强学习算法等有了解的优先；
6.具有全栈能力的可以加分；
7.具备良好的学习能力、分析解决问题能力；
8.具有高度的责任心和团队合作精神；"
"职位描述：
        
        工作职责：
1.基于AWS平台，面向全球；
2.负责卓动游戏运营数据云平台的建设；
3.负责海量数据的实时计算、离线计算、存储、查询；
4.参与数据平台自助化建设。
工作要求：
1.计算机相关专业，3年及以上相关工作经验,有扎实的计算机理论基础；
2.熟练Java、Python服务端编程，有良好的编码习惯；熟悉scala的优先；
3.对Hadoop相关生态体系有所了解，要求实际使用过4.Mapreduce或者Spark等进行数据处理，有实际使用经验者优先；
5.对机器学习算法，增强学习算法等有了解的优先；
6.具有全栈能力的可以加分；
7.具备良好的学习能力、分析解决问题能力；
8.具有高度的责任心和团队合作精神；"
"职位描述：
        
        岗位职责：1、负责DMP技术架构设计与构建，根据业务规划及技术规划制定应用架构方案；2、负责设计构建DMP数据采集、存储、处理及分析框架，设计数据处理的技术流程和规范；3、负责核心功能的架构与代码模板编写，开发与维护系统公用核心模块；4、负责基于大数据技术的海量数据的自动化分析和统计工作。岗位要求：1、计算机或相关专业本科及以上学历，3年以上大数据相关技术的项目经验；2、精通SparkHive SQL，熟悉数据治理、元数据管理、数据质量管理、数据湖、数据资产化等理论和方法，有一个以上相关项目经验；3、具有较强的架构能力，具有分布式计算、实时计算、数据仓库、数据挖掘系统的架构经历优先；4、精通大数据处理技术，熟悉Hadoop、Spark、Storm等技术体系，拥有大数据中心整合、优化等项目经验；
5、熟悉DMP/DSP技术原理，了解用户的行为分析及建模；有RTB/DSP/SSP/EXCHANGE/DMP等数据应用从业经历者优先。"
"职位描述：
        
        工作职责：?
1、协助算法工程师进行算法优化,建立基于深度学习的图像识别模型；
2、参与数据采集，数据处理，数据增广，模型高参等一系列工作；
3、参与调优神经网络。?
任职资格：?
1、计算机相关专业，课程少，能实习三个月以上；
2、有扎实的基础，对Java/Python能熟练掌握；
3、有对网络爬虫的使用经验；
4、动手能力强。

优先条件：
有图像处理、文字识别相关经验或作品优先有图像处理、文字识别相关经验或作品优先。"
"职位描述：
        
        大数据研发总监
岗位职责：
（1）根据业务需求进行数据模型的调研、设计、开发及验证工作，并持续进行模型的优化；
（2）负责数据模型架构的构建，建立数据抽取、清洗、校验等数据加工流程规范及OLAP多维数据分析模型；
（3）开发数据统计系统、数据可视化系统等。
（4）持续对系统的技术架构进行改进和优化，提升海量数据的查询性能和用户体验。
（5）管理大数据平台研发团队，制定平台规划和技术路线，确保公司平台技术优势；
（6）协调各个环节及资源，推进团队工作，保障大数据平台的高效可靠运营；
（7）负责组织核心技术研究和攻关工作，组织制定与实施重大技术决策和技术方案；
（8）跟进重大项目进展，把控技术风险；
（9）建立高效研发流程和规范，持续提升平台的研发效率和质量。
?
任职要求：
Must have
（1）统招本科及以上学历，计算机、软件工程、人工智能、数据挖掘等相关专业；
（2）5年及以上大数据相关工作经验；5人以上团队带领经验；
（3）精通Java开发，有多个脚本语言（shell,python)开发经验；
（4）熟练掌握多种大数据处理技术，如Hadoop、Spark；
（5）精通HBase、Redis、Elastic Search等开源大数据存储技术，并能结合不同的业务场景深入使用；
（6）对数据敏感、对技术敏感，有研究的意识和直觉者更佳；
（7）有良好的团队合作意识，沟通表达能力和综合协调能力。
?
Prefer to have：
（1）熟悉国内外多个云计算平台，如AWS、Google Cloud
（2）关注最新的大数据技术，熟悉国内外各大开源社区"
"职位描述：
        
        岗位职责：
1、负责大数据平台的设计、开发、单元测试工作；
2、能够按照进度要求完成相关的开发任务，
3、配合测试人员的测试工作，及时修复测试过程发现的BUG，并不断对系统进行优化；

任职要求：
1、大学本科毕业，3年或3年以上工作经验；
2、精通Java或C/C++，熟练使用scala；
3、精通CDH、spark、storm；
4、熟悉MySQL、Redis、HBase、ES系统；
5、熟悉分布式软件开发过程、软件设计模式、常用的的开发框架；
6、具有良好的沟通能力，良好的团队合作精神，对工作积极主动，能有条理的完成工作任务。
7、有基于hadoop、spark、storm进行数据产品开发经验者优先。

备注：外派岗位，长期驻场上海移动（宁桥路600号）"
"职位描述：
        
        为项目外派驻岗，到深圳福田区金田路4036号荣超大厦上班（平安证券），介意慎投
岗位职责：
1、参与团队BI项目的数据开发与模型创建；
2、支持业务部门数据分析/挖掘需求以及报表需求；
3、支持公司商机项目开展，提供商机数据，并追踪实际效果。
4、上级安排的其他工作。
任职要求：
1、大专以上学历，计算机及相关专业，有机器学习、深度学习实际经验优先；
2、 精通SQL语言，熟悉数据库的范式原理，熟练操作oracle/sqlserver/mysql/hive中的任一数据库，有过项目开发的数据库设计经验尤佳；
3、有专门学习过软件工程相关的课程，对项目开发过程及过程文档有比较好的理解；
4、有良好的编码习惯，逻辑严谨，思维清晰；
5、为人稳重、责任心强、细心、好学、接受新知识的能力强、有较强的抗压能力；
6、掌握Python技能者尤佳。"
"职位描述：
        
        为项目外派驻岗，到深圳福田区金田路4036号荣超大厦上班（平安证券），介意慎投
岗位职责：
1、参与团队BI项目的数据开发与模型创建；
2、支持业务部门数据分析/挖掘需求以及报表需求；
3、支持公司商机项目开展，提供商机数据，并追踪实际效果。
4、上级安排的其他工作。
任职要求：
1、大专以上学历，计算机及相关专业，有机器学习、深度学习实际经验优先；
2、 精通SQL语言，熟悉数据库的范式原理，熟练操作oracle/sqlserver/mysql/hive中的任一数据库，有过项目开发的数据库设计经验尤佳；
3、有专门学习过软件工程相关的课程，对项目开发过程及过程文档有比较好的理解；
4、有良好的编码习惯，逻辑严谨，思维清晰；
5、为人稳重、责任心强、细心、好学、接受新知识的能力强、有较强的抗压能力；
6、掌握Python技能者尤佳。"
"职位描述：
        
        为项目外派驻岗，到深圳大剧院平安银行，介意慎投


1、使用hive构建数据仓库，数据加工后同步到oracle，做报表展示
2、熟练使用oracle，
3、懂数据仓库基本架构
4、熟练使用hive
5、有报表开发经验
6、SQL基本功要扎实"
"职位描述：
        
        1、在大数据架构师带领下，开展大数据架构设计优化及平台功能完善工作；
2、负责大数据方向某个领域的技术研究；
3、参与大数据产品研发及项目实施过程中的开发工作；
4、针对大数据平台运维中出现的问题进行分析，提供技术支持。
职位要求：

1、硕士研究生及以上学历，计算机/数学等相关专业；
2、精通至少一门语言（java、python、scala），熟悉linux操作，能编写shell脚本；
3、熟悉Hadoop、Hive、HBase、Spark、kafka、storm等相关大数据相关技术，具有以上大数据平台项目实施经验；
4、有较强的学习能力，对技术有钻研精神；?
5、具备良好的团队合作精神，对工作有热情，能够承受压力。"
"职位描述：
        
        岗位职责：

 搭建基于Hadoop/Spark的大数据平台和BI系统，实现离线/实时的数据存储和加工处理，保证数据质量；
 从数据模型、数据采集、数据传输、数据存储、ETL、数据仓库、OLAP等方面进行大数据系统架构的设计和落地；
 负责对ETL、OLAP脚本做性能分析，优化离线/实时大数据计算任务的性能;
 负责海量数据的清洗、处理和挖掘工作，支持数据分析师和算法工程师的数据需求；
 基于海量数据进行业务分析，灵活运用可视化工具，参与产品与应用的数据研发，分析数据成因，发掘数据商业价值；

岗位要求：
1.本科以上学历，具有3年以上互联网或移动互联网并基于Hadoop/Spark等应用开发经验，对分布式计算理论有深刻理解；2.熟悉Hadoop大数据相关技术体系，包括HDFS、Sqoop、Kafka、Spark、Hive、Oozie、Impala、Kylin等；熟悉CDH；3. 精通Python、Scala、Java中至少一种，能熟练编写规范代码；4. 熟悉数据仓库工具及方法论，有大数据分析与BI设计及开发经验；精通SQL，熟悉Hive、Impala或Kylin编写和性能调优；；5. 精通Spark、SparkSQL、SparkStreaming等框架并能实际使用与调优；6. 个性开朗，对技术钻研好学、逻辑思维能力强，沟通能力优秀，有团队合作精神；7. 有大规模数据集成经验，有电商数据分析背景优先考虑；"
"职位描述：
        
        岗位职责： 1、负责数据ETL平台的设计和开发，元数据管理，数据质量管理； 2、负责数据仓库模型、主题数据集市的建设，报表开发，及客户标签开发；参与大数据平台规划、建设、完善。
3、数据治理研究，数据技术的研究、引进与日常开发和维护工作。 岗位要求： 1、国内外名校本科及以上学历，计算机、电子信息、通信等相关专业，有数据仓库相关工作经历优先，有金融行业经验优先； 2、熟悉数据仓库ETL开发，熟悉kettle及Python；熟练使用SQL及存储过程开发，了解hadoop大数据平台生态；
3、具备良好的数据分析能力，了解报表开发，熟悉报表工具，有报表开发经验； 4、具备良好的沟通能力和服务意识，较强的事业心、责任感和团队合作意识。"
"职位描述：
        
        岗位职责：
1、掌握爬虫相关开发技术，能够高效的开发互联网爬虫采集新闻数据； ? ?
岗位要求：
1、本科及以上学历，计算机或相关专业，具有爬虫开发经验者优先；2、熟悉HTTP协议，熟悉正则表达式、XPath、CSS选择器等，了解常用验证码识别技术；"
"职位描述：
        
        岗位职责：
1、负责数据的采集、清洗、过滤、入库、分析、挖掘的开发和调优工作；2、负责Hadoop、Spark、Elasticsearch、Redis、MySQL集群搭建，性能调优；3、负责大数据业务处理流程的性能分析和调优；4、负责大数据产品、技术平台、数据接口的文档编写；5、及时追踪大数据技术发展，参与评估新技术引入。 ? ?

任职要求：?
1、全日制本科及以上学历，计算机及相关专业；2、熟练掌握java语言，同时掌握scala者优先；3、熟悉Hadoop/Hbase/Spark/Storm/Elasticsearch/Kafka/Redis等开源系统，具备相关系统的开发能力；4、熟悉主流关系型数据库的使用和优化，精通SQL；5、良好的沟通和学习能力。"
"职位描述：
        
        职位描述

 数据体系建设，构建强壮高效的数据处理系统
 为业务部门提供在线和离线的数据产品及模型


岗位要求

 计算机相关专业本科以上学历，有良好的计算机专业基础知识；
 具有数据仓库和数据建模的相关经验，熟练掌握至少一种分布式计算框架，如hadoop、spark、flink等，并理解其架构和工作原理；
 熟练掌握Java/Scala/Python中的一种或多种；
 具有良好的沟通和团队协作能力，对技术持有开放的态度和热情


关于公司
华扬联众于2017年8月2日在上交所上市，股票代码603825，总部在北京。
?
华扬联众全国数据技术中心（HDTC）整合了华扬联众核心数据与技术资源，立志为客户与合作方带来更高效，更具竞争优势的数字营销，实现“数据思维创造的行动力”。HDTC目前已经拥有超过80位数据工程师及分析研究人员，并将在新的架构目标中持续加大投入。于西安、南京、上海各地均设有研发中心。主要研发数字广告等相关的技术产品，产品用户覆盖至全国。多条产品线缺开发工程师；
?
您关心的

 双休；
 六险一金、年底双薪；
 每年一次调薪；
 每年一次出国旅游；
 年度旅游、各种节假日+圣诞节放假；
 十天带薪年假、七天带薪病假；
 结婚津贴、baby津贴、定时电影票等等；
 每月两次公司内部分享培训。"
"职位描述：
        
        工作职责：
1、负责数据分析系统的设计和开发；2、支持业务数据报告需求；3、积极主动研究大数据时代的各种前沿技术、并能在产品中得以运用实施；
岗位要求：
1、大学本科及以上学历，计算机相关专业，3年-5年以上工作经验；
2、对数据敏感，良好的数据分析和业务分析能力；
3、精通/熟练掌握SQL语言；
4、熟悉Linux、Shell、Java；
5、熟悉分布式计算原理，具备Hadoop、Hive、HBase、Spqrk、Redis等开发经验；
6、具备大数据高并发实时查询经验者优先考虑；
7、有互联网行业工作经验者优先。
关于公司：
华扬联众于2017年8月2日在上交所上市，股票代码603825，总部在北京。
华扬联众全国数据技术中心（HDTC）整合了华扬联众核心数据与技术资源，立志为客户与合作方带来更高效，更具竞争优势的数字营销，实现“数据思维创造的行动力”。HDTC目前已经拥有超过80位数据工程师及分析研究人员，并将在新的架构目标中持续加大投入。于西安、南京、上海各地均设有研发中心。主要研发数字广告等相关的技术产品，产品用户覆盖至全国。多条产品线缺开发工程师；
您关心的：
双休；
六险一金、年底双薪；
每年一次调薪；
每年一次出国旅游；
年度旅游、各种节假日+圣诞节放假；
十天带薪年假、七天带薪病假；
结婚津贴、baby津贴、定时电影票等等；
每月两次公司内部分享培训。"
"职位描述：
        
        岗位职责：
1、电力系统智能负荷预测、规划/运行优化方法研究、电力市场智能决策方法研究
2、对能源运行的海量数据进行清洗与分析，开发大数据计算的相关算法，并搭建实验平台；
3、基于电力大数据和专业机理，深度挖掘数据内在价值，为用户侧购售电交易、节能、电能质量治理、智能运维、故障诊断等应用场景提供核心算法支持；
?
基本要求：
1、硕士及以上学历，电力系统、电气工程及自动化、经济、数学、金融等相关专业，两年以上电力信息化系统开发经验或985高校硕士毕业生优先；
2、熟悉掌握Python、Java等编程语言一种以上；
3、熟悉常见的人工智能优化方法和机器学习编程框架，具备电力AI项目或相关编程实践经验者优先。"
"职位描述：
        
        岗位职责：
1.负责大数据平台的技术选型、大数据系统架构设计和开发工作；
2.深入了解所业务，与各业务方合作，通过数据挖掘、机器学习的方法来帮助各业务方发掘改进产品和业务的机会，并辅助做出重要决策。

任职要求：
1.计算机或相关专业本科及以上学历，至少3年或以上大数据的开发经历；
2.有海量数据系统和实时计算系统的工程架构经验，熟悉大型分布式系统的架构和开发；?
3.精通Hadoop生态系统各服务；熟悉Hadoop、Hive、Spark、Storm等大数据和实时计算框架 ；
4.有基于Hadoop、Hive、Hbase、Spark、Storm等大数据技术构建数据分析平台、分布式计算业务的设计和开发工作的实际经验；
5.有实际的大数据仓库模型设计和开发经验，了解ETL的相关理论，并应用到具体项目需求中；
6.从事过用户日志挖掘分析、用户画像、反欺诈交易、风控模型等大数据应用产品开发的优先。"
"职位描述：
        
        1、负责大数据平台的规划和搭建及业内选型2、负责规划数据挖掘的整体流程，并参与用户产品和数据产品的决策3、与业务部门密切配合，寻求数据层面的业务价值，利用数据分析结论推动产品优化 ? ?
岗位要求：
1、有5年以上大数据相关项目经验2、了解大数据框架技术如Hadoop等3、熟悉金融业务包括：证券、保险、公募基金、交易所等业务"
"职位描述：
        
        岗位职责：
1、该岗位主要负责大数据平台架构的开发和维护，负责海量据的处理、分析、挖掘；
2、负责大数据平台产品开发；
3、负责高并发、大存储的数据系统，实时计算处理系统的研发；
4、负责海量数据的处理、分析、挖掘；
5、负责SQL on Hadoop 组件、BI引擎开发与优化；
6、完成上级领导交办的临时性工作任务。
任职资格：
1、本科及以上学历；
2、具备扎实的JAVA语言基础，拥有JAVA项目开发经验；
3、熟悉Hadoop、Hive、Spark开发编程，或者具有其他并行计算的实践经验；
4、至少熟练使用Hive、Impala、Presto、SparkSQL其中一种，能够理解内部运行逻辑；
5、熟悉Presto、Kylin、Spark等开源大数据处理工具或计算引擎，并构建过相关应用开发，具有源码修改和性能调优能力者优先。
6、至少熟练使用主流关系数据库（Oracle、Mysql、DB2、SqlServer等）中的一种，熟悉SQL优化，熟悉PL/SQL编程；
7、理解分布式缓存机制，熟悉或使用过Redis、Memcached；
8、具备良好的逻辑思维，学习能力强，有创新精神，善于学习钻研新技术，良好的团队合作意识。

具有以下条件者优先：
1、一年以上大数据处理、大数据分析经验；

2、一年以上Hadoop 相关项目实际研发经验，如Hadoop、Hive、Spark等；（可接受优秀的应届毕业生）

3、熟悉Hadoop、Hive、Spark 底层API调用，或者对Hadoop、Hive、Spark源码有深入研究和工作经验者；

4、熟悉开源多维分析工具，如Presto、Kylin、Mondrian，具有BI引擎开发与优化"
"职位描述：
        
        工作职责
1、负责数据产品的服务开发工作。
2、参与前期需求沟通和分析，以产品化开发的思维，完成需求分解和数据架构设计。
3、与产品经理、测试工程师等其他团队沟通合作，保证产品研发工作的质量和进度。
4、参与新技术的技术难题的攻关，根据业务规划和技术规划设计数据解决方案。
职位要求
1、大学本科或以上学历，计算机、数学或统计等专业，3年以上数据开发经验。
2、精通Java编程语言，熟练掌握jvm性能调优。
3、精通spark streaming、storm、flink等实时计算技术，并有相应的开发、性能调优实战经验。
4、熟悉Hadoop生态，了解存储、计算框架的原理。熟悉Redis、HBase、Spark、Kafka、Elasticsearch。
5、良好的语言沟通与表达能力及自我驱动力。
6、具有大数据全链路开发优先。"
"职位描述：
        
        1.统招本科及以上学历，计算机、软件或相关专业；
2.5年或以上（应届生除外）的后端开发经验，并具有扎实的代码功底和实战能力；
3.熟练掌握java、python、shell语言及其生态圈；
4.熟悉Linux操作系统及其环境中的开发模式；
5.熟悉常用的数据库技术，了解常用的各类开源框架.组件或中间件；
6.熟悉Hadoop技术及其生态圈(Spark等)；
7.工作踏实、积极，责任心强，能承担压力，有较强的执行力、解决复杂问题能力和自我驱动能力；
8.良好的沟通能力和团队协作能力；

加分项：
1.有前端研发经验者优先；
2.有架构经验，系统优化经验者优先；
3.熟悉金融、银行类项目者优先；
4.熟悉人工智能相关概念，知晓人工智能运行逻辑；
5.认同并坚信人工智能能为产业带来革命性的变化，对未知的渴求。"
"职位描述：
        
        岗位职责：
1、负责公司数据分析产品的数据仓库的开发和维护；?
2、负责数据分析、加工、清理、处理脚本的开发；
3、负责数据相关平台的搭建、开发、维护、优化；
4、与数据分析团队配合，进行行业机器学习模型的构建与迭代；
5、快速熟悉行业客户数据，主动探索并学习行业业务数据；
6、分布式平台应用部署（Hadoop/Spark/Hive/Hbase）。
?
任职要求：
1、计算机相关专业，1年或以上数据工程、数据处理经验；
2、掌握mysql或postgres等关系数据库知识，了解Oracle数据库，对海量数据挖掘分析有浓厚兴趣，了解Hadoop，PySpark技术，熟练Hadoop/Spark/Hive/Hbase者优先；
3、熟练掌握SQL查询及优化，有海量数据处理、分析经验者优先；4、熟练Linux Shell，了解python语言，能够用python编写脚本者优先；5、逻辑思维能力强，具备良好的自主学习和业务理解能力；6、良好的人际沟通及团队合作能力，具有强烈的责任心。"
"职位描述：
        
        职位描述：岗位职责
????1. 负责数据指标体系建设；
????2. 负责基于大数据的数据仓库的设计、开发；
????3. 设计数据运营平台、为业务提供OLAP、报表、数据提取等服务；
????4. 负责挖掘用户需求及产品使用习惯，建立数据模型，用数据推动业务发展；
岗位要求
????1. 大专及以上学历，3年及以上经验，熟悉数据仓库、数据建模经验；
????2. 精通SQL（熟悉Hive sql、Spark sql优先）；
????3. 有Owner精神，善于沟通，有良好的团队合作精神；
????4. 有大型公司数据统计/分析相关经验优先；
????5. 既熟悉传统BI, 又熟悉大数据BI的优先"
"职位描述：
        
        岗位描述：?1、负责按计划高质量完成系统的开发落地实现?2、负责与大数据平台其他相关系统进行开发、联调、配合?3、负责实时流及中间件数据处理工作?任职要求：?1、本科学历，3年以上工作经验，具有较强的学习能力?2、熟练Linux操作系统，熟悉linux环境下的集群搭建?3、熟悉spring、mybatis、spring?boot等框架?4、熟悉mysql，postgrep关系型数据库以及了解Elasticsearch分布式文档存储系统?5、熟悉MapReduce执行原理和执行流程，以及hdfs分布式存储原理?6、熟悉zookeeper、flume、sqoop、kafka以及hive和hbase原理?7、熟悉java和scala语言，能根据spark的api进行java或者scala开发，能结合flume、kafka、spark等框架对数据进行处理?8、能够接受出差。"
"职位描述：
        
        岗位职责
1、负责华为云大数据及AI服务产品特性的设计、代码开发，测试验证及运维工作；
2、负责交付特性、子系统设计文档和接口，参与特性代码开发。


岗位要求
1、至少精通C、C++、Java、Python中的一种；
2、有完整的项目开发经验，具备系统核心模块看护经验；
3、有云服务化开发经验、DevOps实践经验、开源社区项目代码贡献者优先；
4、具备云计算、大数据、高性能计算相关领域开发维护相关经验优先"
"职位描述：
        
        岗位职责：
1）面向金融、公安、交通等行业客户提供大数据算法解决方案，帮助客户挖掘数据价值，构筑差异化竞争力，支撑解决方案取得商业成功；
2）负责智慧交通中交通流量预测的建模和算法设计、开发；
3）负责金融领域的反欺诈建模和算法设计、开发；
4）负责公安领域的业务建模和算法设计；
5）在新数据分析算法上实现技术突破，比如在精度、准度、效率等方面有显著提升，进一步成果达到业界领先水平，在产品竞争力上可以跟行业标杆可比；
6）能够把握行业发展趋势，根据未来客户的潜在需求，提出并论证新的技术方向和课题。

岗位要求：
1）熟悉Spark、流计算、Hadoop、Flink、GraphX、GraphLab、HBase等开源大数据平台；
2）熟悉数据挖掘算法，对分类、聚类、时序、图等算法有很深了解；
3）具有大数据软件工程能力，至少在大数据开源平台上有2年以上开发经验者优先；
4）具有金融反欺诈行业数据分析、数据建模经验者优先。"
"职位描述：
        
        岗位职责：
1、负责Hadoop/Spark等大数据场景下方案开发验证和性能调优；
2、负责x86、arm64架构下，大数据性能调优工具需求分析、设计及代码编写，性能工具框架看护。
岗位要求：
1. 熟悉C/C++/Java等一种以上编程语言；
2. 熟悉linux操作系统，熟悉Shell、Python语言；
3. 熟悉大数据开发框架，熟悉Hadoop/Spark/Hbase/MPP DB及业界主流流处理平台如Storm/Flink/Spark Streaming之一，对于上述组件有实际的性能调优经验者优先。"
"职位描述：
        
        ? ?【岗位职责】

 负责华为大数据平台解决方案和架构设计
 负责华为大数据产品的交付和性能比拼，大数据开发设计

【任职要求】
?1.熟悉Linux的基本操作命令，熟悉Java/Python/Shell的一种和多种；
?2.有Hadoop/HBase/Spark/Hive等数据库经验者优先
?【工作地点】深圳，西安"
"职位描述：
        
        【岗位职责】
1、负责Hadoop/Spark/图数据库/流处理/搜索引擎产设计和开发；
2、负责Hadoop/Spark生态圈组件维护，开源社区动态跟踪、竞争力分析和规划技术演进；
【任职要求】
1、精通Java/Scala/Python主流开发语言，具备Linux环境开发经验；
2、有分布式软件开发经验，熟悉Hadoop/Spark/HBase/Hive/Flink/Elasticsearch中至少一个组件。"
"职位描述：
        
        业务技能要求：
1、熟练掌握Java、C++、python等主流开发语言的一种；
2、熟悉Linux配置和Shell使用；
3、熟练掌握常用的软件架构模式，并能熟练使用基本的编程编译工具；
4、3年及以上项目开发经验，熟练掌握Java/Web/JS/C++等主流开发语言，独立承担过20K以上模块开发、维护工作，并能独立承担4K规模子系统和模块开发设计工作，有以下相关经验、技能者优先考虑：
1）熟悉分布式架构、有分布式软件开发经验者；
2）熟悉Openstack、WMWare等云操作系统软件者；
3）有云计算及大数据/SDN/NFV领域开发经验者；
5、具有良好的沟通能力，刻苦、敬业、有上进心，有良好的团队合作精神。对技术有激情，喜欢钻研，能快速接受和掌握新技术，有较强的独立、主动的学习能力。
专业知识要求：
1、精通Java/Scala/Python/C/C++/JavaScript/JSP中的一种或多种；
2、有完整的项目开发经验，系统核心模块看护经验者优先；
3、有大数据Hadoop/HBase/Flume/Kafka/Flink /Hive/Spark等开源大数据技术相关经验者优先。
4、有GIS、LBS等数据挖掘算法优先；
5、有Angular、Jquery、Spring、Tomcat、Restful经验者优先"
"职位描述：
        
        1. 负责内部各类人效数据源系统（Aone、HRM、信息平台、CRM等）的采集、清洗、加工，以及对产品端提供数据服务；2. 协同BI、算法、产品等角色，共同打造智能数据产品。岗位要求1. 计算机相关专业，3年以上数据仓库相关开发经验；2. 熟悉Hadoop/Hive/Hbase/Storm/NoSQL等若干个数据处理框架，有较好的SQL性能调优经验；3. 有互联网产品用户行为研究/日志采集/大数据处理/数据可视化经验优先；"
"职位描述：
        
        岗位职责：
1、负责大数据平台的建设，接入和管理各业务数据，进行数据采集、抽取、整合、提取和数据可视化等工作；
2、负责数据仓库建设；
3、负责数据服务的分布式实现，满足可扩展性等业务指标。


任职资格：
1、本科及以上学历，计算机科学、自动化、软件工程、电子信息工程、数学、统计学等专业毕业，211/985院校优先；
2、初级1年以上工作经验，高级3年以上工作经验，统招本科毕业；
3、熟悉Linux/Unix系统，有动态语言开发经验，熟悉Python、C/C++、Java等任一一种语言并了解其优缺点； 熟悉多种web框架并了解其优缺点；
4、熟悉多种存储软件(如MySQL/PostgreSQL/Redis/MongoDB/DynamoDB)；
5、具备良好的识别和设计通用框架和模块的能力；
6、熟悉分布式、多线程、异步及高性能设计，会性能调优；
7、熟悉hadoop生态系统常见项目的使用（hdfs、hive、hbase、spark等），具有spark、数据仓库开发经验，有实际大数据项目优先；
8、具有良好的团队合作精神和表达沟通能力；
9、熟练的英语读写能力。"
"职位描述：
        
        职位描述：
1.负责业务模块数据仓库的构建；
2.负责数据模型的设计，ETL实施、ETL性能优化、ETL数据监控以及一系列技术问题的解决；
3.负责全产品线数据字典维护，提升数据资产质量。
4.负责大数据产品的整体架构设计；
5.负责大数据相关的技术进行前瞻性研究，为团队提供长远的技术储备。
人员任职要求：
1.计算机、数学相关专业本科及以上学历，三年以上大数据开发工作经验；
2.熟练掌握Hive/SQL，熟悉Spark/Map-Reduce分布式计算框架，
3.熟悉大数据的离线和实时处理，可以进行海量数据模型的设计、开发；
4.熟悉ElasticSearch,HBase优先;
5.工作认真，负责，良好的团队合作精神和解决问题分析能力。钻研技术克服困难，勇于挑战；有数据分析经验优先。"
"职位描述：
        
        工作职责:1、PaaS平台数据仓库的设计与开发，2、OLAP相关技术研发，海量数据OLAP应用的优化，3、实时数据的ETL开发，4、实时OLAP引擎的运维保障。任职资格:1、数学、统计、计算机等相关专业，大学本科及以上学历；2、了解统计学、数学、人工智能和数据挖掘理论基础，了解数据仓库、数据挖掘与分析的相关知识，具有良好的数据模型设计能力，熟悉常用统计分析方法、数据挖掘基本算法；3、熟悉Linux环境开发，熟练使用Shell、Python等脚本语言之一；4、熟悉 hadoop 生态，包括但不限于Hadoop, HBase, Hive, Kafka, Flume，ElasticSearch，Spark，Storm, Druid/Presto/Impala 等，具备2年以上开发和使用经验；5、具有OLAP数据仓库应用经验，熟悉相关ETL、Cube等技术；6、有MPP类(Clickhouse,Greenplum)数据库开发经验的优先-7、具有SaaS,PaaS行业经验者优先。"
"职位描述：
        
        从事智慧城市、智能交通大数据相关的软件产品和工具的研发，涵盖数据采集、接入、清洗、分析、挖掘各个阶段；
1、协助公司大数据模块化平台的搭建与优化工作；
2、负责海量数据采集、接入、清洗、分析、挖掘的代码实现；
3、协助建立并完善的数据分析挖掘流程及体系。
任职要求 ：
1、2年以上软件开发工作经验，本科以上学历，计算机相关专业；
2、能熟练运用Java/Python/Scala/多种语言进行软件开发；
3、熟练掌握基本的算法和数据结构，熟练掌握至少一种主流关系型数据库的使用和开发，熟练掌握SQL语言，熟悉NoSQL和NewSQL数据库；
4、精通Hadoop、Storm、Spark、HBase、Flume、Kafka、ES等组件的原理，精通分布式系统开发，数据仓库技术；
5、对Hadoop平台架构能够不断优化，提升数据产品的质量和体验；
6、强烈的责任心与求知欲，对技术有极大的热情，有良好的沟通能力。"
"职位描述：
        
        工作职责：
1. 大数据相关模型和算法的研发，基于分布式数据存储和计算平台进行领域大数据工具的研发，包括主题统计分析工具、数据挖掘分析工具和相关数据可视化工具等；
2. 支持大数据产品和工具在领域项目中的落地；
任职要求：
1. 计算机、软件工程、数学、统计等相关专业，研究生学历者优先考虑
2. 熟练掌握至少一种下列编程语言：Java、C、Python；
3、熟悉SKlearn、Tensflow、spark等工具
4. 熟悉机器学习算法，可应用成熟算法进行高性能软件的开发；
5. 熟悉Hadoop、Elasticsarch、Neo4j等开源产品；
6. 学习能力强，良好的团队合作能力；
7. 有大规模批量数据处理经验者优先."
"职位描述：
        
        岗位职责：
1、负责构建Spark/HDFS大数据处理架构；
2、负责基于Spark技术的海量数据的自动化分析处理和统计工作；
3、基于Spark框架大数据架构的设计、开发和维护；
4、根据相关需求使用SparkStreaming/Storm、SparkSQL进行数据处理、查询和统计等工作；
5、实现大数据的深层次挖掘和准确业务推荐/营销。


任职要求：
1、大学本科一批及以上学历，计算机相关专业毕业，有扎实的计算机理论基础，对数据结构及算法有较强的功底；
2、熟悉Linux环境下的Java/C/C++编程，对大数据开发保持浓厚兴趣；
3、熟悉Hadoop或Spark，对Hdfs/Mapreduce/Hbase等软件有一定的研究，能解决Hadoop的复杂问题；
4、有优秀的学习能力，良好的沟通表达能力和团队合作精神；
5、熟悉Jvm运行机制及内存管理者优先、熟悉Shell,Python等脚本语言者优先、有分布式或并行计算的开发经验者优先、有阅读过Hadoop相关软件源码者优先。"
"职位描述：
        
        职位描述：
岗位职责：?
1、负责XX数据仓库的架构设计,?开发和实施；
2、负责数据ETL流程的建设，优化以及解决ETL相关技术问题；
3、负责机器学习流水线的架构设计,?开发和实施；
4、负责数据任务调度系统、数据监控系统的设计，开发和实施；
5、负责数据schema管理系统的设计，开发和实施。

任职要求：
1、本科及以上学历，计算机相关专业;两年以上互联网行业大数据相关工作经验；
2、了解并行和分布式计算的基本原理；熟练掌握Hadoop,hdfs, hive, Spark,Storm,flink，cassandra, hbase、ElasticSearch等常用的大数据系统或式计算框架；熟悉MySQL, postgres, MongoDB等数据库；
3、具备优秀的数据敏感性；
4、优秀的分析问题和解决问题的能力，勇于解决难题；强烈的上进心和求知欲，较强的沟通表达能力与协作推进能力；?
5、热爱互联网，对互联网产品和技术有浓厚的兴趣，热衷于追求技术极致与创新；
6、有开源社区贡献经验的开发者优先考虑。"
"职位描述：
        
        岗位职责：
1、负责公司数据仓库的搭建以及快速并行化查询需求的支持
2、负责公司的数据处理、数据统计以及数据挖掘的开发工作?
3、负责公司后台日志统计分析系统的具体开发工作??
4、利用hadoop、spark等框架做数据的实时及离线分析
?
岗位要求：
1、本科以上学历，java基本功扎实，熟悉Scala的优先
2、熟悉分布式计算和存储技术，熟悉Hadoop、MapReduce、Spark等
3、熟悉MYSQL、ORACLE等关系数据库
3、熟悉Mongo、HBase等NOSQL数据库。?
4、熟悉大数据的统计分析和挖掘，了解常用的数据统计方法和挖掘算法。
5、熟悉Linux?操作系统,?可以自行部署开发环境
?
加分项：
1、对程序开发有浓厚热情的，愿意深入学习，立志成为开发大牛的；
2、有写博客习惯或能提供github地址的
3、了解股票，期货和其他金融衍生品的知识者优先"
"职位描述：
        
        岗位职责：1. 负责大数据管理平台的设计与开发；2. 负责大数据平台相关组件的二次开发；3. 负责数据仓库的ETL设计与开发；4. 负责基于机器学习/NLP的底层数据挖掘开发。任职要求：1. 211/985院校本科以上学历，计算机，数学等相关专业；2. 3年以上的大数据开发经验，掌握整个大数据开发流程；3. 掌握java、python中的一种语言，能熟练使用shell脚本；4. 精通Hadoop/hive/spark/presto/airflow等开源大数据技术组件中的至少两种；5. 具备良好的团队合作精神、较强的自驱力，抗压能力，沟通能力，责任心以及独立解决问题的能力；6. 有数据标签/用户画像/自动化ETL开发等经验优先。"
"职位描述：
        
        岗位职责：
1.?? 负责管理大数据平台技术栈；
2.?? 参与大数据项目的技术架构评审，提供架构优化建议；
3.?? 负责主导大数据平台日常运维工作；
4.?? 负责解决大数据开发的疑难问题，提供大数据开发的技术支持；
5.?? 负责建立大数据平台多租户管理、资源管理和平台运营制度，制定大数据开发规范；
6.?? 负责优化大数据任务的资源调配，提升大数据平台的数据处理能力和资源利用率；
7.?? 积极了解业界发展、互联网相关新技术及趋势，参与规划公司未来数据架构方向。
?
任职资格：
1.???????? 统招本科及以上学历，3年以上大数据开发运维经验。
2.???????? 熟悉大数据平台（CDH）的运营管理，熟练使用CDH管理平台；
3.?? 熟悉Hadoop/Spark大数据主流生态技术，如HDFS、HBase、Hive、Kudu、yarn、presto、spark、spark streaming等；
4.?? 能对大数据技术进行合理应用并解决开发和运维的技术问题。
5.???????? 熟悉大数据平台的集群部署、数据存储、数据处理等方面的可用性、可靠性设计和性能评估标准，以及相应的性能调优；

具备以下条件之一或以上者优先考虑：
1.?? 拥有保险行业大数据系统开发经验者优先。
2.?? 拥有大数据平台平台运营、运维经验者优先"
"职位描述：
        
        任职要求：
1. 计算机或者相关专业本科以上学历，两年以上工作经验；
2. 熟悉多种主流ETL工具；
3. 熟悉主流数据库系统中的一种或多种，例如Oracle、DB2、Teradata、SQL Server等；
4. 熟悉Linux/AIX等操作系统，熟悉常用的shell命令；
5. 具有较强的自学能力，能够承受较强的工作压力；
6. 具备较强的沟通能力，能快速融入团队；
7. 工作踏实认真，有责任心；
8. 具备银行金融行业项目经验者优先；"
"职位描述：
        
        工作职责
1、负责物联卡大数据平台的业务数据采集； 2、负责物联卡大数据平台的业务数据清洗、转换工作； 3、负责物联卡大数据平台的业务应用模型建模； 4、负责物联卡大数据平台的业务应用spark/phthon代码开发。

任职资格
1、计算机或相关专业本科以上学历； 2、有过大数据相关工作经验一年以上或有过BI/经营分析系统开发等相关数据分析开发一年以上工作经验； 3、熟悉数据仓库和数据建模的相关技术细节； 4、熟悉HADOOP、SPARK、HIVE、HBASE、SQOOP等大数据技术框架； 5、至少能熟练使用JAVA、PHTHON中的任意一种技术语言； 6、善于沟通、积极主动、工作责任心强，善于团队合作；"
"职位描述：
        
        岗位职责：

 负责产品的数据建设，建立完善的底层存储，数据计算，数据仓库，OLAP分析，实时计算，业务建模等；
 负责产品所有的相关数据，包括数据收集，数据加工（离线/实时），数据可视化，数据仓库等，完整的一套数据处理流；
 负责大数据领域的前沿技术研究和技术难点攻克。

任职要求：

 计算机或相关专业本科以上学历，大数据开发相关工作经验3年以上；
 精通Java / Scala / Python?任意一门；
 深刻理解大数据处理（流计算、分布式计算、分布式文件系统、分布式存储等）相关技术和实现；
 熟悉Hadoop / Hive / HBase / Spark / Storm / Kafka / Elasticsearch?等。

加分项：

 熟悉某一大数据源码优先；
 相关互联网公司工作经验优先。"
"职位描述：
        
        任职要求：
1、3年及以上数据处理（ETL）开发经验，能独立完成数据处理开发工作
2、熟悉mysql/oracle等标准数据库，熟练上述数据库的开发
3、有hadoop和hiveSql的使用经验
4、熟悉ETL设计，熟悉数据仓库的架构、开发规范和流程
5、熟悉至少一种ETL开发工具，如Datastage，Informatica,?kettle等
6、具备数据仓库实施经验者优先"
"职位描述：
        
        任职要求：
1、3年及以上数据处理（ETL）开发经验，能独立完成数据处理开发工作
2、熟悉mysql/oracle等标准数据库，熟练上述数据库的开发
3、有hadoop和hiveSql的使用经验
4、熟悉ETL设计，熟悉数据仓库的架构、开发规范和流程
5、熟悉至少一种ETL开发工具，如Datastage，Informatica,?kettle等
6、具备数据仓库实施经验者优先"
"职位描述：
        
        项目背景：?开发的是一个大数据平台产品，在大数据的各种工具上封装一个产品提供大数据数据服务的门户，满足企业各种应用需要。这是一个大数据产品，不针对具体某种行业或者业务。
?
岗位要求
1、三年及以上相关工作经历，本科及以上学历；
2、具有大数据生态系统项目工作经验，如Hadoop, Hive, HBase, Spark, Kafka；
3、具有java和/或Python开发经验，Python经验优先；
4、具有大数据产品能力和性能调整经验者优先；
5、熟悉MySQL/PostgresSql/Oracle等；
6、在处理大量结构化和非结构化数据方面有经验，有MapReduce经验者优先。"
"职位描述：
        
        
岗位职责：
1.负责ETL设计、模型设计、开发、技术支持等工作，并保证数据安全、及时、稳定、可恢复
? ?

任职要求：
1、3年及以上数据处理（ETL）开发经验，能独立完成数据处理开发工作
2、熟悉mysql/oracle等标准数据库，熟练上述数据库的开发
3、有hadoop和hiveSql的使用经验
4、熟悉ETL设计，熟悉数据仓库的架构、开发规范和流程
5、熟悉至少一种ETL开发工具，如Datastage，Informatica,?kettle等
6、具备数据仓库实施经验者优先"
"职位描述：
        
        
岗位职责：
1.负责ETL设计、模型设计、开发、技术支持等工作，并保证数据安全、及时、稳定、可恢复
? ?

任职要求：
1、3年及以上数据处理（ETL）开发经验，能独立完成数据处理开发工作
2、熟悉mysql/oracle等标准数据库，熟练上述数据库的开发
3、有hadoop和hiveSql的使用经验
4、熟悉ETL设计，熟悉数据仓库的架构、开发规范和流程
5、熟悉至少一种ETL开发工具，如Datastage，Informatica,?kettle等
6、具备数据仓库实施经验者优先"
"职位描述：
        
        【技术要求】
1.熟练Hadoop、Hive、Spark、Kafka等技术;?
2.丰富的面向对象编程经验，Java或Python开发语言
3.熟悉RDBMS (MySql、PostgresSql、Oracle等)和NoSQL (HBase、MongoDB、Redis,HBase、等)
4.掌握配置和调优开源软件。
5.熟练使用JBoss/Wildfly, Git, Gerrit。
6.有处理大量结构化和非结构化数据的经验。有MapReduce经验者优先。
7.大数据产品的容量和性能调优经验优先。
8.了解机器学习和机器学习的经验，如scikitt -learn，是一个优势。
9.有Web UI开发经验者优先考虑，特别是反应和其他工业架构。
【工作内容】
1.系统设计和工程集团的重点是技术创新和卓越的大数据分析产品设计的各个行业。该集团负责设计、实施和验证，以满足爱立信客户的要求。
2.我们正在寻找具有良好设计和开发技能的软件开发人员。这个角色承担着技术责任，包括设计和开发新的应用程序，优化和改进现有的大数据分析应用程序。
3.与产品负责人合作，建立一个基于需求的成本效益和可靠的解决方案。
4.以商定的成本和良好的质量执行解决方案。
5.将应用程序与其他/外部系统或应用程序集成。
6.故障诊断和故障修复
7.部署应用程序和支持用户。
8.提出改进和优化思路并进行跟踪。"
"职位描述：
        
        工作职责：
1. 负责金融数据的抓取和清洗工作；
2. 搭建数据服务平台，完善数据平台架构，不断提升数据的准确性和及时性；
3. 监控数据的准确性，建立和完善数据审核机制和平台；
4. 参与其它具体金融业务产品模块设计和实现，以及后端金融算法实现和优化。
职位要求：
1. 熟悉 Linux 环境下的 Python / JAVA 编程，优秀的编程能力和风格；
2. 熟悉爬虫原理，熟悉常见的反爬虫技术，有爬虫相关项目开发经验者优先；
3. 掌握 http 协议，熟悉 html、dom、xpath 等常见的数据抽取技术；
4. 熟悉 Linux 操作系统和 Shell 编程，以及分布式系统；"
"职位描述：
        
        岗位职责：
1.负责ETL设计、模型设计、开发、技术支持等工作，并保证数据安全、及时、稳定、可恢复
任职要求：
1、3年及以上数据处理（ETL）开发经验，能独立完成数据处理开发工作
2、熟悉mysql/oracle等标准数据库，熟练上述数据库的开发
3、有hadoop和hiveSql的使用经验
4、熟悉ETL设计，熟悉数据仓库的架构、开发规范和流程
5、熟悉至少一种ETL开发工具，如Datastage，Informatica,?kettle等
6、具备数据仓库实施经验者优先"
"职位描述：
        
        ?项目背景：?联想LUDP2.0大数据平台是基于联想大数据LEAP产品搭建的大数据平台，支持多业务部门的数据分析。此岗位将参与联想大数据平台日常维护和开发工作。
??职责??
? ? ?1、参与联想大数据平台日常运维：大数据相关服务的管理和优化
? ? ?2、参与联想大数据平台的Bug修复和新增功能开发
??技能??
? ???1)?精通Java编程语言
? ? ?2）熟悉Hadoop、Spark等大数据相关服务组件
? ? ?3）了解大数据应用程序的开发
? ? ?4）具备在Linux系统上进行软件部署、问题分析和排查的能力
? ? ?5）具有较好的沟通能力
??工作年限/项目经验?
??? ?1）1年以上大数据开发或维护经验,
? ? ?2）有Hadoop部署、管理和优化经验
? ? ?3）有Web应用服务开发经验
? ? ?4）有大数据实时流处理(如Storm、Redis)开发经验者优先考虑
? ? ?5）有Scala或python开发经验优先考虑"
"职位描述：
        
        岗位职责：
1.负责ETL设计、模型设计、开发、技术支持等工作，并保证数据安全、及时、稳定、可恢复
任职要求：
1、3年及以上数据处理（ETL）开发经验，能独立完成数据处理开发工作
2、熟悉mysql/oracle等标准数据库，熟练上述数据库的开发
3、有hadoop和hiveSql的使用经验
4、熟悉ETL设计，熟悉数据仓库的架构、开发规范和流程
5、熟悉至少一种ETL开发工具，如Datastage，Informatica,?kettle等
6、具备数据仓库实施经验者优先"
"职位描述：
        
        岗位职责：
1.负责ETL设计、模型设计、开发、技术支持等工作，并保证数据安全、及时、稳定、可恢复
任职要求：
1、3年及以上数据处理（ETL）开发经验，能独立完成数据处理开发工作
2、熟悉mysql/oracle等标准数据库，熟练上述数据库的开发
3、有hadoop和hiveSql的使用经验
4、熟悉ETL设计，熟悉数据仓库的架构、开发规范和流程
5、熟悉至少一种ETL开发工具，如Datastage，Informatica,?kettle等
6、具备数据仓库实施经验者优先"
"职位描述：
        
        
岗位职责：
对副总裁负责，负责部门整体规划及部署，兼任产品研发工作。

1.?? 围绕机构发展战略，基于现有数据，提炼数据价值，制定产品发展规划；
2.?? 根据产品发展规划路线图，负责数据产品及服务的产品设计、创新、研发、风险控制及维护；
3.????? 对标行业或跨行业相关机构，进行产品升级及迭代，以更好满足客户的现有需求及潜在需求；
4.????? 带领团队完成机构基础数据采集、清洗、架构、质控工作，确保数据的完整、唯一、准确、及时；
5.????? 与技术团队协同确保产品的落地；
6.????? 协助副总裁负责数据部管理工作，制定相关规章和流程，确保部署的工作有效执行；负责部门预算管理、团队管理和能力提升。

基本能力要求：? ?

1. 计算机及相关专业本科以上学历；
2. 具有6年以上工作经历、3年以上团队管理经验；
3. 具备大数据项目的研发和项目管理实践；
4.?? 有互联网行业从业经验者优先；
5.?? 工作积极主动，具备较强组织沟通协调能力、团队管理能力、应变能力和独立解决问题能力；具有较强的抗压能力，勤于学习，勇于担当。"
"职位描述：
        
        1、熟悉Hadoop配置，了解HDFS结构；
2、具有设计管理HBase数据库经验；
3、熟练编写Hive脚本，sparkSQL脚本；
4、map reduce程序、Java语言版的spark程序、scala语言版的spark程序、Python语言版本的spark程序，至少熟悉其中两个；
5、有JAVA开发大数据应用客户端经验；
6、具有ElasticSearch项目经验；
7、参与过MONGODB项目开发。"
"职位描述：
        
        岗位职责：
1、负责、参与大数据相关专业课程的日常授课工作以及教学大纲、教材、教学案例、教案、讲稿、多媒体课件等课程建设等；2、负责、参与调研大数据人才市场需求发展趋势，制定与完善大数据相关专业培养方案；3、研究最新大数据相关技术，参与大数据研发项目；4、根据大数据项目开发需求，编写相关项目方案；

任职要求：
1、计算机、数学、统计学等大数据相关专业本科及以上学历，985、211优先，硕士优先；
2、熟练掌握C、Java或C++编程，熟悉Linux操作系统；
3、具备良好的语言表达能力以及文字功底；
4、有较强的责任心和团队协作意识；
5、熟悉Hadoop、Spark等大数据技术生态圈者优先；
6、熟悉SAS、R、Python等数据处理常用语言者优先；
7、熟悉Tableau等可视化工具者优先；
6、有数据挖掘、数据分析等数据处理工作经验者优先；
7、有大数据业务培训授课经验者优先；"
"职位描述：
        
        任职资格：
1、计算机相关专业本科及以上学历；?
2、熟悉Hadoop、HDFS，MapReduce，Hive等开源分布式系统；?
3、熟悉Spark、SparkSQL、SparkStreaming、Storm等框架；
4、熟悉python、shell、java等中的1种以上 ；
5、3年以上工作经验，至少有1年大数据开发或分析经验；?
6、有持续学习的能力；喜欢开源软件，乐于知识分享；对工作认真负责；可以独立承担较大工作压力；
7、有物联网经验优先。?

岗位职责：
1、使用大数据相关的技术(Hive、hadoop、hdfs）解决业务相关问题；?
2、理解 HDFS 体系架构，并能给予Hive、HDFS、python、R、Spark、Zeus等工具构建离线系统；?
3、利用大数据平台实现对数据的分析和处理；?
4、负责各类离线系统的业务调研，并与公司其他部门负责沟通协调；
5、负责离线系统中数据处理工作（数据采集、清洗、汇总、集成等）；
6、负责协助完成离线系统中数据上下层衔接处理工作；?
7、负责各类离线系统的开发、部署等工作；?
8、负责各种高并发场景解决方案；
8、具有良好的逻辑思维能力，可以独立承担工作压力，善于学习，与团队沟通无障碍 。"
"职位描述：
        
        工作职责: 1、负责分析业务部门数据需求，提炼维度、指标，制定数据平台标签体系； ?2、负责数据应用产品的设计和开发，如自助分析与取数产品的开发和优化; ?3、负责数据应用产品的相关测试; ?4、负责数据仓库外围数据接口开发; ?5、负责数据应用产品的推广和使用培训。任职资格: 1、全日制统招本科及以上学历，计算机相关专业; 2、3年以上工作经验，具有自助分析与取数、用户画像等数据产品开发经验优先，熟悉数据应用开发流程，掌握HTML5或JS、JAVA、Hive SQL等; 3、具有良好的业务理解能力; 4、具有责任心、工作积极、有团队协作精神、有良好的沟通能力。"
"职位描述：
        
        技术层面：1. 基于 Hadoop Spark 数据 ETL 开发2. 基于 Restful Java Web 后台接口开发3. 技术文档编写，新技术调研备注：有两年以上java web开发经验能力层面：1. 思路清晰，善于通盘考虑，控制风险点2. 吃苦耐劳，能承受较大压力，工作任务3. 能积极和同事高效沟通配合，自燃型员工4. 对于自己的工作质量有严格要求，有强迫症5. 对自己的定位有清晰认识"
"职位描述：
        
        工作职责：
1.负责平台的搜索数据分析、挖掘等工作；
2.负责平台搜索用户画像；
3.负责数据的可视化工作，以及商业智能，为提升用户体验提供数据支持。

职位要求：
1.熟练掌握JAVA开发，熟悉掌握分布式应用开发原理，熟练掌握多线程开发，熟练掌握设计模式；
2.熟悉jvm，有线上调优经验；
3.熟悉常用的大数据分析框架，如hive、spark、flink、Impala等，并熟悉运行原理；
4.良好的计算机编程素养；
5.熟悉机器学习算法加分。"
"职位描述：
        
        岗位职责：
1、 参与大数据平台设计和实施，负责基于Hadoop生态的大数据平台相关的应用开发；
2、 负责数据建模与分析,负责对用户行为数据的深度挖掘，用数据驱动产品迭代；
3、 大规模数据挖掘和在线和离线海量数据分析平台的开发。
任职要求：
1、计算机、数学、统计学等相关专业本科及以上学历，5年以上工作经验；
2、熟悉Hadoop，Spark，Storm等分布式框架；
3、熟悉kafka ,logstash, flume、hive ,mesos,nomad,hbase等组件的使用；
4、精通Python,java,Scala,C/C++等一种或多种开发语言；
5、熟练操作SQL，掌握至少一种以上数据分析工具（SPSS、SAS、R等)；
6、具有5年及以上互联网、电商、大数据分析相关工作经验者优先；
7、有较强的沟通协调能力、学习能力以及逻辑思维能力。
我们给您提供：
1、工龄：按公司规定享有工龄工资，每月递增，1000元封顶；
2、全勤奖：100元；
3、有薪假期：按国家规定享有相应的有薪节假日及相关节日福利；
4、社会保险：按相关规定入职购买五险+商业险；
5、文娱活动：公司定期组织各种文娱活动、员工生日会、部门经费活动等；
6、餐饮情况：公司提供优惠餐,免费员工晚餐；
7、职业生涯：完善的横向调岗及纵向晋升通道，完善的核心人才培训体系；
8、其他福利：特殊职位证书补贴、下午茶等；"
"职位描述：
        
        岗位描述：
1、负责大数据平台的整体架构规划、设计，使系统体系化并具有技术前瞻；
2、负责数据采集，清洗，存储，计算、应用的整体架构；
3、负责大数据平台的运维管理，做到高可用；
4、解决大数据技术难点和问题（比如性能）。

岗位要求:
1、熟悉开源大数据生态，精通Hadoop，Spark，Storm，Hive，HBase，Cassandra，Kafka等大数据和相关技术；
2、熟悉数据挖掘和机器学习等相关算法和技术；
3、Java基础扎实，有分布式系统设计经验，能对分布式常用技术进行合理应用，解决实际架构问题 ，有大型业务系统的架构设计和实施能力，熟悉分布式系统的设计和应用；
4、有很强的分析复杂问题和解决复杂问题的能力，有强烈的责任心和使命感；?
5、技术视野开阔，学习和抗压能力好，有很强的分析和解决复杂问题的能力，具备良好的沟通和组织协调能力"
"职位描述：
        
        岗位职责：

 参与大数据平台的通用功能设计和开发、单元测试、文档编写等工作；
 负责大数据平台的数据整合、数据挖掘、画像推荐等方面的技术研究工作；

任职要求：

 精通Java或scala语言；
 本科以上学历，计算机、应用数学、统计学相关专业;
 熟悉大数据技术包括Hadoop、Spark、Flink、Kafka、Hive、ElasticSearch、HBase、kylin、Zookeeper等，并具备2年以上实际的大数据开发经验，对分布式数据处理和数据存储设计有很强的理解和优化能力，具备实时流数据处理的项目经验；
 熟悉常用机器学习算法，包括但不限于决策树，线性回归，聚类，支持向量机，关联规则，线性规划等；
 熟悉深度学习领域的基础理论，熟悉TensorFlow常用的神经网络模型如：DNN、CNN、LSTM等；
 熟悉Linux操作系统，熟练使用Shell或Python完成相关工作；
 优秀的分析问题和解决问题的能力，对解决具有挑战性的问题充满激情，良好的沟通能力和团队合作能力；"
"职位描述：
        
        岗位职责：
1、对海量数据进行清理；
2、基于大数据平台，使用数学建模、数据挖掘等方法，进行数据分析，设计并开发符合业务需求的数据处理功能；
3、参与大数据项目的需求分析和设计讨论，解决客户的技术问题，编写相关技术文档。

岗位要求：
1、本科以上学历，1年以上数据开发工作经验；
2、精通Java语言，熟练使用Hadoop进行分布式编程，熟悉Linux命令行操作和Shell脚本；会使用Python者优先；
3、能够对复杂数据进行抽象和简化，有一定的产品思维；
4、很强的学习能力及抗压能力。"
"职位描述：
        
        职责描述：1）负责人工智能金融大数据产品的设计与开发，解决海量数据面临的挑战；2）管理、优化并维护Hadoop、Spark等集群，保证集群规模持续、稳定； 3）负责HDFS/hive/HBase的功能、性能和扩展，解决并实现业务需求；4）协助业务和算法人员建立数据模型，对数据进行挖掘、优化及统计。

任职要求：1）本科及以上学历，3年及以上相关经验；2）熟练使用C/C++、Java、Python、Scala之中至少两种语言，具有较强编码能力；3）熟悉Hadoop/HBase/Spark/Storm/Hive/Kafka，熟悉数据挖掘策略与算法；4）熟悉分布式系统设计范型，有大规模系统设计和工程实现的经验；5）数据控，对利用新技术解决问题有热情，开源社区积极参与者优先；6）有互联网数据挖掘，金融行业数据处理经验优先。"
"职位描述：
        
        工作职责：
(1) 运用标注工具，对图片、视频数据进行整理及标注
(2) 对标注结果进行质量评估，并反馈标注结果
(3) 与项目管理人员配合，进行标注工具优化，标注流程优化等工作；?
(4) 高效地完成精准标注工作。
任职资格：
(1) 熟练使用office等办公软件
(2) 对图像、视频、语料数据敏感，具有敏锐的观察、分析和判断能力
(3) 性格开朗，做事认真仔细
(4) 优秀的团队协同能力，出色的执行力"
"职位描述：
        
        岗位职责:
上市以来，凡科通过为企业用户提供多元、高效、易用的互联网工具，已帮助了越来越多的企业有效降低了运营成本。随着凡科规模的进一步扩大，我们期待着更多新鲜血液的加入！?

「你将会负责」负责或者参与如下工作的一种或者几种；
1、负责数据仓库的设计和维护,?开发可靠,?高效准确的数据集市,?并提供技术支持；
2、负责数据产品的研发,?包括但是不限于数据的收集,?转化,?存储,?展示；?
3、维护大数据基础设施,?解决大数据的存储,?计算,?监控等问题。
「我们希望你」
1、本科及以上学历，熟悉Linux操作系统，掌握shell或者python脚本语言；
2、熟悉java编程基础,?扎实的编程能力，对解决具有挑战性问题充满激情；
3、熟悉hadoop生态,?对于生态组件包括但不限于（hdfs, hbase,hive，spark）有深入理解；
4、优秀的沟通理解能力，能快速理解业务，用数据解读业务；
5、对技术富有热情，具有强烈的主动学习意识。

「凡科人专享福利」
☆任性金主
提供优厚薪资待遇?八险一金?年终奖金?年度调薪?伯乐奖?结婚及生育礼金
☆职场晋阶
入职培训?技能晋阶?大咖分享?育才项目?学习分享会?完善的晋升机制
☆溜溜假日
双休?法定节假日?带薪年假?节日礼品?节日福利活动?婚假?产假?陪产假
☆缤纷生活
吃喝玩乐腐败金?周年礼物?生日惊喜?零食任吃?年度旅游活动，海内外随你pick
☆健康加分
年度健康体检?瑜伽班 舞蹈班 每周有足球 篮球 羽毛球 乒乓球等体育活动"
"职位描述：
        
        岗位职责:
上市以来，凡科通过为企业用户提供多元、高效、易用的互联网工具，已帮助了越来越多的企业有效降低了运营成本。随着凡科规模的进一步扩大，我们期待着更多新鲜血液的加入！?

「你将会负责」
1、负责或者参与如下工作的一种或者几种；
2、?负责数据仓库的设计和维护,?开发可靠,?高效准确的数据集市,?并提供技术支持；
3、负责数据产品的研发,?包括但是不限于数据的收集,?转化,?存储,?展示；
4、维护大数据基础设施,?解决大数据的存储,?计算,?监控等问题。

「我们希望你」
1、熟悉Linux操作系统，掌握shell或者python脚本语言；
2、熟悉java编程基础, 有扎实的编程能力，对解决具有挑战性问题充满激情；
3、熟悉hadoop生态, 对于生态组件包括但不限于(hdfs, hbase, hive,spark)有深入理解；
4、优秀的沟通理解能力，能快速理解业务，用数据解读业务；
5、对大数据处理有丰富的经验和广阔的视野。

「优先是你」
1、有流量分析，用户行为分析等相关开发经验；
2、参与过企业级数据仓库的设计和实现。

「凡科人专享福利」
☆任性金主
提供优厚薪资待遇 八险一金 年终奖金 年度调薪 伯乐奖 结婚及生育礼金
☆职场晋阶
入职培训 技能晋阶 大咖分享 育才项目 学习分享会 完善的晋升机制
☆溜溜假日
双休 法定节假日 带薪年假 节日礼品 节日福利活动 婚假 产假 陪产假
☆缤纷生活
吃喝玩乐腐败金 周年礼物 生日惊喜 零食任吃 年度旅游活动，海内外随你pick
☆健康加分
年度健康体检 瑜伽班 舞蹈班 每周有足球 篮球 羽毛球 乒乓球等体育活动"
"职位描述：
        
        岗位职责：
1、负责大数据平台的架构、研发和持续优化。
2、负责大数据的数据管理与调度，数据可视化，数据开发与服务等相关组件的开发。
3、负责运维大数据等大数据应用的开发。
4、参与解决大数据基础架构项目中的关键架构问题和技术难题，负责项目中关键技术难点的攻关。

任职要求：
1、精通Java语言，深刻理解面向对象思想，熟悉常用项目构建工具，具备大规模高并发访问的Web应用开发经验；
2、熟练掌握?SpingMVC?，Mybatis等开源框架的使用、整合，掌握其原理；
3、熟练使用jQuery，Ajax，Bootstrap，JavaScript，Css，Html等前台技术；
4.、熟悉Hadoop，Hive，Hbase，Spark，impala，Flink等开源技术者优先考虑
5.、有大数据调度引擎，BI等数据可视化平台开发经验者优先考虑。"
"职位描述：
        
        岗位职责：
1.负责大数据基础平台开发与管理
2.负责大数据基础设施建设：调度系统，数据开发工具以及可视化工具
3.助力数据化运营业务，构建丰富多样的大数据应用。
4.从事大数据平台化的开发，提升海量数据的处理性能；
5.数据平台的维护优化和重构.
任职要求：
1、精通Java、熟悉Spring?MVC开发架构等；
2、有数据仓库架构的开发经验者优先，例如调度系统、元数据管理、OLAP引擎、数据同步等；
3、熟悉分布式系统架构或模型，对资源管理、调度算法、并行数据处理有自己的理解；
4、熟悉Hadoop / Hive / Hbase / Spark / impala / Flink等开源技术，对相关系统源码有研究更佳。"
"职位描述：
        
        工作职责：
1、负责公司大数据平台建设；2、根据业务需求，制定数据仓库和数据分析平台的实施和持续更新；3、攻克技术难关，保证大数据系统的稳定运行；4、完成大数据产品的开发。
职位要求：
1、计算机相关专业全日制本科及以上学历，3年以上工作经验，2年以上大数据相关经验；2、熟悉Java或Scala语言，熟悉Spark，Hadoop，Kafka，Hive，HBase，ZooKeeper等大数据相关技术；3、精通SQL语句并对Redis，Mongodb等NoSQL数据库有一定经验；5、对于高并发、高稳定可用性、性能、大数据处理有过实际项目产品经验者优先；6、责任心强，工作踏实，有团队协作精神，沟通能力强者优先。"
"职位描述：
        
        岗位职责：
1，负责公司各类数据的ETL开发工作，构建公司企业征信数据产品;?
2，基于hadoop/storm/spark 等大数据技术进行各类数据的处理工作;?
3，参与数据产品及相关数据应用的开发。
?
岗位要求：
1，计算机、通信等相关专业，本科及以上学历。
2，三年以上Java开发经验；一年以上大数据平台数据项目开发经验。
3，熟悉Hadoop、Storm、Spark、Hive技术, 能熟练运用进行相关的数据清洗、ETL等开发工作。
4, ?熟练使用Hive、Flume、Sqoop等工具，对数据敏感, 能够快速根据需求完成从数据源接入到结果数据输出。
5, 对MySQL、Redis、Mongo等数据库有一定了解和使用经验。
6，对大数据技术有强烈兴趣，乐于接受挑战，自学和独立工作能力强，勤奋肯干，有责任心。
7, 良好的沟通协作能力, 在同类大数据公司有相关工作经验者优先。"
"职位描述：
        
        岗位职责：
1、从事大数据平台或大数据产品的设计、开发、优化工作。
2、利用大数据相关技术实现对数据的采集、分析、挖掘、可视化，让数据充分发挥价值。
3、开发金融业相关的风险控制、精准营销、数字化运营等相关数据产品。进行大数据相关的新技术研究，提高技术创新能力。
岗位要求：
1、211工程院校或重点财经类、理工类院校全日制大学本科及以上学历2019年应届毕业生，计算机及相关专业。
2、具备全面、扎实的软件知识结构，掌握操作系统、软件工程、设计模式、数据结构、数据库系统、网络安全等专业知识。
3、对面向对象技术，熟悉常用的设计模式有所了解。编程基本功扎实，掌握常用算法和数据结构。
4、了解Linux基本操作，至少熟练使用C/C++/Java/Python/SQL中的一种，了解MySQL等数据库。"
"职位描述：
        
        职位描述：
工作内容：
1、负责银行数据相关产品的建设和相关ETL开发工作。
2、负责数据集市的建设。
3、助力数据化产品运营，构建丰富多样的BI应用。

?工作职责：
1、熟练掌握SQL编程，熟悉Oracle、Teradata、GP、DB2、MySQL、Postgresql等至少一种数据库技术。
2、熟悉Linux操作系统，熟悉Shell、Python或Perl。
3、良好的沟通表达能力和团队协作能力，对自己有较高的要求，喜欢有挑战的工作。
4、对银行的业务和数据有了解者优先。
5、1年以上数据集市模型设计、ETL设计的相关经验者优先。
6、了解Hadoop大数据相关技术和组件，对大数据基础架构和平台有一定了解者优先。"
"职位描述：
        
        工作职责: 1.负责完成公司大数据相关产品的平台化、工具化； 2.负责完成技术选型和详细技术方案设计落地。  任职资格: 1、3年以上IT互联网行业或软件行业工作经验； 2、熟悉大数据技术栈，熟悉hadoop/spark生态圈； 3、良好的Java开发基本功，对JVM、Java多线程并发以及网络通信开发有良好的经验； 4、熟练掌握Java开发主流框架，如Spring，MyBatis等； 5、熟悉echarts/hicharts/fusionCharts等数据可视化组件，有数据可视化开发经验优先； 6、熟练掌握MySQL、Redis、HBase等关系型/非关系型数据库的使用和开发； 7、熟悉Linux系统，能熟练的使用Linux的常用命令； 8、良好的学习能力、团队协作能力和沟通能力；善于思考，能独立分析和解决问题。"
"职位描述：
        
        岗位职责：?
（1）负责公司级大数据平台的相关研发工作，在Spark/Hive上开发大规模数据处理系统；?
（2）通过技术手段提升平台与数据的质量与可用性；?
（3）持续改进和优化大数据计算和存储，提升海量数据的查询性能和用户体验；?
（4）参与大数据平台的规划和技术路线设计，确保公司平台技术优势；?
（5）根据业务需求进行数据仓库模型的调研、设计、开发及验证工作，并持续进行模型的优化；?
（6）协助开发数据统计系统、数据可视化系统等。?

任职要求：?
Must have?
（1）统招本科及以上学历，计算机、软件工程、人工智能、数据挖掘等相关专业；?
（2）6年及以上大数据开发相关工作经验；?
（3）熟练掌握多种大数据处理技术，如Hadoop、Spark、Hive、flume、hbase等；?
（4）熟悉Java或者Scala开发，有多个脚本语言（shell,python)开发经验；?
（5）了解Elastic Search、kylin,kafaka等计算引擎；?
（6）对数据敏感、对技术敏感，有研究的意识和直觉者更佳；?
（7）有良好的团队合作意识，沟通表达能力和综合协调能力。?

Prefer to have：?
（1）熟悉国内外多个云计算平台，如AWS、Google Cloud?
（2）关注最新的大数据技术，熟悉国内外各大开源社区"
"职位描述：
        
        岗位职责：
1．维护以及优化整个大数据平台体系，包括但不限于hadoop、spark、kafka、zookeeper等集群；
2．负责大数据平台开发，涉及数据采集，数据清洗、转换、存储，数据分析等工作；
3．大数据产品的开发与维护，确保产品功能稳定，性能优异，保证研发质量；
4．相关产品设计文档的撰写和完善。
?
任职要求：
1．计算机及相关专业，本科以上学历，2年以上相关工作经验；
2．精通java开发，熟悉scala语言，开发过基于spring boot框架下的java产品；
3．熟悉常见的大数据体系开源框架，特别是spark/spark-streaming框架；
4．具有很强的学习能力和强烈的进取心，具有良好地沟通交流和团队合作能力，优秀的分析问题和解决问题的能力。"
"职位描述：
        
        岗位职责：
1.遵循研发规范高质量完成对应项目或产品的编码工作以及技术文档的输出；
2.参与整体系统的架构设计，制定相关研发方案；
3.主导团队开发人员Code Review，并提供性能、安全性建议；
4.团队技术难点攻关，并指导培养团队人员技术能力；
5.挖掘及梳理产品需求，提供系统规划方案、架构设计方案，并能根据方案展开研发工作；
6.整体系统架构的规划,核心框架代码编写、开发和维护统一的软件开发架构；
7.跟进核心项目，接口规范制定，技术文档编写，确保项目进度和质量；
任职要求：
1. 计算机及相关专业，统招二本及以上学历，3年以上大数据相关工作经验；
2. 熟悉hadoop生态系统以及Zookeeper、Kafka、Flume、HDFS、Hive、Spark技术；
3. 熟悉Oracle、Mysql、Hive、Hbase等，能进行查询优化；
4. 熟悉Talend、Kettle等至少一种ETL工具, 能熟练进行数据抽取；
5. 至少1年以上ETL项目开发和实施经验，掌握数据仓库相关知识、数据流程设计、模型设计等；
6. 有敏捷模式开发经验，遵循代码规范，有公交行业开发经验优先。"
"职位描述：
        
        岗位职责：
1、参与公司商业智能平台的研发工作；
2、参与公司商业智能平台的升级改造工作，包括运维工作。

岗位要求：
1、正规院校本科及以上学历，软件、计算机、通信、信息安全、网络工程等相关专业；
2、良好的Java开发背景，熟悉Spring/MyBatis技术体系；
3、良好的SQL功底，熟悉MySQL或Oracle数据库；
4、熟悉Linux；
5、了解开源Pentaho产品，包括PRD、Mondrian、SaiKu、Kettle等；
6、熟悉Hadoop、Hive、HBase、Storm、Spark等大数据平台；
7、沟通能力强，有较强的学习能力，有较强的责任心与良好的团队协作能力。

员工福利：
1.五天工作制，每天工作7小时（9:00-12:00，14:00-18:00），人性化考勤制度；
2.入职即购买社会保险、住房公积金，另外帮员工购买商业医疗保险；
3.年假5~15天；
4.餐费补贴、结婚礼金、节日礼品或礼金；
5.年终奖+工资额外的季度奖金；
6.每月聚餐经费+周边游+国内外旅游；
7.每年一次体检，身体健康第一位；
8.每周康体活动（每周五下午有游泳、羽毛球、篮球等活动任君选择）；
9.简单的人际关系，十分nice的领导和同事，工作氛围好。"
"职位描述：
        
        岗位职责:

1、负责平台用户/设备行为、状态数据的采集与分析、 ETL处理、元数据管理、多层仓库组织等数据开发工作；2、负责大数据平台的搭建与程序开发；3、需要接受策略分析、特征挖掘、用户行为分析、业务运营分析、在线业务 系统、全站行为分析等多方数据需求的挑战；4、优先考虑能对算法进行开拓性、探索性扩展优化，形成新的独有算法，具备撰写论文、专利能力的人才。 
任职资格:

1、本科或以上学历，五年以上JAVA语言开发并参与不少于三个大型项目经验；2、有NIO、多线程、RPC等应用经验，熟悉JVM配置调优，熟练使用设计模式，熟练使用JAVA监控工具处理JAVA问题，熟悉排序、查询等基本算法；3、三年以上HBase、Zookeeper使用经验，深度理解hbase架构和运行原理，有大规模集群优化经验，参与过开源社区相关组件的源码开发；4、熟悉 Hadoop、 Hbase、 Phoenix、Kyin、 Lookeeper等分布式组件原理和架构；5、有丰富的大规模 Hbase/ Hadoop集群和相关组件实际维护和使用经验；6、业界主流流处理平台如Storm/Flink/Spark Streaming之一，对于上述组件有实际的性能调优经验者优先。"
"职位描述：
        
        岗位职责:

1、负责平台用户/设备行为、状态数据的采集与分析、 ETL处理、元数据管理、多层仓库组织等数据开发工作；2、负责大数据平台的搭建与程序开发；3、需要接受策略分析、特征挖掘、用户行为分析、业务运营分析、在线业务 系统、全站行为分析等多方数据需求的挑战；4、优先考虑能对算法进行开拓性、探索性扩展优化，形成新的独有算法，具备撰写论文、专利能力的人才。 
任职资格:

1、本科或以上学历，五年以上JAVA语言开发并参与不少于三个大型项目经验；2、有NIO、多线程、RPC等应用经验，熟悉JVM配置调优，熟练使用设计模式，熟练使用JAVA监控工具处理JAVA问题，熟悉排序、查询等基本算法；3、三年以上HBase、Zookeeper使用经验，深度理解hbase架构和运行原理，有大规模集群优化经验，参与过开源社区相关组件的源码开发；4、熟悉 Hadoop、 Hbase、 Phoenix、Kyin、 Lookeeper等分布式组件原理和架构；5、有丰富的大规模 Hbase/ Hadoop集群和相关组件实际维护和使用经验；6、业界主流流处理平台如Storm/Flink/Spark Streaming之一，对于上述组件有实际的性能调优经验者优先。"
"职位描述：
        
        【岗位职责】
1、跟踪业务部门业务发展，承接业务部门数据需求。
2、负责公司大数据平台的日常维护。
3、用数据分析手段进行业务洞察，提供业务改进建议。
4、根据公司产品和业务发展特点，负责研究相关大数据产品和技术发展方向
【任职要求】
1、本科及以上学历，计算机相关专业。
2、精通Java，基本功扎实，熟悉Scala语言。
3、熟练使用Linux，对Linux常用维护命令熟悉；熟悉Hadoop/Spark/HBase/Hive/Storm/Kafka等大数据开源技术框架中至少2种(能力强可以培养)
4、能够熟练使用Spring/SpringMVC/MyBatis/Spring Boot等开源框架。
5、良好团合作意识，能独立分析数据需求，并转化成系统模块或接口，能独立进行代码实现。"
"职位描述：
        
        岗位职责：
1、跟踪业务部门业务发展，承接业务部门数据需求。
2、用数据分析手段进行业务洞察，提供业务改进建议。
3、根据公司产品和业务发展特点，负责研究相关大数据产品和技术发展方向。
任职要求：
1、本科及以上学历，计算机相关专业。
2、精通Java，基本功扎实，熟悉Scala语言。
3、熟练使用Linux，对Linux常用维护命令熟悉；熟悉Hadoop/Spark/HBase/Hive/Storm/Kafka等大数据开源技术框架中至少2种(能力强可以培养)
4、能够熟练使用Spring/SpringMVC/MyBatis/Spring Boot等开源框架。
5、良好团合作意识，能独立分析数据需求，并转化成系统模块或接口，能独立进行代码实现。"
"职位描述：
        
        职位描述1. 参与实时计算平台和上下游完整体系的建设，向公司输出实时计算服务能力；2. 以实时计算平台为支撑，串联公司线上业务核心流程，支持包括但不限于风控，广告等业务场景；3、大数据平台的整体架构规划、设计，使系统体系化并具有技术前瞻；4、解决大数据技术难点和问题（比如性能）。职位要求1、熟悉开源大数据生态，精通Hadoop，Spark，Storm，Hive，HBase，Flink ，Kafka，Flink，Druid 等大数据和相关技术；2、Java基础扎实，有分布式系统设计经验，能对分布式常用技术进行合理应用，解决实际架构问题 ，有大型业务系统的架构设计和实施能力，熟悉分布式系统的设计和应用；3、学习能力强，有良好的较好的创新能力和逻辑思维能力，善于主动思考，对技术有强烈激情；4、有良好的沟通能力，跨团队协作能力，具备出色的计划和执行力，强烈的责任感；"
"职位描述：
        
        一、职位描述：? 
1、负责BI项目的实施、协助数据仓库的设计、建模等，并编写相关的系统设计文档；? 
2、对BI项目需求分析、模块详细设计，并进行项目开发；? 
3、?根据个人意愿和公司安排可常驻在北京、天津、成都?、重庆、广州?、深圳 
二、职位要求：? 
1、专业：计算机、软件开发等相关专业；? 
2、知识技能：掌握SQL?Server、Oracle、DB2等数据库的应用及SQL编程能力、会创建存储过程；? 
3、了解数据结构、数据仓库、数据建模等知识；? 
4、参与过业务系统的开发及实施，对于微软BI有所了解；? 
5、工作经验：具备1-2年以上业务系统开发工作经验；? 
6、素质要求：良好的需求分析能力；? 
7、优先条件：具备BI应用实施经验者优先；具有存储过程编写经验者优先? 
8、能适应经常出差。"
"职位描述：
        
        1.精通数据库，Linux操作系统、Java编程和脚本编程2.熟悉Hadoop生态，熟练应用mr，hive，hbase，hdfs，spark，flume，kafka，yarn等组件3.有优秀的逻辑思维能力;对数据敏感;善于用最佳的形式展现数据，精通各类图表的应用"
"职位描述：
        
        工作职责：
1.?大数据技术团队将基于数据通过数据建模，ETL设计开发，使用Hadoop等产品对数据进行深度加工，构建数据资产管理平台，帮助业务向前走的重要数据研发部门；
2.?深入业务场景，发现业务痛点，设计数据化、智能化解决方案
3.?持续关注大数据领域动态和前沿技术，合理地引入到工作中，提升大数据能力；
4.?将解决方案沉淀成可复用、可配置的灵活平台，降低技术产品复用的成本，提升技术输出效率；
5.?能够组织跨团队协作、推动甚至直接负责项目优质如期落地，熟悉数据及数据技术并能与业务和技术人员很好的沟通与协作。
?
任职要求：
1.?较为丰富的数据仓库及数据平台的架构经验，精通数据仓库建模及ETL设计开发；有海量数据性能处理经验；在大数据资产管理与治理有一定成功产品化经验；
2.?.有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop、spark等生态相关技术并有相关开发经验，有Hive/Flink的开发经验尤佳；
3.?.具备一定的JAVA、Python语言的开发能力，具备机器学习算法能力尤佳；
4.?良好的思维逻辑性、语言表达能力；
5.?工作经验2年及以上。"
"职位描述：
        
        工作职责：
1.?建立公司各个业务场景和部门的报表体系；
2.?建立业务特征的指标体系和相应的数据监测体系，为管理层和业务方决策提供有质量的数据支持；
3.?负责跟踪发现数据问题，并多维度分析定位问题；
4.?开发业务相关报表和临时需求；
5.?撰写数据分析报告，为公司运营决策、产品推广和销售策略提供数据支持。
?
任职要求：
1.?精通Tableau BI报表工具
2.?具备数据产品设计、数据报表平台设计项目的实践经验，掌握业务分析思路和方法；
3.?思路清晰、耐心细致、有责任心、工作主动性强；
4.?有JAVA相关开发经验者，电商从业经验者优先。
5.?大学数学、统计学、计算机等相关专业本科或以上学历，1年以上数据分析或数据挖掘相关工作经验"
"职位描述：
        
        岗位职责：
1. 负责基于大数据实时和离线数据仓库维护，开发与维护报表出账、广告审核、业务监控、数据分析及导出的数据处理系统；
2. 参与DMP平台数据建立与维护
3. 参与数据相关项目的需求分析，技术评估，方案设计
岗位要求：
1、 计算机相关专业，全日制本科以上，2年以上软件开发经验
2、 精通python开发，熟悉Linux Shell，掌握Java/PHP/Python等一种以上语言的开发能力，有扎实的编程功底
3、 了解Hadoop、Spark、Kafka等大数据生态组件，熟悉MapReduce、Hive、Hbase，具有HQL/SQL开发能力
4、 具备良好的分析解决问题能力,善于理解客户需求，积极主动，行动力强"
"职位描述：
        
        1、 负责hadoop平台上的数据存储，数据维护和优化；
2、 参与大规模数据快速查询系统的架构设计和开发;
3、 大规模数据挖掘和机器学习算法的实现和维护;
4、 在线和离线海量数据分析平台的开发。
职位要求：?
1)?两年以上hadoop的应用开发经验，据有CDH,Hbase权限管理，cdh平台优化的经验，至少一个企业级数据仓库项目开发经验或大数据处理项目经验；
2)??据有spark stream、kafka、hbase组件组成的实时计算业务使用场景，精通Java或Scala；
3)?对数据结构、算法有深刻理解，有预测模型，行为分析模型，推荐模型具体实施经验者优先；
4)?熟悉hadoop生态圈中的hive、phoenix、kafka、flume等，对hive、phoenix开发有实际经验者优先；
5)?技术敏感，有一定独立分析，技术研究能力，乐于接受挑战，具有良好的团队合作精神。"
"职位描述：
        
        任职资格：
1.大数据平台开发, 满足日益增长的数据计算需求
2.离线计算/实时计算开发, 为线上业务提供数据支撑
岗位职责：
1.扎实的计算机基础, 至少一年大数据平台相关经验
2.熟练掌握如下最少一门语言: Scala/Go/Python
3.熟练掌握如下最少一个组件: Hadoop/Spark/Kafka/Kudu/FFlume 等, 具备问题定位/解决能力, 有 HBase/Cassandra 等分布式存储相关经验加分, 有开源社区贡献的加分
4.乐于沟通, 敢于担当, 具备良好的沟通和团队协作能力
5.熟悉数据仓库和数据建模的相关技术细节，有实际项目编程经验
6.熟悉大数据平台数据流程和ETL开发，有实际开发经验"
"职位描述：
        
        职位描述
1.主导数据仓库基础架构的建设，以满足数据仓库对时效性、正确性、可扩展性和易用性的要求；
2.通过分析相关系统，梳理潜在的数据源和日志清洗需求，并设计合适的、可扩展的数据模型；
3.开发并维护数据流水线，挖掘数据中的有价值信息，发挥大数据价值，帮助各个部门用数据驱动决策。
4.参与流数据引擎的开发

任职要求：
熟悉java语言，熟悉基本的数据结构、算法，基础扎实；
熟悉Hadoop大数据生态相关组件，包括但不局限于hive、hbase、kafka、spark、elasticsearch、flink和yarn等；
熟悉linux系统基本操作，会shell脚本更好；"
"职位描述：
        
        职位描述
参与流计算引擎开发
任职要求：
熟悉java语言，熟悉基本的数据结构、算法；
熟悉Hadoop大数据生态相关组件，包括但不局限于hive、hbase、kafka、spark、elasticsearch、flink和yarn等；
熟悉linux系统基本操作，会shell脚本更好；

支持在所内完成毕业论文，有中科院导师指导。
实习至少6个月。"
"职位描述：
        
        职位描述：
大数据底层架构设计和实施；
对移动设备数据和社交数据进行挖掘分析和建模；
逐步构建基于用户行为、喜好的标签系统，并应用于相关的个性化系统和业务分析中；
负责数据管理平台的核心技术实现与优化；
负责大数据在广告领域的创新应用，持续推动业务线的商业效果改进；

任职资格:?
本科及以上，计算机、软件工程、统计学、数据挖掘、机器学习等相关专业。
3年及以上大数据流程架构经验，熟悉Hbase/Hive/Hadoop/Spark或等主流分布式开发平台，有高性能集群设计和开发经验。
精通Linux，熟练掌握Python/C/Shell/Java，熟练掌握SQL数据库语言 HiveSQL/Mysql/Sqlserver。
具有良好的逻辑分析能力、沟通能力和协调能力。?
积极的工作态度，勤奋上进，有责任心。"
"职位描述：
        
        
【岗位职责】1、负责数据仓库建设，设计、优化和落地; 2、负责数据ETL、建模，业务数据开发和调优。

【职位要求】1、数据仓库有较扎实的理论基础，数据模型建设、应用层建设有比较丰富的经验; 2、对自己专注的技术或业务领域有深入的理解和把握，能够有自己专注的技术长项;3、熟练编写各类SQL，对sql有优化经验优先;4、有Hadoop、Hive、Spark、Flink等大数据技术使用经验者优先"
"职位描述：
        
        工作职责:参与海量数据实时处理与分析，实时服务系统设计与开发；任职资格:1、计算机、软件等相关专业，两年以上工作经验；2、熟悉Java、C++基础知识，熟悉相关原理及性能调优；3、熟练掌握Storm、Kafka等流式处理框架，熟悉Mysql、Redis、HBase等存储原理及应用开发；4、熟悉网络通信，常用缓存架构、数据结构及算法应用等；5、较强的分析解决问题能力，沟通协调及团队精神，有一定抗压能力；6、有大型分布式系统开发经验优先；7、有大型互联网工作经验优先；"
"职位描述：
        
        工作职责:参与海量数据实时处理与分析，实时服务系统设计与开发；任职资格:1、计算机、软件等相关专业，两年以上工作经验；2、熟悉Java、C++基础知识，熟悉相关原理及性能调优；3、熟练掌握Storm、Kafka等流式处理框架，熟悉Mysql、Redis、HBase等存储原理及应用开发；4、熟悉网络通信，常用缓存架构、数据结构及算法应用等；5、较强的分析解决问题能力，沟通协调及团队精神，有一定抗压能力；6、有大型分布式系统开发经验优先；7、有大型互联网工作经验优先；"
"职位描述：
        
        1.?参与医学大数据语义解析产品的开发，对临床数据中的医学信息进行精准提取；
2.?理解临床数据的含义，并撰写提取规则与处理逻辑，完成特定临床数据集上的医学信息提取；
3.??在给定数据和测试集的条件下，对提取规则进行性能测试和优化，在测试集上达到指定的指标；
4.?与数据分析师配合，对数据集特征进行分析，对提取规则进行优化；
5.?基于python 或者 java 进行医疗业务开发；

经验要求
1.???熟练掌握至少一门编程语言（python/java/…），有1年以上的开发经验；
2.??逻辑性较强，能条理清楚地拆解问题和实现；
3.???责任心强，做事细心，有出色的抗压能力和耐心，能够应对常规的大数据解析处理工作；
4.?熟悉正则表达式、对使用正则表达式进行数据处理相关的项目经验者优先；
5.?熟悉Linux操作系统、Shell命令者优先；
6.?有医学数据解析处理经验者优先；
7.?有较强的沟通能力和团队配合精神，有较大规模项目研发经验者优先；"
"职位描述：
        
        岗位职责：
1.Hadoop、MPP大数据平台管理、配置和平台优化
2.飞鸿数大数据平台POC测试
3.飞鸿数大数据平台日常运维、技术支持服务
4 .基于Java、C/C++、SQL、Python、Shell及相关开发工具的大数据应用开发、数据分析应用、ETL应用
5. 图像、语音、视频的多媒体处理相关开发
任职要求
1. 熟悉Linux操作系统使用
2. 掌握Java、C/C++、Python（1种语言以上）开发
3. 能够基于SQL、PL/SQL、Shell（1种语言以上）开发数据处理脚本
4. 掌握Oracle、MySQL、SQLServer、Postgresql(post cr c SQL)（1种以上DB）的使用和DB管理常用命令
5. 掌握Hadoop、HBase、Spark、Greenplum（1种以上）的大数据平台使用
6. 具有数据仓库、ETL数据处理初步知识，或者具备图像、语音、视频相关多媒体数据处理的初步知识
7. 能够阅读英文技术文档

佳讯大家庭，不仅是您施展能力的舞台，还将收获：
1. 工资+年底双薪；
2. 五险一金+补充医疗保险和意外险，年度体检；
3. 弹性工作时间+周末双休；
4. 带薪年假，安排好工作，来一场说走就走的旅行；
5. 团队旅游，世界很大，让我们一起去看看吧；
6. 生日惊喜，节日礼金；
7. 工作日餐补；"
"职位描述：
        
        
岗位职责：
1、负责大数据平台的系统架构搭建、设计、整体框架实现、核心代码编写等；
2、负责大数据处理框架相关技术组件的性能调优和复杂故障处理；
3、负责大数据项目的技术把关，控制架构质量，解决项目开发过程中的技术难题；
任职要求
1、专科及以上学历，计算机或相关专业，4年以上大数据经验；
2、精通Java、python开发语言,有3年以上开发经验。
3、熟悉大数据相关框架和组件原理，如Hive，Elasticsearch，Hadoop/Spark，Flink，Kafka。
4、熟悉Linux操作系统，具备在Linux上开发、部署、调优Hadoop生态环境项目经验；
5、精通Oracle、MySql等常用关系数据库，以及MongoDB、Redis等NoSQL数据库，熟悉构化和非结构化建模，具有丰富的数据库设计经验；
6、精通大数据生态技术：有Hadoop、Zookeeper、HBase、Hive、Flume、Kafka、Sqoop、Spark等实际项目经验，
7、精通流式处理技术，有Storm，Flink、SparkStreaming至少一种实现项目经验；
8、有企业级数据仓库(EDW)/BI系统的建设经验，有海量数据建模实践经验优先考虑"
"职位描述：
        
        职位描述：
1.负责公司大数据平台产品的技术工作，包括存储、处理、分析、挖掘、架构设计、研发工作；
2.负责设计、构建和优化基于hadoop/Hbase的存储平台架构；
3.负责整体提升hadoop/Hbase/Spark集群的高可用性、高性能、高扩展特性；
4.根据业务需求，提出最优的技术解决方案
?

任职要求
1.相关工作2~5年经验
2.扎实的Java、Scala语言基础,对JVM运行机制有深入了解
3.对Hadoop、Hive、Hbase、Kafka、elasticsearch、Spark能熟练运用，并有深入认识,；
4.良好的SQL语句功底，熟悉MySQL、Oracle数据库中的一种
5.具备Hadoop/Hbase/Hive/Zookeeper等大规模集群的开发、运维经验者优先
6.对文本分词有实战经验，熟悉Solr／Lucene开发优先。
7.具有良好的沟通协作能力和分享精神"
"职位描述：
        
        
工作职责：
1、负责公司数据平台建设；
2、负责用户标签体系的建设；
3、负责数据程序上线前的review;
4、大数据平台的维护.
任职资格：
1、计算机或相关专业，专科及以上学历，2年以上工作经验；
2、精通kafka、spark streaming、hive、hbase、mysql，以及java、python语言；
3、有数据平台规划经验者优先；
4、有用户画像体系建设经验者优先；
5、有机器学习落地经验者优先；
6、具有较强的沟通理解能力，有责任心。"
"职位描述：
        
        岗位要求：
1. 参与设计、开发公司大数据平台（包括在线分析、离线分析、数据报表等）；
2. 深入理解业务，满足业务数据需求，通过数据辅助业务决策、推动业务发展；

任职资格：
1. 深刻理解SQL基本原理，并熟练使用；
2. 理解Hadoop体系相关技术，具备Spark/Hive/Impala/Presto等实际开发经验；
3. 理解基本数据结构及算法；
4. 2年以上大数据相关工作经验；
5. 熟练使用python/scala/java之一；
6. 本科及以上学历，计算机相关专业；"
"职位描述：
        
        岗位职责：1、负责大数据相关平台的搭建、开发、维护、优化，分布式平台应用开发（Hadoop/Spark/Hive/Hbase）；2、负责大数据集群的搭建、管理和维护；3、负责数据模型架构的构建，建立数据抽取、清洗、校验等数据加工流程规范及OLAP多维数据分析模型；4、持续对系统的技术架构进行改进和优化，提升海量数据的查询性能和用户体验。任职要求：1、统招本科及以上学历，数学、统计学、计算机等相关专业，同岗位工作至少3年以上；2、熟悉Java开发，有脚本语言（shell,python)开发经验者优先；3、熟悉Hadoop/Flume/Spark/Hive/Kafka；具有MapReduce开发经验，有实际大数据项目经验，熟悉cloudera优先；4、掌握HBase、Redis、Elastic Search等开源大数据存储技术，并能结合不同的业务场景深入使用；5、熟悉常用Java Web开发框架，如：Spring、Mybatis等；6、熟悉多线程编程、网络编程，对Java自带线程池有一定研究；
7、具有CDH运维的经验。"
"职位描述：
        
        工作职责:1. 负责公司的数据平台和数据产品研发。2. 开发并实现优秀的数据流、数据仓库、查询引擎、数据工具/产品，提供高可用的数据服务，发挥数据价值。3. 持续优化系统性能，攻克技术难题。任职资格:1. 计算机或相关专业本科及以上学历，2年以上工作经验，1年以上大数据开发经验, 扎实的数据结构和算法功底。2. 熟悉Linux/Unix开发环境，熟练掌握PYTHON/JAVA/PHP/GO其中至少一种以上。3. 熟悉一项或多项大数据生态框架，如Hadoop、Druid、Storm、Spark、Hive、Kafka、Flume、Hbase、Kylin、Canal、Sqoop等。4. 较好的编码能力。5. 有后端开发经验者优先。"
"职位描述：
        
        工作职责:- 负责大规模数据存储，高性能离线/实时计算平台的研发与维护- 理解和分析数据挖掘需求和数据特点，开发中间数据层及策略中间件- 用户行为分析、核心指标制定与相关性分析等大数据需求?任职资格:- 计算机相关专业本科以上学历，1年以上大数据领域项目经验- 熟悉常用数据结构和算法, 熟练Linux环境及shell脚本- 熟悉hadoop/hbase/spark等大数据相关开源工具中一门或几门- 精通C/C++/java/php里的一门或几门，具有扎实的面向对象开发经验- 乐于解决具有挑战性的问题, 具备优秀的分析问题、解决问题能力- 拥有丰富用户行为分析经验者优先"
"职位描述：
        
        岗位描述：?

 负责公司的数据平台和数据产品研发。?
 开发并实现优秀的数据流、数据仓库、查询引擎、数据工具/产品，提供高可用的数据服务，发挥数据价值。
 ?持续优化系统性能，攻克技术难题。

岗位要求:

 计算机或相关专业本科及以上学历，2年以上工作经验，1年以上大数据开发经验,?扎实的数据结构和算法功底。
 ?熟悉Linux/Unix开发环境，熟练掌握PYTHON/JAVA/PHP/GO其中至少一种以上。
 ?熟悉一项或多项大数据生态框架，如Hadoop、Druid、Storm、Spark、Hive、Kafka、Flume、Hbase、Kylin、Canal、Sqoop等。?
 较好的编码能力。
 有后端开发经验者优先。"
"职位描述：
        
        
工作职责：
1.负责公司数据平台和数据产品研发。2.开发并实现优秀的数据流、数据架构、数据工具/产品，提供高可用的数据服务，发挥数据价值。3.持续优化系统性能，保证系统稳定性，攻克技术难题。
4. 负责因项目研发需要而赋予的其他工作职责
任职资格：
1.计算机或相关专业本科及以上学历，三年以上大数据项目经验，对数据和业务敏感，有较好的数据模型设计能力；。2.熟练使用linux平台，至少精通Java/Scala/Python/Shell等其中一门编程语言；3.熟练掌握Hadoop/Spark/Mysql/Kafka/Redis/Hbase/Hive等技术，对大数据实时处理有丰富经验；4.熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；5.思路清晰，具有良好的自学能力、良好的团队合作和沟通协作能力，有项目管理经验者优先；"
"职位描述：
        
        工作职责:1、参与一课业务相关数据仓库的数据模型设计；2、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；3、参与项目规划，数据采集设计，数据仓库开发，模型开发，报表开发等；4、总结数据仓库建模的方法，完善数据产品平台化和系统化。任职资格:1、对数据仓库/BI相关工作有强烈兴趣，对数据和业务敏感，有较好的数据模型设计能力；2、了解数据仓库模型建模理论、数据仓库数据分层架构，多维数据模型设计；3、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python/PHP等其中一门编程语言；4、有Hadoop/Spark/Hive/HBase/列式数据库/Kylin/ElasticSearch其中一项使用经验；5、参与过大型数据仓库架构设计、模型设计、ETL设计者优先；6、学习能力强，热衷开源技术，有团队观念。"
"职位描述：
        
        工作职责:1、参与公司的通用数据平台和运营分析类数据产品研发，包括广告BI、实时计算平台等，服务于多条业务线；2、面向海量大规模数据问题，每天处理千亿增量的用户行为数据；3、开发并实现数据流建设，参与数据采集、传输、持久化存储、查询等环节，提供高可用的数据服务，发挥数据价值； 4、为大数据的全生命周期提供服务，降低数据的使用门槛，攻克技术难题，保证系统的稳定高效运行。任职资格:1、计算机或数学相关专业；2、有扎实的数据结构和算法基础 ；3、熟悉Linux/Unix开发环境，熟练掌握PYTHON/JAVA/PHP/GO其中至少一种以上；4、熟悉一项或多项大数据生态框架，如Hadoop、Druid、Storm、Spark、Hive、Kafka、Flume、Hbase、Kylin、Canal、Sqoop、Flink等；5、较好的编码能力，对大数据技术有强烈的学习热情。"
"职位描述：
        
        1、大数据平台部署搭建hadoop、yarn、hbase，java语言(3-5年)大数据资深开发，
熟悉数据分析在线分析和离线分析框架，至少各1种：
在线分析涉及框架: (flume-ng日志聚合、storm流式计算、spark内存计算）
离线分析涉及框架: Impala
2、了解基本的统计分析方法，对机器学习略有了解。
3、熟悉业务平台网络访问优化，具备较强的调优排障能力。

任职要求：
?1.精通Unix/Linux操作系统、Bash、良好的编码规范；
?2.具备2年以上开发经验，至少熟悉1种开发语言：PHP、Java、Rubby、Python、Perl；
?3.具有良好的学习能力、沟通能力、服务理念和合作精神；
?4.强烈的责任心与主动性，对所负责工作有owner意识，并能自我驱动成长；
?5.有数据仓库建设经验，熟悉python和web前端开发优先；
?6.有运维自动化、监控系统、发布系统、运营支撑系统等开发经验者优先；
?7.有大型分布式系统设计与开发经验者优先；"
"职位描述：
        
        岗位职责：1、负责大数据系统设计和开发2、数据开发数据产品开发工具开发等3、并负责完成核心代码技术攻坚4、根据开发规范与流程独立完成模块的设计、编码、测试以及相关文档。任职资格1、3年以上开发经验熟练掌握Java、Scala、Python、C中的至少两种开发语言2、至少参与过3个以上完整的大数据项目3、熟悉Aliyun中至少一个云平台的大数据解决方案4、熟练掌握Hadoop、Hive、Hbase、Spark、Storm等分布式框架原理有相关的调优、运维、开发经验5、具有Postgresql、MySql、MongoDB等其中一种数据库应用开发经验6、对技术有激情喜欢钻研能快速接受和掌握新技术有较强的独立、主动的学习能力良好的沟通表达能7、有标签系统、用户画像系统、推荐系统的设计和研发经验的优先考虑。"
"职位描述：
        
        工作职责:1、负责业务、财务部门对数据应用需求的技术实现，完成从数据源到应用底层的ETL流程。2、参与风控、推荐、图像/语音识别、爬虫等系统设计、开发，维护现有的平台代码。3、承接业务模型到数据模型、算法模型的落地，促进金融风控、用户推荐等策略优化。任职资格:1、全日制本科及以上学历，精通python，有2年以上开发经验。掌握MongoDB、MySQL、Redis、消息队列等常用组件。2、具备独立设计数据库，并且开发小工具的能力。3、熟悉Linux环境下的开发环境，熟悉Nginx配置、调优，熟悉Shell脚本。4、熟悉Django/Flask等至少一种框架。5、良好的需求沟通、逻辑分析、协调、执行、抗压能力。6、有推荐、爬虫经验者优先。"
"职位描述：
        
        
岗位职责：
1、?负责基于大数据平台的离线，实时数据仓库搭建，数据仓库的基础架构、ETL设计、流程优化，元数据系统设计；建立数据生命周期框架，整体管理数据的生产、建模、应用及质量体系建设；
2、?负责离线或者实时销售指标系统、风控系统底层指标系统开发维护；
3、?对海量数据整合分析，挖掘用户，产品及潜在数据信息，为销售、风控，运营决策支撑体系提供完善的数据平台支持；
4、?负责大数据数据仓库（离线，实时）方向技术团队管理，业务技能和技术能力培养；
? ?


任职要求：
1、?精通数据仓库理论、具备大型数据仓库架构设计、模型设计优化等能力；
2、?对数据敏感，有较强的逻辑分析能力，对数据处理和分析有多年从事经验，有复杂业务和算法的数据平台建设经验；
3、?全日制本科以上学历，计算机相关专业； 3-5年以上完整实施DW/BI项目实施和开发经验、有一定的团队管理经验；
4、?熟悉Hadoop2、Spark/Streaming、Kafka、Flume、Presto、kylin等；
5、?熟练掌握Java/Python语言、有丰富的后台服务开发经验，对系统架构设计与性能调优有经验；
6、?熟悉主流数据挖掘算法开发实施经验者优先；
7、?要求较强项目管理经验和研发管理经验，有金融行业经验者优先；"
"职位描述：
        
        【工作内容】??
1.负责数据农场、洞察平台、可视化平台、机器学习平台等的搭建与不同环境中的部署
2.参与数据农场、洞察平台、可视化平台、机器学习平台的整合开发
3.提升智能数据平台产品的持续集成能力
4.针对内外部客户的需求，利用智能数据平台进行ETL开发，设计洞察数据模型与可视化模型建模

【岗位要求】
有数据仓库，BI产品经验，熟悉企业数据分析具体流程
代码能力较强，具有单独完成单个模块的能力。
1.计算机专业本科或以上学历；
2.五年以上数据开发经验，熟悉大数据技术如Hive、HBase、Spark、Jstom，Flink等，有HDP或者CDH套件使用维护经验更佳；
3.熟悉Hadoop、Spark、Kafka、Flink等的设计原理，熟悉其中一种或几种开源工具的源码更佳；
4.扎实的编程基础，善于分析问题，乐于钻研；
5.熟悉Linux系统系统
6.精通Java、Python、Scala等任意一种主流开发语言；
7.熟悉关系数据库以及NoSQL数据工具至少一种产品，如MySQL、MongoDB、Redis等；
8.逻辑性强，心理素质好，能承受工作压力"
"职位描述：
        
        岗位职责：1.构建数据仓库，负责ETL相关建设，负责数据治理相关工作；2.支持产品、运营、销售等业务对数据的需求，提供数据驱动和决策；3.负责仓库建模，构建标准化建模体系；4.优化现有数据产出链路，提高数据交付效率；
任职要求：1.3年以上大数据处理、数据挖掘等领域开发经验，计算机相关专业本科及以上学历；2.熟悉MapReduce, Hadoop, Pig, Spark, Hive, Sqoop等大数据相关技术及组件；3.熟悉数据仓库建模体系和数据治理；4.熟悉linux等相关操作系统的使用，熟练使用Shell, SQL；5.很强的自我驱动力、结果导向并极具责任感，有良好沟通能力和团队协作精神；7.有良好的数据结构知识优先；8.有Java工程经验优先。"
"职位描述：
        
        职责描述：
1.?????接收业务需求，分析需求，实现需求；
2.?????参与数据仓库需求调研、建模以及ETL数据处理；
3.?????完成项目数据梳理、数据模型设计、重构及优化等，并基于各业务系统需求提供统计、分析服务；
4.?????负责数据仓库的运维管理、性能分析及调优；
5.?????设计/优化公司各项业务指标体系，支撑数据化运营。
岗位要求：
1.?????本科以上学历，计算机、统计、数学等相关专业,2年以上大型数据仓库开发经验；
2.?????有扎实的SQL基础，熟悉至少一种数据库 oracle、teradata、mysql、hive、maxcompute，有阿里云maxcompute经验者额外加分；
3.?????有互联网用户行为采集、处理经验、保险行业经验者优先;
4.?????熟悉数据仓库理论、主流建模思想以及数据仓库相关管理知识；
5.?????熟悉ETL设计开发流程，至少掌握一种ETL工具 kettle,datastage,ssis等；
6.?????熟悉报表开发流程，至少掌握一种报表开发工具，如BIEE，QlikView，Power BI，Tableau，帆软等；
7.?????有一定的业务理解能力和沟通能力，能独立完成工作?
8.?????了解Hadoop生态体系，有实时计算、流计算经验者额外加分；
9.?????具有良好的业务理解能力、沟通能力和团队协作能力，能独立完成工作
10.??有较强的数据敏感度，能承受一定的工作强度与压力。"
"职位描述：
        
        
岗位职责：
参与众安车险事业部大数据实验室大数据平台及数据应用开发方面的工作：
1、负责数据分析、加工、清理、处理程序、模型部署的开发；
2、负责业务需求沟通，负责系统模块结构和流程逻辑的设计和优化；
3、负责数据相关平台的设计、搭建、开发、维护、优化；

任职要求：
1、计算机相关专业，本科及以上学历，5 年以上 Java 开发工作经验，学习能力突出；
2、熟悉 Hadoop 生态系统内常见项目的使用（HDFSHIVEHBASESPARK等），有实际大数据项目经验优先；
3、熟练掌握 Oracle、MySQL 等主流数据库；
4、精通 JAVA，熟悉基于 J2EE 的 WEB 架构设计，熟悉 Web 开发流程，有丰富的 Web MVC（Struts、Spring，Hibernate等）开发经验；
5、熟悉 Linux/Unix 系统环境下的操作；
6、具有良好的沟通能力、组织能力及团队协作精神，有较强的分析和解决问题的能力；"
"职位描述：
        
        工作内容：
1、负责大数据BI设计和开发；
2、数据仓库、数据集市的模型设计与开发；
3、负责ETL数据准确性验证及ETL任务的优化；
4、参与大数据平台和数据仓库的的搭建。

岗位要求：
1、两年以上数据开发相关经验，优先考虑具有保险行业背景同学
2、精通使用MySQL、oracle、hive等SQL数据处理技术
3、深入理解Hadoop、kafka、strom等大数据生态相关技术原理
4、参与过完整的ETL、数据模型和数据分析项目者优先考虑
5、具有数据指导业务发展的意识，可主动发现数据内在价值;"
"职位描述：
        
        工作职责:1.利用大数据平台实现公司的业务需要，解决数据分析、数据挖掘等业务需求；2.参与基于大数据平台建立相关的数据采集、清洗、数据应用的设计和开发；3.管理、优化、维护大数据平台，保证系统的持续、稳定；4.参与开发数据产品或组件，构建海量数据存储、计算和管理的平台。任职资格:1.计算机及其相关专业，本科及以上学历，大数据开发3年及以上工作经验；2.熟悉Hadoop、hbase、kafka、Spark、es、flink等相关技术和原理；3.编程基本功扎实，熟悉常用数据结构，擅长Java编程语言，熟悉JVM机制，熟悉shell、python等脚本语言；4.具有较强的团队意识与良好的沟通能力，高度的责任感，较强的学习能力以及快速解决问题的能力；5.有平台设计经验者优先考虑。"
"职位描述：
        
        岗位职责：
1、承担建设基于Hadoop/Spark生态的大数据离线/实时处理平台；
2、参与业务数据、生产日志的抽取、转储、检索等相关工作；
3、跟进大数据前沿技术的发展，将合适的技术方案适时引入业务场景。

任职要求：
1、 计算机、金融、统计、数学等相关本科或以上学历；
2、 掌握Hadoop、HBase、Hive、Kafka、Flume、Spark 等大数据技术；
3、 掌握数据挖掘，python，机器学习经验者优先；
4、 有较强的学习能力，勤奋踏实，责任心强，有较强的沟通协调能力，有一定创新能力。"
"职位描述：
        
        1、负责数据库系统部署方案的计划、设计和实施，设计数据库整体架构，负责项目的数据库开发；
2、负责SQL存储过程的编写等数据库应用开发；
3、负责算法和ETL效率的优化.

任职要求：
1、统招本科学历，有1年以上开发经验；
2、熟悉主流数据库（Oracle、MySQL、MSSQL）的安装和使用，有一定的维护能力；
3、熟悉SQL语言，熟悉Python者优先；
4、熟悉主流数据库相关监控、分析、开发和管理工具,了解数据库相关监控平台者优先；
5、有强烈的责任心，工作积极主动，具有很强的沟通表达能力及团队合作精神"
"职位描述：
        
        工作内容：
1、负责数据库设计、建模、建库等工作:；
2、负责GIS数据加工与生产、专题数据加工、遥感影像处理；
3、负责相关任务质量检查；
4、负责部分相关文档编写；
5、完成部门分配的其他相关任务；
?
任职资格:
1、计算机相关专业毕业，有数据库理论基础；
2、熟悉Oracle、SQL Server等主流数据库，熟悉数据建模；
3、熟悉各种GIS标准及数据格式；
4、团队合作精神好，能承受较大的工作压力，能适应经常出差；"
"职位描述：
        
        工作内容：

1.? 作为技术体系云计算大数据专家，对云计算大数据业务演进规划和整体方案设计负责；

2.? 领导研发和技术顾问团队为公司提出云计算大数据解决方案，并在开源技术上，组织实施；

3.? 对大数据领域新技术的跟踪研究/落地实践/关键技术攻关/技术团队使能。

4.? 根据业界容器技术的发展，给出在P层(PAAS)需要发展的平台服务能力的模型/方案；

5.? 参与重大技术项目的决策，指导、审核项目总体技术方案，对各项目进行质量评估。
任职资格：

1、精通spark，flink，hbase,storm，或者其它主流大数据框架，contributor级的人才，具备丰富的架构设计能力，精通大型系统的架构设计、系统分析、软件实现、性能优化、系统安全等；? ?

2、精通Java或C++熟悉Linux系统和多种数据库的管理；??

3、精通基于hadoop体系的大数据解决方案和产品架构设计，熟悉多种相关产品的应用；

4、熟悉Docker的使用，了解Docker的基本设计原理的优先；具有Apache Mesos, Google? ?kubernetes使用经验的优先；熟悉go编程语言尤佳。??

5、 具有敏锐的公司产品相关行业技术发展趋势把握能力和宏观分析判断决策能力、较强的组织管理能力、良好的人际关系协调和沟通能力；

6、 5年以上一线互联网公司研发管理经验，丰富的研发梯队培养与团队管理能力；

7、BAT及国内知名互联网公司工作经验背景优先；

8、有大数据方面的认证，如CCDH等者优先。"
"职位描述：
        
        任职条件
1、熟悉Hadoop/Hive/HDFS/Spark等大数据工具， 熟悉MySQL/MongoD等数据库技术；
2、熟悉Linux开发环境，能熟练使用Git/Vim等工具；
3、熟悉Python，具备较强Python处理数据能力；
4、具备较强学习能力，沟通表达能力，抗压能力；
5、具备爬虫开发、ETL等工作经验者优先。"
"职位描述：
        
        任职条件
1、熟悉Hadoop/Hive/HDFS/Spark等大数据工具， 熟悉MySQL/MongoD等数据库技术；
2、熟悉Linux开发环境，能熟练使用Git/Vim等工具；
3、熟悉Python，具备较强Python处理数据能力；
4、具备较强学习能力，沟通表达能力，抗压能力；
5、具备爬虫开发、ETL等工作经验者优先。"
"职位描述：
        
        工作职责：
1.负责公司数据处理逻辑的设计和优化；
2.负责公司各种数据模型的设计、开发和优化。
岗位要求：
1.熟悉HDFS、MapReduce和HBase的基本实现原理；
2.熟悉至少1种分布式计算引擎的实现原理，具备性能调优能力；
3.熟练使用Java或Scala语言进行开发；
4.具备1年以上的TB级别数据平台开发经验；
5.良好的工作习惯、沟通能力和学习能力。"
"职位描述：
        
        岗位描述：
1. 参与亿级产品实时分析和批处理的架构设计和开发；
2. 负责平台ETL开发、数据仓库设计，支持产品的各类数据需求；
3. 参与大数据平台后台、页面等各项开发工作；
4. 参与大数据基础平台的维护和性能优化；
?
岗位要求：
1. 1年以上Spark开发经验，有数据平台项目开发经验，熟练使用大数据技术栈；
2. 熟悉关系型数据库，熟练SQL，有SQL性能调优经验；
3. 熟悉搜索框架Lucene、ES和相关技术（索引、分词）；
4. 具有较强学习能力、自我驱动能力、责任感。"
"职位描述：
        
        岗位职责：
1、负责大规模数据存储，高性能离线计算平台的研发与维护
2、理解和分析数据挖掘的需求和数据特点，开发中间数据层及策略中间件
3、用户行为分析，核心指标制定与相关性分析，竞争产品跟踪等大数据需求

任职要求：
1、计算机相关专业本科以上学历，2年以上大数据领域项目经验
2、熟悉常用的数据结构和算法，熟练linux环境
3、熟悉hadoop/hbase/spark/kylin等大数据相关开源工具中的一门或几门
4、精通c/c++/java/php里的一门或几门，具有扎实的面向对象开发经验
5、乐于解决具有挑战性的问题，具备优秀的分析问题，解决问题能力
6、思维灵活，对数据敏感，擅长与产品经理，数据挖掘工程师等进行交流沟通及合作
7、有数据挖掘，机器学习工作经验者优先"
"职位描述：
        
        岗位职责：
1、对海量数据进行数据处理、分析、统计、挖掘工作；
2、负责协助完成应用系统中数据上下层衔接处理工作；
3、对用户数据进行分析和挖掘，提供决策支持。

任职要求：
1、全日制本科及以上学历，计算机，软件工程及相关专业；3年以上大数据研发经验，有互联网工作经历优先考虑；
2、熟练掌握Java开发语言，额外熟练掌握C++/C/golang/PHP等任一开发语言优先考虑；
3、熟悉HTTP协议；
4、熟悉Hadoop/Hive/Hbase/Spark/Storm等分布式计算环境进行海量数据分析；
5、做过数据仓库，对数据治理、数据标准及元数据有很好理念及实施经验的优先；
6、良好的沟通能力和团队精神，具备创新意识。"
"职位描述：
        
        工作职责
1. 理解业务的本质需求，设计和构建对应业务的数据仓库，负责ETL流程的开发和优化工作，开发结构层次合理、灵活可扩展的数据仓库
2. 利用Hadoop、Spark等大数据技术对车端海量数据进行预处理，支持预测模型、算法等工程化实现
3. 和数据产品经理一起，解决业务数据分析、数据异常相关的技术问题
4. 设计和开发数据产品和工具，系统化、自助化地提高业务分析效率
5. 对现有系统的进行架构深入分析及系统优化，进一步提升系统的性能及数据处理能力
任职要求：
1. 计算机相关专业, 统招本科或以上学历，2年以上相关工作经验
2. 熟悉Java/Python编程，数据结构与算法功底扎实，精通面向对象编程
3. 具备较丰富的hadoop/hive/hbase/spark/flink/kafka等大数据工具应用和开发经验
4. 掌握数据仓库(DW)/OLAP/数据统计理论，并灵活应用
5. 有容器相关技术（k8s，docker）经验者优先
6. 对数据敏感、对新技术敏感，有一定技术研究能力
7. 有海量数据开发经验和数据挖掘项目经验者优先
8. 熟练的英文听说读写能力，较强的沟通能力、逻辑思维能力和抽象能力，较强的责任心和快速学习能力
9. 适应创业公司氛围，自我驱动，透明直接沟通，团结合作，高效快速的应对变化
10. 对新技术有持续的热情，对业务产品有前瞻性理解"
"职位描述：
        
        岗位职责：
1、对海量数据进行数据处理、分析、统计、挖掘工作；
2、负责协助完成应用系统中数据上下层衔接处理工作；
3、对用户数据进行分析和挖掘，提供决策支持；

任职要求：
1、全日制本科及以上学历，计算机，软件工程及相关专业；3年以上大数据研发经验，有互联网工作经历优先考虑；
2、熟练掌握Java开发语言，额外熟练掌握C++/C/golang/PHP等任一开发语言优先考虑；
3、熟悉HTTP协议；
4、熟悉Hadoop/Hive/Hbase/Spark/Storm等分布式计算环境进行海量数据分析；
5、做过数据仓库，对数据治理、数据标准及元数据有很好理念及实施经验的优先；
6、良好的沟通能力和团队精神，具备创新意识。"
"职位描述：
        
        岗位职责：
1.设计业务系统云端的技术架构，编写核心代码；
2.负责大数据基础平台的架构设计与实现
3.负责高并发、高性能的视频数据处理平台的设计和优化
1. Design thed cloud technology architecture of business system, write the core code;
2. Responsible for the design and implementation of large data infrastructure platform
3. Responsible for high concurrent, high-performance video data processing platform design and optimization
任职要求：
1.精通Java、Scala语言，对JVM运行机制有深入了解；
2.熟悉Hadoop、Spark并具有实际开发经验；
3.在分布式计算、大规模存储系统方面有实际开发经验，熟悉RabitMQ/kafka等分布式消息系统
4.熟悉大数据相关工具链的搭建、应用、优化，如：Mapreduce/Sqoop/Hdfs/Hive/Spark-Streaming/Solr等；
5.熟练使用ETL工具进行数据抽取，清洗，转换，关联等操作；
6.计算机相关专业，本科以上学历，大数据相关工作经验3年以上；
--- 
1. Proficient in Java, Scala language, understanding the JVM operating mechanism in-depth ;
2.Familiar with Hadoop, Spark and have practical development experience;
3. In the distributed computing, large-scale storage systems have practical development experience, familiar with RabitMQ/kafka and other distributed messaging systems
4.familiar with large data related tool chain , such as: Mapreduce / Sqoop / Hdfs / Hive / Spark-Streaming / Solr;
5. Proficiency in ETL tools for data extraction, cleaning, conversion, association and other operations;
6. Computer related professional, bachelor degree or above, large data related work experience for more than 3 years;"
"职位描述：
        
        岗位描述
1. 参与人民在线众云大数据产品线相关大数据平台和大数据处理框架的架构规划设计；?
2. 参与数据治理工作，提升数据易用性及数据质量；?
3. 理解并合理抽象业务需求，发挥数据价值，主动思考不断优化，与业务团队紧密合作；?
4. 管理、优化并维护Hadoop、Spark等集群，保证集群规模持续、稳定。

岗位要求
1. 两年以上相关工作经验；
2. 熟练掌握java语言，Scala和python至少掌握一种，熟练使用linux,强悍的编码和 troubleshooting能力；?
3. 熟悉大数据开源栈spark/hadoop、Hive、Hbase、ElasticSearch、kafka、redis, strom/spark-streaming/flink，有至少TB以上级大数据处理经验；
4. 有SparkStreaming的实时统计或实时规则引擎整体架构开发经验优先；有SparkML开发经验优先；?
5. 对数据敏感，认真细致，善于从数据中发现疑点；?
6. 善于沟通，具备优秀的技术与业务结合能力；?
7. 有风控研发经验者优先，对风控行业有自己思考的优先；
8. 学习能力强，喜欢研究开源新技术，有团队观念，具备独立解决问题的能力。"
"职位描述：
        
        职位描述
?
工作内容/职位描述：
?
1、涉及TB级别以上，数据仓库底层构建，根据业务需要对底层数据进行清洗转换，实现相应各类分析数据集市构建
2、开发各业务部门需要的各种报表脚本，解决日常运营常规性需求；
3、数据分析类产品设计和开发；
?
任职资格：
?
1、计算机相关专业本科以上学历，三年以上Java Web应用软件开发经验；
2、精通Servlet、Spring、Hibernate、iBatis开发，对虚拟机及Linux下的开发环境有较深厚的开发经验；
3、熟练MySQL，对数据库有较强的设计能力，同时熟悉大数据相关技术；
4、掌握hive sql/pig语言，具备扎实的程序设计基本功和学习能力 ，
5、熟悉Hadoop(HDFS/MapReduce/Hive)、Spark、HBase、Storm、Kafka、Flume等类框架技术，对源代码有一定研究者优先；
6、具有大数据产品开发、实时计算开发经验、报表平台研发、数据仓库建设经验者优先。
7、熟悉网络编程，具有设计和开发对外API接口经验和能力；
8、具有良好的沟通，团队协作、计划和创新的能力；"
"职位描述：
        
        工作职责：1、参与公司大数据产品规划,大数据处理分析平台的架构设计；2、负责数据存储、清洗、分析程序的开发与平台搭建；3、负责大数据相关技术发展方向的预研；4、业务数据仓库搭建；5、数据可视化平台搭建；6、自助数据平台搭建，自助提取数据或自助生成周期报表平台；7、数据分析与运营，给业务提供支持与驱动产品优化；8、基于大数据进行数据分析与预测；?任职资格：1. 本科以上学历2. 有过从 0 到 1 搭建数据平台的经验3. 离线领域hadoop的ETL开发经验4. 实时计算领域包括storm、spark、flink等的开发经验其中之一经验者；5. 加分项：对于增长黑客感兴趣"""
"职位描述：
        
        工作内容：
1. 负责数据挖掘小组的数据统计
2. 保障基础数据质量
3. 其他统计以及数据预处理

职位要求：
1. 计算机、统计学、数学相关专业?
2. 精通sql语言，熟悉ODPS优先
3. 有耐心、细心以及沟通能力，为人乐观
4. 熟悉数据描述性统计方法
5. 熟悉hadoop，hive，spark优先"
"职位描述：
        
        岗位职责：

 负责数据研发工作，针对业务诉求和实际数据情况，能独立完成项目的系统分析，根据开发规范和数据模型设计实现数据开发任务，保证数据质量；
 基于hadoop平台进行数据模型设计、数据ETL开发，整合和处理负杂数据；
 数据系统建设和构建数据应用，包括数据采集、提取、分析与数据产品化，以及模型架构设计及优化工作；
 同产品、BI等团队协作深度挖掘数据商业价值，建设公共数据服务，实现高质量数据共享，推动部门数据应用能力；
 深入理解数据产品的使用场景，为业务方在可用性、成本上做更好的设计做参考。


任职要求：

 本科及以上学历，4年以上大数据开发相关工作经验；
 具有丰富的数据研发经验，对数据处理、数据建模、数据分析等有深刻认识和实战经验。
 较为丰富的数据仓库及数据平台的架构经验，精通数据仓库建模及ETL设计开发；有较为系统的海量数据性能处理经验；
 有从事分布式数据存储与计算平台应用开发经验，有Hadoop、Hive、Spark 等离线计算、实时计算数据研发经验
 熟练使用Python/Java或其他语言进行复杂业务逻辑的数据处理工作，具备海量数据处理以及性能优化的能力；
 责任心强，做事细致，具备较强的沟通协作能力和快速学习能力。"
"职位描述：
        
        岗位职责：
1、业务数据数据挖掘和智能数据展现；
2、各业务数据的采集、清洗、整合，数据仓库的建设；
3、基于大数据分析平台的产品开发和维护，完成各业务的离线/实时计算。
?
任职要求：
1、熟练使用Linux，良好的编程基础， 熟悉SQL，java, python ；
2、熟悉常用机器学习算法（如 svm, k-means，HMM），了解算法内在原理；
3、了解大数据生态圈，熟悉Hadoop、Hive、Hbase、Spark、Storm 等分布式开源项目优先；
4、对有数据可视化、人物画像，个性化推荐，CTR,搜索有相关工作经验优先；
5、具有较好的沟通能力和团队合作精神。"
"职位描述：
        
        岗位职责：
1、负责项目中数据处理工作（数据采集、清洗、汇总等），保证数据的准确性和稳定性；

2、支持业务团队的数据建设工作；

3、 参与数据仓库、数据集市的设计、开发和维护。

岗位要求：
1、扎实的编程基础，有JAVA/Python相关开发经验；

2、熟悉SQL，有一定的SQL性能优化经验；

3、有数据仓库建设和ETL经验优先。"
"职位描述：
        
        职位描述：
1、广告各类在线业务的离线数据加工与在线数据服务开发与维护
2、数据服务接口及产品需求研发迭代，代码review、bug修复及日常服务运维
3、针对海量数据处理和查询需求，设计适应业务变化的合理的多维数据分析系统架构，满足多样性的需求
4、海量日志清洗加工，并抽象出可以多业务复用的数据模型
职位要求：
1、计算机相关专业本科以上学历，熟悉Hadoop架构和工作原理，精通MapReduce编程；精通Hive，有HQL优化经验
2、熟悉JAVA，python等多种编程技术，编程能力强，有web服务开发经验，具备独立完成模块开发能力"
"职位描述：
        
        岗位职责：1、 Hadoop数据平台搭建，参与生态圈内工具创新及研发工作；2、 参与人工智能及数据挖掘等研发项目，结合大数据平台探索机器学习应用场景并参与实施任职资格：1、 3年以上Hadoop体系数据平台研发运维经验2、 熟练使用Hadoop/Spark生态圈技术，如：Hive、Hbase、MapReduce、Spark、Oozie、Kafka、Flume等等3、 具备较高的程序开发及调试能力；具备一定的系统设计能力4、 良好的沟通技巧和团队合作意识"
"职位描述：
        
        岗位职责：1、参与海量数据实时处理与分析，实时服务系统设计与开发；2、参与数据分析产品后台开发工作，探索新型数据应用方向；任职要求：1、计算机、软件等相关专业，两年以上工作经验；2、熟悉Java、C++基础知识，熟悉相关原理及性能调优；3、熟练掌握Storm、Kafka等流式处理框架，熟悉Mysql、Redis、HBase等存储原理及应用开发；4、熟悉网络通信，常用缓存架构、数据结构及算法应用等；5、较强的分析解决问题能力，沟通协调及团队精神，有一定抗压能力；6、有大型分布式系统开发经验优先；7、有大型互联网工作经验优先；"
"职位描述：
        
        1、5年及以上 Java 开发经验
2、具有海量数据实时处理后台架构设计经验，精通jVM性能优化
3、具备制定开发规范，指导团队的能力
4、熟悉storm、spark、flink等开源流式计算框架的设计思想和优缺点
5、熟悉redies集群、kafka、zookeeper等分布式后台组件
6、熟练Linux操作系统，熟悉Shell脚本编程及常用Linux操作命令
7、熟练使用Mysql,hive，并熟悉sql优化"
"职位描述：
        
        1、5年及以上 Java 开发经验
2、具有海量数据实时处理后台架构设计经验，精通jVM性能优化
3、具备制定开发规范，指导团队的能力
4、熟悉storm、spark、flink等开源流式计算框架的设计思想和优缺点
5、熟悉redies集群、kafka、zookeeper等分布式后台组件
6、熟练Linux操作系统，熟悉Shell脚本编程及常用Linux操作命令
7、熟练使用Mysql,hive，并熟悉sql优化"
"职位描述：
        
        岗位职责：
1、负责离线，实时数据开发工作，对spark，hive，flink，flume等开发具有丰富经验；
2、负责图计算平台数据开发工作；
3、Json等多种格式数据源解析和落地工作；
4、对数据源进行数据质量开发工作。

任职资格：
1、计算机本科以上学历，至少有5年数据开发经验；
2、具有大规模数据的数据仓库或数据开发相关经验；
3、熟悉spark，hdfs，hive，flink，flume等离线和实时计算技术；
4、了解至少一种图数据库，有过图计算开发经验为佳；
5、掌握SQL，SparkSQL，ES Query DSL 等查询语言，拥有SQL性能调优经验；
6、具有一定业务理解能力，较强的责任心、团队合作能力和沟通能力。"
"职位描述：
        
        岗位职责：
1、参与城市计算数据平台的设计及集群开发；
2、提升数据平台运营能力、保障承载业务能力；
3、负责数据平台模块开发，保证稳定性、安全性；
4、配合团队共同参与Hadoop及相关开源技术的使用、封装和优化。

任职资格：
1、计算机相关本科以上学历，3年以上大数据平台开发相关经历；
2、精通Java/Scala至少一种，良好的代码编写素养，熟练掌握操作系统、网络原理、数据结构与算法；
3、精通Hadoop、Hive、Spark、Flink、HBase等大数据技术的原理以及优化，并有一定的大数据平台建设调优经验;?
4、参与或主导过大型数据平台建设项目，对大数据平台有整体的感知能力;
5、在开源社群活跃并有积极贡献者优先；
6、思维敏捷，有较强的钻研学习能力；
7、较好的沟通能力、团队合作。"
"职位描述：
        
        岗位职责：
1、研究大数据技术在金融风控领域的应用；
2、参与风控智能决策系统的规划设计和实施；
3、解决项目中的技术难题，关键技术难点攻关。

任职资格：
1、计算机或相关专业本科及以上学历，扎实是java基础，3年以上大数据开发经验；
2、熟悉Linux/Unix开发环境，精通java/python/shell，扎实的数据结构和算法功底，熟悉JVM原理，做过JVM调优者优先；
3、具有丰富的数据加工处理经验，对数据处理、数据清洗，数据建模、数据分析等有深刻认识和实战经验；
4、熟练使用mapreduce、hive、spark等进行数据加工；熟悉hive和spark的编写和性能调优；
5、熟悉常用开源分布式系统，对Hadoop/Hive/Spark/Storm/Flink/HBase/Redis中的一项或多项有深入了解，能够独立排查及解决分布式系统的问题；
6、清晰的逻辑分析和表达能力，热爱技术，乐于分享，对行业和技术的发展有自己的见解；
7、良好的团队精神和合作意识，强烈的责任心，对工作有激情，良好的沟通能力。"
"职位描述：
        
        职责描述：
1、参与数据需求的沟通和模型设计；

2、负责大数据平台的数据需求开发，包括实时和批量处理；

3、负责不同数据源的接入解析落地的设计开发工作；

4、负责数据质量监控，解决数据运行和质量问题。

任职要求：
1、计算机本科以上学历，至少有3年数据开发经验；

2、精通Java/Scala/Python，至少有3年以上开发使用经验；

3、熟悉Spark，Hive，Flink，JStorm等大数据实时计算技术；

4、掌握Hive SQL，SparkSQL，ES Query DSL 等查询语言；拥有SQL性能调优经验；

5、具有较强的业务理解能力，较强的责任心、团队合作能力和沟通能力；

6、有过图数据库开发或Spark MLlib开发经验者优先考虑。"
"职位描述：
        
        岗位职责：
1、负责大数据平台以及智能数据产品的规划和搭建、系统及功能模块设计，平台的维护和优化, 制定清晰的大数据产品技术研发路线图；
2、负责规划数据挖掘的整体流程，并参与用户产品和数据产品的决策；
3、与业务部门密切配合，寻求数据层面的业务价值，利用数据分析结论推动产品优化；
4、带领团队对于产品数据进行分析，指导工程师完成数据挖掘相关的算法、应用的设计与开发；
5、技术团队的管理及考核，制定开发、运营规范，撰写相关技术文档指导和培训工程师；负责大数据核心技术团队的人才培养；
6、关注前沿技术，研究其中的商业价值，根据公司战略进行应用转化。
任职要求：
1、计算机、数学相关专业，全日制本科及以上学历
2、8年以上工作经验，5年以上团队管理经验，具备30人以上数据与技术团队管理经验为佳。
3、精通Hadoop／Spark、Hive、HBase等主流的大数据技术，至少3年以上产品／平台项目研发经验；具备大型复杂Hadoop数据平台的建设实施经验；精通Java及Python；
4、领导开发过数据产品，能够把数据和业务系统形成闭环；
5、对数字，数据敏感，具备良好的逻辑思维能力，能够从海量数据中发现有价值的规律；
4、有极强的项目管理能力和资源协调能力，有很好的沟通能力；
5、符合以下条件者优先：
(1) 具有较强的数据挖掘、机器学习、语义分析的理论基础和实际项目经验，精通数据分析与各种算法与模型；构建用户画像分析体系；
(2) 极强的零售大数据、电商平台系统设计和系统架构能力或者项目经验；
(3)必要的产品管理意识和产品设计的评估技能；"
"职位描述：
        
        岗位职责:1、负责开发和优化hadoop大数据平台，构建基于大数据平台的数据分析体系；2、负责基于大数据平台的数据应用实施项目的设计开发；3、指导和培训数据使用人员，提升大数据分析和处理技能。岗位要求
1、统招全日制本科以上学历,?计算机专业优先；2、2年以上Hadoop实施及大数据批量或实时处理分析经验，有过搭建分布式硬件服务区集群经验优先；3、熟悉基于Hadoop的Java开发，熟悉Linux系统；4、独立的思维能力，乐于沟通、协作，具备高度的自我约束能力、学习能力和表达能力，能够承担较大工作压力和责任；5、有金融行业、互联网行业数据项目实施经验者优先。"
"职位描述：
        
        岗位描述：
1. 基于Spark与Hadoop，进行海量数据模型设计、数据ETL开发；?
2. 负责长天长大数据平台的基础数据服务接口开发，包括数据提取、分析与结果整理；?
3. 负责分布式数据平台框架下的数据架构设计与开发，以及新的数据应用服务的开发；
4. 参与环保数据分析模型体系构建及数据主题设计和开发；
5. 参与开发网络爬虫程序，爬取第三方环保相关数据；
6. 参与企业端生产IOT时序数据的接入和应用的开发。


岗位要求：
1. 熟悉Hadoop或Spark分布式数据开发技术，熟练掌握数据库技术；?
2. 精通海量数据仓库的系统设计和开发，精通数据建模、ETL过程、元数据管理等数据仓库主要环节；?
3. 精通OLAP分析引擎kylin，实时消息框架kafka，全文检索Elasticsearch；"
"职位描述：
        
        工作职责:1. 针对实际的数据与业务诉求，收集并整理需求说明书，根据开发规范和数据模型设计实现数据开发任务2. 负责数据应用系统开发，配合外部系统进行数据联调工作，部署数据任务工作任职资格:1. 有Java/Scala/Python一种或多种开发经验；2. 熟练掌握JAVA开发，及分布式计算原理，熟练掌握多线程并发；3. 熟悉hadoop、flume、kafka、Hive、Hbase、Impala、sqoop、elk、zookeeper等hadoop组件的使用和调优；4. 熟练掌握hadoop/storm/spark/Flink等分布式系统的开发和实施；5. 5年以上大数据平台开发经验，有多个数据产品开发和实施经验，有互联网公司工作经验者优先；6. 具备很强的责任心，做事细致、严谨，同时需要具备较强的沟通和快速学习能力。"
"职位描述：
        
        工作职责:1. 负责大数据数仓的ETL设计和开发以及维护工作。2. 对海量数据进行统计分析，为产品决策提供数据支持；3. 参与大数据平台建设，对BI分析、数据产品开发、数据挖掘等离线计算开发工作。任职资格:1. 5年以上数据仓库ETL设计及开发经验，有互联网工作者优先；2. 熟悉ETL设计、调度、监控、算法等，能够熟练的进行事实表、维度表的开发；3. 熟悉Linux操作系统，具有良好的Shell或python编程能力；4. 熟悉hive和常用数据库的SQL/HQL编写，有较好的SQL性能调优经验；5. 对hadoop、Hive、spark、Impala、Persto、Kylin、Ooize、Azkaban等大数据组件有一定的了解；6. 具备很强的责任心，做事细致、严谨，同时需要具备较强的沟通和快速学习能力。"
"职位描述：
        
        岗位职责""1、负责和参与公司大数据基础架构平台的建设，保障数据平台服务的稳定性和可用性；2、参与多机房数据同步、数据ETL、数据仓库的整体框架规划和设计。""任职要求""1、本科及以上学历，5年以上大数据开发经验；2、熟悉Hadoop、Storm、Spark、Flume、Kafka、Hbase等组件的原理，有良好的系统性能优化及故障排除能力；3、负责和参与大数据基础架构平台的监控、资源管理、数据流管理，能够开发各种Hadoop大数据自动化运维与监控工具；4、对Hadoop平台架构能够不断优化，提升数据产品的质量和响应速度；5、精通Shell/Python/Java语言的一种或多种；6、有大规模hadoop运维经验者优先，有hadoop/hbase开发经验者优先。"""
"职位描述：
        
        职责描述 a. 将参与基础数据系统/计算任务集群的搭建运维，有爬虫系统经验的优先 b. 将参与数据仓库ETL及数据脚本、数据任务的项目开发，以及数据仓库的建模、取数、报表 c. 将参与项目中业务模型的算法落地，有数学功底及有算法基础的优先
 任职要求 a.3年以上大数据领域开发的工作经验，对Linux操作系统熟悉，有大规模分布式系统相关搭建、开发/架构、运维经验优先。  b.精通Hadoop/Flink/Spark编程优先，至少熟悉Java/Scala/Python/R/Julia/Matlab等数据语言中的2种。  c.有强烈的求知欲和自我驱动能力，良好的技术规划和业务沟通能力"
"职位描述：
        
        工作职责
1、负责云集的大数据开发及平台稳定性保障工作
2、负责处理大数据平台Hadoop/Hive/Spark/Storm等问题及性能优化
3、根据业务需求开发相应工具
任职资格
1、四年以上工作经验，有大型互联网行业从业经验
2、有Hadoop/Hive/Spark/Storm/Zookeeper 等相关开发经验或从事分布式相关系统的开发工作
3、熟悉Linux/Unix系统和丰富的Java开发经验
4、具有强烈的责任心，求知欲望强"
"职位描述：
        
        岗位职责：?
1、基于 hadoop 生态圈相关开源解决方案，比如 MR/Hive/Kafka/spark/storm 开发大数据统计分析平台，支持部门的产品运营、统计分析；?
2、基于 Hive/spark/storm 开发相应的离线/实时统计分析服务或报表，支撑下游业务方应用，如：数据监控、日报展现、运营统计分析、业务方调用等；
3、基于海量日志下的多维统计分析与查询方案设计与实现，并能对其存储空间与查询效率进行优化；?
4、除此之外，亦需要深入业务，对财务数据，数据报表，数据后台进行来发支持。

任职要求 ，由于处于创业阶段，希望但不限于具备以下技能：
1、熟练掌握 Java 编程语言、有 Java 后台服务相关开发经验优先；
2、熟练掌握 spark、storm 等大数据技术其中一种或多种，海量数据场景下的多维统计与查询有相关经验者优先。?
3、熟悉MySQL或NoSQL原理，有相关使用经验即可；?
4、有电商大数据经验者优先
5、本科及以上学历，3年以上工作经验"
"职位描述：
        
        工作职责：
1、负责公司大数据基础平台建设工作，包括数据收集、作业调度、数据仓库、数据处理、在线数据服务等；
2、负责高并发、大存储的数据系统的研发工作；
3、负责公司分布式数据平台系统建设，全面参与项目需求分析、架构设计和技术研究
?岗位要求：
1、本科以上学历(学信网可查），3年以上相关工作经验。
2、精通Linux操作系统，熟悉Java、Scala、Python开发常用语言框架，熟悉Scala尤佳
3、2年以上大数据项目实战经验，熟悉Hadoop、Hbase、Spark、Pig、hive、HDFS、sqoop、yarn等开源框架，并熟悉其工作原理；
4 、熟悉传统数据库，对flume 、kafka、es、redis、mongodb等技术有实际项目经验
5、熟悉整个大数据的完整处理流程，包括数据的采集、清洗、预处理、存储、分析和可视化；
7、有较强的独立、主动的学习能力，良好的沟通表达能力和团队协作能力；"
"职位描述：
        
        工作职责：
1.负责基于spark、hadoop开发游戏分析报表；
2.负责参与数据处理调优等；
3.参与其他一些平台化数据产品的开发。
招聘要求：
1.本科以上学历，计算机专业优先；
2.3年以上JAVA开发经验，熟悉linux基础命令；
3.了解hadoop生态系统，有实际经验者优先；
4.独立的思维能力，乐于沟通、协作，具备高度的自我约束"
"职位描述：
        
        岗位职责：
1、负责大数据平台的建设以及优化；
2、基于海量数据，支持业务对数据的分析和使用；
岗位要求：
1、 大学本科以上学历、计算机、数学相关专业；
2、熟悉大数据主流开源组件:Hadoop/Hive/HBase/Spark, 并了解其特性和使用场景；
3、理解维度建模、实体建模方法论，有实际数据仓库ETL开发经验优先；"
"职位描述：
        
        岗位要求：
1、大学本科以上学历、计算机、数学专业；
2、深刻理解维度建模、实体建模方法论；
3、至少2个以上大型数据仓库模型设计经验；
4、3-5年数据仓库ETL开发经验；
5、有海量数据处理与存储经验；
6、熟悉Hadoop生态圈架构，如Spark、Hive、KafKa、Hbase、Parquet等开源组件；
7、有大数据项目运维经验；熟悉阿里云数加产品（有项目经验尤佳）。

岗位职责：
1、协助架构师完成中台架构；
2、协助架构师完成数据建模；
3、负责协助架构师搭建中台开发平台；
4、负责指导低级别开发人员大数据开发。"
"职位描述：
        
        工作职责:工作职责： 1、参与开发和维护公司的数据仓库，包括但不限于架构设计、升级改造和数据仓库模型未来规划 2、参与简历和维护数据处理系统，保证数据正确性和系统可靠性3、探索、开发并维护数据基础设施，提供各种高效数据访问和处理工具4、和分析师，数据科学家与工程师们密切合作， 设计和开发数据仓库的架构和标准任职资格:任职要求： 1、熟悉大规模数据处理的技术，了解分布式计算环境的原理。2、熟悉数据库性能基本概念如索引，分片，分区等，深入理解关系型数据库的schema设计和性能调优。3、有熟练操作和优化SQL的经验。4 ? 有实际部署和开发MPP平台（Greenplum, Vertica,etc）经验者优先考虑。5、熟悉Hadoop生态圈，熟悉Hbase、Spark、Impala等开发者优先考虑。"
"职位描述：
        
        工作职责：
1、参与Hadoop系统的架构设计、系统研发和业务挖掘工作。
2、参与图像大数据挖掘项目的开发。

任职资格:
1、具备三年以上Java/Spring工作经验, Hadoop研发经验两年以上；
2、熟悉Java平台IO、多线程、网络等基础知识和相关框架；
3、熟悉Linux基础知识和常用命令，能独立分析和解决问题；
4、熟悉HDFS、Hbase、Hive等大数据存储技术工具，原理和应用；
5、熟悉Yarn/Mesos、MapReduce/Spark，Kylin等大数据分析技术工具，原理和应用；
6、熟悉数据集成和大规模数据转换技术和工具，如Kettle，Sqoop，Flume等；
7、熟悉数据采集工程（爬虫）工作原理，能编写和部署大规模爬虫系统；
8、善于学习、与人沟通、为人正直、诚信, 有较强的事业心；
9、具有数据仓库建设或应用相关项目经验优先。
有以下经验尤佳：
1）熟悉搜索引擎开发；
2）熟悉Scrapy或者WebMagic；
3）熟悉NoSQL或NewSQL技术；
4）熟悉Scala/Python/R；"
"职位描述：
        
        职责描述：1.负责hadoop/spark/hive等大数据项目的建设,管理,优化2.负责大数据分析需求的设计和开发,承担数据抽取、清洗、转化等数据处理程序的开发3.负责BI数据分析,数据报表平台的建设、维护任职要求：1.了解hadoop/spark/hive等大数据技术的原理以及与优化方法,有相关的开发经验2.精通sql,熟练使用sql处理各种复杂格式数据3.熟悉linux环境和常用的操作4.有较强的学习能力,热衷于新技术的学习和实践

其他：我们有着完善的薪资福利体系和丰富多彩的员工生活
1. 一年1-2次调薪；2．年终奖：1-6月工资，根据公司这一年的经营情况综合考量；3．娱乐旅游活动：每周羽毛球、每月市内户外游、每季度省内周边游、每年省外或国外游；4．下午茶：公室零食饮料不限制提供，更有酸奶水果、每周一次下午茶会，各种无限制；5．大事补贴:逢婚、育、大病等个人大事给予礼金；6. 每月员工生日会：每月都可以吃到名品蛋糕，公司还为寿星准备礼物哦7．节日补贴：节假日组织聚餐、各种节日礼品及现金补贴；8．内部分享培训福利：鼓励内部或邀请外部牛人分享知识技能给予相应奖励；9．优秀员工奖：每两月选出若干优秀员工给予奖励；10．休假福利：7天带薪年假、调休假、双休日/法定公众假期、婚假、丧假、产假、陪产假等；11．社会保险：凡公司员工在入职当月公司为其办理社保一档；12. 住房公积金：凡公司员工在入职当月公司为其办理住房公积金;13. 医疗：公司每年一次体检;14. 文化书籍福利：买什么书你说了算，公司负责采购书本供借阅共享，提高知识技能（书籍类型不限）。"
"职位描述：
        
        岗位职责：
1.负责大数据项目的需求分析，产品设计与定义工作；?
2.负责大数据平台的搭建，大数据相关项目的研发工作；
3.参与研究大数据技术应用的解决方案；

任职要求
1.计算机相关专业本科及以上学历；
2.精通Java/J2EE编程，熟练使用Eclipse/Git等开发工具，2-3年以上Java开发经验。
3.熟悉linux操作系统，掌握常用linux命令，熟悉Shell脚本编程。
4.熟悉数据库原理、多线程编程、IO、网络编程、操作系统等，基本功扎实；
5.主动好学，具备良好的沟通合作技巧，较强的责任心及团队合作精神。
6.有金融领域大数据平台建设、实施经验者优先。"
"职位描述：
        
        岗位职责：
1、负责配合销售推动大数据商业应用在水务、水利、政府、运营商等行业的落地；
2、负责项目前期的客户技术交流，提供初步建议方案，直至提供详细定制化的解决方案，展示大数据的商业价值；
3、负责编写大数据项目的投标方案和讲标资料，参加招投标会，负责讲标和答疑工作，参加合同谈判，为合同签订提供技术上的保障，最终达成本岗支持统计销售额的任务指标；
4、研究行业、市场、用户需求、潜在竞争对手在大数据方面的前沿信息，为公司的大数据产品提供指导；
5、配合其他部门完成产品规划建议、市场宣传、培训、设备选型等工作。?

任职要求：
1、3-5年工作经验，具备大数据产品设计、开发、售前支持的从业经验，数学、统计学、数据挖掘等相关专业优先；
2、技术专业知识全面；良好的方案策划和提案能力；熟悉项目招投标的流程及工作内容；
3、具备一定的数据分析能力，能根据客户需求进行相应的数据分析并完成数据分析报告，并对相关结果进行解读和汇报；
4、有很好的沟通技巧，较强的团队协作精神，工作认真踏实，能承受一定的工作压力；
5、对新知识的探索精神，不断研究并分享新的业务、技术知识。"
"职位描述：
        
        岗位职责：
1、负责配合销售推动大数据商业应用在水务、水利、政府、运营商等行业的落地；
2、负责项目前期的客户技术交流，提供初步建议方案，直至提供详细定制化的解决方案，展示大数据的商业价值；
3、负责编写大数据项目的投标方案和讲标资料，参加招投标会，负责讲标和答疑工作，参加合同谈判，为合同签订提供技术上的保障，最终达成本岗支持统计销售额的任务指标；
4、研究行业、市场、用户需求、潜在竞争对手在大数据方面的前沿信息，为公司的大数据产品提供指导；
5、配合其他部门完成产品规划建议、市场宣传、培训、设备选型等工作。?

任职要求：
1、3-5年工作经验，具备大数据产品设计、开发、售前支持的从业经验，数学、统计学、数据挖掘等相关专业优先；
2、技术专业知识全面；良好的方案策划和提案能力；熟悉项目招投标的流程及工作内容；
3、具备一定的数据分析能力，能根据客户需求进行相应的数据分析并完成数据分析报告，并对相关结果进行解读和汇报；
4、有很好的沟通技巧，较强的团队协作精神，工作认真踏实，能承受一定的工作压力；
5、对新知识的探索精神，不断研究并分享新的业务、技术知识。"
"职位描述：
        
        岗位职责
1. 参与公司大数据计算工作系统的设计及开发
2. 完成业务核心代码和测试代码编写，配合项目经理完成产品的交付
3. 参与优化大数据服务器集群系统的架构和优化
4. 定期的code review，保证代码质量
5. 调研新技术并应用于产品开发中

应聘要求
1. 熟练使用一门以上的编程语言，比如Java, Scala, Python, Go等。
2. 熟练使用SQL和数据库，如：MySQL，PostgreSQL等，会进行数据库性能优化
3. 熟悉编写MapReduce的程序，和Hadoop生态系统的工具，比如Hive, Hbase, Spark等
4. 熟练设计和优化各种数据模型。
5. 熟悉任务调度框架，如：azkaban、oozie、airflow, 等，并编写过较复杂的ETL工作流程。
6. 有Linux系统操作经验，能够在Ubuntu, CentOS等系统下进行工作
7. 具备优秀的编程能力及良好的编程习惯
8. 对技术有激情，喜欢钻研，能够快速接受和掌握新技术，有良好的团队合作精神、能够承受较大的工作压力
9. 有2到5年的相关项目工作经验。"
"职位描述：
        
        岗位职责：1、负责产品数据库研发，参与系统整体架构设计；2、负责数据库部分的需求分析、建表，索引，以及运维管理。任职资格：1、计算机相关专业大专以上学历，三年以上mysql开发运维经验；2、3年以上mysql数据库DBA全面运维工作经验,熟悉POSTGRESQL数据库管理；3、熟练使用互联网企业主流和常用的开源系统，熟悉数据缓存产品日常运维和架构设计；4、有阿里云RDS,DRDS MYSQL优化、管理经验者优先；5、开发经验丰富，能迅速完成交办相关工作，能协助实施解决项目中遇到的数据库问题，包含数据库优化；6、需具备需求分析和系统设计能力；7、沟通能力良好，具备团队合作精神，能适应一定压力开展工作。"
"职位描述：
        
        岗位职责：
1.?依据业务模型，负责大数据计算平台的架构设计，以及核心功能的开发，满足实时、离线计算的需求；?
2.?负责产品实时计算平台的设计和开发，为实时监控、实时运营数据分析、个性化推荐提供数据支持。
?
任职要求：?
1.?本科以上学历，扎实的计算机专业基础，有3年以上大数据平台开发经验，1年以上的大数据计算/存储设计经验；?
2.?精通一种或几种以下语言，Python/Java/Scala；?
3.?熟练掌握Hadoop、Spark、Storm、HBase的原理特性以及适用场景，精通Spark实时计算开发，并具备大规模数据集的实际开发经验；?
4.?有大规模数据计算平台的架构设计经验，且精通大规模数据集的存储方案设计优先；
5.?具备用户问题的定位及解决能力，善于归纳总结，对数据敏感；?
6.?思维活跃、敢于担当、乐于沟通，具有良好的团队合作精神，积极主动，能承受一定的工作压力。"
"职位描述：
        
        职位描述：1、负责离线/实时大数据存储/计算平台的搭建，架构设计与主要代码开发2、通过设计运用合适的技术方案来支撑各种业务场景3、根据需求使用Spark Streaming、Spark SQL和Presto进行数据处理、查询、统计工作任职要求:1、统招本科以上学历，3年以上数据仓库领域相关经验，对数据仓库系统架构具有良好的认知，了解数据仓库相关技术，如ETL、报表，具备数据分析技术2、了解主流的大数据生态系统组件，如Hadoop, Hive, Spark, Flink, Presto, Superset等3、熟悉Spark Streaming和Spark SQL，RDD，DataFrame编程，有良好的java基础4、熟练使用SQL，较强的编码/调试诊断能力，扎实的数据结构和算法功底"
"职位描述：
        
        岗位职责：
1、负责承接运营部门的数据报表需求进?数据的收集、整理、清洗、编制、验证及输
出。
2、协助运营及产品部门完成报表界?设计，并固化常态需求设计多维数据模型展??案
3、负责完成报表层数据表结构设计、并独?完成报表开发及测试?
4、负责OSS业务数据后台 (包含数据仓库、数据集市、报表平台)等项?的ETL开发、
数据模型设计及对应应?层的开发。
5、确认运营数据的正确性，监控业务数据异常，并作出预警。
6、负责协同进?Web产品后台的部分产品项?开发?作。

任职资格：
1、本科及以上学历，计算机、应用数学、统计及相关专业；
2、具备数据采集、清洗整理、分析建模等能力；
3、了解数据处理和数据可视化；
4、了解SQL语言，会使用至少一种主流数据库，至少一种ETL工具，至少一种分析和建模工具，至少一种数据可视化工具和方法；
5、有业务流程设计或互联网产品规划设计经验为佳
6、良好的沟通交流能力，较好的逻辑分析能力，善于理解和分析业务，对数据敏感。

岗位要求
1. ?学本科及以上学历?计算机类相关专业.
2. 掌握python编程语?。
3. 熟练使?mysql数据库。
4. 熟悉Linux环境，掌握常?操作命令。
5. 熟悉http?络协议。
6. 熟悉web后台开发相关技术，例如flask、django等，对web前端技术有所了解。
7. 熟练掌握常?的数据结构和算法。
8. 学习能?强，有良好的编程习惯，规范，有逻辑性

公司福利:
1、团建与旅游：每年一次事业部级户外拓展；每月一次部门团建活动；突出贡献的同事可获得国外旅游机会。
2、补贴与报销：购买手机、电脑、参加培训等工作相关物品可享受一定比例的补贴。
3、下午茶与营养晚餐：每周均有下午茶，还有营养加班晚餐。
4、弹性工作时间（不打卡）：以工作结果为导向，灵活安排自己的上下班时间。
5、节日福利：传统节日公司均会提供节日礼品。
6、结婚礼金:如果你还单身，恭喜你，当你结婚时可享受公司提供的结婚礼金。
7、带薪年假：转正后可获得长达12天的年假。
8、调薪与年终奖：根据个人的绩效和贡献，业绩优秀者可享受每年4月和11月会有两次调薪机会；年底提供丰厚年终奖，根据自己的贡献给予相应的回报。
9、定期分享启发成长:公司一月组织两次分享会，鼓励成员间相互交流学习，分享成功经验，启发共同进步。公司还会邀请行业大咖来做分享，既包括心理学、领导力、项目管理等个人成长相关知识，还涵盖了AI、区块链、大数据等技术分享。
10、健身器材供应：公司设有健身区，工作之余可以舒展筋骨，放松身心。

我们崇尚:
Simple? ?Passion? ?Adventure
简单可信赖 热情愿拼搏 突破爱探索
我们的使命
Inspiring Growth
如果您具备我们的任职条件，想拥有一份事业，也跟我们一样崇尚 SPA,那就快来加入我们吧！"
"职位描述：
        
        岗位职责：
??1、参与公司大数据平台架构、技术发展战略规划及产品体系规划；
??2、参与公司大数据平台的核心代码开发，技术路线研究工作；
??3、负责公司核心集群搭建，保证其高可用和稳定性
??4、跟进了解开源社区Hadoop的功能，及时了解新的技术架构和功能特性，有针对性地应用于公司大数据业务。
岗位要求：
??1、正规院校计算机、数学相关专业本科及以上学历；
??2、5年及以上大数据平台、分布式应用开发经验；
??3、精通Java/Scala，具备Hadoop/Hbase/Flink/Hive/Zookeeper/Spark/Kafka等集群搭建、优化经验；
4、具备MR、hive UDF、实时计算等实际开发经验；
??5、具备搜索引擎、电子商务平台、云计算平台、个性化推荐引擎开发经验者优先；
??6、强烈的主动性与工作责任心，对所负责工作有owner意识，并能自我驱动不断成长。"
"职位描述：
        
        【岗位职责】
1、负责建设乐信大数据平台；
2、负责基于大数据技术的海量数据的自动化分析处理和统计工作；

【任职条件】
1、计算机/应用数学/软件工程等相关专业本科及以上学历，5年及以上大数据相关工作经验，具备大数据处理平台架构设计经验，熟悉数据仓库的设计理念；
2、熟悉大数据处理相关产品架构和技术（如Hadoop/Hive/HBase/Spark/Kafka/Storm/Flume等），对内部实现机制深入了解，对其中的部分组件进行代码进行过深入研究；
3、熟悉各种互联网常用开源软件（如Zookeeper/Redis等），有知名互联网/软件/通信厂商大型项目经验者优先；
4、熟练使用java、scala，熟悉linux平台及shell脚本开发
5、具有良好的沟通能力、组织能力及团队协作精神，有较强的分析和解决问题的能力；"
"职位描述：
        
        岗位职责
1、深入理解会员及乐卡产品、模式及流程，负责数据的提取、BI设计和展示，以及数据运营分析平台的需求分析、设计和基础数据开发；
2、负责挖掘用户需求及产品关注重点，优化完善数据工具，建立数据模型，为产品规划和运营提供决策依据及策略指导，驱动业务更优发展；
3、关注大数据应用相关方向的前沿发展，结合产品特点，设计个性化、可视化的数据产品和平台。

任职要求
1、计算机或统计学相关专业本科及以上学历；
2、3年及以上BI、数据仓库、大数据开发经验；
3、精通SQL；对Hadoop/Hive,Hbase,Spark,Storm一种或者几种有一定的理解，可在这些框架上进行数据处理工作；
4、良好的沟通能力，良好的团队合作意识及抗压能力；责任心强，有强烈的主人翁意识积极推进相关工作的进展；对海量数据建模工作充满热爱和激情；
5、有SparkR或Python开发经验者优先。"
"职位描述：
        
        【职位描述】： * 负责大数据中间件产品研发； * 负责大数据分析平台软件的研究和开发； * 负责数据仓库产品的研究和开发。 【任职资格】： * 计算机科学、应用数学、统计学、经济学、物理学、天文学、商业分析、信息系统、数据科学或相关专业本科或以上学历；（应届毕业生或工作时间小于2年） * 优秀的学习能力与发现、分析并解决问题的能力； * 良好的团队合作精神与沟通能力。 【技能要求】： * 具备良好的学习能力、逻辑思维能力、口头表达能力和交付文档能力； * JAVA基础杂实，有相关开发或者实习经验，熟悉IO、多线程、MQ、数据结构与设计模式等； * 精通Hadoop/Hive/Hbase，对Hadoop、Hive、Storm、Spark等源码有研究者优先； * 有分布式监控、搜索、调度、部暑其中一项经验优先； * 熟悉分布式、缓存、消息机制，常用的DAL/ORM框架和设计模式；"
"职位描述：
        
        岗位职责:
1、参与快递大数据的开发，实现数据驱动业务，降低营运成本，提升公司效率；
2、根据业务需求进行数据模型的调研、设计、开发及验证工作，并持续进行模型的优化；
3、负责数据模型架构的构建，建立数据抽取、清洗、校验等数据加工流程规范及OLAP多维数据分析模型；
4、持续对系统的技术架构进行改进和优化，提升海量数据的查询性能和用户体验。

岗位要求：
1、本科及以上学历，计算机、数据挖掘等相关专业，3年以上工作经验；
2、熟悉Java开发，有脚本语言（shell,python)开发经验者优先；
3、至少熟悉一种大数据处理技术，如Hadoop、Spark；
4、掌握HBase、Redis、Elastic Search等开源大数据存储技术，并能结合不同的业务场景深入使用；
5、对解决具有挑战性的问题充满激情，具有良好的分析问题和解决问题的能力，能够医治各种系统的疑难杂症。"
"职位描述：
        
        岗位职责:
1、参与快递大数据平台的研发和设计；
2、负责研发和改进大数据组件，提升系统性能；
3、持续对系统的技术架构进行改进和优化，提升海量数据的查询性能和用户体验。
?
岗位要求：
1、本科及以上学历，计算机、数据挖掘等相关专业，3年以上工作经验；
2、熟悉Java开发，有脚本语言（shell,python)开发经验者优先；
3、至少熟悉一种大数据处理技术，如Hadoop、Spark；
4、掌握HBase、Redis、Elastic Search等开源大数据存储技术，并能结合不同的业务场景深入使用；
5、对解决具有挑战性的问题充满激情，具有良好的分析问题和解决问题的能力，能够医治各种系统的疑难杂症。"
"职位描述：
        
        岗位职责:
1、参与快递大数据平台的研发和设计；
2、负责研发和改进大数据组件，提升系统性能；
3、持续对系统的技术架构进行改进和优化，提升海量数据的查询性能和用户体验。
?
岗位要求：
1、本科及以上学历，计算机、数据挖掘等相关专业，3年以上工作经验；
2、熟悉Java开发，有脚本语言（shell,python)开发经验者优先；
3、至少熟悉一种大数据处理技术，如Hadoop、Spark；
4、掌握HBase、Redis、Elastic Search等开源大数据存储技术，并能结合不同的业务场景深入使用；
5、对解决具有挑战性的问题充满激情，具有良好的分析问题和解决问题的能力，能够医治各种系统的疑难杂症。"
"职位描述：
        
        岗位职责：
1、参与快递大数据的开发，实现数据驱动业务，降低营运成本，提升公司效率；
2、根据业务需求进行数据模型的调研、设计、开发及验证工作，并持续进行模型的优化；
3、负责数据模型架构的构建，建立数据抽取、清洗、校验等数据加工流程规范及OLAP多维数据分析模型；
4、持续对系统的技术架构进行改进和优化，提升海量数据的查询性能和用户体验。
?
岗位要求：
1、本科及以上学历，计算机相关专业，深入理解数据建模及业务抽象；
2、熟悉数据管理标准、元数据管理、数据质量管理；
3、1年以上的基于Hadoop架构DW/BI项目实施和开发经验；熟悉Hadoop Hive, Spark sql等；
4、熟悉Oracle、Greenplum、TeraData等主流数据仓库的技术细节；
5、能熟练进行SQL查询优化、有海量数据处理经验；熟练使用Unix/Linux操作系统，熟悉常用的Shell/Python/Perl工具。
6、良好的沟通能力和团队精神，具备创新意识。"
"职位描述：
        
        职位描述：
1.负责设计和搭建部门各数据平台的建设和维护；
2.负责不同数据管道的搭建，三方渠道数据接入、三方平台数据获取；
3.负责部门数据仓库和内部数据产品的架构设计、应用开发、优化完善；
4.负责数据仓库ETL流程的优化及解决ETL相关技术问题；
5.负责数据可视化、数据展现工具、创新数据业务等技术的研发；

职位要求：
1.具备良好的编程能力和代码风格，熟练掌握Java/Python/shell语言其中的一种，熟练使用SQL，并具有一定优化能力；
2.熟悉Mysql数据库，有sql调优经验；
3.有ETL经验，熟悉sqoop/kettle/informatica/spark sql等工具；
4.有数据统计系统或熟悉BI 数据仓库原理和实施,有BI系统开发经验者优先；
5.有三方数据接入、三方平台数据获取经验者优先；
6.有对互联网金融行业业务数据进行分析，挖掘用户行为特征，构建用户精准营销的指标体系，辅助运营决策、产品改进经验者优。"
"职位描述：
        
        职位描述：
1、 负责数据现状调研，了解客户需求、识别数据管理问题，盘点数据资产，并完成相关调研工作；
2、 负责数据需求与问题的深化分析，包括业务流程、业务规则、数据流程等；
3、 配合销售完成客户交流，提供售前技术支持，并完成方案制作。
4、完成公司安排的其他事项。
?
任职资格：
1、 专科及以上学历，信息化及计算机相关专业，性别不限；
2、 熟练掌握SQL查询操作，具备Linux系统基础；
3、 善于学习，具备良好的执行力、沟通能力及表达能力，有一定方案写作能力。"
"职位描述：
        
        工作职责：???
1.参与大数据平台的构建维护，持续对系统的技术架构进行改进和优化????
2.参与数据仓库建设，根据务设计多维模型、实现ETL。?????
3.支持业务实时审批和实时监控等实时计算?

任职要求：?
1、计算机及相关专业本科以上学历，3年以上大数据相关工作经验；?
2.?对基于Hadoop的大数据体系有深入认识，具备良好的数据采集、处理、分析能力，熟悉hive,spark，kudu等技能；?
3、熟悉scala或java语言编程；???
4.?优秀的逻辑思维能力，具备专研精神，学习能力强；"
"职位描述：
        
        岗位职责：??
1、 根据业务需求，负责计算机视觉、图像处理等相关算法的研发和优化；??
2、负责研究现有算法和跟进前沿技术。??
任职要求：??
1、计算机、数学或者统计学相关专业，机器学习、计算机视觉、图像处理等相关方向，本科及以上学历，两年以上算法研究经验优先；??
2、熟练掌握C/Java/Python等至少一种编程语言，具备较强的编程实现能力；??
3、熟悉使用Caffe/TensorFlow/MXNet/(Py)Torch等一种或几种主流深度学习框架；??
4、学习能力强，热爱机器学习并能长期从事相关工作。
5、有团队合作精神、创新精神和良好的沟通能力。"
"职位描述：
        
        1、 负责公司大数据平台数据处理工具ETL、流处理平台等建设，功能规划，平台演进，维护调优等；2、 结合公司业务特征，负责公司数据仓库规划、数据仓库建设、数仓管理等；3、 负责大数据处理技术研究及新技术引进，参与超大规模实时/离线数据计算框架，存储、查询、可视化解决方案的设计，研发；4、 负责公司业务数据仓库模型建设及全业务数据域打通；5、 负责BI报表和可视化项目，和客户深度沟通，理解客户的业务挑战，提供解决方案，制定开发计划并执行，支持各单位日常数据需求和任务；


任职资格
1、 熟练掌握关系型数据库,例如：Oracle、Mysql、Vertica等；熟悉NoSql数据库，例如HBase、Redis、MongodDB等；具备丰富的数据库管理和运维调优经验；2、 熟悉数据仓库领域知识和技能者优先，包括但不局限于：元数据管理、数据开发测试工具与方法、数据质量、主数据管理，数据打通等；3、 有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验着优先，如Hdfs、Mapreduce、Hive、Hbase、Spark、Storm；4、 精通数据预处理、检验、清洗、分析方法，精通各种常用统计检验方法；熟练掌握一门或多门编程语言，并有大型项目建设经验者优先，如Java、Python、Shell和scala等；5、精通Linux，熟悉日常运维、搭建常见服务器、定位解决日常问题的能力，具备ETL开发经验优先；6、 良好的语言沟通与表达能力，有丰富的数据开发经验，较强的数据、平台、技术理解能力；7、 具备数学类、计算机类等相关专业统招本科及以上学历，具有3年及以上大数据开发工作经验，有互联网行业背景优先。"
"职位描述：
        
        任职要求：

1、具有计算机领域硕士学位，工作经验不限；

2、具有hadoop，hbase，mppdb等大数据实际项目经验，对源码有深入研究；

3、熟悉linux集群和有分布式数据库/存储；理解hadoop，Hdfs，mapreduce原理，熟悉分布式计算模型或有高效索引技术经验；

4、以下任一经验者优先：（1）具有PB级海量数据存储经验者；（2）在数据处理，数据挖掘，数据分析等方面有丰富经验者；（3）具有食品安全追溯系统开发经验者；

5、对研究技术有浓厚兴趣，善于总结沉淀，乐于与他人分享。

6、具备独立撰写高水平研究报告的能力，能够主导国家省市等项目申报工作。"
"职位描述：
        
        任职要求：

1、具有计算机领域硕士学位，工作经验不限；

2、具有hadoop，hbase，mppdb等大数据实际项目经验，对源码有深入研究；

3、熟悉linux集群和有分布式数据库/存储；理解hadoop，Hdfs，mapreduce原理，熟悉分布式计算模型或有高效索引技术经验；

4、以下任一经验者优先：（1）具有PB级海量数据存储经验者；（2）在数据处理，数据挖掘，数据分析等方面有丰富经验者；（3）具有食品安全追溯系统开发经验者；

5、对研究技术有浓厚兴趣，善于总结沉淀，乐于与他人分享。

6、具备独立撰写高水平研究报告的能力，能够主导国家省市等项目申报工作。"
"职位描述：
        
        岗位职责：
1.? 负责单位的大数据采集、数据服务平台、业务分析系统的开发相关工作；设计与开发分布式存储、数据处理与分析框架；
2.?配合产品经理进行大数据项目和产品的组织实施和项目管理，对项目和产品进行架构设计；
3.?负责大数据相关项目和产品的计划定制并带领团队实施；
4.?负责大数据平台新组件的研究、探索与应用；
负责大数据技术开发团队的管理，并进行相关技术培训。

任职要求：
1.?计算机、信息、通讯相关专业本科以上学历，5年以上工作经验；
2.?熟悉大数据生态相关技术、包括但不限于YARN、HDFS、IMPALA、HBASE等生态技术和框架，具有2年以上相关经验；
3.?熟练掌握Kafka、Spark Streaming等实时处理技术和框架的开发；
4.?熟练使用Shell、Python等脚本语言；
5.?熟练使用SQL语言编写数据库脚本；
6.?具有较强的责任心、执行力，有良好的沟通技巧和团队合作精神；
7.?有强烈的责任意识，有良好的计划能力，并具有结果导向思维，能够承受较大的工作压力；
8、熟悉主流数据挖掘算法开发实施经验者优先；
9、有安全、政府、军民融合、科技情报、环保、交通与物流、金融、创新平台、教育等行业的项目管理与实施经验。"
"职位描述：
        
        工作职责：1、根据业务需要，负责大数据业务系统平台的整体评估、设计，完成数据采集、清洗、整合、存储及大数据平台数据分析、用户行为分析等工作，降低数据的使用门槛；2、负责数据平台的存储架构及关键模块的开发、搭建、运维；3、构建扩展的大数据环境任务编排与调度系统，负责数据平台数据分析及框架开发进行数据挖掘；4、设计实现可靠的高性能类SQL大数据查询引擎，提供ETL，分析及数据洞察的服务能。5、进行开发规范制定，数据平台各项指标体系建立，数据质量保障，以实现数据的最大价值；6、从数据价值的角度规划中长期数据产品的规划和设计；7、负责组建和管理大数据团队，并带领团队实现大数据平台的高效搭建和运行。?任职资格：1、本科以上学历，计算机、软件工程等相关专业，计算机基础扎实，熟练数据结构和算法；2年以上大数据系统开发及应用经验。2、具有大数据平台搭建经验，深入理解hadoop、HBase、spark、Hive、storm、kafka、Redis等技术原理，有丰富的的调优、稳定性、高可靠性实战经验；3、精通一种或多种编程语言(Java、C++、Python)。4、熟悉Linux系统原理、熟练运用Linux命令与脚本；5、熟悉关系型数据库原理及SQL语言。熟悉Oracle，MySQL，Postgresql为佳；6、具备软件产品架构设计经验，能够根据具体需求进行可行性研究、技术选型、系统架构设计、系统功能设计等；7、良好的沟通与协调能力，较强的职业精神，能有效组织协调团队完成各类开发工作；"
"职位描述：
        
        1.熟悉Linux操作系统和Shell编程语言；2.大数据处理经验丰富，熟悉hadoop map/reduce编程；有Hbase、Spark、Storm的应用开发经验；3.熟悉其它分布式存储相关技术，包括HDFS，Hive、Redis、mongodb、 Flume、Kafaka、Sqoop、Zookeeper、ElasticSearch等。ps：1. 具有海量数据调优、数据倾斜调优经验者优先考虑；2. 有大数据平台开发经验者优先考虑；3. 具有SQL优化经验优先考虑；4. 熟悉REDIS使用的优先考虑。"
"职位描述：
        
        岗位职责：
1.???负责基于Hadoop技术生态设计开发大数据产品，
2.???解决团队在大数据开发及管理中遇到的技术问题
?
岗位要求：
1.???熟悉Hbase及phoenix应用，并有相关项目研发经历
2.???熟悉hadoop生态圈产品，能够使用Mapreduce技术实现分布式应用，
3.???精通Hadoop，对分布式计算原理有较深的理解，熟悉Mapreduce编程 ,了解Hadoop集群管理及优化
4.???精通Java编程，熟悉Linux系统，并能够完成linux上代码开发与调优
?
加分项：
1.???看过Hbase源码者优先
2.???有Hbase性能调优经验者优先
3.???有过Hadoop、Hbase、kafka、MongoDB及Spark使用经验者
4.???熟练使用Mesos及Yarn等资源管理框架
5.???阅读或者修改过任何一个hadoop生态圈中的开源系统
6.???具备Geoserver开发经验，熟悉ArcGIS，以及地信行业开源软件者"
"职位描述：
        
        岗位职责：
1. 参与机器学习平台研发，设计机器学习算法组件；
2. 优化迭代平台算法，完善行业案例、算子应用场景；
3. 持续提升机器学习算法可用性和易用性，降低使用门槛。
任职要求：
1. 计算机相关专业，本科及以上学历；
2. 3年以上的分布式系统、大数据系统相关工作经验；
3. 熟悉Hadoop/Spark生态的体系架构，有相关研发经验；
4. 熟悉常用的机器学习算法，熟练掌握Scala, Java，Python中至少一门编程语言；
5. 良好的沟通和团队协作能力。
【加分项】：
1. 对机器学习算法有较深的了解；
2. 熟悉常见分布式机器学习框架（mlllib、tensorflow、mxnet等等）的底层设计；
3. 有基于分布式计算框架开发经验和大规模数据处理经验；
4. 全面了解机器学习应用于实际问题的完整流程，有相关实际项目经验。"
"职位描述：
        
        岗位职责：
1、基于海量数据，利用数据挖掘、机器学习、AI等技术，进行大数据场景下的数据统计、数据挖掘、机器学习、深度学习，包括数据整理、模型建立、模型应用、评估优化等
2、负责分析挖掘客户/行业对大数据产品的需求，建立和优化数据分析流程，利用大数据分析结论帮助客户/行业解决实际问题。例如：文本挖掘、用户画像、个性化推荐、风险预测等
3、提供数据应用创新思路，将客户需求准确转化为可执行的数学模型，编写数据挖掘算法并对其进行优化

任职要求：
1、本科及以上学历，数学、统计学、运筹学、计算机或相关专业；两年以上相关工作经验
2、具有相关数据分析、数据挖掘项目经验
3、能够使用机器学习算法解决常见的业务问题
4、掌握数据采集、数据清洗、数据监测等数据分析操作流程
5、精通Java/Python/Matlab/R语言一种或多种
6、熟悉大数据开发者优先"
"职位描述：
        
        1、计算机、软件相关专业本科以上学历；
2、熟悉主流大数据技术、掌握Kafka、ElasticSearch、HBase等大数据系统原理；
3、熟悉Java系统开发和性能调优，熟练掌握相关开发技术；
4、熟悉Shell或Python开发的优先"
"职位描述：
        
        岗位职责：?
1. 负责公司大数据平台的架构设计、研发和调优工作，持续提升平台系统的可用性、可靠性、可维护性和可扩展性；
2. 负责企业级数据应用的设计研发与维护，将基础策略算法、数据挖掘分析能力落地实践。

岗位要求：?
1. 本科及以上学历，计算机相关专业；
2.?3年以上的海量数据处理工作经验，对主流大数据技术和框架（如Hadoop、Spark、Flink、Flume等）有深入了解；
3. 熟悉分布式存储相关技术，不限于HDFS、Hive、Redis、Mongodb、ElasticSearch、Kafka、Sqoop等；
4. 熟悉Linux操作系统，掌握Java、Scala、Python等至少一种开发语言，了解分布式应用设计；
5. 了解常用的分类、回归、聚类等算法及应用场景；
6. 对主流的研发流程、质量控制方式、项目管理方式有充分的了解；
7. 具备自主的学习能力和追求卓越的态度，具有良好的团队协作精神。"
"职位描述：
        
        1、本科及以上学历，4年以上工作经验，2年以上大数据架构经验
2、熟悉整个大数据技术体系
3、具备大型分布式系统总体设计能力
4、悉hadoop、Hive、Hbase、Storm、Spark、sqoop、Flume等分布式文件、分布式计算、流数据处理等多种技术
5、具有数据安全、网络安全经验优先"
"职位描述：
        
        岗位职责：
1. 参与公司气象环保大数据平台构建。
2. 完成大数据平台数据处理及平台服务等开发工作。
3. 结合公司实际，让大数据技术服务于公司的业务发展。
4. 优秀的团队意识和沟通能力，有强烈的学习欲望和快速学习的能力，乐于接受挑战。
?
任职要求：
1. 本科及以上学历，3年以上的研发经验，从事过大型系统的架构、研发工作。
2. 对大数据生态圈有深入的了解，具备Hadoop、Hive、Hbase、Pig、Storm、Spark、phoinex等项目的开发经验。
3. 熟悉关系型数据库（Oracle、MSSQL、MYSQL等）及一种NoSQL（mongodb、redis、hbase 等），需要有实际开发经验。
4. 精通JAVA编程语言，了解java GC机制，可以对hdfs、hbase、spark进行框架调优、了解传统关系数据库的原理,有open TSDB实践者优先。
5. 了解数据挖掘和机器学习算法，包括聚类、分类、回归等。有相关实际经验。"
"职位描述：
        
        岗位职责：
1、负责公司大数据平台架构的整体规划和设计；根据业务需求建立数据仓库
2、负责通用数据平台开发，大数据环境下的数据分析、统计建模等工作
3、将技术实现及业务场景联系起来，根据业务需求快速提出技术解决方案
4、制定数据处理整个流水线的相关规范；调研、分析新技术，促进平台进化
5、分析和解决具体的在使用平台的过程中出现的疑难问题
任职要求：1、计算机相关专业，统招一本及以上学历，2年以上数据开发经验；2、有Python方面的工作经验，熟练掌握Numpy、Pandas等科学计算库；3、了解Flask，Tornado等Web框架, 并至少熟练掌握其一；4、熟悉MySQL、Redis、Cassandra、Kafka、RabbitMQ、Jupyter Notebook等数据库和工具；5、有数据仓库或数据挖掘项目实际经验者优先；6、良好的团队合作和沟通协调能力，优秀的问题分析和解决能力，对挑战性问题充满激情，工作主动性强。"
"职位描述：
        
        1、计算机相关专业硕士及以上学历，有较好的理论基础和快速学习能力。
2、熟悉Linux操作系统使用，掌握至少一门开发语言，如C++、Java、Python。
3、熟悉RNN、CNN等深度学习算法及其常用开发框架如TensorFlow, caffe之一者优先。"
"职位描述：
        
        1、计算机相关专业硕士及以上学历，有较好的理论基础和快速学习能力。
2、熟悉Linux操作系统使用，掌握至少一门开发语言，如C++、Java、Python。
3、熟悉RNN、CNN等深度学习算法及其常用开发框架如TensorFlow, caffe之一者优先。"
"职位描述：
        
        1、计算机相关专业硕士及以上学历，有较好的理论基础和快速学习能力。
2、熟悉Linux操作系统使用，掌握至少一门开发语言，如C++、Java、Python。
3、熟悉RNN、CNN等深度学习算法及其常用开发框架如TensorFlow, caffe之一者优先。"
"职位描述：
        
        主要职责：
1、? 医疗健康大数据平台技术开发和维护；
2、? 大数据存储与计算任务的管理维护和开发；
3、? 大数据相关框架/工具/中间件的设计和开发。
4、 为大数据架构提供完整的技术解决方案
?
任职要求：
1、? 3年以上 Hadoop/Hive/Hbase/Spark/Mesos/Kafka 等大数据技术栈相关经验；
2、? 具有扎实的 Java/Scala等开发语言功底，可以开发高效可靠的代码，能阅读Java、Scala、Python源码，快速定位问题并解决问题
3、 深入理解 Mapreduce及Spark 原理，阅读过Hadoop/Spark源码，精通Spark
4、 ?熟悉 MySQL/Oracle/DB2/PostgreSQL/Greenplum之一，有PB级数据处理经验者优先；
5、? 熟悉 ETL 相关工作流程和方法；
6、 有良好的系统性能优化及故障排除能力；
7、? 良好的信息安全意识，熟悉常见的数据脱敏方法，有实际项目经验者优先；
8、 具有一定数据分析和机器学习项目经验者优先；
9、 有参与过医院His、Lis、Cis、EMR、PACS等系统建设或数据治理者优先
10、 良好的团队合作能力、分析和解决问题的能力、积极进取，责任心强；"
"职位描述：
        
        工作职责：
1、承担金融工程研究，主要包括组合的绩效、风险分析、资产配置，不同资产的风险与估值定价方面；
2、上述模型的开发、测试、维护工作；
3、承担数据中心ETL、数据库模型设计/开发、数据质量保障工作。
?
任职资格：?
1、学历水平：国内外知名院校的金融、统计、工程、计算机、数理及其他自然科学学科硕士或以上学历；
2、工作经验：具有境内外主要金融机构（券商、对冲基金、基金、第三方等）从事金融工程、风险管理、金融科技软件开发等其中一方面或多方面的工作者优先考虑，一年到三年相关研究工作经验；
3、所需技能：
1）具有清晰的逻辑推理能力、扎实的数学建模和数理统计能力；对大规模金融数据处理和分析和挖掘能力；有大数据处理经验者优先；
2）优异的编程能力（Matlab、R、Python等）；精通Oracle等数据库管理系统的操作使用及管理；
3）良好的沟通能力；优秀的团队合作精神；具有强烈的责任心以及优秀的职业精神和职业道德。"
"职位描述：
        
        岗位职责：
1、负责无人驾驶数据建模以及数据服务化的设计开发；
2、负责数据仓库ETL流程的优化及解决ETL相关技术问题；
3、支撑团队基于数据的提取、分析和应用等需求和场景。
?
任职要求
1、?计算机相关专业本科及以上学历，良好的语言沟通与表达能力和自我驱动动力；
2、 精通Linux，熟练掌握Docker容器技术的原理，部署和使用优化；
3、能够独立或带队进行项目开发，熟悉编程语言，如Java、Python、Scala等；
4、三年及以上ETL和数据pipeline开发经验，理解数据治理的重要性；
5、丰富的大数据系统使用和开发经验，包括但不限于Hadoop/Spark/Hive/HBase等；
6、有较强的逻辑思维能力，善于分析、归纳、解决问题；
7、有相关分布式系统架构和P2P网络系统开发经验者优先；
8、了解主流NoSQL数据库的原理与使用，尤其是KV型数据库，包括不限于RocksDB；
9、精通各种数据结构和算法，熟悉分布式、多线程及高性能的设计、编码及性能调优；"
"职位描述：
        
        岗位职责：
1. 负责大数据分析需求设计和开发，承担数据抽取、清洗、实时统计及离线数据处理等程序开发；
2. 开发数据统计系统，完成项目数据统计与分析任务，为业务运营提供数据支持服务；
3. 根据项目需求预研并引入新的大数据分析技术
岗位要求：
1. 计算机及相关专业，1年以上工作经验；
2. 扎实的java基础，1年以上大数据开发经验，对分布式存储和计算原理有较深的理解；
3. 熟练使用spark streaming、 Hbase、kafka、elasticsearch、redis等相关工具；
4.具有1年以上的基于spark streaming/flink/storm等实时数据统计分析开发经验；
5. 熟悉Linux/Unix操作系统，熟练使用scala语言；
6. 热爱开发，有较强的学习能力和快速解决问题的能力，具备较强的责任心和良好的沟通能力。"
"职位描述：
        
        岗位职责：
1、负责公司Hadoop相关产品的架构设计和系统调优；
2、完善和优化现有实时流计算系统和存储系统，编写核心开发框架；
3、善于发现系统的性能瓶颈、设计缺陷，提出改进方案并实施；
?任职资格：
1、计算机科学或相关技术学科的学士、硕士学位（或同等学历）；
2、Java或python相关开发经验2年以上，熟悉并理解缓存、消息、RPC调用框架、序列化等原理，熟悉http等相关通信协议；
3、精通分布式数据处理底层技术，包括但不限于：hadoop/elasticsearch/hive/spark/hbase/kafka/flume等，用过mysql，redis，hbase等开源存储；
4、具有强烈的责任心，良好的沟通、学习能力，良好的团队合作意识，勇于接受技术挑战；
5、有车联网行业经验优先。"
"职位描述：
        
        岗位职责：
1、负责大数据集群的日常维护、监控、异常处理等工作，保障集群稳定运行；
2、负责大数据自动化运维以及数据化运营平台开发工作；
3、负责大数据集群的用户管理、权限管理、资源管理、性能优化等；
4、深入理解数据平台架构，发现并解决重大故障及性能瓶颈，打造一流的数据平台；
5、跟进大数据前沿技术，不断优化数据集群；
岗位要求：
1、2 年以上大数据运维经验；
2、有良好的计算机和网络基础，熟悉linux文件系统、内核、性能调优，TCP/IP、HTTP等协议；
3、熟悉大数据生态，有相关（HDFS、Hive、Hbase、Sqoop、Spark、Flume、Zookeeper、ES、Kafka）的运维及开发经验；
4、熟练使用shell、python等脚本语言开发相关运维管理工具；
5、良好的文档撰写习惯。"
"职位描述：
        
        岗位要求：
1、计算机或相关专业本科及以上学历，对数据处理、数据建模、数据分析等有深刻的认识和实战经验；
2、熟悉Linux系统，具备shell、Python等脚本开发能力；
3、熟练掌握Hadoop、Hbase、Hive、Storm、Spark Streaming、flink等大数据开发工具中的一种或几种；
4、具备良好的工作习惯和团队协作精神。"
"职位描述：
        
        工作职责:
1、负责江苏联通微信大数据平台架构的设计与实施。
2、参与建设、维护、优化基于实时技术的数据平台，参与数据、工具平台相关的功能接口、数据接口开发，完成业务功能。
3、参与用户画像、个性化推荐系统等数据产品的开发工作。
4、通过大数据平台和工具，支撑海量数据分析、数据挖掘、机器学习工作，提升江苏联通微信营销效果"
"职位描述：
        
        岗位要求：
1、计算机技术、计算机应用、通信、电子信息、自动化等相关专业本科及以上学历2、具备良好的逻辑思维能力，较强的沟通和文字表达能力；?3、熟悉SQL语言，熟悉常用算法和数据结构；?4、熟练使用C 、Java、C#、Scala中至少一种编程语言，熟悉面向对象设计模式；熟练使用Python、R中任意一种脚本语言；?5、熟悉分布式系统原理，熟悉Hadoop、Spark、Impala、Hive等大数据平台开源软件；?6、有较强的学习和动手能力，工作踏实有责任心，有较强团队协作能力。?
?注：1.具有数据库管理、数据建模、数据开发和分析挖掘经验者优先考虑；"
"职位描述：
        
        职责描述：大数据PaaS产品设计与研发；包括但不限于实时流计算服务、批处理服务、数据湖分析、ElasticSearch、MapReduce服务等产品的架构与研发；任职要求：1. 全日制本科及以上学历，计算机相关专业，3年以上的大数据相关系统研发经验，扎实的Java语言基础和Linux编程基础；?2. 对大数据相关组件：HDFS、YARN、Spark、Hbase、Storm、Flink、Hive、ElasticSearch、Presto等2至3种组件的架构与底层实现有深入理解，具备相应的定制和研发能力；3. 熟悉微服务架构的系统开发，熟悉SpringBoot、MyBatis等常见项目开发技术栈；?4. 具备较强学习能力及一定的英文文档阅读能力；5. 有开源社区参与经验者优先；6. 熟悉AWS、阿里、华为、腾讯等主流公有云平台中的一到两种，有公有云平台/产品的实际经验者优先；?7. 有大规模Hadoop集群运维、性能调优、高可用部署优化经验者优先；8. 工作有计划性，责任心和执行能力强，具备高度的责任心、诚信的工作作风、优秀沟通能力及团队精神。"
"职位描述：
        
        岗位职责：
1.降低数据使用成本，让数据赋能业务走的更快
2.体现数据驱动运营的价值。
工作内容：
1.包括不限于参与设计与开发与用户深度运营平台，商家数据营销系统，广告投放推广数据系统。
2.基本的数据处理工作包括不限于日志，业务数据与展会图像视频。
3.基于现有数据应用平台的需求开发维护工作。
4.参与推进数据应用工具的场景落地。
基本要求：
?1.精通Java程序开发，熟悉Linux开发环境；
2.熟悉kafka/nifi/spark等分布式数据处理技术，熟悉其运行机制和体系结构;
3.熟悉mysql，hive,elasticsearch，hbase，redis等存储引擎的数据存储及使用方法;
4.有一定的前端如react,angularjs,extjs 开发经验更佳；
5.对数据有一定的敏感性，有良好的沟通表达能力和跨团队协调能力；
6.计算机或相关专业本科以上学历（3年以上工作经验）。"
"职位描述：
        
        工作内容：
1.数据仓库的ETL设计、开发、维护或项目管理；
2.和BI团队及需求部门进行有效沟通，跟进及问题解决；
3.负责数据管理工作，如研发规范、质量规范、保障规范的制定与推动实施落地；
4.用户与商家画像的基础数据清洗工作和基础标签提取。
基本要求：
1.2年以上ETL项目开发和实施工作经验，掌握数据仓库相关知识、ETL数据流程设计；
2.熟悉Hadoop、Hive、HBase、Spark等开源框架,熟悉UDF，使用过Nifi更佳；
3.熟悉主流关系数据库,熟练SQL开发，熟悉Linux， Shell，Java或者Python编程；
4.熟悉数据仓库领域数据模型设计方法，并有相关设计经验；
5.较好的沟通理解能力，性格乐观，态度踏实，积极上进。"
"职位描述：
        
        岗位职责:1、?负责部门数据自动化报表系统的开发（其中涉及到数据爬虫、ETL、报表展示，等）；2、?承担部门大数据平台的技术选型、架构设计（含数据设计）和开发的工作，能够从零搭建大数据平台；3、?负责数据埋点（含APP、Web、H5端）和数据平台的测试，能够进行埋点代码的检查，独立设计和执行测试用例，编写测试报告，并进行缺陷跟踪和推进bug修改，等；4、?制定部门数据质量控制体系，对部门各项数据进行检验，为部门的数据准确性负责。如果数据出现异常，及时与相关部门沟通解决；5、?负责大数据平台自动化测试脚本的开发、调试、执行，负责相关测试工具的开发，提高数据测试的效率；6、?负责数据处理、报表制作，建设报表体系，能够编写脚本实现报表的自动化生成；7、?承担其他数据工作（如数据采集、数据处理、指标梳理、数据提取、文档编写，等）；8、?完成领导交办的其他工作。
任职资格:1、?本科及以上学历，5年以上大数据研发经验，能够独立搭建大数据平台；2、?有良好的程序开发基础，熟练使用Java、python等编程语言，熟悉主流大数据工具/平台（如Hadoop/Hive/HBase/Spark，等），有大数据实际项目开发经验，有BI平台研发经验者优先；3、?熟悉Linux、UNIX系统，至少掌握ORACLE、MYSQL、DB2、Greenplum主流数据库中的一种，熟悉SQL以及SHELL脚本开发； 4、?掌握web前端html、js、css与web服务器nginx、tomcat等相关技术，对ios、Android的开发实现技术有缺陷分析和捕获能力，了解ECharts者优先；5、?能看懂IOS和安卓代码，进行埋点代码检查；6、?能够建立部门数据质量保障体系，并对部门数据（数据平台）进行测试，保障部门数据的准确性；7、?对自动化测试有一定的了解，能够搭建大数据自动化测试平台者优先；8、?具有一定的数据分析的能力，能够制作数据分析报告和数据报表；9、?细心、耐心、有很强的责任感，对产出的质量有高要求，执行力强，富有团队精神。加分项：有开源大数据BI工具（例如：superset、kettle、kylin等）的二次开发经验优先。备注：此岗位为外包，非中投证券劳动合同制员工，需和外包公司签约后派遣至中投证券工作。"
"职位描述：
        
        岗位职责:1、负责大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；2、负责数据仓库、ETL搭建优化工作；3、深入理解大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；4、开发大数据自动化运维、监控、故障处理工具，监控所有基础设施组件、应用程序，提供紧急应急措施。 任职资格:1、计算机专业，本科及以上学历，2-3年以上数据仓库开发经验；2、熟悉Hadoop、HBase、Kafka、Hive、Spark等组件的工作原理，开发及维护过相关服务；3、精通python，熟悉脚本语言(shell，perl等），有开发经验者优先；4、主动性强，具有良好的沟通、协调和组织能力，富有团队精神。"
"职位描述：
        
        工作职责：
1..参与大规模数据系统的架构设计和开发，主要面向信贷业务方向；
2. 负责数据的分布式实现，满足可扩展性等业务指标
3. 协助大数据经理进行数据字典维护、数据开发知识资产的维护，同步变更开发，进行项目质量的保证。

任职要求：
1. 有ETL设计和开发经验，熟悉SSIS、Kettle、Informatica、DataStage(其中任意一项即可)等ETL开发工具研发工具。
2. 掌握 python编程语言
3. 熟悉My SQL、Oracle、SQL Server等数据库之一，熟悉SQL语言；
3. 对大数据理论、数据仓库理论、行业应用有一定的认识与研究，熟悉大数据相关技术；
4. 理解Hadoop各组件的原理和实现，具备很强的故障排查能力，有很好的技术敏感度和风险识别能力；
5.有阿里云大数据平台开发经验的优先
6.有金融背景或者小额贷款开发经验的优先"
"职位描述：
        
        工作职责：
1、参与抽数跑批任务平台日常监控维护。2、运用BI工具为各业务系统提供数据及报表分析支持；3、负责数据库及ETL开发，研究跟进BI开发技术；4、参与大数据平台的数据仓库模型的需求分析、建模；

任职资格：1、本科以上学历，软件工程、计算机相关专业；2、有Hadoop大数据平台BI工作经验者优先，了解Hive、Impala等大数据工具；3、4年以上ETL、BI相关工作经验，有较好的SQL性能调优经验；有完整数据仓库项目经验优先，有数据集市ETL架构设计经验优先；有大数据分析、BI系统研发、机器学习经验优先；4、熟悉Postgresql、GP、Mysql等主流结构化数据库。5、熟悉ETL数据流设计；掌握至少一种BI报表工具，如Smart BI、Cognos、Tableau等；6、具备良好的沟通能力和团队合作能力，能承受巨大工作压力，富有进取心。
职位诱惑：薪资高，市场领先的全面薪酬 ；假期长，(福利年假、全薪病假、生日假……）； 培训多，全员覆盖、定制化课程、外聘讲师；?福利全，五险一金、补充商业险、餐补、团建费 ； 空间大，发展通道多，管理岗公开竞聘 。"
"职位描述：
        
        岗位职责：
1、负责大数据平台的数据采集，数据应用的设计、开发、测试和上线；
2、负责大数据平台系统的部署、维护和性能优化；
3、参与大数据平台规划、制定和完善开发规范、标准和流程；
4、参与大数据平台新技术预研。
任职要求：
1、本科或以上学历，3年以上工作经验，有基于大数据数据仓库的数据需求分析、设计、开发和优化经验；
2、精通SQL或HQL，精通至少一种数据仓库系统，如GREENPLUM/POSTGRESQL/TERADATA/ORACLE/DB2等。
3、熟悉linux操作系统，熟悉SHELL/PYTHON/PERL至少一种脚本语言，且有JAVA开发能力优先；
4、熟悉HIVE及HQL，了解MR/TEZ/SPARK原理，且有优化及定制开发能力优先；
5、熟悉kafka以及至少一种实时流处理框架如sparkStreaming、flink、storm等，有实时流处理项目经验优先；
6、具备良好的沟通交流能力和文字语言表达能力，较好的逻辑分析能力。"
"职位描述：
        
        【岗位职责】
1、协助开展业务需求收集、整理、汇总；
2、协助完成数据分析类需求的可视化实现，通过报表、图表、仪表盘等实现；
3、协助开展需求的评估、设计、开发、测试、上线、业务推广；
4、制定和完善相关需求开发规范、制度、流程；
5、形成条线清晰的项目产品开发模式和经验，并在内部推广与分享；
6、协助团队解决系统出现的性能或关键问题；
7、协助进行开发团队建设、人才培养、指导团队成员工作；
8、协助制定技术发展的方向，持续对大数据前沿技术进行前瞻性研究, 并负责适时引入。
【任职要求】
1、计算机相关专业，全日制大学本科及以上学历，三年或三年以上开发经验；
2、熟悉掌握BIEE、BO、Cognos、QlikView等商业智能分析工具中的一种或多种；
3、精通ECharts、Tableau、SmartBI、永洪BI等可视化工具的一种或多种；
4、熟悉kylin等大数据分析引擎中的一种或多种；
5、追求代码的合理性、优雅性，欢迎有代码洁癖者加入我们；
6、善于学习和运用新知识，对新技术、新领域具有浓厚兴趣；
7、自信、诚恳、乐观向上、主动性强、积极性高，响应快、执行力高、心思缜密，富有团队精神、责任心、使命感与创新意识，具备良好的沟通协调和书面表达汇报的能力；
8、性格开朗，能持续承受较大工作压力和工作强度，愿意挑战自我潜能，有优秀的敬业精神。

【优先考虑】
1、有金融行业经验优先，有互联网行业经验优先；
2、掌握与熟悉Java开发者优先；
3、熟悉SQL开发者优先；
4、熟悉hadoop/hbase/hive者优先；
5、精通shell/perl/python/R等语言中至少一门以上者优先；
6、有参与海量数据实时查询/计算系统设计开发经验者优先。"
"职位描述：
        
        岗位描述：
1、? 理解大数据产品的业务，并通过业务识别需求，参与系统规划、架构设计和开发等工作，推动大数据平台产品最终落地。
2、? 开发和维护数据平台的系统和框架，发现和解决存在的技术问题，保证系统的性能和稳定性。
3、? 代码编写、文档撰写、code review和单元测试，确保项目的进度和质量，并指导和培训新员工。
岗位要求：
1、? 计算机相关软件专业，本科及以上学历，5年及以上相关行业工作经验，2年以上大数据相关开发经验；
2、? 精通Java或者C++等面向对象语言，熟悉Linux、Spring、MySQL，常见NoSQL系统以及分布式架构等；
3、? 深刻理解大数据处理(流计算、分布式计算、分布式文件系统、分布式存储等)相关技术,有大数据平台开发经验者优先；
4、? 具备系统性能调优、可靠性优化等技能，对疑难问题具有较强的系统化分析能力；
5、? 能根据自己对业务的理解，具备前瞻性的架构规划和并提出可落地的实施方案；
6、? 具有大数据行业经验者优先，具有开源项目经验者优先。"
"职位描述：
        
        工作内容：
1. 参与集团数据管理系统项目（ODS+DW），分析与沟通项目需求，协调项目各方人员，协助推动各项工作按时有效推进；
2. 参与集团数据报送与数据网关项目，沟通业务需求，对接试点子公司相关人员，协调咨询公司与子公司具体推进工作；
3. 参与集团数据治理系统，推动数据治理系统与各应用系统集成对接，参与各系统数据标准化推进与数据质量控制；
4. 参与集团财务BI系统等分析应用开发，分析与沟通业务需求，参与系统核心模块开发工作，灵活响应业务需求。
任职要求：
1.曾负责并参与过大型数据类项目管理与开发工作，例如集团类数据仓库、大数据平台、经营分析平台等，熟练使用数据分析工具，具备Oracle、MySQL、GreenPlum或者Hadoop等数据库/大数据平台（至少两种以上）开发经验；
2.了解数据管理与数据治理领域工作内容，具有数据标准和数据质量管理经验为佳；?
3.具有较强的业务分析能力，表达清晰，具备较强的沟通协调能力；
4.具有较强的项目与团队管理经验，工作责任心强、严谨敬业，具有较强的团队协作管理能力；?
5.至少5年相关工作经验，有大型金融机构从业经验者优先 。"
"职位描述：
        
        
工作职责/任职要求：?
1、【必要】2年以上大数据开发和治理经验，能将大数据平台整合到现有业务；熟悉hadoop/spark及衍生大数据技术或中间件的建设和实施;
2、【必要】熟悉大数据etl流程，熟悉主流的数据仓库建模，熟悉olap/cube流程及分析工具
3、【必要】3年以上java开发经验，对模块化、服务化、高并发、多线程并发编程有一定经验；
4、【可选】能快速分析和解决问题者优先
5、【可选】有实际特征工程实施、机器学习模型训练经验优先；
6 、【可选】担任过技术组长或leader优先
7 、【可选】有过招投标技术方案编写者将优先考虑
8、 【可选】最好当前处于离职状态，无不良价值观，沟通顺畅，具有较强的团队合作精神，对研发有浓厚兴趣者优先。"
"职位描述：
        
        
职位描述：
负责大数据处理、挖掘、数据系统建设和开发。
负责大数据仓库的模型开发、维护和优化。
任职要求：
4年以上大数据处理、数据挖掘等领域开发经验，计算机相关专业本科及以上学历；
掌握数据仓库实施方法论、深入了解数据仓库体系；
掌握数据仓库的设计理论，了解数仓分层结构和维度建模。
掌握大数据相关技术，具备Hadoop、HBase、Hive、Spark、ES等主流组件开发经验。
熟练掌握hive-sql，impala，spark-sql，以及性能调优。
熟练使用Linux系统，有java、python、shell、等编程经验。
海量数据处理有经验者优先。"""
"职位描述：
        
        工作职责：1、参与公司大数据基础平台的规划、设计与实施，提供大数据存储，计算，调度等服务；2、负责维护并保障hadoop集群稳定；3、关注开源社区，结合业务，寻找最佳解决方案。任职资格:1、4年以上Hadoop生态相关研发和优化经验（Hadoop/MapReduce/Hive/HBase/Spark等）；2、熟悉Hadoop/Spark生态环境体系的搭建和管理，有大平台架构开发经验，具有实际集群搭建和调优经验；3、 熟悉分布式系统、分布式计算系统的工作机制，熟悉Hadoop生态圈相关核心技术的工作机理；4、精通Java,了解多线程，socket开发，熟悉Spring框架；5、思路敏捷清晰，良好的表达和理解能力，良好的学习能力。"
"职位描述：
        
        研究并开发基于Hadoop, hive, hbase, spark的海量（百TB级）数据处理分析程序，使用java，python等开发数据服务接口等

任职要求：?
1、 掌握java开发，面向对象的设计方法，语言、框架不限，对jvm 内存管理熟悉最佳
2、 掌握 hadoop/hive/spark/hbase, 如果对于相关开源框架有所研究最佳?
3、 熟悉mysql数据库，并具有一定的SQL功底；?
4、 熟悉python，scala等语言更佳。
5、 对数据建模、存取、处理、可视化等相关技术有很强的学习热情"
"职位描述：
        
        职位描述：
1、负责大数据平台的开发建设，建立数据生态服务，解决海量数据面临的挑战；
2、协助管理、优化并维护Hadoop、Spark等集群，保证集群规模持续、稳定；
3、负责HDFS/hive/HBase的功能、性能和扩展，解决并实现业务需求；
4、负责大数据产品的自动化、问题诊断、全链路跟踪、数据安全等平台的设计和开发
?
职位要求：
1、至少熟悉或者擅长一门程序设计，java/python/go/c++/scala熟悉一门语言即可，有高效、高可靠代码开发经验
2、熟悉Linux操作系统?
3、热爱开源技术，熟悉一种或者多种大数据生态技术（Flume，Kafka、Hive、Hbase、Spark、Storm、Hadoop、Flink等），熟悉源码者优先
4、熟悉OLAP引擎者的设计和开发者优先?
5、有TeamShip意识，具备良好的沟通以及协调能力，能单打独斗也能擅长团队作战。"
"职位描述：
        
        职位描述：
1.负责B2D各产品数据相关的开发工作；
2.根据产品需求，设计开发数据处理程序(MR / Spark)；实时数据处理程序 (SparkStreaming)；
3.数据接口服务开发。
职位要求：
1.计算机相关专业本科及以上学历，2年及以上大数据开发相关工作经验；
2.熟悉linux系统，熟练掌握JAVA语言；
3.熟悉Mysql，具备一定的SQL功底；
4.熟悉Hadoop生态，熟悉HDFS/Hbase/Hive，熟练掌握MapReduce,Spark程序开发；
5.熟悉HBase、Codis、Kafka原理，并至少在一个实际项目中使用；
6.熟悉SparkStreaming，有实际项目经验；
7.有较好的沟通交流能力，较强的抗压能力，对自己的输出负责。"
"职位描述：
        
        1、理解数据的产品应用场景逻辑，通过统计方法和通用分布式框架工具语言如hadoop，不断加强数据服务质量；
?
2、负责数据清洗、转换、建模等工作,对海量用户行为数据通过hadoop/spark等进行离线和实时处理；
?
3、参与用户画像、个性化推荐系统等数据产品的开发工作。
?
4、参与数据、工具平台相关的功能接口、数据接口开发，完成业务功能；
?
?
岗位要求：
?
1、精通java或scala语言，具有面向对象编程思想，对底层实现有一定研究；
?
2、精通spark?sql、spark?streaming等编程，具有实际大型分布式集群项目开发经验；
?
3、熟悉Linux操作系统，熟悉Linux?shell编程；
?
4、熟悉mysql，redis等常用数据库，jetty等中间件；
?
5、熟悉分布式存储或NoSQL数据库技术，如hbase等；
?
6、熟悉Hadoop生态环境，精通以下一种或多种大数据技术，如flume、Kafka、Hdfs、MR、elastic?search；
?
7、熟悉常用的数据挖掘算法优先。"
"职位描述：
        
        岗位职责：?
研究并开发基于Hadoop, hive, hbase, spark的海量（百TB级）数据处理分析程序，使用java，python等开发数据服务接口等

任职要求：?
1、 掌握java开发，面向对象的设计方法，语言、框架不限，对jvm 内存管理熟悉最佳
2、 掌握 hadoop/hive/spark/hbase, 如果对于相关开源框架有所研究最佳?
3、 熟悉mysql数据库，并具有一定的SQL功底；?
4、 熟悉python，scala等语言更佳。
5、 对数据建模、存取、处理、可视化等相关技术有很强的学习热情"
"职位描述：
        
        岗位职责：?
研究并开发基于Hadoop, hive, hbase, spark的海量（百TB级）数据处理分析程序，使用java，python等开发数据服务接口等

任职要求：?
1、 掌握java开发，面向对象的设计方法，语言、框架不限，对jvm 内存管理熟悉最佳
2、 掌握 hadoop/hive/spark/hbase, 如果对于相关开源框架有所研究最佳?
3、 熟悉mysql数据库，并具有一定的SQL功底；?
4、 熟悉python，scala等语言更佳。
5、 对数据建模、存取、处理、可视化等相关技术有很强的学习热情"
"职位描述：
        
        职位描述：
?
1、理解数据的产品应用场景逻辑，通过统计方法和通用分布式框架工具语言如hadoop，不断加强数据服务质量；
?
2、负责数据清洗、转换、建模等工作,对海量用户行为数据通过hadoop/spark等进行离线和实时处理；
?
3、参与用户画像、个性化推荐系统等数据产品的开发工作。
?
4、参与数据、工具平台相关的功能接口、数据接口开发，完成业务功能；
?
?
岗位要求：
?
1、精通java或scala语言，具有面向对象编程思想，对底层实现有一定研究；
?
2、精通spark?sql、spark?streaming等编程，具有实际大型分布式集群项目开发经验；
?
3、熟悉Linux操作系统，熟悉Linux?shell编程；
?
4、熟悉mysql，redis等常用数据库，jetty等中间件；
?
5、熟悉分布式存储或NoSQL数据库技术，如hbase等；
?
6、熟悉Hadoop生态环境，精通以下一种或多种大数据技术，如flume、Kafka、Hdfs、MR、elastic?search；
?
7、熟悉常用的数据挖掘算法优先。"
"职位描述：
        
        职位描述：
岗位职责：?
研究并开发基于Hadoop, hive, hbase, spark的海量（PB级）数据处理分析程序，使用java，python等开发高并发数据服务。

任职要求：?
1、 掌握java开发，面向对象的设计方法，语言、框架不限，对jvm 内存管理熟悉或者有服务器后端开发（springboot等）经验最佳
2、 掌握 hadoop/hive/spark/hbase, 如果对于相关开源框架有所研究最佳?
3、 熟悉mysql数据库，并具有一定的SQL功底；?
4、 熟悉python，scala等语言更佳。
5、 对数据建模、存取、处理、可视化等相关技术有很强的学习热情"
"职位描述：
        
        岗位职责：?
研究并开发基于Hadoop, hive, hbase, spark的海量（PB级）数据处理分析程序，使用java，python等开发高并发数据服务。

任职要求：?
1、 掌握java开发，面向对象的设计方法，语言、框架不限，对jvm 内存管理熟悉或者有服务器后端开发（springboot等）经验最佳
2、 掌握 hadoop/hive/spark/hbase, 如果对于相关开源框架有所研究最佳?
3、 熟悉mysql数据库，并具有一定的SQL功底；?
4、 熟悉python，scala等语言更佳。
5、 对数据建模、存取、处理、可视化等相关技术有很强的学习热情"
"职位描述：
        
        岗位职责
1.针对公司数据现状,发现数据治理问题,规划和建设数据治理平台,推动数据相关的制度建设,提升公司数据质量和数据治理水平。
2.负责数据治理类项目的开展实施,梳理数据资产和使用评估,提高业务系统的数据质量和集群数据资产利用率;
3.负责制定数据标准、数据管理体系和流程;
4.负责大数据的元数据、主数据、数据质量流程处理等工作;
5.优化,分析业务指标数据逻辑,定期分析项目进度,输出项目推动策略,对核心指标、异常数据进行监测分析,建立并完善数据监测体系;


任职要求：
1.计算机、统计学相关专业本科以上学历,具有大型互联网公司或咨询公司的数据治理相关工作经验者优先;
2.具有扎实的大数据和数据仓库的理论功底,了解数据治理方法论;
3.精通SQL,Python,JAVA,pyspark中至少一种,有相关数据开发和分析经验;
4.具备较高水平的解决方案编制、交流撰写能力;

5.有较强责任心和deadline意识,具备良好的跨团队的沟通能力和项目推进执行能力。"
"职位描述：
        
        职位描述：
1.负责B2D各产品数据相关的开发工作；
2.根据产品需求，设计开发数据处理程序(MR / Spark)；实时数据处理程序 ( SparkStreaming)；
3.数据接口服务开发。
?
任职条件：
1.计算机相关专业本科及以上学历，2年及以上大数据开发相关工作经验
2.熟悉linux系统，熟练掌握JAVA语言
3.熟悉Mysql，具备一定的SQL功底
4.熟悉Hadoop生态，熟悉HDFS/Hbase/Hive，熟练掌握MapReduce,Spark程序开发；
5.熟悉HBase、Codis、Kafka原理，并至少在一个实际项目中使用；
6.熟悉SparkStreaming，有实际项目经验；
7.有较好的沟通交流能力，较强的抗压能力，对自己的输出负责。"
"职位描述：
        
        岗位职责：
1、完成大数据平台和BI展示系统后台管理页面、前端页面的开发；?
2、按照设计要求完成基于hadoop平台的编码任务；
3、负责代码的优化，保证代码质量；?
4、大数据平台所有API系统的研发工作，包括：高并发查询/计算/鉴权/频度、安全防护系统；5、大数据平台系统的研发工作，包括：数据分布式查询/批量存储/高可用服务。
?
任职资格：
1、精通Java语音，具有Spring、Struts、hibernate/ibatis等常用框架开发经验；?
2、熟练使用HTML、JavaScript、CSS、AJAX，掌握面向对象编程；对web产品设计和用户体验有一定了解；?
3、有软件工程知识和质量意识；?
4、良好的团队合作精神和沟通能力，较强的责任心；?
5、三年以上Java开发经验，有hadoop平台使用经验者优先。
6、熟悉mysql、mongo等数据库，熟悉redis/memcache?；
7、熟练linux系统操作，熟悉shell编程。"
"职位描述：
        
        岗位职责：
1、完成大数据平台和BI展示系统后台管理页面、前端页面的开发；?
2、按照设计要求完成基于hadoop平台的编码任务；
3、负责代码的优化，保证代码质量；?
4、大数据平台所有API系统的研发工作，包括：高并发查询/计算/鉴权/频度、安全防护系统；5、大数据平台系统的研发工作，包括：数据分布式查询/批量存储/高可用服务。
?
任职资格：
1、精通Java语音，具有Spring、Struts、hibernate/ibatis等常用框架开发经验；?
2、熟练使用HTML、JavaScript、CSS、AJAX，掌握面向对象编程；对web产品设计和用户体验有一定了解；?
3、有软件工程知识和质量意识；?
4、良好的团队合作精神和沟通能力，较强的责任心；?
5、三年以上Java开发经验，有hadoop平台使用经验者优先。
6、熟悉mysql、mongo等数据库，熟悉redis/memcache?；
7、熟练linux系统操作，熟悉shell编程。"
"职位描述：
        
        hbase
1、使用大数据组件对海量数据进行开发与维护2、对大数据组件进行调优（hbase,hdfs,yarn,spark,jstorm,kafka,flume,azkaban,hive等）3、支撑各业务线数据需求以及实时离线计算需求，维护优化各个大数据组件平台稳定高效运行4、有一定的对大数据组件进行源码调整的能力
任职要求：1、具有三年及以上大数据开发维护经验，熟练使用hbase,hive,flume,spark,mr,storm,kafka中的一种以上大数据组件2、熟练掌握linux常规命令与工具3、对Hadoop、HBase等源码有研究优先4、熟悉java，有并发应用或者分布式应用软件开发经验优先5、熟练使用shell或python编程6、良好的系统分析、架构设计能力7、对数据敏感、对新技术敏感8、对工作踏实，负责，有一定的抗压能力，有一定的团队沟通能力，能吃苦耐劳
flume ? ? kafka ? ? hbase经验者"
"职位描述：
        
        工作职责：1. 参与/负责数据仓库ETL（数据抽取、加载、清洗、转换）处理任务的设计和开发工作2. 参与/负责数据报表的设计和开发工作3. 参与/支持相关BI业务分析的开发和实施工作注：精通shell，有hadoop大数据环境经验,有使用一些组件的经验sqoop datax hive spark azkaban等。岗位要求：1.掌握数据库基本知识,对数据库内部结构有较深理解和认识2.精通mysql数据库及mysql存储过程,具有数据模型设计的能力3.精通sql语句编写,具有1年以上基于数据库开发的经验4.具备数据挖掘,数据迁移,ETL处理,sql语句优化,海量数据处理的工作经验5.熟悉Linux操作系统常用命令6.工作严谨细致,有责任心,勤奋踏实,善于思考问题,具有团队合作精神，能承受一定的工作压力;7.精通hadoop及相关组件，如:sqoop datax hive spark azkaban。8.有良好的人际关系和沟通能力，有大型项目经验优先；"
"职位描述：
        
        岗位职责：

1、使用kettle工具进行数据ETL设计，开发，部署，运维；

2、负责ETL过程中文档的编写；

3、ETL过程性能优化；

4、分析源系统数据结构，制定ETL方案；


任职要求：

1、统招本科毕业；

2、精通kettle使用；

3、熟悉Oracle、db2、mysql其中之一；

4、熟练使用sql及存储过程，对数据库性能调优有一定了解；

5、良好的沟通、分析能力；

6、熟练使用Linux系统；

7、良好的团队协作精神，能够承受较大的工作压力；

8、责任心强，工作踏实细心；

9、能够接受长期出差；"
"职位描述：
        
        岗位职责：
1、参与互联网金融业务大数据产品规划,大数据处理分析平台的架构设计；
2、负责数据存储、清洗、分析程序的开发与平台搭建，数据可视化平台搭建；
3、数据分析与运营，驱动产品优化和精准化营销；
4、基于大数据进行数据分析与预测；
任职要求：
1、硕士及以上学历，3年以上工作经验；
2.?有过从?0?到?1?搭建数据平台的经验；
3.?离线计算领域hadoop相关开发经验，实时计算领域包括storm、spark、flink相关开发经验；
4.?熟悉数据处理相关技术，包括但不限于FLume、kafka、Redis、hive、ES等"
"职位描述：
        
        1、?工作职责:
1、负责公司数据仓库、数据集市的模型设计和搭建
2、负责各种网络数据的采集、清洗、整合工作
3、负责大数据的分布式存储、维护、管理和优化等工作
4、负责数据仓库技术架构的规划和设计，对数据质量、稳定性等做管理，让数据标准更规范、数据获取更高效；

2.任职要求:
1、本科以上学历，3年以上数据岗位的经验，对数据仓库、数据平台、数据分析等领域有深刻的理解，丰富的数据架构经验，精通数据建模及ETL设计开发；
2、扎实的数据结构和算法能力，精通关系型数据库（mysql，oracle，SqlServer）和非关系型数据库；
3、熟悉Hadoop、hive、HBase、Zookeeper?、Storm?、Spark等分布式框架，对hadoop源码有深入研究和工作经验者优先；
4、掌握JAVA、Python、GO语言优先，有爬虫经验优先；
5、具备较强的逻辑思维能力，能快速分析并解决出现的问题,具有较强的沟通能力；"
"职位描述：
        
        岗位职责：
1、负责Java核心代码开发，并亲自解决系统开发、运行中出现的重要、疑难技术问题；2、配合架构师负责软件复用设计（通用服务与组件），负责重要组件的设计和开发，并逐步建立组件库；3、指导系统设计师、软件工程师开展系统设计和开发工作，负责项目代码质量审核检查工作；4、负责交付的开发任务以及其他项目任务工作。
岗位要求：
1、本科以上学历，计算机相关专业，具备3年以上工作经验，有基于Web系统的分析、架构、设计、开发等实际工作经验；2、了解JavaEE、精通常用的设计模式，掌握面向服务（SOA）体系，掌握SSH，SpringMVC，SSI等主流开发框架；解Dubbo等开源技术框架，对hession、webservice等有较好理解；3、熟悉Mysql等关系数据库的使用，掌握并且能使用Memchache、OsCache一种缓存框架；4、有良好的代码风格和编程习惯，能从业务使用角度出发考虑系统设计，有关注细节的良好习惯；5、责任心强，良好的对外沟通和团队协作能力。 6、有业务数据建模，报表开发或者帆软报表开发经验。"
"职位描述：
        
        工作职责:1、负责大数据平台需求分析，设计、代码编写；2、负责对大数据hadoop集群进行维护及调优。
任职资格:1、本科以上学历，计算机相关专业，熟悉数据结构以及算法；2、3年以上开发经验，熟练掌握常用的软件架构模式，并能熟练使用基本的编程编译工具；3、熟悉大数据开发知识，具有大数据Hadoop项目开发经验；4、有完整的项目开发经验，具备系统核心模块开发经验；5、熟悉Linux操作系统，熟悉SHELL编程；6、熟练掌握Java、C++、python、C等主流开发语言的一种；7、熟悉mysql、PostgreSQL数据库，了解SQL优化；8、具有良好的沟通能力、团队精神，刻苦、敬业、有上进心，喜欢专研新技术。"
"职位描述：
        
        岗位描述：1、根据业务需求，进行相关数据统计。2、根据产品需求，进行数据库存储过程等脚本开发。3、监控数据处理定时任务，解决异常。应聘资格要求：1、本科及以上学历，计算机或相关专业。2、1年以上数据统计及相关工作经验。3、熟悉Linux操作系统级命令行操作。4、掌握Oracle或MySQL其中一种数据库。5、熟悉SQL语句的调优，存储过程的编写。6、能够熟练使用JAVA，Python或php其中一种开发语言优先。"
"职位描述：
        
        岗位职责：
1.? 参加团队会议与讨论，并给予有意义的建议；
2.? 协助后端团队和架构师完成数据库相关的设计与开发；
3.? 协助业务部门抓取、分析数据。

任职要求：
1.? 熟悉SQL、ETL、等等，能独立编写语句、交易、ETL任务；
2.? 对计算机算法有良好的理解与实践经历；
3.? 能够完成基本的数据处理与转换；
4.? 具有优秀的沟通能力，包括口头与书面的交流能力；
5.? 能同时进行并完成多个项目，有优秀的时间管理能力；"
"职位描述：
        
        岗位职责：
1.? 高校数据库的管理与维护；
2.? 高校数据的分析；
3.? 协助开发各类数据平台；
4.? 数据清洗与入库；
5.? 完成上级安排的其他工作。
岗位要求：
1. 全日制本科以上学历，计算机相关专业，1年以上相关工作经验；
2. 熟悉python，全面掌握python的基本语法，基本数据结构，常用library，熟悉numpy，pandas的基本用法和功能，了解Python自然语言处理；
3.熟练掌握MySQL；
4.有一定的数理统计基础，热爱和数据打交道；
5.认同创业文化，事业心强。"
"职位描述：
        
        大数据开发工程师
工作职责：
1. 基于海量用户行为数据，建立、评估、持续优化数据模型，包括但不限于：用户价值评分、用户风险评分、用户偏好预测 、用户画像构建等等，产出用户标签。
2. 负责标签体系规划和制定、标签的设计和开发、标签产品的构建。
3. 促进标签产品在公司各业务领域的应用，持续提升用户产品体验，并探索新的商业模式。
岗位要求：
1. 本科及以上学历，计算机或数学相关专业，工作3年以上（架构师6年以上）。
2. 精通hive sql,spark sql，spark上的JAVA开发。
3. 有2年以上用户画像构建和应用实战经验优先，有数据挖掘实践经验，擅长从海量数据中发现有价值的规律。
4. 思维清晰敏捷，逻辑分析能力强，具有良好的语言和书面表达能力。
5. 自我驱动能力强，踏实勤勉，对有挑战的问题充满激情。"
"职位描述：
        
        大数据开发工程师
工作职责：
1. 基于海量用户行为数据，建立、评估、持续优化数据模型，包括但不限于：用户价值评分、用户风险评分、用户偏好预测 、用户画像构建等等，产出用户标签。
2. 负责标签体系规划和制定、标签的设计和开发、标签产品的构建。
3. 促进标签产品在公司各业务领域的应用，持续提升用户产品体验，并探索新的商业模式。
岗位要求：
1. 本科及以上学历，计算机或数学相关专业，工作1年以上。
2. 精通hive sql,spark sql，spark上的JAVA开发。
3. 有数据挖掘实践经验优先，擅长从海量数据中发现有价值的规律。
4. 思维清晰敏捷，逻辑分析能力强，具有良好的语言和书面表达能力。
5. 自我驱动能力强，踏实勤勉，对有挑战的问题充满激情。"
"职位描述：
        
        工作职责：-负责Hadoop?ecosystem运维工作-参与高可用，持续交付系统的架构设计-参与或主导监控，容灾，快速响应方案的设计与实施-保障Zookeeper/Hdfs/MapReduce/Yarn/Hive/HBase/Spark/Presto/Impala等系统稳定性，并不断优化-深入了解Hadoop大数据平台架构，可基于业务实现定制化功能开发和Bug修复职位要求：-本科以上学历，8年以上数据行业工作经验，5年以上Hadoop相关工作经验-精通Hadoop?ecosystem相关系统，熟悉底层架构，实现原理-精通Java,5年以上开发经验-深入理解Unix/Linux系统,?精通一门以上脚本语言，Python/Shell(AWK)/Perl等-优秀的问题分析解决能力，严谨，踏实的工作态度，强烈的责任心和进取心态-优秀的学习，沟通能力和团队合作精神，强烈的主动Push意识"
"职位描述：
        
        职位描述:
能够运用自身经验知识解决疑难问题的能力具备数据产品等方面的知识和技能参与过2个以上中、大型数据研发项目，并担任过某一模块负责人，丰富的实操经验在既定工作目标下独立完成工作交付，对标准化工作非常熟练，能够协调资源解决较疑难的问题在项目中可以作为独立成员，能够培训和教导初级员工
必选项:
必须要有3年以上大数据相关工作经验,5年以上研发经验必须深入掌握Java/Scala等开发语言熟悉常见的大数据处理平台Hadoop/Spark和Hbase, HDFS分布式存储，熟悉Kafka消息队列和Redis缓存框架，了解Phoenix/Hive/SparkSql/Impala相关工具使用，且在项目中实际应用过
解决问题的能力、独立工作的能力、团队合作意识较强者优先掌握Storm/Spark Streaming/Flink中至少一种大数据实时计算框架必须知名公司背景,参与过2个以上中、大型数据研发项目，并担任过某一模块负责人，丰富的实操经验（有独立开发大数据模块的经验）"
"职位描述：
        
        1、在数据架构师指导下进行数据开发工作 2、参与公司级别用户画像或者Cube产品的开发 3、参与产品设计评审，从数据出发，对业务建模
任职要求：
1、5年及以上数据开发经验，精通SQL 2、有丰富的数据产品开发经验，参与过用户画像或者多维分析产品工作 3、熟悉hadoop,hive,spark使用及调优，有kylin使用经验者优先"
"职位描述：
        
        岗位职责：
1、大数据系统搭建，维护；
2、大数据平台设计和开发；
3、 根据运营需求统计相关数据；
4、 熟练地编写Shell脚本，使用脚本来完成日常系统运维工作，掌握一种以上的脚本语言；
5、根据项目的不同完成数据库容量规划，性能规划，数据库服务器选型，数据库引擎选择，数据库设计，数据字段的类型选择，SQL查询优化。
任职要求：
1、熟练使用Mysql，Redis/MongoDB，精通SQL及数据库性能调优；2、熟悉Linux系统，具备Shell/Python等脚本开发能力；3、熟悉数据仓库和数据建模的相关技术细节；4、熟悉Hadoop大数据处理系统的的开发、搭建、部署及维护；5、熟悉海量数据的处理、分析、统计、挖掘、数据可视化工作；6、对互联网产品有见解，关注前沿技术，有较强的学习能力、分析能力和动手能力；7、本科及以上学历，3年工作经验。"
"职位描述：
        
        
职位要求：
- 计算机或相关专业，本科及以上学历；
- 至少精通一门面向对象的编程语言，深入理解其思想
- 有良好的数据结构知识和算法基础
- 有强烈的求知欲，学习能力强
如果符合以下条件有加分：
- 有大数据处理项目经验的优先
- 熟悉Kafka，Hadoop，hbase等工具使用的优先"
"职位描述：
        
        - 岗位职责
1. 参与CBNData数据仓库架构设计与研发，针对CBNData所依托的阿里巴巴内外的大数据，利用ODPS（SQL）进行数据提取，清洗，挖掘与分析，实现高质量的数据互通和共享；
2. 参与CBNData数据产品与应用的数据研发，发掘数据商业价值，打造极致体验的数据产品；
3. 助力数据化研究和分析，构建丰富多样的商业BI应用。

- 岗位要求
1. 熟悉数据仓库模型设计与ETL开发经验 ，掌握Kimball的维度建模设计方法，具备海量数据加工处理（ETL）相关经验；
2. 掌握至少一种数据库开发技术：Oracle、Teradata、DB2、Mysql等，灵活运用SQL实现海量数据ETL加工处理；
3. 熟悉Linux系统常规shell处理命令，灵活运用shell做的文本处理和系统操作；
4. 有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验着优先，重点考察Hdfs、Mapreduce、Hive、Hbase；
5. 熟练掌握一门或多门编程语言，并有大型项目建设经验者优先；
6. 熟悉数据仓库领域知识和技能者优先，包括但不局限于：元数据管理、数据开发测试工具与方法、数据质量、主数据管理；
7. 全局意识，良好的逻辑思维、语言沟通与表达能力和自我驱动动力。"
"职位描述：
        
        职责:1、负责大数据平台规划，运维和优化工作；2、保证大数据平台各核心服务运行的稳定、高效；3、持续优化大数据平台，提升数据产品的质量和响应速度；4、基于大数据平台的数据处理与相关应用设计开发；5、研究大数据前沿技术，改进现有系统的服务和运维架构，提升系统可靠性和可运维性。
要求：1、计算机或相关专业本科以上学历；2、五年以上Java开发经验，三年以上大数据平台开发经验；3、熟悉 Hadoop生态圈，深入理解大数据平台框架； 4、使用并深入探究过以下流式数据组件: Flume, Kafka, SparkStreaming；5、使用并深入探究过以下数据批处理组件: Hive, HBase, Impala, SparkSql；6、熟悉Python、Shell等脚本语言，有爬虫开发经验者优先；7、热爱技术，工作责任心强，具备良好的团队合作精神，良好的沟通及协作能力。"
"职位描述：
        
        职责:1、负责大数据平台规划，运维和优化工作；2、保证大数据平台各核心服务运行的稳定、高效；3、持续优化大数据平台，提升数据产品的质量和响应速度；4、基于大数据平台的数据处理与相关应用设计开发；5、研究大数据前沿技术，改进现有系统的服务和运维架构，提升系统可靠性和可运维性。
要求：1、计算机或相关专业本科以上学历；2、五年以上Java开发经验，三年以上大数据平台开发经验；3、熟悉 Hadoop生态圈，深入理解大数据平台框架； 4、使用并深入探究过以下流式数据组件: Flume, Kafka, SparkStreaming；5、使用并深入探究过以下数据批处理组件: Hive, HBase, Impala, SparkSql；6、熟悉Python、Shell等脚本语言，有爬虫开发经验者优先；7、热爱技术，工作责任心强，具备良好的团队合作精神，良好的沟通及协作能力。"
"职位描述：
        
        1、负责海量科技数据及其挖掘结果的可视化呈现；
2、配合数据科学家、数据挖掘工程师，根据不同应用场景探索海量科技数据的产品应用；
3、实现特定应用场景下数据的可视化呈现；
?
任职要求
1、计算机专业本科及以上学历，视野开阔，对新技术充满热情；
2、精通各类前端技术，如HTML5、JavaScript、jQuery、Node.js等，了解前端安全架构者尚佳；
3、熟悉各类前端开发包、前端图形开发包，如Bootstrap、ECharts、D3.js等；
4、熟悉Hive/HBase/Neo4j者优先；
5、具有手机端Web开发经验者优先。"
"职位描述：
        
        1、负责海量科技数据及其挖掘结果的可视化呈现；
2、配合数据科学家、数据挖掘工程师，根据不同应用场景探索海量科技数据的产品应用；
3、实现特定应用场景下数据的可视化呈现；
?
任职要求
1、计算机专业本科及以上学历，视野开阔，对新技术充满热情；
2、精通各类前端技术，如HTML5、JavaScript、jQuery、Node.js等，了解前端安全架构者尚佳；
3、熟悉各类前端开发包、前端图形开发包，如Bootstrap、ECharts、D3.js等；
4、熟悉Hive/HBase/Neo4j者优先；
5、具有手机端Web开发经验者优先。"
"职位描述：
        
        岗位职责：
1、需求分析和产品功能设计；
2、负责核心技术问题的攻关，解决项目开发过程中的技术难题；
3、负责大数据分析系统相关具体设计、开发；
4、协助管理数据产品项目的开发进度和质量。

任职要求：
1. 3年以上数据平台搭建、数据开发/分析相关工作经验；
2. 精通Hadoop，HBase，Spark，Kafka，Hive或其他分布式数据计算存储技术中的至少一种；
3. 精通Java，Scala或者其他数据平台开发语言中的至少一种；
4. 精通数仓建模和ETL过程；
5. 实战专家，能够带领团队进行疑难问题攻坚；
6. 具有战略性思维，保证数据平台团队处于数据技术领域的前沿。"
"职位描述：
        
        工作职责：

1、基于Hadoop/Spark/Storm/Kafka/Elasticsearch等平台进行海量数据应用系统开发；2、负责大数据平台产品研发、维护和客户现场大数据处理技术。3、负责结构化和非结构化数据的解析和清洗,海量数据查询和报表展现；4、负责超大规模数据平台的搭建、维护和优化；5、负责大数据采集、存储框架研究，在线或离线数据存储模型设计；?6、负责大数据平台新技术的开发使用和性能优化，测试。


任职资格：

1、数据仓库建模方法、元数据管理、数据质量体系管理。2、5年以上数据仓库开发或者大数据方面工作经验,对数据较强敏感性。熟悉数据ETL相关工具及架构体系，会Kettle优先；?3、有3年以上BI方向经验。使用cognos、tableau经验的优先，有经分系统开发、设计经验优先。4、熟悉使用hadoop/hive/spark/Hbase等大数据开源框架使用经验；5、有过数据处理经验，能够高效完成数据处理和计算；"
"职位描述：
        
        工作职责：

1、负责数据分析相关系统的开发、测试、部署及上线工作，参与代码评审，确保开发质量2、参与业务部门临时数据分析需求，合作开展专项数据分析工作3、协助运营人员处理生产问题并提供技术支持，解答业务部门反馈的数据问题及各类咨询4、参与公司数据分析需求调研、评估、系统分析及架构设计工作

任职资格：

1、计算机、管理信息类、统计学、数学等相关专业本科及以上，两年以上金融行业数据平台建设及开发经验2、掌握大数据处理的基本技能，熟练掌握Oracle等数据库的使用、SQL及其调优，熟悉ETL开发、熟悉常见的BI工具，了解Hadoop、Hive、Sqoop相关组件的使用等3、具备良好数据分析、挖掘、建模能力，有基于SAS、Python、Spark等工具分析经验者优先考虑4、具有非常强的责任心，并具备较强的服务意识与沟通协调能力"
"职位描述：
        
        职位描述 ? ?
负责公司大数据平台、关系数据库，非结构化数据库管理和维护，负责数据管理和维护、备份、优化等工作 ? ?
任职要求（建议从经历、资历、能力等要求综合描述） ? ?
1、本科以上学历，计算机或相关专业； ? ?
2、具有一定的数据库维护经验，如mysql、oracle、mongodb，redis等，熟悉关系数据库，非关系数据库，实时数据库等，能用命令操作及查询;具备编程经验，熟悉sql、java、python； ? ?
3、有一定大数据运维经验，有hive或hbase经验;熟悉Linux系统，具备shell编程经验； ? ?
4、有团队合作精神，会使用svn、git等团队协作工具，工作认真、仔细，良好的沟通、组织、协调能力和时间管理能力； ? ?
5、有大数据相关工作经验者可适当放宽条件。"
"职位描述：
        
        岗位职责：
1、负责大数据处理平台的总体技术工作，包括需求分析、架构设计、研发、以及性能分析工作； ? ?
2、负责设计、构建和优化基于hadoop/Hbase/Hive的存储平台架构； ? ?
3、负责整体提升hadoop/Hbase/Storm/Spark集群的高可用性、高性能、高扩展特性； ? ?
4、根据业务需求，提出最优的技术解决方案；分解详细的开发任务，制定/编写开发计划、开发文档、开发流程图； ? ?
5、负责完成数据规则的定义、数据建模、数据清洗及转换、数据治理、数据集成等工作； ? ?
6、负责数据架构的规划，并制定实施标准和规范，确保得到有效的执行，同时保障数据以及文档的质量达到预定的标准。 ? ?

任职要求：
1、本科以上学历，计算机或相关专业； ? ?
2、5年以上软件开发经验，精通Java开发，3年以上Hadoop相关开发经验； ? ?
3、具备数据库系统基本理论知识，至少掌握一种主流商业数据库产品如Oralce的管理和应用，精通SQL语言，精通存储过程；? 
4、对hadoop的MapReduce原理有深入研究，有相关项目的实际开发经验； ? ?
5、熟悉Hadoop、Hive、impala和Hbase、storm等开源项目； ? ?
6、对基于hadoop的大数据处理体系有深入认识，具备相关产品（hadoop/storm ? /hive/hbase）项目应用研发经验，熟悉分布式系统、分布式计算系统的工作机制，能熟练掌握相关核心技术的工作机理；具有大规模数据平台，高并发大型系统，大数据等架构设计和开发经验； ? ?
7、具备数据管理和存储相关项目和系统的开发经验，具有丰富的数据分析、挖掘和数据仓库建模的项目实践经验； ? ?
8、具有良好的沟通、组织和领导能力，出色的分析问题和解决问题的能力，对解决具有挑战性问题充满激情，具备强烈的进取心和优秀团队合作精神。"
"职位描述：
        
        岗位职责
1.参与大数据平台设计、开发、优化数据接入、数据存储、数据计算服务框架；
2.参与大数据平台平台功能开发、建设，包括数据传输、调度、主数据，分析系统等；
3.助力数据化运营业务，构建丰富多样的大数据应用。
?
岗位要求
1.大学本科以上学历；
2.熟悉ETL开发，对Hive SQL、Presto SQL、Kylin、Druid等开发和原理性调优有实战经验，熟悉python、scala编程语言；
3.熟悉Hadoop生态，了解存储、计算框架的原理，熟悉Redis、HBase等NoSQL数据库；
4.熟悉Spark/Kafka/ElasticSearch，熟悉分布式计算系统的工作机制，具有分布式文件系统、分布式数据库系统、集群存储系统等经验优先。"
"职位描述：
        
        1.本科及以上学历，计算机相关专业，3年以上项目开发经验，有1~3年大数据或数据仓库项目经验。
2.具备良好的Java开发技能，对主流框架技术有深入了解，两年以上的Java开发经验。
3.熟悉Linux系统，能够在Linux环境中熟练地部署、配置和开发大型复杂的平台软件，有使用shell、perl、python脚本一种或多种处理问题的经验。熟悉版本控制工具Git的使用。
4.对大数据基础架构和平台有全面和深刻理解，至少熟悉下面的大数据技术和系统之一：HadoopEcosystem（如HDFS,Hbase,MapReduceYARN,Hive,Pig等）、Spark、Storm等等。
5.具有分布式系统或数据库系统的理论基础，具有分布式文件系统、分布式数据库系统、集群存储系统等架构设计经验。
6.熟悉分布式存储和非结构化数据相关NoSQL或NewSQL等数据库技术，例如Neo4J、Hbase、Redis、Cassandra,等等，拥有MemCache、Redis、EhCache等cache开发经验，理解其原理和工作模式者优先；
7、有OLAP开发经验者优先。
8.曾设计开发或运维过实际上线的大数据系统项目者优先。
9.熟悉软件开发流程和配置库的使用，拥有软件开发流程中的代码规范意识、配置管理规范意识、文档撰写规范意识。
10.具有很强的团队意识、沟通能力和独立解决问题的能力，学习能力和主动性强，具有钻研精神，充满激情，乐于接受挑战；"
"职位描述：
        
        1.丰富的Java研发经验，精通Java，熟悉Python中的一种- 熟悉Mysql，熟悉网络编程及并发技术，熟悉安全解决方案- 有丰富后端服务系统的设计和实现经验，有独立的系统级设计能力2.扎实的计算机基础，熟悉常用的数据结构和算法，熟悉Linux系统环境3. 熟悉大数据技术栈，对Hadoop、Hive、Spark、Hbase、Kafka、ELK等开源组件有使用及优化经验4.统招二本以上学历，计算机相关经验"
"职位描述：
        
        1，熟悉基于hadoop、Hbase、hive、spark技术栈进行离线数据分析或实时数据处理

2，熟悉基于Neo4j和Spark Graphx实现图计算、数据挖掘；
3，熟悉基于Docker和Kubernetes进行弹性计算应用服务开发；
4，熟悉基于SSM、Redis进行Java高并发、高可用服务开发；
5，至少有一个大数据平台CDH或者TDH的开发经验；
6，熟悉python语言，熟练使用pyspark，hive，scoop；有java经验优先；
7、学历本科及以上，工作年限3年以上。

工作地址：浦东唐镇卡园三路"
"职位描述：
        
        1，熟悉基于hadoop、Hbase、hive、spark技术栈进行离线数据分析或实时数据处理
2，熟悉基于Neo4j和Spark Graphx实现图计算、数据挖掘；
3，熟悉基于Docker和Kubernetes进行弹性计算应用服务开发；
4，熟悉基于SSM、Redis进行Java高并发、高可用服务开发；
5，至少有一个大数据平台CDH或者TDH的开发经验；
6，熟悉python语言，熟练使用pyspark，hive，scoop；有java经验优先；
7、学历本科及以上，工作年限3年以上。

工作地址：浦东唐镇卡园三路
此项目为保险公司项目外包岗，不能接受者勿投，谢谢！"
"职位描述：
        
        工作职责:1任职资格:任职要求：1.计算机或相关专业本科以上学历；2. 3年以上Hadoop大数据平台实际生产环境经验；熟悉Apache spark资源管理、调度和性能调优；熟悉Spark，Kafka，HDFS，Hive，Hbase，MapReduce，Yarn，Flume，Mesos，ZooKeeper中的2个以上组件；3. 理解Spark和Map Reduce的原理，能够根据日志分析程序运行出现错误的原因，并对程序运行的参数进行优化，给予业务开发人员建议和支持；4. 熟悉分布式系统、分布式计算系统的工作机制，熟悉 Hadoop生态圈相关核心技术的工作机理；有一定源码研究者优先；5. 熟悉Linux系统管理工作；熟悉Shell编程，能够编写脚本解决日常问题，包括自动化的工作流设计；6. 熟悉Scala或者Python编程者优先。"
"职位描述：
        
        工作职责:岗位职责：1.负责高并发，大存储和实时流的Hadoop/spark大数据平台规划，运维，监控和优化工作；2. 保证Hadoop/spark平台各核心服务运行的稳定、高效；3. 对Hadoop/spark平台运维不断优化，提升数据产品的质量和响应速度；4. 开发各种Hadoop大数据自动化运维与监控工具；5. 研究大数据前沿技术，改进现有系统的服务和运维架构，提升系统可靠性和可运维性。任职资格:任职要求：1.计算机或相关专业本科以上学历；2. 2年以上Hadoop大数据平台实际生产环境经验；熟悉Apache spark资源管理、调度和性能调优；熟悉Spark，Kafka，HDFS，Hive，Hbase，MapReduce，Yarn，Flume，Mesos，ZooKeeper中的2个以上组件；3. 理解Spark和MapReduce的原理，能够根据日志分析程序运行出现错误的原因，并对程序运行的参数进行优化，给予业务开发人员建议和支持；4. 熟悉分布式系统、分布式计算系统的工作机制，熟悉Hadoop生态圈相关核心技术的工作机理；有一定源码研究者优先；5. 熟悉Linux系统管理工作；熟悉Shell编程，能够编写脚本解决日常问题，包括自动化的工作流设计；6. 熟悉Scala或者Python编程者优先。"
"职位描述：
        
        1.?负责公司业务的售前售后支持，包括方案制作、现场设备安装调试和技术培训；2.?系统集成项目现场管理及实施；任职要求：1、具备2年以上数据库实施及运维管理经验；2、精通关系数据库原理，熟悉Oracle、mysql和SQLServer数据库的运行机制及体系构架；3.?熟悉Oracle、mysql和SQLServer数据库数据库系统的规划、安装、配置、监控、备份及性能调试；4、精通SQL脚本及数据库触发器、存储过程和自定义函数的编写，有丰富的数据库管理、运维调优经验；5、熟练使用数据库管理、分析、设计工具；6.?熟悉mpp库的安装、运维，hadoop安装、运维，elasticsearch的安装、运维；7.?熟悉Linux系统管理操作；"
"职位描述：
        
        工作职责：
1、完成软件系统代码的实现，编写代码注释和开发文档。
2、参与公司大数据产品规划,大数据处理分析平台的设计。
3、负责数据分析、加工、清理、处理程序的开发 ???????????????
4、负责数据相关平台的搭建、维护和优化。
5、根据设计文档或需求说明完成代码编写，调试，测试和维护。
6、协助测试工程师制定测试计划，定位发现的问题。 ?????
7、配合项目管理人员完成相关任务目标。
? ?
任职要求： ?????????????????
1、良好的java基础、熟悉大数据相关开源项目; ?????
2、海量用户行为数据的分析挖掘，负责过大数据业务的研发和优化工作; ????????????
3、熟练使用mapreduce、Spark、Flink等计算框架进行处理离线、实时数据; ????????????
4、熟练NOSQL数据库Mongodb、HBase、Redis等;
5、参与过用户画像,个性化推荐,有建模经验的优先考虑;
6、有良好的敬业精神和团队合作精神,具有技术领域的探索和钻研精神,对技术开发工作有浓厚的兴趣,愿意并努力接受技术挑战或技术创新。"
"职位描述：
        
        职位描述：
任职要求：
1、计算机、数学相关专业全日制本科以上学历；
2、至少5年以上的Java开发经验，3年以上大数据应用系统的开发和设计经验；
3、熟悉Hadoop生态圈技术体系，对离线计算、内存计算和流式计算均有深刻理解，如Hadoop、hive、Spark、flink、presto等，熟悉开源数据交换工具如sqoop，streamset，kettle等；
4、精通Hive、HBase仓库设计，深刻理解MR运行原理和机制，能进行任务执行效率的优化；
5、熟练掌握Linux Shell、Flume、Kafka、Redis等相关技术；
6、熟练掌握Elasticsearch、Lucene、Solr、Kylin、Phoenix、Alluxio中一种或多种；
7、逻辑思维能力强，做事有条理，具备较强的分析问题和解决问题的能力；
8、思维活跃，性格开朗，责任感强，工作积极主动，执行力强，有良好的团队协作意识。
岗位职责：
1、参与存储、计算、监控当中的一个或多个方向，打造稳定可靠的大数据平台；
2、负责基于大数据平台的应用设计、开发和维护，对现有系统优化，提高性能；
3、规划设计大数据产品，解决大数据研发中遇到的难点。积极主动，系统接收挑战，"
"职位描述：
        
        岗位职责：
1. 负责公司大数据平台的设计和开发制定数据架构规范，进行核心代码编写，指导团队落地；
2. 负责数据基础架构和数据处理体系的升级和优化，技术难题攻关，持续提升核心系统性能，保证系统的安全、稳定、高效运行
3. 研究数据模型和计算框架的创新与落地，包括：大规模数据实时化、大数据技术容器化、私有云实施方案、数据模型规范化等方面参与制定并实践团队的技术发展路线
4. 建立良好的公司内外的业界技术影响力；参与培养未来数据人才；有效辅导团队，提升数据研发能力

任职资格 ：
1. 本科以上学历，5年以上开发经验，其中3年以上大数据架构或相关工作经验
2、深刻了解Hadoop生态圈技术体系，对离线计算、内存计算和流式计算均有深刻理解，如Hadoop、hive、Spark、Flink、Kafka、presto等，有开源二次开发经验者优先，有过大规模交易实时计算经验者优先
3、精通实时数据仓库设计，深刻理解MR运行原理和机制，能进行任务执行效率的优化，熟悉开源数据交换工具如sqoop，streamset，kettle等；
4、熟悉elasticsearch、Lucene、Solr、Kylin、Phoenix、Alluxio等相关技术
5、 性格积极乐观，诚信，能自我驱动，有较强的语言表达能力；具备强烈的进取心、求知欲及团队合作精神；具有良好的沟通、团队协作、计划和创新的能力"
"职位描述：
        
        1、计算机相关专业，3-6年工作经验；2、具有数据仓库/数据集市项目经验；3、熟悉常见大数据基础组件的使用，如Hadoop/Hive/Hbase/Impala/Spark/Sqoop等4、较好的沟通表达能力，积极主动；"
"职位描述：
        
        1.负责数据仓库ETL流程设计与实现；
2.客户方日常项目需求的开发与实现；
3.配合客户方的数据查询、处理及统计工作；
任职资格：
1.计算机相关专业，大专及以上学历；
2.3年以上工作经验，2年以上ETL开发经验；
3.熟悉SQL开发及Linux系统（包括文件系统，常用命令，安装配置，性能参数调整等）；
4.有大数据平台开发经验优先；
5.有证券或金融行业数据仓库开发经验者优先；"
"职位描述：
        
        3年以上的数据开发经验，最近2年用的数据库是oracle；
掌握sql存储过程；
对etl? 报表有一些了解"
"职位描述：
        
        a、????工作年限>=5年，正规院校，本科或大专，相关专业（计算机、自动化、电子、数学、物理）毕业，有学习能力，为人正直，能承受一定工作压力；b、????有大数据平台应用开发和设计经验；c、????对Hadoop、Spark/Flink、Kafka、ElasticSearch、Flume、Zookeeper中之一或部分技术有设计和开发经验；??????如有以下能力之一，可优先考虑：a、????有分布式系统设计或者研发能力；b、????有大数据平台设计开发经验；c、????有工作流、调度系统、数据加载、运维监控、搜索引擎、自动化布署等方面开发或者设计经验；"
"职位描述：
        
        1、本科学历，计算机相关专业，3-6年工作经验；
2、具有数据仓库/数据集市项目经验；
3、熟悉常见大数据基础组件的使用，如Hadoop/Hive/Hbase/Impala/Spark/Sqoop等
4、较好的沟通表达能力，积极主动；"
"职位描述：
        
        任职要求：
1.具有丰富的数据仓库开发经验，有2年以上互联网或移动互联网并基于Hadoop/Storm/HIVE/Hbase/Spark等应用开发经验，对分布式计算、数据仓库理论有深刻理解 ；
2.熟练掌握linux常规命令与工具 ；
3.对Hadoop、Spark、Hive、Storm等源码有研究优先 ；
4.精通JAVA、MapReduce、Python，有并发应用或者分布式应用软件开发经验优先 ；
5.精通shell编程，sql编程、awk脚本语言等；?
6.良好的系统分析、架构设计能力；?
7.对数据敏感、对新技术敏感，有数据挖掘技能者优先 ；
8.了解无线端技术、有ios/android下开发经验者优先；
9.对商业和业务逻辑敏感，具备良好的分析、组织、沟通能力和团队精神。

岗位职责：
主要负责银行风控体系开发、银行AI场景开发等。"
"职位描述：
        
        ? ??岗位要求： （1）?计算机及相关专业本科以上学历，双证齐全，学信网可查； （2）?至少5年以上数据类项目的开发经验，具有良好的编程基础，了解编程语言原理，有实际大型项目开发经验者优先； （3）?熟练掌握数据库开发技术，有至少2年oracle存储过程开发经历，有数据库优化经验优先 （4）?具备独立完成某一功能模块设计及开发的能力； （5）?熟悉Linux操作系统，掌握常用shell命令 （6）?具备良好的解决问题的能力，工作认真细致，积极主动，责任心强，乐于专研技术，探索技术原理； （7）?具备良好团队合作精神和良好的沟通协作能力。 岗位职责： 1、能够完成核心产品代码的研发工作，解决项目中关键问题和技术问题； 2、工作责任心强，具备良好的团队合作精神，良好的沟通及协作能力。熟悉软件开发流程和配置库的使用，拥有良好的代码规范意识和文档编写能力。"
"职位描述：
        
        任职要求： 1.?15年毕业起，计算机及相关专业本科以上学历，双证齐全，学信网可查；2.?至少2年java开发经验，3年大数据开发经验，拥有实际的大数据项目开发经验；3.?熟悉大数据开发框架，Hadoop、Hive、HBase、Storm、Kafka等大数据主流工具和技术，熟悉Linux操作系统，Shell编程等；4.?掌握常用的设计模式和架构模式，能够熟练使用建模工具进行系y设计；5.?能够完成核心产品代码的研发工作，解决项目中关键问题和技术问题；6.?工作责任心强，具备良好的团队合作精神，良好的沟通及协作能力。熟悉软件开发流程和配置库的使用，拥有良好的代码规范意识和文档编写能力。 岗位职责： 1、参与大数据应用平台的设计与开发，解决海量数据面临的挑战； 2、负责大数据机器学习等模型的优化和集成工作，实现各类模型按统一的规范对外提供restful服务。 3、负责智能化决策平台的优化完善，实现大数据资源、模型资源能够实时对接到业务系统。 3、协助团队成员建立数据模型，对数据进行挖掘、优化及统计。"
"职位描述：
        
        1.负责大数据平台的架构设计与核心代码编写；
2.负责大数据平台的数据架构规划，把控大数据平台需求和设计；
3.负责大数据平台相关服务组件的性能调优，技术难点攻关；
任职要求：
1.计算机相关专业，本科及以上学历；
2.3年以上大数据平台开发、设计、运维经验；
3.熟练掌握Zookeeper、ElasticSearch、Flume、Kafka、HBase,Hive等大数据组件（2种以上）；
4.精通java/scala中一种或两种语言，熟练掌握Python，shell编程；
5.良好的逻辑思维能力，做事积极主动，有较强的执行力和较好的沟通能力；
6.有证券或金融行业数据仓库开发经验者优先。"
"职位描述：
        
        岗位职责：
1.负责数据分析、加工、清理、处理程序的开发（ETL开发）； 
2.负责数据相关平台的搭建、开发、维护、优化。

任职要求：
1.计算机相关专业，大专及以上学历，3年以上相关经验
2.熟悉hadoop生态系统内常见项目的使用（hdfs、hive、hbase、spark、zookeeper,yarn等），具有MapReduce开发经验，有实际大数据项目经验优先；
3.具有良好的沟通能力、组织能力及团队协作精神，有较强的分析和解决问题的能力"
"职位描述：
        
        岗位要求：
1、计算机及相关专业本科以上学历，双证齐全，学信网可查；?
2、3年以上3年以上报表开发项目相关工作经验，熟练使用一种数据库，如Oracle/Mysql，有Tableau等BI工具使用经验者优先；?
3、有金融行业大数据数据数据仓库、报表平台设计研发等经验者优先，有SAS编程经验者优先。?
岗位职责：
1、具备独立完成某一报表开发及数据开发的能力；?
2、具备良好的解决问题的能力，工作认真细致，积极主动，责任心强。"
"职位描述：
        
        （1）3年以上数据类工作经验；
（2）具备 shell/perl/python 脚本经验（至少其中之一），不局限于数据处理；
（3）具备扎实的SQL/HQL经验；
（4）具备至少1年数据仓库基础模型开发经验，具备一定的银行业务知识与数据分析能力；
（5）具备良好的沟通能力，有咨询经验的优先；

注：考虑银行外包，薪资根据金融年限定，具体面议。"
"职位描述：
        
        1.*统招本科及以上学历；
2.*4年以上数据开发工作经验，近三年从事BI项目应用开发或需求分析工作；
3.至少掌握一种BI工具、掌握COGNOS报表优先；
4.熟悉需求分析流程，能够指导初级人员进行需求分析及应用开发工作；
5.精通数据库SQL语言，能够进行复杂业务SQL实现；
6.沟通表达能力好，能够快速理解客户需求并进行及时响应和引导；
7.熟悉TERADATA数据库优先；
8.熟悉证券业务者优先；"
"职位描述：
        
        体需求如下：
1、统招本科及以上学历；
2、熟练掌握帆软Report/BI开发工具，从事帆软工具开发2年及以上、能独立部署、优化帆软工具；
3、有利用帆软工具开发多维报表、可视化指标或大屏监控者优先；
4、熟悉数据库开发流程，熟练编写存储过程，熟练操作Mysql、oracle等数据库；
5、具备较强的数据分析能力和数据敏感性，有金融行业从业经验优先；
6、沟通表达能力强，能够快速理解客户需求并进行及时响应和引导；
***至少2年以上的相关工作经验"
"职位描述：
        
        1. *统招本科及以上学历；
2. *3年以上数据开发工作经验，从事过模型设计或ETL工作；
3. *精通ETL算法，熟悉LINUX系统；
4、至少熟悉一种脚本语言（perl、shell、python）；
5. *精通数据库SQL语言，能够进行复杂业务SQL实现；
6. *熟悉ORACLE、HIVE、HBASE等数据库优先；
7. 熟悉证券业务者优先；"
"职位描述：
        
        1、参与大数据应用平台的设计与开发，解决海量数据面临的挑战；
2、负责大数据机器学习等模型的优化和集成工作，实现各类模型按统一的规范对外提供restful服务。
3、负责智能化决策平台的优化完善，实现大数据资源、模型资源能够实时对接到业务系统。
4、协助团队成员建立数据模型，对数据进行挖掘、优化及统计。
任职要求：
1、数学、统计、计算机等相关理科专业，全日制本科及以上学历；?
2、至少3年以上Java开发经验，1至2年大数据开发经验，拥有实际的大数据项目开发经验；?
3、熟练运用python或者spark进行数据建模，熟悉hive、hadoop大数据处理技术的优先考虑；
4. 有金融行业、风险防控等领域经验的优先考虑。"
"职位描述：
        
        工作职责：
1.????? 支持大数据相关项目或工作项，基于业务需求，对项目技术方案进行设计，并负责代码实现以及部署上线
2.????? 对公司各领域相关数据进行梳理、分析，识别潜在问题及其商业价值
3.????? 负责大数据平台工具的开发，支持大数据平台数据工程开发标准化，提升项目交付效率和质量
4.????? 内外部相关数据接入Data Lake
5.????? 负责大数据平台技术组件的验证工作
任职资格：
1.学历要求：全日制本科或以上学历 2.专业要求：计算机科学、计算机应用、软件工程等 3.工作经验：3年以上Java开发经验 4.专业知识： （1）能够熟练基于Hadoop生态系统组件（Hbase、HDFS、SPARK、Kafka、Solr等）进行数据应用开发 （2）熟悉NoSQL数据库开发，如MongoDB、Redis等 （3）良好的SQL语句功底，熟悉MySQL、PostgreSQL、Oracle数据库中的一种 （4）熟悉负载均衡、读写分离、SOA架构、系统性能调优等技术 （5）对新技术有孜孜不倦的热情"
"职位描述：
        
        ●技术要求
本科以上、计算机相关专业，3年以上工作经验
1年以上海量级离线分析系统的设计或开发经验 ?
有扎实的大数据理论基础，熟悉hadoop、hive、spark等常用技术
熟练使用常用数据库(MySQL,Oracle),具有较强的SQL功底。
掌握Python或者Java语言,能使用某一种开发语言编写小工具程序解决现场遇到的一些突发需求。
掌握Linux系统使用，熟悉常用命令。
熟练使用office常用办公软件。
熟悉数据挖掘、机器学习、特征工程加工等概念及使用场景
了解决策树、聚类、逻辑回归、关联分析、svm、贝叶斯等算法。
有过离线加工任务开发经验优先。
●岗位职责描述：
通过海量数据挖掘、机器学习、特征工程等方法，构建用户画像、行为分析、个性化推荐、预测等算法。
运用统计学以及数据挖掘相关知识，并使用阿里base平台，对数据进行建模，分析，验证等工作。
对数据中心已有的数据分析模型算法进行调优。
维护目前已上线的专题系统。
●有以下经验者优先考虑：
??- 有阿里云大数据开发平台开发经验
??- 有政府行业相关从业经历背景或了解公安行业相关业务经验者
??- 有地理信息、移动通讯等数据挖掘关联经验者
??- 有业务类系统需求调研、产品设计经验者
??- 有客户现场服务经验者优先"
"职位描述：
        
        岗位职责：
1.负责核心业务标准化cube数据的开发建设；
 2.负责核心业务数据建模以及数据服务化的设计开发；
3.负责数据仓库ETL流程的优化及解决ETL相关技术问题；
4.协助其它岗位工作，并完成领导交办的其他工作。
?
任职要求：
1、具有很强的开发和动手能力，熟悉一种以上变成语言，如Java、Python等；
2、深入理解常用数据建模理论，可独立把控数据仓库各层级的设计；
3、三年以上ETL开发经验，理解数据治理的重要性；
4、丰富的大数据库系统使用和开发经验，包括但不限于Hadoop/Spark/Hive/Hbase等；

该岗位隶属于三只松鼠南京研究与创新中心（以下简称南京研创中心）技术部，南京研创中心是三只松鼠正在新建的业务中心，是三只松鼠的创新业务总部，位于江苏省南京市建邺区。
南京研创中心致力于创新型业务领域的开拓和建设，正全力推进“松鼠小店”新零售分销模式、智能商业零售板块、社交电商领域等新业务，以最终完成品牌向平台化的重大转变，值此之际，诚邀社会各优秀人士的加入。
技术部将依据公司总体经营目标，负责三只松鼠供应链、分销平台产品设计、技术架构、技术实现、平台运维。采用电子商务先进的理念、技术和最佳实践，并结合市场需求和行业趋势，设计、构建并运行三只松鼠电商平台，保障实现公司经营目标。"
"职位描述：
        
        【岗位职责】?
1.基于Hadoop、hive等构建数据仓库平台，开发分布式计算业务;
2.搭建数据仓库开发、部署的流程，保证日常数据稳定、安全、准确；?
3.为项目开发人员提供大数据技术指导及解决大数据平台应用中遇到的技术难题；?
4.辅助管理Hadoop集群运行，稳定提供平台服务。
【任职要求】：?
1、本科或以上学历，计算机软件或相关专业，3年以上Java开发经验，1年以上大数据项目经验；?
2、对于Java基础技术体系（包括JVM、类装载机制、多线程并发、IO、网络）有一定的掌握和应用经验；?
3、对Hadoop、Hive、Hbase、Spark一种或者几种有一定的理解；熟悉基于Hadoop、Spark平台的典型算法实现，
有用户画像、推荐系统、数据挖掘等实际项目经验优先；?
4、熟悉Hive、mysql等和大数据ETL处理过程；?
5、熟练使用Tomcat、Redis、Kafka等中间件，熟悉Linux/Unix shell 及常用命令。"
"职位描述：
        
        岗位职责：
1、负责公司大数据产品源数据采样开发；2、负责公司大数据产品场景抽象设计；3、负责公司大数据产品算法选择；4、负责公司大数据产品算法验证及数据产品化；5、和技术团队合作，结合最新的大数据技术，设计和规划基础大数据算法场景及其推动实现；

任职资格：
1、本科及以上学历，计算机、通信、应用数学、金融数学、模式识别、人工智能等专业优先考虑；2、3年以上技术数据挖掘或算法实现类的技术开发经验，3年以上互联网或物流行业相关行业经验优先；3、 熟悉常用机器学习和数据挖掘算法，包括但不限于决策树、Kmeans、SVM、线性回归、逻辑回归以及神经网络等算法；4、熟练使用SQL、Matlab、Python/Linux Shell等脚本开发等；5、对Hadoop、Spark、Storm等大规模数据存储与运算平台有实践经验；6、 熟悉TensorFlow、Keras等一种或者多种深度学习框架，有实际应用经验；7、C/C++/PYTHON/JAVA至少精通一种编程语言；8、数学基础要好，如高数，统计学，数据结构。"
"职位描述：
        
        岗位职责：1、主导大数据团队的算法/数据框架搭建，并进行优化和落地；2、学习并跟进机器学习/人工智能在房地产领域的创新:3、参与大数据平台架构设计、核心编写，解决项目开发过程中的重大技术问题；

能力要求:1、计算机、统计学或相关专业硕士以上学历，5年以上大数据相关工作经验。2、熟悉MongoDB、Hadoop/Hbase/Storm/Spark/TensorFlow/Hive等主流技术。3、至少掌握一门语言(Scala/Java/python/php/R),熟悉一种算法库(MLib/Weka/R算法库等),有机器学习平台搭建经验。4、精通或者熟悉数据库设计，熟悉Oracle/MySQL集群等，并具有较好的 SQL 编写及优化能力；熟悉amazon数据产品者优先。 5、具有较强的数据挖掘、优化理论、机器学习的理论基础和项目实践，精通数据分析与各种算法模型，?? 例如分类、回归、聚类、关联、Boosting、SVM、神经网络中的至少一种。"
"职位描述：
        
        岗位职责：
1、负责企业级数据仓库的数据架构、核心方案设计，并推动落地；
2、带领大数据开发团队实现各项数据接入与处理、数据仓库建设、数据分析与挖掘及数据展示；
3、负责团队关键技术问题解决及开发指导；
4、保持与业界联系，持续跟进大数据领域的发展和新技术。
?
岗位要求：
1、本科以上学历，5年以上大数据项目实战经验；
2、熟悉大数据相关技术：HDFS、Sqoop、Kafka、Spark、Hive, Flume等；
3、对数据敏感、逻辑性强，熟练掌握各数据处理、数据统计分析、数据挖掘方法，具备处理和分析较大量级数据的能力以及较强的总结分析能力；
4、熟练使用至少一种常用的编程语言，包括但不限于Python、Scala、Go、Java、SQL等；
5、 较强的文字功底、沟通能力和逻辑表达能力，具备良好的团队合作精神和主动沟通意识；6、优秀的分析问题和解决问题的能力，对解决具有挑战性问题充满激情；
7、有数据可视化相关技术，AI相关算法经验优先。"
"职位描述：
        
        岗位职责：1、搭建集团级数据湖及业务域数据专题分析模型；2、对业务数据进行抽象和建模，搭建分析型数据模型；3、对数据进行质量分析并清洗，加工，萃取；

岗位要求：1、大学本科以上学历，信息科学、统计学、应用数学、管理学等领域专业；4年以上数据仓库工作经验；2、熟练掌握SQL语言，熟悉对常用数据库MySQL，Oracle等的开发使用；3、精通维度建模理论，了解ODS,DWD-DWS,ADS的分层结构；4、熟悉常用的ETL技术，至少会使用其中一种informatica,kettle等；5、熟悉Hadoop、Hive、HBase、Spark、Flink等大数据框架者优先；6、有基于数据中台理念搭建数据仓库的项目经验者优先；7、有地产行业工作经验者优先。"
"职位描述：
        
        岗位职责：
1、负责基于Hadoop/Spark/Flink生态体系，建设海量数据的实时、离线数据平台系统;
2、负责大数据平台的整合搭建、开发，以及系统问题的解决和持续优化,技术运营维护工作;
3、保证集群高效稳定运行，分析定位、解决平台各类运行问题;
4、负责大数据相关前沿技术研究及实践;
?
岗位要求：
1、本科及以上学历，至少3年以上实际大数据类开发经验，其中参与过开源社区贡献最好；
2、熟练掌握至少一种编程语言，Scala、Java， 熟练掌握至少一种脚本语言python、shell；
3、熟悉大数据生态系统Spark、FLINK、Hadoop、Kafka、Yarn、Elasticsearch的架构、底层原理和技术细节，并有丰富开发、调优、维护经验。
4、有在电商、 分布式大数据处理，推荐系统，分布式数据挖掘经验者优先；
5、深入研究过Spark、FLINK、Hadoop、Kafka、Yarn、Elasticsearch等源代码者优先;"
"职位描述：
        
        岗位职责：
1、负责基于Hadoop/Spark/Flink生态体系，建设海量数据的实时、离线数据平台系统；
2、负责大数据平台的整合搭建、开发，以及系统问题的解决和持续优化,技术运营维护工作；
3、保证集群高效稳定运行，分析定位、解决平台各类运行问题;
4、负责大数据相关前沿技术研究及实践；

岗位要求：
1、本科及以上学历，至少3年以上实际大数据类开发经验，其中参与过开源社区贡献最好；
2、熟练掌握至少一种编程语言，Scala、Java， 熟练掌握至少一种脚本语言python、shell；
3、熟悉大数据生态系统Spark、FLINK、Hadoop、Kafka、Yarn、Elasticsearch的架构、底层原理和技术细节，并有丰富开发、调优、维护经验。
4、有在电商、 分布式大数据处理，推荐系统，分布式数据挖掘经验者优先；
5、深入研究过Spark、FLINK、Hadoop、Kafka、Yarn、Elasticsearch等源代码者优先。"
"职位描述：
        
        工作职责：
1. 与相关业务负责人对接，深入了解并抽象业务需求，分析数据应用可行性，形成需求调研和应用可行性设计。?
2. 通过对业务和数据调研，进行数据模型（数据仓库）设计，协同产品开发，数据分析团队进行开发工作。
3. 建设及持续完善大数据仓库，提高数据质量，通过数据驱动业务增长。
任职要求：
1.2-5年大数据相关工作经验，熟悉数据仓库模型设计与 ETL 开发，具备海量数据处理能力，有电力行业数据仓库建设维护经验优先；
2.熟悉 Oracle，熟练使用HiveSQL进行ETL开发； ?
3.熟练掌握 Java/Scala ，有扎实的代码功底和实战能力，有Spark Streaming实时流处理开发经验优先；
4.熟悉Hadoop、HBase、Hive、Spark等大数据平台或框架的架构和工作原理，具有大规模数据采集处理等项目经验；
5.有较强的数据分析和解决问题的能力，沟通能力强，思路清晰。"
"职位描述：
        
        岗位职责：1，主要工作是基于storm/flink的大数据实时计算开发；2，参与基于spark/scala的大数据离线计算开发；3，熟悉业务形态，参与需求分析和方案设计岗位要求：1，学历不限，具备扎实的Java开发基础；2，有1-2年流式实时计算的相关经验；3，精通storm或flink开发，熟悉kafka；4，熟悉storm的trident开发，或者storm源代码有修改定制经验尤佳；5，熟悉mysql/mongodb/hbase/redis；6，熟悉Spark/Hadoop/Hive等大数据相关技术；7，有scala/spark开发经验尤佳。"
"职位描述：
        
        1、本科及以上学历，3年以上数据库相关经验；2、精通SQL语言，熟练掌握常用数据库(MySQL/Oracle/GP)；3、熟练掌握索引技术、SQL优化、Sharding, Partition；4、熟练掌握Linux-操作命令，Shell脚本；5、熟练掌握Vertica和Postgresql；6、熟练掌握Airflow/NIFI/KETTLE等主流ETL调度平台；7、熟练掌握数据库平台性能优化、运行情况监控与维护；8、掌握Hadoop(HDFS/Hbase/Hive)优先；9、掌握Spark(Spark SQL)优先。"
"职位描述：
        
        岗位职责：
1、 负责大数据平台数据建模 、数据抽取、监测数据的开发与优化；
2、负责数据的优化与维护，根据业务动态进行调优；
3 、负责通过模型优化提升数据统计效率。
任职要求：
1、熟悉大数据平台Hadoop、Hive部署及调优，具备一定服务器架构能力
2、对关系型数据库能够熟练操作，包括MySQL数据库设计、管理与优化、熟练MySQL主从调优，集群架构；
3、掌握一定开发语言基础，例如Python，Shell，Java，C++等
4、具备关系型数据库大数据挖掘经验，有企业内部管理系统数据挖掘和大数据工具应用经验者优先。"
"职位描述：
        
        岗位职责：
1.负责大数据平台数据建模、数据抽取、监测数据的开发与优化；
2.负责数据分析业务开发的优化与维护，根据业务动态进行调优；
3.负责通过模型优化与算法改进，进行业务数据分析；

任职要求：
1、熟悉大数据平台Hadoop、Hive部署；
2、熟悉主流开源分布式存储技术Flume、Kafka、Hbase、MapReduce、Spark、es 等；
3、熟练使用sql，hsql ，熟悉mysql，?
4、熟悉使用python，java，sacla 其中一种语言，熟悉Shell等；
5、有PB级数据开发经验者优先。"
"职位描述：
        
        岗位要求：
1.本科及以上学历，计算机相关专业，基础扎实；
2.熟悉 Linux 的 Shell 命令，灵活运用 Shell 做文本处理和系统操作；
3.熟练掌握一门或多门编程语言，参与过大型项目者优先，熟悉 Java，Scala，Kotlin者优先；
4.优秀的沟通与表达能力及较强的自我驱动能力；
5.实习时间可保证一周三天以上，倾向于可实习半年的学生。
加分项：
具有丰富的海量数据 ETL 加工处理经验；
有从事分布式数据存储与计算平台应用开发经验，熟悉 Hadoop，Spark，HBase，Cassandra 及 Hive 等；
有从事实时计算的经验，如 Spark Sreaming 及 Storm 等。
?工作内容：
借助开源大数据组件对业务数据进行ETL处理，完成业务数据的分析、统计需求。

简历投递链接：https://career.qiniu.com/school"
"职位描述：
        
        岗位描述：
1、基于Hive与Hadoop，进行数据建模、数据ETL任务开发；
2、负责公司业务报表的开发，包括数据统计、分析与输出；
3、负责分布式数据平台框架下的数据架构设计与开发，以及新数据应用开发；
4、参与数据基础平台搭建，公司业务数据采集任务开发；
岗位要求：
1、 本科或以上学历，计算机、数学等相关专业，3年以上工作经验；
2、 熟悉Hadoop或其他分布式数据开发技术，熟练掌握数据库技术；
3、 有数据仓库（百T及以上）的系统设计和开发，精通数据建模、ETL过程、元数据管理等数据仓库主要环节优先；
4、 精通SQL,PL/SQL，精通Mysql数据库优先；
5、 熟练使用Hadoop或其他分布式平台的一种，能使用Java、Python或其他语言编写MapReduce进行大数据处理；?
6、 从事过云计算公司数据平台的开发、数据计算工作者优先；"
"职位描述：
        
        职位描述：
1、负责医学文案的撰写，如采访提纲、调研题库、讨论话题等；
2、负责项目内容的完善、更新、维护、推广；
3、负责项目相关数据的统计、整理，撰写项目报告；
4、负责与其他相关部门沟通协调，推进项目、把控质量、监控进度；
5、参与专业会议现场和网络报道，如采访专家、制作专题等；
6、参与项目前期方案的策划、设计、评估；
7、负责医学相关文献检索、翻译、整理和分析；
8、负责跟踪医学领域热点，为项目方案提供专业建议。

任职条件：
1、临床医学专业/药学专业，本科及以上学历；
2、英文读写能力强，熟练英文对话则更佳；
3、可熟练进行专业文献阅读及资料查阅；
4、思路清晰，文字编辑、文案组织能力较强；
5、有良好的团队协作、沟通协调能力；
6、工作细致、责任心强，具有一定的抗压能力和自我调节能力；
7、熟知各种互联网新媒体（微信公众号、微博……）尤佳 ；
8、有临床工作经验或网络经验者优先。"
"职位描述：
        
        职位描述：
1、 负责公司大数据基础架构相关工作；
2、 为算法，分析师，知识库以及研发内部提供基础工具和平台；
3、 解决研发内部遇到的各种疑难杂症,指导初级工程师的工作。

任职条件：
1、三年以上大数据研发相关经验；
2、精通Spark，包括PySpark；
3、熟悉大数据生态体系，对Kafka/HBase/HDFS/Hive/Kylin等组件有深入理解和使用经验；
4、熟练掌握SQL，对Hive原理和调优方法有实际经验；
5、有开源项目优先。"
"职位描述：
        
        职位描述：
1、参与公司大数据系统平台与应用的设计、开发、维护；
2、针对具体的业务问题的研发、维护及优化，满足业务数据需求；
3、参与构建日志收集、数据仓库、ETL、调度系统、分析系统等环节。

任职条件：
1、计算机、数学、统计专业，1 年及以上 Hadoop 工作经验；
2、熟练使用 Mac/Linux 操作系统，以及常用的 Shell 命令和工具；?
3、熟练使用 Java/Scala 中的一种开发语言；
4、熟悉常用的数据指标、数据分析工具和平台（Hadoop、Hive、Spark、Kafka 等），了解数据分析的基本方法和常见问题；?
5、工作认真负责，有较强的钻研学习能力和分析解决实际问题的能力；
6、具有数据分析和数据挖掘方面的项目经验者优先；
7、具有互联网用户行为分析经验者优先。"
"职位描述：
        
        职责描述：
1、负责参与数据模型体系构建及数据主题设计和开发，数据仓库和业务数据集市的建设；
2、负责数据集市架构设计、建模以及ETL开发，构建可扩展的数据仓库以及数据分析解决方案；
3、负责数据集市需求调研和需求分析；
4、完成业务模型抽象、项目数据梳理，设计数据模型，提供统计、分析服务。

任职要求：
1、有至少1年数据仓库实施和模型设计经验，本科以上学历；
2、深入理解DW，BI相关的知识，包括：ETL、数据仓库、OLAP、多维数据模型等；
3、熟悉数据仓库建模理论，以及数据仓库数据层级关系，精通多维数据模型设计，具备大型数据仓库架构设计、模型设计和处理性能调优等相关经验；
4、熟练使用主流数据模型设计工具；
5、精通SQL，能够熟练使用HiveQL和Spark SQL进行数据开发，熟悉Hive数据模型优化；
6、具有良好的团队协作精神和沟通能力，较强的逻辑思维，学习能力和解决问题的能力，可承担较大的工作压力；
7、有独立设计数据仓库经验，熟悉数据仓库相关理论知识者优先；"
"职位描述：
        
        
 负责大数据平台的设计开发，包括平台组件选型及搭建、平台服务开发；
 参与设计数据仓库模型、构建分层体系、元数据管理及核心应用开发；
 参与数据清洗、转换和加工（ETL）；
 负责新技术的调研、选型、推广和应用。


技能要求：

 本科及以上学历，计算机相关专业，3 年以上大数据工作经验；
 熟悉 Hadoop 生态，对 HDFS, Hive, MapReduce, Spark, HBase, Impala 中至少一个有深入理解和使用经验；
 熟练使用 SQL，至少熟悉一种关系型数据库；
 深入理解维度模型，有数据仓库设计和开发经验；
 熟练使用 Python，有良好的编码习惯；
 熟悉 Kafka, Spark Streaming, Flink，有实际使用经验者优先；
 熟悉 ElasticSearch, Solr, ClickHouse, Redshift 等技术优先；
 提供技术博客 / GitHub 账号，有开源贡献和优质技术文章优先。


关于我们：

 我们是一个年轻的数据科学团队，希望通过技术改变商业世界，实现数据驱动的精细化研究、运营与决策。我们的产品正在持续服务国内外顶尖的企业，包括多家大型快消企业，时尚大牌，国际一线汽车厂商，以及著名对冲基金；
 我们团队里有许多顶尖的开发者和数据科学家，来自腾讯、百度、快播、华为、BCG、麦肯锡，毕业于海内外著名高校；
 我们获得了来自著名投资机构的三轮投资，资金充足，处在高速发展的上升期。但我们仍然是一个小公司，你的加入仍然可以对公司的发展轨迹产生明显的影响和贡献。


公司福利：

 有竞争力的薪酬：工资、一年两次调薪机会、五险一金、年终奖、节假日福利、生日礼物等。既有情怀，又有“钱”途；
 合理的工作时间：我们有弹性工作时间制度，并追求使用技术去高效解决问题，不提倡加班；
 团队活动：YiMBA系列课程、每周的篮球和羽毛球运动，每周分享会，每月聚餐、生日会等。我们是一个有凝聚力的团队；
 年度体检：豪华体检，健康强壮的身体是工作的基础；
 零食饮料：不间断的供应丰富优质的零食饮料；
 年度旅游：前脚去泰国后脚去巴厘岛，随着团队的壮大，以后能去得更远；
 舒适的工作环境：我们有一个漂亮的办公室，开放式的设计和十分开阔壮观的窗景

... ...."
"职位描述：
        
        工作职责：
1、打造业界领先的大数据基础设施，包括数据接入，同步，存储、计算，查询等环节的分布式系统，为海量数据和大规模业务系统提供可靠的基础设施；?
2、与开源社区保持交流，发现对业务场景有帮助的特性并引入生产环境，或将经内部验证的特性贡献到社区；
3、承担千台规模集群的管理工作，与业务一起解决性能优化、容量规划、预算审计等问题，保障集群高效稳定经济运行；
任职资格：?
1、计算机基础扎实，熟悉常用数据结构和算法，具备较强的逻辑思维能力和编码能力；
2、掌握分布式系统原理，对存储、计算、消息队列、资源管理，数据同步等中的一项或多项有深入的理解和认识；?
3、乐于挑战没有明显答案的问题，能快速理解业务场景，从具体问题中抽象出通用的解决方案；?
4，熟悉Hadoop， Hbase， Zookeeper，Flume，K8s等基础服务中的一项或多项；
5、有Kafka或者同类型技术设计开发及集群管理经验者优先。"
"职位描述：
        
        工作职责：
1、负责公司级的通用数据平台开发，服务于全公司各个用户产品线；?
2、面向PB级超大规模数据问题，每天处理百亿增量的用户行为数据；?
3、为大数据的全生命周期提供服务，覆盖数据产生，传输，存储，计算，查询，可视化的全流程；?
4、构建设计良好的数据流、调度系统、查询引擎，同步服务、分析系统、流程规范，数据工具/产品，降低数据的使用门槛，保证系统稳定高效运行，以实现数据的最大价值。
任职资格：
1、熟悉linux编程环境，有较强的开发能力（java/scala/c++/python等 )，对新技术有强烈的学习热情;
2、熟悉多项大数据处理/分析相关的工具/框架，e.g. azkaban,? Hive, Spark, kylin, druid, flume, kafka, hbase, canal, sqoop etc；
3、优秀的理解沟通能力，能快速理解业务背景，对数据敏感，崇尚数据说话，深信数据在驱动业务、支撑决策上的价值。"
"职位描述：
        
        工作职责：
1、负责一点资讯大数据仓库平台的开发建设；
2、设计并实现大规模分布式计算算法，处理海量数据；
3、跨部门协作，协同分析并解决数据问题；
4、深入的数据挖掘和数据分析。
任职资格：
1、熟练使用Java/C/C++/Python 等语言进行开发（至少熟练掌握一种），有高效、高可靠代码开发经验 ；
2、有扎实的算法基础，熟悉常见的数据结构，了解分布式算法和分布式系统；
3、精通常见的开源分布式计算/存储相关技术，包括YARN，MapReduce，Hive，Pig；
4、熟悉常见的数据计算优化策略，有优化MapReduce作业、Hive作业，Pig作业执行效率经验；
5、熟悉OLAP引擎者的设计和开发者优先 ；
6、熟悉机器学习，有数据挖掘和深度数据分析者优先。"
"职位描述：
        
        工作职责：
1、负责公司级的通用数据平台和分析型产品，服务于全公司各个用户产品线；?
2、面向PB级超大规模数据问题，每天处理千亿增量的用户行为数据；?
3、为大数据的全生命周期提供服务，覆盖数据产生，传输，建模，统计分析，实验评估，可视化的全流程；?
4、构建设计良好的数据流、调度系统、查询引擎，数据服务、分析系统、流程规范，数据工具/产品，降低数据的使用门槛，保证系统稳定高效运行，以实现数据的最大价值。

任职资格：
1、熟悉linux编程环境，有较强的开发能力（java/scala/c++/python等 )
2、熟悉多项大数据处理/分析相关的工具/框架，e.g. azkaban, Hive, Spark, kylin, druid, flume, kafka, hbase, canal, sqoop etc；?
3、强悍的编码能力，生产环境快速 trouble-shooting能力，对新技术有强烈的学习热情；4、优秀的理解沟通能力，能快速理解业务背景，对数据敏感，崇尚数据说话，深信数据在驱动业务、支撑决策上的价值。
4、985/211学历，硕士优先。

团队文化：?1.崇尚极客精神，鼓励通过引入更先进的架构，在提高交付能力的同时，提高团队成员的技术水平；??2.鼓励独立思考，对事不对人，不盲信盲从权威；??3.快乐工作，高效工作。公司优势：1.资讯类独角兽公司，国家资金背景，有望明年特股上市。??2.针对一点资讯PB级别海量数据分析，具有挑战性的多业务数据使用场景；??3.通过数据驱动业务，充分发挥数据的价值，令人激动的用户增长项目；??4.清北复交中科院等一流高校、BAT等互联网公司背景年轻化的团队，与美国顶级大学海龟博士合作交流的机会；??5.零食、饮料、水果，免费班车，有竞争力的薪资待遇，定期的团队活动，轻松融洽的工作氛围"
"职位描述：
        
        1） 精通java；
2） 熟练掌握传统数据库MySQL，具有调优SQL的经验?；
3） 掌握数据分析的基本流程，擅长数据采集、清洗、分析等环节?
4） 有过大数据处理相关经验，有Hadoop生态系统相关工具如Spark/MR的开发与维护经验， 对流式处理如storm/Jstorm有过了解；
5） 了解Hive/Hbase/ES/Druid中一个或两个分布式数据库的搭建和开发；

加分项：
1） 有过数据产品ETL，OLAP开发经验"
"职位描述：
        
        关键职责? 
1.主导数据仓库基础架构的建设，以满足数据仓库对时效性、正确性、可扩展性和易用性的要求；?
2.与数据分析师密切合作，深刻理解其需求，并给出恰当的解决方案；?
3.通过分析相关系统，梳理潜在的数据源和日志清洗需求，并设计合适的、可扩展的数据模型；?
4.开发并维护数据流水线，使得数据分析师和数据科学家便于从数据中挖掘洞察，为业务部门赋能；?
5.与公司相关团队有效沟通，及时解决技术及管理问题；?
6.积极学习新技术新理念，通过更先进的技术及管理手段，大幅提高交付能力；?
7.积极与团队成员分享经验教训，提高团队其他成员的技能。??

任职资格?
1.本科或以上学历，计算机、通信等相关专业；?
2.熟悉C/C++/Java/Python一种或多种编程语言，编程能力优秀；?
3.熟悉分布式系统基本原理；?
4.对技术富有热情，自我驱动力强，乐于快速学习和尝试新技术、新工具；?
5.善于沟通，具备优秀的技术与业务结合能力；
6.能够在持续创新的快节奏环境中工作。?
?
具备以下条件的候选人优先考虑? 
1.熟悉Spark, Hadoop/YARN, Hive, HBase, Storm等技术；?
2.具有大数据开发经验；?
3.对数据敏感，善于从数据中发现疑点，有用户行为分析经验。

团队文化? 
1.崇尚极客精神，鼓励通过引入更先进的架构，在提高交付能力的同时，提高团队成员的技术水平；?
2.鼓励独立思考，对事不对人，不盲信盲从权威；?
3.快乐工作，高效工作。

公司优势：?
1.资讯类独角兽公司，国家资金背景，有望明年特股上市。?
2.针对一点资讯PB级别海量数据分析，具有挑战性的多业务数据使用场景；
3.通过数据驱动业务，充分发挥数据的价值，令人激动的用户增长项目；??
4.清北复交中科院等一流高校、BAT等互联网公司背景年轻化的团队，与美国顶级大学海龟博士合作交流的机会 ；
5.零食、饮料、水果，免费班车，有竞争力的薪资待遇，定期的团队活动，轻松融洽的工作氛围。"
"职位描述：
        
        工作职责：
1.负责公司级的通用数据平台和分析型产品，服务于全公司各个用户产品线； ?2.面向PB级超大规模数据问题，每天处理千亿增量的用户行为数据； 3.为大数据的全生命周期提供服务，覆盖数据产生，传输，计算，建模，统计分析，实验评估，可视化的全流程； 4.构建设计良好的数据流、数据仓库、调度系统、kv存储，查询引擎，数据服务、分析系统、流程规范，数据工具/产品，降低数据的使用门槛，保证系统稳定高效运行，以实现数据的最大价值。 ? ?

任职资格：
1.熟悉linux编程环境，有较强的开发能力（java/scala/c++/python等 ?);
2.强悍的编码能力，对新技术有强烈的学习热情； 3.加分项，熟悉一项或多项大数据处理/分析相关的工具/框架，e、g、 azkaban, hadoop, Hive, Spark, kylin, ?druid, flume, kafka, hbase, mesos, kubernets, redis etc。

团队文化：? 1.崇尚极客精神，鼓励通过引入更先进的架构，在提高交付能力的同时，提高团队成员的技术水平；?? 2.鼓励独立思考，对事不对人，不盲信盲从权威；?? 3.快乐工作，高效工作。  公司优势： 1.资讯类独角兽公司，国家资金背景，有望明年特股上市。?? 2.针对一点资讯PB级别海量数据分析，具有挑战性的多业务数据使用场景；?? 3.通过数据驱动业务，充分发挥数据的价值，令人激动的用户增长项目；?? 4.清北复交中科院等一流高校、BAT等互联网公司背景年轻化的团队，与美国顶级大学海龟博士合作交流的机会；?? 5.零食、饮料、水果，免费班车，有竞争力的薪资待遇，定期的团队活动，轻松融洽的工作氛围"
"职位描述：
        
        岗位职责：
1、负责大数据平台的规划设计，负责hadoop集群的开发、调优、监控；
2、负责数据基础架构和数据处理体系的升级和优化，不断提升系统的稳定性和效率；
3、挖掘数据层面的业务价值，设计并实现数据相关报表，推动产品、业务优化升级

任职要求：
1、本科以上学历，计算机或相关专业，3年以上大数据平台工作经验；
2、参与过电商核心数据平台搭建，并有设计数据平台相关报表的经验；
3、熟练掌握Java开发，熟悉JVM运行原理；
4、熟悉Hadoop平台相关技术原理（HDFS、Yarn、Hive、Mapreduce、Spark等）；
5、熟悉Linux操作系统及常用命令，具备基本的系统运维经验；
6、有大规模Hadoop集群运维经验者优先；
7、熟悉数据仓库领域知识和技能者优先，包括但不局限于：元数据管理、数据开发测试工具与方法、数据质量、主数据管理；
8、具有快速解决问题的能力和较强的学习能力；
9、能自我驱动，有较强的沟通能力及团队合作精神，强烈的责任感及进取精神"
"职位描述：
        
        岗位职责：1、负责公司大数据平台建设、开发2、依据业务需求，进行数据产品的规划和设计开发，为数据分析和运营等人员搭建友好高效的数据产品，如报表、BI系统等3、协助对业务数据进行分析、建模，为业务部门的数据化运营提供支持任职要求：1、本科或以上学历，2年以上大数据开发或数据仓库或BI经验，熟练掌握Java或者Python开发语言2、熟悉Hadoop或Hadoop生态圈相关技术，如Hive、Spark等，或者大数据云服务技术。3、对业务有敏锐的洞察力，有较强的业务理解与分析能力；4、具备良好的团队合作精神，有较好的沟通交流能力，善于主动思考和行动，乐于解决具有挑战性的问题；5、具有电商领域大数据开发、推荐系统研发经验的优先考虑。"
"职位描述：
        
        岗位职责：
1、主导数据平台业务开发与维护，参与数据平台体系建设与技术结构设计。
2、能够促进公司数据业务发展，加快公司数据体系的建设进程，为其它业务做好辅助决策工作。
3、负责数据平台基础框架开发与维护工作，负责数据业务技术方案输出以及开发工作，参与项目管理，协助管控项目流程，对项目结果负责。

任职要求：
1、计算机或相关专业，本科及以上学历；
2、精通java语言，熟悉java开源框架，至少3年以上的java开发经验；
3、熟悉大数据处理相关的开源中间件项目(如hadoop/storm/spark/kafka/flink等)，2年以上大数据产品和数据分析相关项目经验；
4、良好的沟通能力，工作细致，有强烈的责任心;
5、对技术有热情，技术视野开阔。"
"职位描述：
        
        工作职责:1、负责公司大数据平台的建设和开发；2、负责公司数据仓库的建设和开发；3、负责数据服务和需求的自动化、工具化、流程化，提升效率及数据管理水平。任职资格:1、计算机或相关专业本科以上学历，硕士、博士优先；2、熟悉linux系统、C/C++语言；精通shell、python、lua等任一种脚本语言；3、具有扎实的数据结构及算法功底，熟悉常用的数理统计方法和机器学习方法；4、熟悉hadoop/spark生态中各个基础组件的使用，优缺点和适用范围，有相关的实践经验；5、对数据敏感，具有优秀的分析问题解决问题能力，具备独立承担模型设计和系统搭建的能力；6、性格开朗，责任心强，良好的沟通能力和团队协作能力；7、有互联网领域的大数据平台、数据抓取、数据开发、数据可视化经验者尤佳。"
"职位描述：
        
        岗位职责：
1、熟悉ETL程序开发流程；
2、负责与需求人员接口，熟悉项目的需求规划说明；
3、负责与业务数据部接口，熟悉项目的开发计划，及项目的概要设计说明数据库设计；
4、按计划完成ETL功能模块的功能设计、代码实现, 代码编写和单元测试。
5、根据项目要求，协助完成《详细设计说明书》的编写；
6、严格遵守相关开发工具的编码规范；
7、参与需求和设计讨论，对项目开发各个环节进行签字确认；
8、提交相关年、月、日计划和总结；

任职资格：
1、 计算机，信息技术，软件工程等相关专业本科或以上学历，三年以上BI项目开发或实施经验；? ?
2、 熟悉DW/BI项目系统结构和基础知识，2年以上ETL项目经验。
3、 熟悉一种以上的主流ETL工具使用，（ODI、Informatica，Datastage，Kettle）。
4、 熟悉一种以上主流大型关系数据库管理系统（ORACLE、DB2、Sysbase、SQL SERVER），擅长SQL的编写与调优。
5、 了解数据质量控制与异常数据处理、熟悉ETL过程调度。
6、优秀的沟通协调能力；
7、较强的学习能力及自我提升能力。"
"职位描述：
        
        岗位职责：
1.公司数据管理、应用产品需求分析、系统设计；
2.公司数据管理、应用产品代码编写、功能实现；
3.新技术预研、落地；
4.下级工程师指导及培养，及小组管理；

职位要求：
1、大学本科或以上学历，计算机相关专业；
2、2年以上软件开发工作经验，以核心开发人员身份参加过较大型BI项目；有团队管理经验优先；
3、熟悉Kettle、Datastage等一种以上的主流ETL工具；
4、熟悉数据库技术，熟悉Mysql或ORACLE中的一个以上，精通SQL的编写与调优；熟悉hadoop开发优先；
5、熟悉数据处理、数据质量控制、元数据管理相关技能；
6、有较强的需求理解、分析，系统设计能力；
7、较强的学习能力及技术研究能力，对大数据行业有较强兴趣；"
"职位描述：
        
        工作职责：
1、基于hadoop、spark等构建数据分析平台，进行设计、开发分布式计算业务;
2、辅助管理Hadoop集群运行，稳定提供平台服务;
3、搭建数据开发、部署的流程，保证日常数据稳定、安全、准确；
4、跟进数据项目进程并承担项目的开发、系统分析工作，应用开发。

岗位要求：
1、计算机相关专业本科及以上学历，2年以上编程经验，熟悉hadoop原理、熟悉hadoop集群的搭建、管理及优化；
2、熟悉HDFS/HBase/Hive/MapReduce，有丰富的分布式编程及海量数据处理经验；
3、熟悉Core Java, 熟悉Java IO, NIO, 多线程编程. 熟悉JVM运行机制和内存管理, 网络协议；
4、熟练掌握Linux操作系统，熟悉shell等脚本编程；
5、熟悉storm、kafka、spark streaming等CEP流式计算技术优先;
6、熟悉Oracle、GreenPlum管理及程序开发优先；
7、责任心强，认真细致，良好的沟通能力和团队协作精神，有清晰的逻辑思维能力。"
"职位描述：
        
        工作职责：
1.百亿流量、百万并发推送push系统实时效果跟踪、多维分析系统建设，运营系统建设
2.与算法、AI团队一起，研发和优化推送点击率预测、频率/流量控制等核心推送策略，建设精准推送能力

岗位要求：
大学统招本科或以上学历，计算机或相关专业；
5年以上互联网业务开发经验或大容量网络服务相关经验者优先；
对海量分布式数据处理和存储有较多了解 ，具备海量服务器开发经验者优先；
熟练掌握Java或者Scala语言，LINUX/UNIX开发环境，mysql, nosql及网络等计算机基础专业技能；?
有较强的逻辑思维能力和数据分析能力，能够承担工作压力。

加分项：
有大数据分析处理、运营系统建设经验者，熟悉Strom、Flink、Spark、Druid、ElasticSearch等大数据套件者优先。
有搜索、推荐或广告系统相关算法工作经验者优先。"
"职位描述：
        
        岗位职责：
1、负责搜索业务pb级数据的存储平台的设计、研发工作?
2、深入理解业务场景，致力打造稳定、可靠、安全的对象存储服务?
3、跟踪业界先进的存储体系，不断优化并提升存储性能

任职要求：
1、熟悉Linux环境下编程， 具有3年或以上后台开发经验，具有扎实的编程基础，熟练掌握至少一门语言c++/java/go
2、追求高品质代码，对工程质量有深刻认识， 注重模块化、单元测试、异常测试
3、熟悉Linux下 I/O协议栈，掌握网络编程和网络服务框架等内核，有操作系统相关开发经验
4、熟练掌握对象存储或块存储且有实际的项目经验，精通以下任一开源存储系统：HBASE/HDFS、Ceph、tidb、fastdfs、seaweedfs、LevelDB/RocksDB者优先
5、对coding有极高的热诚，并具有geek精神，如有个人的技术blog或者个人主页，github关注过某项开源项目并能深刻理解其原理(或参与、提交过issue/bug)者优先"
"职位描述：
        
        岗位职责：
1、负责和参与公司大数据基础架构平台的建设，保障数据平台服务的稳定性和可用性；
2、参与多机房数据同步、数据ETL、数据仓库的整体框架规划和设计。
3、负责平台的整体数据架构设计，对数据有较高敏感性，完成从业务模型到数据模型的设计及开发工作；
4、负责Hadoop平台数据仓库、数据集成、数据管理的整体架构设计工作。
任职要求：
1、本科及以上学历，3年以上大数据开发经验；
2、熟悉Hadoop、Storm、Spark、Flume、Kafka、Hbase等组件的原理，有良好的系统性能优化及故障排除能力；
3、负责和参与大数据基础架构平台的监控、资源管理、数据流管理，能够开发各种Hadoop大数据自动化运维与监控工具；
4、对Hadoop平台架构能够不断优化，提升数据产品的质量和响应速度；
5、精通Shell/Python/Java语言的一种或多种；
6、有大规模hadoop运维经验者优先，有hadoop/hbase开发经验者优先。

此职位工作地点为深圳市福田区。"
"职位描述：
        
        岗位职责:

1.负责实现vivo 大数据处理、分析的平台化2.根据实际需求，制定系统实现目标、系统实现计划3.协调团队成员，齐心协力完成系统建设 
任职资格:

1.具有较深的大数据技术栈，熟悉常用的大数据处理组件。2.精通大数据ETL处理架构，精通基于hive的数据仓库架构和建设3.具有比较扎实的Java开发基础。4.熟练掌握Hadoop生态组件，例如：MR、hdfs、spark、hive、hbase等5.逻辑思维清晰，有较强的团队协作能力，踏实上进。"
"职位描述：
        
        岗位职责:

基础大数据组件研发方向：1.负责Hadoop的研发资源隔离、预算管理、权限控制、集群联邦方案的研究和开发2.消息系统kafka研发，负责负载均衡、权限控制、预算管理、资源隔离方案预言与研发3.KV系统Hbase研发，负责负责负载均衡、权限控制、预算管理、资源隔离方案预言与研发4.计算系统spark、flink平台化、性能优化、接口封装、调度集成等开发5.hive扩展能力提升，hive元数据组织方式重构研发。数据开发平台研发方向：1、日志采集系统研发（采集agent、采集manager、采集kafka-hdfs等模块）2、ETL配置服务、配置组件研发3、资源管理、预算申请、权限控制服务研发4、kafka、spark、flink、hive平台化开发5、OLAP解决方案开发数据应用产品开发与支持方向：1、基于实时计算的调用链分析系统研发2、基于实时计算的trace、监控系统研发3、数据挖掘工程优化与方案调研、研发4、其他数据产品解决方案研发 
任职资格:

基础大数据组件研发方向：1、精通一门高级编程语言2、至少精通hadoop、spark、kafka等大数据组件中的1种，并具备其中一种源码分析和开发能力3、熟悉大数据平台架构4、熟悉大数据系统的资源管理、高可用建设方案5、熟悉大数据系统的网络架构数据开发平台研发方向：1、精通数据ETL、数据仓库、数据统计分析的开发流程2、精通基于分布式存储、计算系统的数据应用开发3、精通hive、spark、mapreduce编程接口4、熟悉分布式存储和计算系统的基本原理5、熟悉hive、spark、mapreduce的运行机制数据应用产品开发与支持方向：1、熟悉hive、spark、mapreduce编程接口2、熟悉分布式存储和计算系统的基本原理3、熟悉hive、spark、mapreduce的运行机制"
"职位描述：
        
        岗位职责：
负责搜索系统中大数据平台的基础研发，监控、运维 ，维护平台的扩展与稳定性?

任职要求：
1、扎实的java/C++/go基本功，能够熟练理解JVM原理，熟练使用linux/unix操作系统，熟悉shell编程与常用命令?
2、有数据仓库的实际开发经验，对数仓的分层及元数据管理有比较深刻的理解?
3、熟悉常用的大数据相关知识体系与技术栈，如：hadoop、flink、spark、hbase、zk、kafka、flume等，有实际集群部署和系统监控经验?
4、有大数据离线/实时平台的实际开发、优化及较强的trouble shooting能力
5、对coding有极高的热诚，并具有geek精神，如有个人的技术blog或者个人主页，github关注过某项开源项目并能深刻理解其原理(并参与、提交过issue/bug)者优先"
"职位描述：
        
        岗位职责：
负责搜索系统中海量数据的业务分析及应用系统的研发、运维

任职要求：
1、扎实的java/C++/go基本功，理解OO思想、并熟悉常用的设计模式，能够熟练理解JVM原理，熟悉shell编程与常用命令
2、熟悉常用的大数据相关知识体系与技术栈，如：hadoop、flink、spark、hbase、kafka、zookeeper等?
3、有实际大数据应用平台(不仅限于AB Test、血缘关系、OLAP、分布式调度系统 etc)的研发经验
4、熟悉ElasticSearch/Solr搜索引擎并对其有比较深入的优化、开发经验，如对Lucene有一定的研究会更好?
5、对coding有极高的热诚，并具有geek精神，如有个人的技术blog或者个人主页，github关注过某项开源项目并能深刻理解其原理(或参与、提交过issue/bug)者优先"
"职位描述：
        
        工作内容：
1、负责手机端数据采集应用的编写和优化；
2、负责对采集数据的模型分析和挖掘；
3、负责服务器端的逻辑编写和优化。
职位要求：
1、本科及以上学历，计算机相关专业，3年以上相关工作经验；
2、熟练掌握安卓应用的编写，熟悉安卓框架的基本服务及功能；
3、了解常用的perl, python脚本；
4、有数据挖掘、服务器开发背景者优先；
5、工作认真负责，逻辑清晰，抗压能力和学习能力较强。"
"职位描述：
        
        工作职责：
1.?? 参与大数据平台的架构设计与开发。
2.?? 基于业务需求和应用场景，设计和实现大数据产品。
3.?? 为所有业务线提供数据支持和服务。
4.?? 负责技术攻关和创新技术引用，开发具有数据分析、数据挖掘能力的创新型产品。
任职要求：
1.? 计算机相关专业本科以上学历，3年以上数据仓库及BI项目实施经验。
2.? 有基于Hadoop、Hive、HBase、Spark、Storm等大数据技术构建数据分析平台、分布式计算的设计和开发实施经验。
3.? 从事过用户行为挖掘分析、用户画像、推荐系统等大数据应用产品开发。
4.? 熟悉ETL开发及设计。
5. 有机器学习经验者优先。

Versa是什么？
APP Store的2018最佳APP。
Versa可以做什么？一键把你的照片和视频变成艺术品，拯救手机废片的黑科技。掌上PS，0.2秒实现发丝级人物抠像。

谁创造了Versa？格瓦拉产品合伙人CEO蔡天懿，华为芯片算法科学家CTO赵维杰共同创立，再加上4000万App的整编团队。
谁在支持Versa？各轮次资方分别为：真格、红杉、腾讯。"
"职位描述：
        
        岗位描述
1、参与数据平台的搭建
2、完成相关产品的数据处理、分析和挖掘工作；
职位要求：?
1、本科及以上学历，计算机相关专业，每周可实习4天以上，持续3个月以上；?
2、扎实的编程能力，熟悉常见的数据平台架构：例如 Hadoop，Spark，Hive，Storm，Kafka 等；?
3、有极强的责任心和自驱力"
"职位描述：
        
        岗位描述：
1、构建和维护ucloud安全大数据平台，支撑海量数据的接入、计算、存储、查询和分析，对于运行和存储异常情况能及时发现和处理；
2、构建和研发大数据实时处理引擎，支持关联，模型，AI等复杂计算，为ucloud安全产品提供高性能、稳定、可扩展性好的数据实时计算服务；
3、构建和研发大数据离线分析工具，支持深度学习，AI等分析，为ucloud安全产品的运营提供便捷的数据分析工具；
4、使用大数据技术/组件/产品解决业务难题，满足业务需求，支撑安全产品的快速发展。

任职资格:
1、两年以上大数据系统/平台相关工作经验
熟悉大数据处理/分析相关技术(Kafka/Storm/Hadoop/Spark/Hive)等；
2、熟练使用至少一门编程语言(Java/Python/Scala)等；
3、熟练使用至少一种关系型数据库（SQL）和至少一种 NoSQL；
4、具有优秀的编程能力，快速 Trouble-Shooting 定位问题的能力，对新技术有强烈的学习热情；
5、有实时流处理/数据挖掘/机器学习相关经验者优先。"
"职位描述：
        
        岗位职责：
1、负责大数据后端服务功能设计与开发
2、参与大数据平台组件二次开发工作
岗位要求：
1、熟悉Linux操作系统和shell编程，熟练掌握Java编程语言，熟练使用SQL查询语言，对Python编程语言有一定使用经验
2、掌握面向对象设计思维，熟悉常用的设计模式
3、了解Hadoop、Hive、Spark和Kafka等常用大数据组件，有使用经验者优先。"
"职位描述：
        
        岗位职责：
1、负责大数据应用项目设计与开发；
2、大数据平台运维和常规巡检；
3、参与大数据平台相关管理工具开发；
4、参与大数据平台服务接口开发；

岗位要求：
1、熟悉Linux操作系统和shell编程，熟练掌握Java或Scala编程语言，熟练使用SQL查询语言，对Python编程语言有一定使用经验；
2、掌握面向对象设计思维，熟悉常用的设计模式；
3、具有1年大数据的开发经验，熟悉Hadoop、Hive、Spark和Kafka等常用大数据组件；
4、熟悉至少一种关系数据库，有Mysql/PostgreSQL的使用经验；
5、工作积极严谨，有较强的学习能力以及快速解决问题的能力；
6、具备强烈的进取心、求知欲以及团队合作精神；
7、有Spark项目开发经验优先考虑。"
"职位描述：
        
        工作职责：
1、负责大数据平台的系统架构、方案设计；
2、根据项目需求，分析，设计，并实现系统的架构方案。使系统架构具有合理性和可扩展性；
3、负责开发数据统计系统,海量数据分析/查询、分布式存储、流式/实时计算等应用层架构搭建及核心代码实现 ；
4、技术难题攻关，持续提升核心系统性能，保证系统的安全、稳定、快速运行；
?
任职要求：
1、熟悉Hadoop底层文件系统，熟悉Hadoop分布式计算框架，熟悉掌握HDFS、Hbase、Hive、Mapreduce、Spark、Storm、Flink等.
2、精通Java, golang, Python 至少两种编程语言，有较强的分布式计算基础和软件工程能力
3、熟悉业界有影响力数据仓库和大数据领域的产品、解决方案形态和技术，熟悉OLAP、OLTP引擎和DB，熟悉主流数据整合、治理技术和工具；
4、熟悉大数据和数仓领域的系统架构设计方法，有海量数据系统的安装部署维护经验，对大规模数据并行计算／传输／处理等有丰富的经验者优先；
5、熟悉掌握通用大数据数据合并、建模、抽取、分析挖掘机、展示等挖掘算法，具有在实际项目中结合业务场景开发大数据算法的经验者优先；
6、有大型分布式、高并发、高负载、高可用系统设计、开发和调优经验者优先；"
"职位描述：
        
        Tubi 是一家以数据为中心的公司，从产品路线图决策到为我们的服务提供强大动力的算法，数据都处于中心位置。 我们正在寻找热衷于构建可扩展、高吞吐量数据基础架构的高级工程师。??
工作职责：
1.???? 负责批量、实时任务开发和维护
2.???? 负责推荐系统架构搭建和维护
?
职位要求：
1.???? 在数据架构方面有一定实践经验
2.???? 熟悉掌握 Scala 或者 Python
3.???? 对于新技术，能快速评估和权衡利弊，迅速完成和交付项目
4.???? 了解推荐系统、数据挖掘、机器学习等常用算法
5.???? 良好的英语听说读写能力
6.???? 加分项：熟悉 Apache Spark 原理及应用；熟悉 AWS、S3、Redshift、Airflow 等
?
希望了解我们更多？不妨看下这些文章：?
Tubi 中国团队 http://chinateam.tubi.tv/?
Tubi 为什么 https://zhuanlan.zhihu.com/p/36138310?
Tubi 技术博客 https://code.tubitv.com/?
Tubi 主站?https://tubi.tv"
"职位描述：
        
        职位描述：
1. 负责公司大数据身份反欺诈研发及实施团队的管理；?
2. 负责公司金融、政府、企业等领域大数据反欺诈系统的开发、建设；
3. 配合业务、产品，根据不同的业务需求，灵活快速完成挑战性的项目，并保障数据体系的可运维，稳定和效率。

任职要求：
1、具有5年及以上大数据团队管理、开发经验，知识全面丰富，具备技术探索能力；
2.精通Hadoop/Hive/Spark/Storm/Kafka/Flume等技术，熟悉HBase，MongoDB存储产品； 有长期实际开发和应用经验，具备系统优化与性能调优能力；
3.熟悉LINUX，JAVA基础扎实，掌握io、多线程、集合等基础框架，熟悉分布式、缓存、消息、搜索等机制，熟悉脚本编程；有shell、Python开发经验者优先；
4.熟悉数仓体系和大数据处理平台相关子系统功能，如ETL、数据报表、监控、数据质量等；??
5.有技术热情，有良好团队管理能力，团队合作精神，跨团队协调沟通能力, 较强的责任心和抗压能力。"
"职位描述：
        
        职位描述：
1. 负责公司大数据身份反欺诈研发及实施团队的管理；?
2. 负责公司金融、政府、企业等领域大数据反欺诈系统的开发、建设；
3. 配合业务、产品，根据不同的业务需求，灵活快速完成挑战性的项目，并保障数据体系的可运维，稳定和效率。

任职要求：
1、具有5年及以上大数据团队管理、开发经验，知识全面丰富，具备技术探索能力；
2.精通Hadoop/Hive/Spark/Storm/Kafka/Flume等技术，熟悉HBase，MongoDB存储产品； 有长期实际开发和应用经验，具备系统优化与性能调优能力；
3.熟悉LINUX，JAVA基础扎实，掌握io、多线程、集合等基础框架，熟悉分布式、缓存、消息、搜索等机制，熟悉脚本编程；有shell、Python开发经验者优先；
4.熟悉数仓体系和大数据处理平台相关子系统功能，如ETL、数据报表、监控、数据质量等；??
5.有技术热情，有良好团队管理能力，团队合作精神，跨团队协调沟通能力, 较强的责任心和抗压能力。"
"职位描述：
        
        工作职责：
1.负责大数据反欺诈产品和方案在金融行业?/?互联网行业?/?游戏行业等?的推广支持；
2.挖掘并逐步引导行业需求，树立公司产品在该行业的品牌和产品优势地位；
3.开拓新市场，发展新客户，探索新场景新模式，撰写形成符合客户需求的解决方案；
4.负责大数据相关产品市场信息的收集及竞争对手的分析；

任职要求：
1.?本科以上学历，计算机或相关专业；
2.?两年以上金融行业?/?互联网行业?/?游戏行业客户解决方案经验；有良好的沟通、表达、文档能力；
3.?形象良好，语言表达和思维逻辑清晰、性格乐观、能承受压力；
4.?了解信息安全技术者优先考虑；
5.?大数据反欺诈公司从业者优先考虑；
6.?有较强的学习能力，为人踏实稳重，有高度责任心。"
"职位描述：
        
        工作职责：
1、参与系统的需求分析和技术方案预研。
2、负责大数据产品的研发、设计工作，及大数据平台的完善；
3、负责各种生产、测试环境业务系统问题的快速定位和解决；
4、负责代码编写、单元测试，确保代码执行性能、质量和安全；
5、协助客户参与各种环境业务系统的投产及技术支持。
?
任职要求：
1、思路清晰，善于思考，能独立分析和解决问题，较强的表达和沟通能力，责任心强，具备良好的团队合作精神和承受压力的能力，能接收项目驻场；
2、熟练使用Kafka、Redis、Storm、ElasticSearch等大数据组件，并有相关项目开发经验；
3、对MySQL、Oracle数据库有一定的了解和使用经验；
4、对Tomcat、Weblogic服务器有一定的了解和使用经验；
5、有Java开发经验者优先；
6、有shell、Python开发经验者优先；
7、工作积极主动，具有良好的团队协作精神；
8、逻辑清晰，快速的学习能力及良好的沟通能力。"
"职位描述：
        
        工作职责：
1、利用大数据相关组件实现企业级数据的搜集和存储； 有开源组件源代码的阅读及修改经验优先考虑；
2、利用大数据相关组件实现数据清洗，转换等工作；?
3、利用大数据相关组件提供（数据可视化以及海量数据下的多维钻取分析）的接口；?
4、整合大数据相关组件，构建数据沙盒，支撑多租户的数据分析；?
5、组件性能调优；??

任职资格：?
1、4年以上工作经验，2年以上数据项目经验，至少熟练掌握Java，C++,Scala，Python中的一种或多种；?
2、熟悉Spark或Mapreduce等一种分布式计算框架；
3、熟悉SparkStreaming,? Storm，Flink,等一种流处理框架；
4、熟悉MPP和搜索引擎，例如Impala或者Presto，Elasticsearch等；?
5、熟悉分布式存储系统如：logstach，flume，zookeeper，kakfa，elk，S3等。
6、熟悉NoSQL存储如：Hbase、MongoDB。?
7、大数据及数据分析：hadoop，spark，hdfs，storm，flink，等
8、有大数据相关组件性能调优经验或机器学习经验优先考虑；
9、拥有良好的学习能力。"
"职位描述：
        
        工作职责：?

1、利用大数据相关组件实现海量的搜集和存储；?
2、利用大数据相关组件实现数据清洗，转换等工作；?
3、利用大数据相关组件实现数据可视化以及海量数据下的多维钻取分析；?
4、整合大数据相关组件，构建数据沙盒，支撑多租户的数据分析；?
5、组件性能调优；??

任职资格：?

1、3年以上相关工作经验，至少熟悉Java，Scala，Python中的一种；?
2、熟悉Spark，Flink，Mapreduce等分布式计算框架。
3、熟悉 Storm，SparkStreaming等流处理框架。
4、熟悉MPP和搜索引擎，例如Impala，Presto，Elasticsearch等；?
5、熟悉熟悉分布式存储系统，例如HDFS，Ceph等。
6、熟悉列存储，例如Hbase，MongoDB，CouchDB等；?
7、了解PowerBI，Tableau等任一一款可视化工具优先考虑；?
8、有大数据相关组件性能调优经验或机器学习经验优先考虑；

如果你还具备以下技能那就更好了：1.?喜欢阅读源代码；2.?热爱阅读各类技术、非技术书籍；3.?喜欢学习，拥有持续学习的能力，认为学习本身就是一种乐趣；4.?喜欢开源软件，乐于知识分享；5.?拥有自我管理能力，自我驱动，做自己的老板。


加入TW，你将会得到什么提升：? 全球化技术视野，出国出差机会? 结对编程，一对一“过招”快速学习成长的机会? 敏捷开发技术实践环境：? 学习型组织，书海遨游，session多多，有饭有Fun? 精彩纷呈的各类专属社区活动，等待你的参与分享? 努力实现梦幻般的男女1：1工作环境? 水果、茶点、饮料随时享用职业发展路径:? 热爱代码的你，可以醉心于代码的世界，专心学习和研究技术? 热爱分享的你，可以成为咨询师，为有需求的客户提供帮助? 热爱创造的你，可以在内部的支持下，开发属于你自己的产品，走内部创业之路? 期望走管理之路的你，一样可以通过主动承担更多责任变得强大? 包罗万象的你，最后你成为了项目通用的专家，为内部同事，外部客户搭建良好的沟通合作平台。"
"职位描述：
        
        工作职责：
1、利用大数据相关组件实现海量的搜集和存储；
2、利用大数据相关组件实现数据清洗，转换等工作；
3、利用大数据相关组件实现数据可视化以及海量数据下的多维钻取分析；
4、整合大数据相关组件，构建数据沙盒，支撑多租户的数据分析；
5、组件性能调优；?
?
任职资格：
1、3年以上相关工作经验，至少熟练掌握Java，Scala，Python中的一种或多种；
2、熟悉Spark，Flink，Mapreduce等分布式计算框架。
3、熟悉 Storm，SparkStreaming等流处理框架。
4、熟悉MPP和搜索引擎，例如Impala，Presto，Elasticsearch等；
5、熟悉熟悉分布式存储系统，例如HDFS，Ceph等。
6、熟悉NoSQL存储，例如Hbase，MongoDB，CouchDB等；
7、了解PowerBI，Tableau等任一一款可视化工具优先考虑；
8、有大数据相关组件性能调优经验或机器学习经验优先考虑；"
"职位描述：
        
        
 负责建立一个复杂的大数据分析平台，用于改变大型工业管理其资产的方式
 建立高度可扩展的框架，用于获取、转化、增强 IoT规模的数据
 建立分布式存储和计算系统，
 使用Hadoop生态系统组件开发数据结构和流程
 负责ETL，Data Pipeline
 实施机器学习算法于软件上
 了解世界前沿的工具和框架，并能够针对具体任务选择最佳工具


任职要求：

 计算机、软件工程等相关专业本科，研究生学位优先
 3年以上系统开发经验
 优秀的编程能力，熟悉掌握Python、Java
 熟悉各种数据处理技术（Hadoop，Spark，Kafka等）
 1年以上NoSQL数据库经验
 具有REST API的经验或知识，并通过微服务提供数据。
 使用版本控制（Git等）进行协作代码开发的经验。


加分项：

 作为开源贡献者的经验
 有数据建模（机器学习）经验
 在Github上有上传代码或demo


除此之外HR想说：

 截至目前，我们的程序员小伙伴都毕业于211/985学校，还有硅谷的技术大牛带队指导，探寻讨论技术设计、技术框架和技术选型，是一个纯技术、重技术、崇尚技术的小团队；
 热烈欢迎各种小姐姐加入；
 想要转型学习使用其他语言的小伙伴，也请快快砸来简历，我们更看重潜力而非目前的技术水平，HR小姐姐期待你们的加入~~"
"职位描述：
        
        工作职责：?
1、负责大数据统计平台建设与优化；
2、负责广告效果分析，反作弊平台建设；
3、负责移动广告平台相关系统的设计研发及持续优化。
?
职位要求：
1、计算机或相关专业本科学历及以上，2年工作经验；
2、精通大数据采集、处理、存储、查询相关技术；
3、熟悉Hadoop/Hbase/Hive/Spark/Storm/Kafka相关技术；
4、至少熟练掌握 Java/Scala/Python 中一门语言；
5、有做过大数据量查询优化的优先；
6、有大数据服务运维、性能调优者优先；
7、熟悉常用的设计模式，对MVC框架有了解；?
8、强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"
"职位描述：
        
        岗位职责：
1、负责海量数据的实时计算、离线计算、存储、查询；
2、负责研发类大数据平台的规划、设计、开发和运维工作；
3、参与用户画像、智能推荐系统的规划与设计；
任职要求：
1、全日制本科以上学历，有3年及以上大数据开发相关工作经验；
2、熟悉Spark、spark streaming、Hadoop相关的框架和技术；
3、具备扎实可靠的编程能力，精通scala/java编程语言，熟悉Flume、kafka、Hive、Sqoop、Hue等大数据工具；
4、具备良好的学习能力、沟通能力、适应能力，责任心强，能在压力下独立解决问题；
5、具备海量数据处理经验、数据挖掘、平台调优工作经验者优先。"
"职位描述：
        
        工作职责:1. 基于上亿量级用户日志数据，实现零售门店关键指标的统计功能；2. 深度分析用户线上和线下顾客的人口统计学信息和行为规律，并做产品化研究和开发；2. 负责大规模用户数据离线/在线服务的架构设计和开发；3. 从事大数据创新应用产品和前瞻技术的研究和开发。
任职资格:1. 3年以上软件开发经验；2. 精通Java编程，大型系统中运用Java的经验，熟练使用Spring、iBatis等开源框架；3. 熟悉mysql数据库开发，精通SQL语言；4. 有MongoDB、Redis等NoSql应用的开发经验；5. 掌握主流的大数据处理技术，包括hadoop, Hive, Spark等，有高并发系统开发经验优先；6. 熟悉Hadoop、HBase、ElasticSearch者优先；"
"职位描述：
        
        工作职责:负责支撑人口统计(统计魔方)产品研发及项目交付的位置大数据挖掘和人口统计模型开发工作。包含人口统计、人口监测、人口构成、人口流动、人口预测等数据模型开发。具体如下：1. 基于上亿量级位置数据，实现人口统计、人口监测、人口流动等指标的数据加工工作；2. 负责大规模用户数据离线/在线服务的架构设计和开发；3. 从事大数据创新应用产品和前瞻技术的研究和开发。任职资格:1. 计算机或相关专业本科以上学历； 2. 精通Java/python/Scala程序开发(至少一种)，熟悉Linux/Unix开发环境；3. 熟悉常用开源分布式系统，Hadoop/Hive/Spark；4. 熟悉数据仓库原理，熟悉SQL语言;5. 具有良好的沟通协作能力，具有较强的分享意愿，对业务有很好的理解能力。6. 位置大数据数据挖掘、数据科学、统计学背景优先。"
"职位描述：
        
        工作职责:
负责支撑人口统计(统计魔方)产品研发及项目交付的位置大数据挖掘和人口统计模型开发工作。包含人口统计、人口监测、人口构成、人口流动、人口预测等数据模型开发。具体如下：
1. 基于上亿量级位置数据，实现人口统计、人口监测、人口流动等指标的数据加工工作；
2. 负责大规模用户数据离线/在线服务的架构设计和开发；
3. 从事大数据创新应用产品和前瞻技术的研究和开发。
任职资格:
1. 计算机或相关专业本科以上学历；
2. 精通Java/python/Scala程序开发(至少一种)，熟悉Linux/Unix开发环境；
3. 熟悉常用开源分布式系统，Hadoop/Hive/Spark；
4. 熟悉数据仓库原理，熟悉SQL语言;
5. 具有良好的沟通协作能力，具有较强的分享意愿，对业务有很好的理解能力。
6. 位置大数据数据挖掘、数据科学、统计学背景优先。

数睿科技有限公司 / Intelli Global Corporation (IGC)
IGC是由 ???? 杨德斌（前香港政府CIO)，
车品觉（前阿里巴巴数据委员会会长)，以及
Antoni Vives（前西班牙巴塞隆{副市长) 共同创立；
并有多位国际级智慧城市及大数据科学专家作为公司顾问，包括Stephen Goldsmith（前美国纽约市副市长）、杜平（原国家发改委司长/国家信息中心常务副主任(法人)兼智慧城市研究中心主任)，期望借助专家团队在智慧城市顶层设计以及城市管理的丰富治理和实战经验，辅以数字化的智慧城市管理工具/平台，帮助全球各地城市管理者实现新型智慧城市管理模式。
?
我们的愿景
共创“以人为本，数据驱动，指标向导”的宜居智能城市。
?
公司业务
IGC将为全球不同的城市提供智慧城市顶层设计顾问服务，并提供关键智慧城市和大数据/人工智能相关平台产品，协助企业和政府利用智能城市理念管理城市，提高城市居民的生活质量，降低管理成本，提升城市治理效率。
目前, IGC 收购了一支数据科学家和技术团队, 他们利用第三方数据开发了人口动态监测产品， 并已被北京统计局采用。
IGC与国家发展改革委员会下属的国家信息中心建立了战略伙伴关系, 成立了未来城市联合实验室。
此外, IGC 还与 Talkingdata、阿里云 和 AWS 签署了合作协议, 互相使用和转售其产品和解决方案。
IGC全球总部设于香港，K在中国北京和珠海横琴自贸区设立分公司。公司计划在未来几年内将聘请100至300专业和研发人才。"
"职位描述：
        
        工作职责:1. 负责基础服务的规范制定和架构设计2. 负责基础服务的研发3. 负责服务编排、服务组装框架的架构设计4. 负责服务编排、服务组装框架的研发5. 负责海量数据OLAP解决方案的调研和封装任职资格:1. 精通Java，熟练使用多线程编程技术，了解Scala语言，能使用Scala编写一般Spark程序，熟悉Python/Go等其它编程语言更佳； 2. 基本功扎实，对编写程序代码很考究，有良好编码风格，有实际参与编码或主导研发的系统或项目；3. 精通Hadoop/Spark/HBase/Hive/Storm/Kafka等大数据开源技术框架中至少2种，读过相应开源项目源码更佳； 4. 能够熟练使用Spring/SpringMVC/MyBatis/Spring Boot等开源框架；熟悉Jetty（或Tomcat）常用的WEB容器； 5. 熟悉MySQL数据库，能够使用SQL编程，了解Greenplum,vertica更佳； 6. 良好团合作意识，能独立分析数据需求，并转化成系统模块或接口，能独立进行代码实现。"
"职位描述：
        
        工作职责:工作职责：1. 参与Saas大数据平台的演进与迭代，独立完成需求分析，负责新功能的研发；2. 维护和优化Saas大数据平台的etl系统；3. 维护和优化Saas大数据平台的计算系统和存储系统；4. 参与架构设计与系统部署等工作。任职资格:1. 本科学历，具有3到5年相关行业的工作经验，具有良好的编程基础，熟练掌握java语言；具备jvm调优经验者优先；2. 具备druid/kafka/flink/cassandra/elasticsearch等相关大数据技术栈相关工作经验；3. 有高并发编程经验优先；4. 善于沟通和团队合作，工作细致负责，具有一定的抗压能力。"
"职位描述：
        
        工作职责:1.基于TalkingData数据和客户数据，深度分析数据中的规律，挖掘数据价值； 2.参与数据、工具平台相关的功能接口、数据接口，实现业务功能； 3.参与数据平台、工具平台的架构、设计以及实现； 4.与数据计算/存储团队合作，优化数据平台的性能，解决兼容性、功能性Bug，提高稳定性。 任职资格:1、精通Java语言、熟悉Spring、Spring MVC、Mybatis等常用Java框架；2、熟悉RDBMS（比如MySQL）的开发，熟悉SQL语言；3、熟悉Java并发编程，有优良的Trouble Shooting能力，能解决各种性能瓶颈（比如IO、CPU、Memory等）； 4、熟悉NoSql应用（比如MongoDB、Redis等）的开发经验者优先；5、熟悉常用大数据中间件，有Zookeeper、Kafka、Elasticsearch等开发经验者优先；6、掌握Hadoop、Spark、Storm中至少一种大数据技术，阅读过源代码者优先； 7、对大数据技术有钻研热情，乐于分享；8、有金融行业经验者优先； 9、出色的沟通技巧和团队合作精神。"
"职位描述：
        
        工作职责：
1.?负责大数据平台的基础组件开发和服务监控，保证数据平台服务稳定性的情况下完成技术迭代。2.?负责各类数据产品的设计和开发工作。3.?负责数据开发团队的人员管理和流程搭建，帮助团队成长。4.?参与数据的收集、存储、计算、分析、挖掘、展示的全过程，通过数据达成业务决策。

任职要求：
1.?五年以上开发经验，至少两年的团队管理经验，了解人员考核和管理。2.?良好的沟通能力和业务理解能力，较强的数据和逻辑分析能力。3.?自我驱动，良好的学习和思考习惯。4.?熟悉hadoop、spark、kafka、flume、hbase等大数据常用组件，有过大规模的设计和实施经验，能针对业务场景进行优化。5.?熟悉Web的前后端开发，有过使用Spring?Cloud，Vue，ELK等开发经验者优先。"
"职位描述：
        
        工作职责：
1、负责数据仓库架构设计、建模和ETL开发，构建可扩展的数据仓库和分析解决方案；
2、负责分析和解释产品试验，市场运营活动等结果，为产品改进，推广等提供数据支持；
3、负责建立用户数据分析模型，针对用户行为进行数据监控和统计，发现用户行为模式与规律，为改进推荐系统提供支持。
职位要求：
1、全日制本科（重点高校）学历及以上，计算机相关专业，热爱计算机科学和互联网技术，乐于快速学习和尝试新技术、新工具；
2、具备强悍的编码能力，熟练使用SQL，熟悉Python或R语言的优先；
3、优秀的分析问题和解决问题的能力，对解决具有挑战性问题充满激情；
4、熟悉至少一项分布式计算平台，例如Hadoop，Spark，Hive，Storm，Kafka等；
5、有较强的逻辑/概率思维能力，善于分析、归纳、解决问题。"
"职位描述：
        
        工作职责：

1、负责大数据平台研究开发，数据采集；2、流式数据处理：参与开发高并发、实时的流处理作业，了解数据仓库架构设计、建模和ETL开发。职位要求：1、全日制本科（重点高校）学历及以上，计算机相关专业，热爱计算机科学和互联网技术，乐于快速学习和尝试新技术、新工具；2、具备强悍的编码能力，熟练使用java或scala；3、至少熟悉一种流式计算框架，如spark streaming或flink，熟悉大数据相关组件hbase、hive、kafka等；4、优秀的分析问题和解决问题的能力，对解决具有挑战性问题充满激情；5、有较强的逻辑/概率思维能力，善于分析、归纳、解决问题。"
"职位描述：
        
        岗位职责：
我们致力于为shopee搭建通用数据平台产品，对TB级别的商品数据进行匹配和价格分析，为数据研发和运营分析提供高效、可靠的大数据产品。
?1. 负责公司大数据产品的前端界面设计与开发；
2. 前端表现层及与前后端交互的架构设计和开发；
3. 根据产品需求，分析并给出最优的页面前端结构解决方案；
4.??持续优化前端体验，优化代码并保持良好兼容性，提升web界面的友好和易用性；
5.??能够对前端的技术难点进行技术攻关；
6.??持续集成自研的大数据产品。
任职要求：
1. 本科以上学历，至少2年以上工作经验；
2.?责任心强，有独立完成任务能力；
3.?熟悉HTML/HTML5、CSS，熟悉页面架构和布局，对Web标准和标签语义化有深入理解；
4.?熟悉Ajax、JavaScript、DOM、XML、JSON等前端技术，对模块化开发有经验者优先；
5.?理解WEB标准和兼容性，能编写符合W3C标准、兼容多种浏览器的前端页面代码；
6.?有大数据产品开发经验者优先；
7. 提供 github/开源项目优先。"
"职位描述：
        
        工作职责：
我们致力于为Shopee构建企业级的数据仓库，为数据运营人员提供高可用、高一致、高准确的数据支撑，实现跨境电商业务的精准化和智能化运营。
1.?负责数据仓库建设以及数据模型的设计和开发
2.?负责数据仓库ETL流程的优化及解决ETL相关技术问题
3. 负责跨数据中心的数据采集和接入工作
4.?参与跨境电商业务相关数据指标的设计与计算
5. 持续优化数据仓库及数据集市应用
任职要求：
1.??本科及以上学历，计算机等理工科相关专业
2.??2年及以上企业级数据仓库开发经验，日增量数据达到TB/PB级
3.??熟悉数据仓库理论，具备复杂的业务需求梳理能力
4.??熟练掌握SQL开发，熟练掌握Hive等数据仓库中的一种或几种
5.??熟练掌握Hadoop及Map-Reduce应用开发，熟练掌握HBase、Storm、Spark、Kafka、Druid等大数据开发工具中一种或几种
6.??熟悉Linux系统，具备shell、python等脚本和Java语言开发能力
7.??有Golang语言开发经验者优先
8.??学习能力强，喜欢研究开源新技术，有团队观念，具备独立解决问题的能力"
"职位描述：
        
        工作职责：
我们致力于为shopee搭建通用数据平台，对TB级别的商品数据进行匹配和价格分析，为运营人员以及我们的卖家提供可靠和准确的信息。
1.??参与跨数据中心数据同步和数据集成架构设计, 实现全量和增量数据同步通用系统
2.??参与数据搜索平台的设计和优化
3.??参与高可用数据平台跨数据中心容灾设计
4.??实现多国家和地区TB甚至PB级别商品数据的收集
5.??持续集成自研的数据挖掘系统
6.??持续集成自研的人工智能推荐系统
工作要求：
1. 本科以上学历，至少2年以上工作经验
2.?责任心强，有独立完成任务能力
3.?语言不限, 有Golang经验优先
4.?有丰富的服务端经验
5.?熟悉 Elastic Search, Kafka，Redis或者 NoSQL/NewSQL优先
6.?有跨数据中心公有云（阿里云, AWS, DigitalOcean, Linode...）经验优先
7.?有TB甚至PB级别数据爬虫经验优先
8.?提供 github/开源项目优先"
"职位描述：
        
        任职要求：
1.从事数据仓库领域工作2年及以上
2.熟悉数据建模、ELT设计与应用、报表开发等
3.熟悉数据仓库领域知识与技能
4.熟悉常用数据库的性能特点，能够灵活运用SQL实现海量数据ETL加工处理
5.了解大数据基础架构和平台，具备相关产品（Hadoop、Hive、HBase、Pig、Sqoop、Spark）项目应用研发经验
6、熟悉Linux系统，能熟练运用Java、Scala、Python语言进行开发
岗位职责：
1.负责公司数据仓库的架构设计和开发。
2.负责数据平台相关数据管理工作，如研发规范、质量规范、保障规范的制定与推动实施落地
3.负责数据仓库的建设和维护，包括需求调研分析、软件规划、物理模型、数据处理（抽取、清洗、转化）、项目实施管控等"
"职位描述：
        
        职位描述：1.?负责公司数据架构设计，对企业数据管控具有深刻理解；2.?负责数据质量管理、元数据管理、数据标准管理、数据交换等数据管控治理领域；3.?建立概念数据模型，根据业务发展需求构建合理的数据平台架构；4.?带领大数据团队平台开发方向的成员，一同推进大数据相关项目，以及算法落地等项目；5.?进行CDH集群的管理，以及维护大数据平台。职位要求：1.?全日制本科及以上学历，计算机、信息处理、数学、统计等相关专业背景，5年以上工作经验，2年以上数据治理经验；2.?熟悉数据治理、数据标准、数据建模、主数据、元数据管理方法论，并有丰富的项目经验；3.?熟悉linux/Java，以及Hadoop生态圈的组件框架，具备在组件框架基础上开发的丰富经验；4.?能从项目管理的角度，运用数据治理的相关理论和方法，来统筹和协调各部门推进项目的落地；5.?熟悉关系型数据库、NoSQL数据库、HBase，Hive、Hadoop等；6.?有信息模型设计、用户行为分析、用户标签画像、运营数据分析工作经验者优先；7.?有CDH集群管理以及大数据平台运维经验者优先。"
"职位描述：
        
        1、能够带领技术人员基于Hadoop/ Spark streaming/Storm/Kafka/Elasticsearch等平台进行海量数据应用系统开发； 2、负责大数据平台产品规划、研发、维护和推广， 打造业内领先大数据处理技术。 3、负责结构化和非结构化数据的解析和清洗,海量数据查询和报表展现；
4、负责超大规模数据平台的搭建、维护和优化；
5、负责大数据采集、存储框架研究，在线或离线数据存储模型设计；
6、负责大数据平台新技术的开发使用和性能优化，测试。

岗位要求：
1、5年以上大数据平台方向工作经验、具有团队管理经验 。
2、精通Hadoop/ Spark streaming等各类大数据技术方案， 有大规模实施经验及具有OLTP、OLAP的搭建经验；
3、精通分布式存储，对于互联网公司常用的分布式存储，如es/redis/mongodb/hbase等有专家级的见解和掌握能力。
4、熟悉大数据的存储/计算/检索相关技术：hadoop/hive/ Spark streaming/storm/ Flink/elasticsearch/redis/hbase/kafka/flume等大数据生态圈常用组件，具备非结构化数据到结构化数据转换中所需要的经验和技术积累。?
5、了解数据分析、数据仓库，以及数据挖掘、机器学习算法? 。
6、了解业内常见的数据应用，譬如推荐、搜索优化、广告等。
7、 具备大型数据仓库架构设计、模型设计等相关经验，成功主导某领域核心模块设计。
8、有体育（足球）领域爱好者优先。"
"职位描述：
        
        【工作职责】1、负责ROOBO大数据仓库平台的开发建设. 跨部门协作，协同分析并统一制定数据规范，收集业务所有决策数据。2、设计并实现大规模分布式计算集群，处理海量数据 ，并逐步建立实时数据流分析集群。 3、通过分布式实时计算集群建立数据仓库，在此基础上能灵活统计各种维度的数据报表4、深入数据挖掘和数据分析，提供智能BI数据辅助公司做战略决策【任职资格】 1、熟练使用Java/Scala/C++/Python 等语言进行开发（至少熟练掌握一种），有高效、高可靠代码开发经验? 2、有扎实的算法基础，熟悉常见的数据结构，了解分布式算法和分布式系统? 3、精通常见的开源分布式计算/存储相关技术，包括Hadoop，Hive，Pig，spark/storm 4、有构建通用数据仓库的经验，熟悉OLAP引擎者的设计和开发者优先 5、熟悉机器学习，有数据挖掘和深度数据分析者优先"
"职位描述：
        
        
工作职责:

-设计、开发和优化数据平台，包括但不限于数据爬取、存储、查询、传输
-开发和优化大规模高性能服务
-负责图片存储、文件存储和结构化数据存储等领域相关前沿技术的研究和应用
-负责产品或者子方向性规划及相关人员技术指导

工作要求:

-熟悉至少一种下列编程语言：C/C++、Java、Python、Go、PHP
-熟练掌握多线程、异步编程、网络编程技术，并且有丰富的实际项目经验
-熟悉常用的数据结构、算法设计
-熟悉存储设备、文件系统、Linux操作系统原理
-了解业界主流的分布式存储系统，有大规模分布式存储系统设计、开发经验者优先
-有良好的团队合作意识, 积极主动的工作态度，快速学习能力和较好的沟通表达能力
具有以下条件者优先
-主导过企业私有或公有数据平台的实施和架构设计
-熟悉分布式系统理论，有大规模分布式系统设计架构经验(包括Hadoop/HDFS/Openstack/Ceph/mongodb/dynamodb/aws-s3/GFS/BigTable等)
-熟悉数据库技术，有数据库内核或者nosql数据库的开发经验
-熟悉操作系统内核，特别是存储设备、文件系统等部分"
"职位描述：
        
        岗位职责：
1. 独立完成小型项目的系统分析、设计，并主导完成详细设计和编码的任务，确保项目的进度和质量；?
2. 能够在团队中完成Code Review的任务，确保相关代码的有效性和正确性，并能够通过Code Review提供相关性能以及安全的建议；
3. 深入理解数据业务，分析用户需求，能够从用户角度推动业务发展，提升公司数据应用能力；?

岗位要求：?
1. 三年以上Java开发及设计经验，优秀的编程能力及良好的开发习惯。具备独立沟通需求，设计，架构，开发的能力；或者熟悉数据仓库模型设计，具备海量数据加工处理（ETL）相关经验；?
2. 至少熟悉一种关系型数据库如Oracle、mysql等，熟练掌握Hive/SQL，熟悉Hadoop/Map-Reduce/MPI分布式计算框架，有海量数据处理经验者优先;?
3. 具有良好的商业敏感度和优秀的数据分析技能，能够开发创新而实际的分析方法以解决复杂的商业问题；
4. 具有良好的沟通、团队协作、计划和创新的能力；"
"职位描述：
        
        岗位职责：
1. 独立完成小型项目的系统分析、设计，并主导完成详细设计和编码的任务，确保项目的进度和质量；?
2. 能够在团队中完成Code Review的任务，确保相关代码的有效性和正确性，并能够通过Code Review提供相关性能以及安全的建议；
3. 深入理解数据业务，分析用户需求，能够从用户角度推动业务发展，提升公司数据应用能力；?

任职要求：?
1. 三年以上Java开发及设计经验，优秀的编程能力及良好的开发习惯。具备独立沟通需求，设计，架构，开发的能力；或者熟悉数据仓库模型设计，具备海量数据加工处理（ETL）相关经验；?
2. 至少熟悉一种关系型数据库如Oracle、mysql等，熟练掌握Hive/SQL，熟悉Hadoop/Map-Reduce/MPI分布式计算框架，有海量数据处理经验者优先;?
3. 具有良好的商业敏感度和优秀的数据分析技能，能够开发创新而实际的分析方法以解决复杂的商业问题；?
4. 具有良好的沟通、团队协作、计划和创新的能力；"
"职位描述：
        
        About RELX
雾芯是一家新锐互联网创业公司，现已成功打造知名电子烟品牌RELX 悦刻。RELX现已获IDG、源码资本和红杉资本的B轮投资。RELX与著名产品研发工程师、药剂师，以及20年经验的优秀调香师合作，在全球市场推出了产品RELX0。未来十年，我们将怀揣加速全球向更健康、更愉悦的生活方式转变的使命，不断创新、奋勇前行。?

Who are we looking for?
具体职责如下：?
1 负责运营后台产品的统一规划，包括产品功能设计、逻辑流程确认、运营后台搭建、实现跟进与优化等
2 负责调研和收集内部各部门对后台的需求，并进行需求管理及方案策划
3 负责协调开发、设计、运营及其他部门同事，推动产品功能及所需内容落地

In return, we offer you
人才是RELX最宝贵的资产，所以我们将为每一位员工提供更广阔的发展空间。?
拥有一份有回报的职业，在透明和业绩驱动的文化中不断成长。RELX每六个月会根据员工的表现提供一次晋升机会。?
拥有内部和外部提供多样化的培训机会，以更快地提高自己的能力。?

What you will bring to the table
1 统招211本科及以上学历，计算机、通讯、电子信息专业优先
2 2年及以上后台产品策划经验，具备足够的业务理解、梳理业务逻辑能力
3 能够主动地和内部各个部门主动沟通，深入理解业务需求，抓住主要问题，形成产品方案
4 熟练使用AXURE, VISIO等工具，输出清晰的MRD/PRD
5 能独立负责项目规划与落地执行，有较好的跨团队沟通及项目管理能力
6 对创业及从0到1搭建一款有意思的新产品充满热情、抗压能力强、执行力强
7 烟民优先，热爱电子产品者优先

Compensation and benefits here
・?极具竞争力的薪酬+丰厚的年终奖金。?
・?定期的团建和Happy Hours 提供无限量零食饮料酒水，工作的同时可以放松身心享受生活。"
"职位描述：
        
        岗位职能

 构建分布式大数据服务平台, 大数据系统运维等工作；
 大数据数据采集量存储, 离线/实时计算, 实时查询；
 大数据部后端作业调度平台开发；
 负责大数据可视化架构设计与搭建；
 理解用户数据统计分析和挖掘的应用场景, 抽象成为数据产品需求；


任职要求：

 有3年以上互联网或移动互联网并基于Hadoop/Storm/Hbase等应用开发经验，对分布式计算、数据仓库理论有深刻理解；
 精通大数据生态圈常用技术如Kafka，Flume，Zookeeper等；
 大数据可视化架构设计，满足业务人员数据需求；
 熟悉Java，scala, shell, python 开发等至少一种语言；
 熟悉维度建模和数据仓库数据管理相关的知识；"
"职位描述：
        
        职位描述：
- 基于每日百亿级广告数据，搭建大数据处理平台
- 实时数据处理：实现流式事件的实时计算，落地储存
- 离线数据处理：完成数据仓库的建立，为数据挖掘提供有效的数据
- 数据分析和建模：用户日志数据抽取、清洗，进行用户标签、行为特征研究、算法设计
- 挖掘用户行为数据和广告投放数据的深层次关系，分析媒体、用户、广告主等数据来提高变现效率
- 为产品和项目提供其他数据挖掘支持，了解广告业务，能和PM合作，基于数据驱动持续优化数据产品
?
任职要求：
- 编程能力强（Java、Python等），熟悉大数据处理技术，善于学习应用业界领先数据架构和技术
- 对大数据开源软件有使用经验，对Hadoop、Hive、Spark其中一项精通
- 熟悉主流的机器学习和数据挖掘算法，包括数据清洗、统计学习、分类聚类算法，并能够验证算法效果，将算法应用在广告业务中
- 良好的团队合作能力和学习能力，对技术有热情，思路开阔，善于思考，关注业界新知，喜欢和他人交流和分享，善于从数据中发现、思考并解决问题
- 有完整数据挖掘或数据分析经历者优先
- 有大型广告系统研发经验者优先"
"职位描述：
        
        BI数据分析师/高级数据分析师?工作职责：?1. 负责根据业务场景，分析数据内涵、解答业务问题和支持决策?2. 负责专题分析，形成业务板块以及业务领域等相关的分析报告?3. 能够持续动态的挖掘日常的业务数据，发现业务的风险和机会点
岗位要求：?1. 3年以上数据分析/挖掘相关工作经验；有互联网相关行业经验?2. 具有深厚的数学、统计学和计算机相关知识，精通SQL等数据查询语言以及ODPS、spark等大数据处理工具，熟悉数据仓库，具有海量数据挖掘、分析相关项目实施经验，参加过完整的数据挖掘项目并有成功案例?3. 对商业和业务逻辑敏感，具备良好的逻辑分析能力和系统性思维能力，良好的跨团队的沟通能力?4. 数字敏感度高，具备较强的分析总结能力，具备良好的数据呈现能力，包括PPT展示和讲解能力?5. 熟悉运用阿里云大数据产品，如MaxCompute（原ODPS)、Quick BI、DataWorks等"
"职位描述：
        
        职责描述：?
1、负责大数据平台架构设计与搭建、技术预研、撰写相关技术文档；?
2、负责处理大数据平台的疑难问题，为数据团队提供可靠的技术支持；
3、参与业务需求调研，根据需求及行业特点设计大数据解决方案并跟进具体项目的实施；?
4、对系统框架相关技术和业务进行培训，并负责核心代码编写，指导团队开发及解决出现的系统问题；?
5、制定大数据平台中数据质量、业务质量监控及管理方案；?
6、设计并实现对BI分析、数据产品开发、算法开发的系统性支持，保障数据挖掘建模和工程化。

任职要求：?
1、本科或以上学历，5年以上数据系统建设经验，3年以上大数据架构设计经验；
2、深入理解分布式技术原理，熟悉Hadoop生态圈，包括但不限于HDFS、Hbase、Spark、Storm等；
3、精通ETL相关技术，并熟练掌握数据可视化相关技术；
4、熟悉主流关系型与非关系型数据数据库，并且深入理解数据结构设计的合理性；
5、了解数据仓库建设过程中面临的挑战与问题，有作为技术负责人系统化解决问题的成功案例；
6、有较强的业务理解能力，善于根据不同业务场景提出有效的技术解决方案；
7、具备良好的抗压能力，并且有强烈的工作责任心（有团队和项目管理经验者优先）。"
"职位描述：
        
        职责描述：
1、负责业务部门的统计分析任务，开发实现数据自动化，为业务部门提供数据支持服务；
2、参与业务需求调研，根据需求及行业特点设计大数据解决方案并跟进具体项目的实施；
3、参与数据仓库建设，ETL过程的设计与实现，负责核心代码编写并保证数据质量；
4、设计并实现对BI分析、数据产品开发、算法开发的系统性支持，保障数据挖掘建模和工程化。

任职要求：
1、本科或以上学历，统计学、数学、计算机等相关专业，3年以上数据仓库系统建设经验；
2、熟悉Hadoop生态圈，包括但不限于Hive、Hbase、Spark、Storm等；
3、熟悉ETL相关技术，并熟练掌握数据可视化相关技术；
4、熟悉主流关系型与非关系型数据数据库，并且深入理解数据结构设计的合理性；
5、了解数据仓库建设过程中面临的挑战与问题，有系统化解决问题的成功案例和经验；
6、具备良好的抗压能力，并且有强烈的工作责任心。

加分项：
1、熟练掌握一种或多种语言（Java、Python等）优先
2、对数据治理有独到见解和实践者优先"
"职位描述：
        
        岗位职责：

- 负责Pony.ai核心业务数据建模以及数据服务化的设计开发；
- 负责数据仓库ETL流程的优化及解决ETL相关技术问题；
- 支撑业务团队基于数据的提取、分析和应用等需求和场景。
?
任职要求
?
- 计算机相关专业本科及以上学历；
- 具有很强的开发和动手能力，熟悉编程语言，如Java、Python、Scala等；
- 三年及以上ETL和数据pipeline开发经验，理解数据治理的重要性；
- 丰富的大数据系统使用和开发经验，包括但不限于Hadoop/Spark/Hive/HBase等；
- 有较强的逻辑思维能力，善于分析、归纳、解决问题；
- 精通Linux，熟练掌握Docker容器技术的原理，部署和使用优化；
- 有相关分布式系统架构和P2P网络系统开发经验者优先；
- 了解主流NoSQL数据库的原理与使用，尤其是KV型数据库，包括不限于RocksDB；
- 精通各种数据结构和算法，熟悉分布式、多线程及高性能的设计、编码及性能调优；
- 良好的语言沟通与表达能力和自我驱动动力，能够独立或带队进行项目开发。"
"职位描述：
        
        工作职责:
1、数据系统搭建，包括数据ETL、数仓建设、数据BI产品；
2、海量日志和业务数据的采集和分析；
3、实时可视化统计平台的数据开发。
任职资格:
1、本科及以上学历，有3年以上大数据相关开发或运维经验；
2、要求有良好的沟通和理解能力，善于学习，熟悉电商业务优先；
3、熟悉hadoop/hive/hbase等开源工具的使用和原理，有实际生产环境的优化或搭建经验优先；
4、有linux系统java/shell/python等语言的开发经验，有框架或架构开发经验优先；
5、理解数据仓库ETL，有高可靠性系统构建经验优先；
6、有elasticsearch/kafka/storm/spark实时计算经验优先。"
"职位描述：
        
        岗位职责： ?1. ?负责机票酒店大数据项目的评估、设计及关键模块研发； ?2. ?参与公司大数据平台及联机分析系统的建设； ?3. ?机器学习算法讨论、评估及算法的最终编码实现； ?4. ?数据平台开发规范制定，数据建模及核心框架研发；任职要求： ?1. ?本科及以上学历，计算机或数学相关专业，三年以上相关工作经验； ?2. ?掌握Java、Python、Scala等 中的一到两种语言； ?3. ?熟悉Mongodb、Hive、Hbase、Redis等NoSQL数据库开发和调优； ?4. ?熟悉数据相关开源框架和工具，如ZooKeeper、Spark、Flink、Impala、Kylin 等； ?5. ?对数据结构和机器学习算法有一定的了解； ?6. ?具有海量数据处理、数据挖掘、数据分析相关项目的工作经验者优先； ?7. ?有机票酒店等旅游行业数据开发经验者优先。"
"职位描述：
        
        工作职责:
1、负责海量分布式数据平台系统建设、全面参与项目的需求分析、架构设计和技术研究及关键技术的开发工作；
2、负责相关开源系统的性能、稳定性、可靠性等方面的深度优化；
3、对海量数据进行挖掘分析，构建数据模型及监控体系；4、将数据分析能力应用于业务进行实践落地。

任职资格:1、统招本科及以上学历，计算机、软件工程相关专业；2、5年数据开发经验，熟悉数据处理和数据存储，了解数据安全处理，如加密和匿名处理；
3、熟练掌握Spark和Nifi相关技术,?具备扎实的SQL功底；
4、了解统计模型，熟悉机器学习优先；
5、熟悉金融服务行业，具备金融业务系统或相关产品研发经验者优先；"
"职位描述：
        
        工作职责:
1、负责海量分布式数据平台系统建设、全面参与项目的需求分析、架构设计和技术研究及关键技术的开发工作；
2、负责相关开源系统的性能、稳定性、可靠性等方面的深度优化；
3、对海量数据进行挖掘分析，构建数据模型及监控体系；4、将数据分析能力应用于业务进行实践落地。

任职资格:1、统招本科及以上学历，计算机、软件工程相关专业；2、5年数据开发经验，熟悉数据处理和数据存储，了解数据安全处理，如加密和匿名处理；
3、熟练掌握Spark和Nifi相关技术,?具备扎实的SQL功底；
4、了解统计模型，熟悉机器学习优先；
5、熟悉金融服务行业，具备金融业务系统或相关产品研发经验者优先；"
"职位描述：
        
        工作职责:1、负责大数据平台技术架构设计、平台建设， 大数据应用开发。2、对海量数据进行挖掘分析，构建数据模型及监控体系；3、将数据分析能力应用于业务进行实践落地。

任职资格:1、统招本科及以上学历，计算机、软件工程相关专业；2、3年数据开发经验，熟悉数据处理和数据存储，熟悉数据安全处理，如加密和匿名处理；
3、熟练掌握Spark和Nifi相关技术,?具备扎实的SQL功底，熟练使用Mysql；
4、了解统计模型，熟悉机器学习，图像处理技术优先；
5、具备金融业务系统或相关产品研发经验者优先；"
"职位描述：
        
        工作职责：

1. 完善和优化现有实时流计算系统和存储系统，编写核心开发框架；

2. 善于发现系统的性能瓶颈、设计缺陷，提出改进方案并实施；

3. 对现有系统进行宏观的思考，规划形成统一的框架、平台或组件；

4. 能够与产品经理、管理团队进行良好的沟通合作，按时保质保量完成开发任务。

岗位要求：

1. 计算机科学或相关技术学科的学士、硕士学位（或同等学历）；

2. Java相关开发经验3年以上，熟悉多线程，高并发处理，有实际项目开发经验； 同时熟悉Python/Scala更佳

3. 精通分布式数据处理底层技术，包括但不限于：hadoop/Flink/Spark/elasticsearch/hbase/kafka/flume等，用过mysql，redis，hbase等开源存储，懂druid.io佳；

4. 熟悉ETL流程，使用过Hive，Impala处理数据作业， 有Kudu经验者更佳

5. 能够主动去分析数据，发现数据异常，不符合业务逻辑的问题，并推动解决

6. 具有强烈的责任心，良好的沟通、学习能力，良好的团队合作意识，勇于接受技术挑战；"
"职位描述：
        
        岗位职责?
1、负责Push业务的数据统计指标体系建设?
2、参与数据仓库产品设计、开发，流程的优化及解决相关技术问题；
3、负责数据仓库ETL脚本的开发，以及数据监控的相关脚本开发；?
4、规划业务相关的主题设计，搭建业务数据仓库；
5、参与数据底层的工具、平台、部署流程等技术体系建设的研发工作。
?岗位要求?
1、本科以上学历，三年及以上大数据相关工作经验；
2、熟悉数据仓库、数据集市模型设计方法论，并有实际模型设计及ETL脚本开发经验；
3、熟悉数据治理方法，包括数据标准化，数据质量，数据模型，元数据的管理等；
4、了解数据仓库的数据质量监控的方法，并且有相关工作项目经验；
5、熟练掌握Shell/Python脚本开发，精通hive?sql，并且熟悉sql性能调优；
6、熟悉Hadoop生态圈，了解Hbase、Sqoop、MR、kylin、spark等大数据处理工具和技术；?
7、具备快速学习能力、沟通协调能力及团队精神，有较强的责任心和学习积极性。"
"职位描述：
        
        主要职责：
1、负责海量分布式数据平台系统建设、全面参与项目的需求分析、架构设计和技术研究及关键技术的开发工作；
2、负责相关开源系统的性能、稳定性、可靠性等方面的深度优化；
3、进行大数据平台上用户画像、个性化推荐等数据挖掘产品的规划及研发；
4、负责解决项目上线后生产环境的各种实际问题，保障大数据平台在生产上的安全、平稳运行；
5、承接部门的开发任务和技术交流工作等。

任职要求：
1、计算机相关专业全日制统招本科及以上学历，并有3年以上Hadoop/Hbase大数据平台实施经验；
2、对Apache Hadoop生态技术体系有深入了解，如HDFS、MapReduce、Zookeeper、HBase、Hive、Impala、Spark、Kylin等；
3、有PB级别互联网或者金融交易数据量处理落地项目实施经验，熟悉整个大数据平台的处理流程和大规模分布式集群的环境搭建；
3)熟悉互联网、移动互联网或电商等行业大数据应用场景及大数据算法，具有相关行业大型项目开发或实施经验优先；
5、熟悉Linux/Unix环境下的Shell脚本、熟悉Python/Shell/Perl任意一种脚本语言；
6、工作积极主动、沟通能力强，具备较强的团队合作精神并能够承受较大工作压力，管理过5人以上团队。"
"职位描述：
        
        主要职责：
1) 负责搜索业务的全量和增量数据，提供大数据技术解决方案
2) 带领团队进行大数据相关平台的技术研究和探索
3) 带领团队进行大数据项目和产品的规划、开发、架构设计等工作
4) 团队大数据技术知识、机器学习、自然语言处理、分布式计算等的培训

任职要求：
1) 熟悉Hadoop生态相关技术并有相关开发经验，有Spark/Flink的开发经验尤佳；
2) 较为丰富的数据仓库及数据平台的架构经验，精通数据仓库建模及ETL设计开发；有较为系统的海量数据性能处理经验；
3) 具备一定的元数据管理及应用开发经验，在大数据资产管理与治理有一定成功的产品化经验；
4) 具备一定的JAVA语言的开发能力，具备一定知识图谱、自然语言交互、机器学习算法应用基础能力尤佳；
5) 具备一定的数据爬虫技术及开放社会公共数据整理加工经验者优先考虑；
6) 熟悉搜索和广告系统，利用大数据工具进行搜索全量索引和增量索引构建或者架构设计日志报表系统的经验者优先考虑；
7) 良好的思维逻辑性、语言表达能力；
8) 候选人不需要具备所有能力，只要其中一项能力具备一定经验，你就有很大机会加入我们团队；"
"职位描述：
        
        职责描述：
1.负责大数据平台关键技术的设计、开发、调优；
2.负责广告业务DMP数据平台建设，主要涉及广告数据分析，用户画像挖掘等

任职要求：
1.计算机相关专业，本科及以上学历，2年以上大数据相关工作经验；
2.熟练掌握Java，Java编程基础扎实；
3.熟悉Hadoop/Hbase/Spark/Storm/Hive，熟悉数据挖掘算法；
4.熟悉一种或集中主流数据库，如Mysql、Oracle等；
5.熟悉Linux系统，熟练使用shell/python脚本处理问题；
6.有TB-PB级数据处理实际工作经验或实时数据平台开发经验优先；
7.具有一定的统计学、数学、人工智能和数据挖掘知识基础，具备数理统理论基础；
8.有互联网数据挖掘、分析相关项目的工作经验者优先；
9.具有较好的沟通表达能力，学习能力强，较好的逻辑分析能力。"
"职位描述：
        
        主要职责：
1、负责海量分布式数据平台系统建设、全面参与项目的需求分析、架构设计和技术研究及关键技术的开发工作；
2、负责相关开源系统的性能、稳定性、可靠性等方面的深度优化；
3、进行大数据平台上用户画像、个性化推荐等数据挖掘产品的规划及研发；
4、负责解决项目上线后生产环境的各种实际问题，保障大数据平台在生产上的安全、平稳运行；
任职要求：
1、计算机相关专业全日制统招本科及以上学历，并有3年以上Hadoop/Hbase大数据平台实施经验；
2、对Apache Hadoop生态技术体系有深入了解，如HDFS、MapReduce、Zookeeper、HBase、Hive、Impala、Spark、Kylin等；
3、有PB级别互联网或者金融交易数据量处理落地项目实施经验，熟悉整个大数据平台的处理流程和大规模分布式集群的环境搭建；
3)熟悉互联网、移动互联网或电商等行业大数据应用场景及大数据算法，具有相关行业大型项目开发或实施经验优先；
5、熟悉Linux/Unix环境下的Shell脚本、熟悉Python/Shell/Perl任意一种脚本语言；"
"职位描述：
        
        岗位职责
1、参与数据仓库产品设计、开发，流程的优化及解决相关技术问题；?
2、负责数据仓库ETL脚本的开发，以及数据监控的相关脚本开发；
3、规划业务相关的主题设计，搭建业务数据仓库；?
4、参与数据底层的工具、平台、部署流程等技术体系建设的研发工作。

岗位要求
1、本科以上学历，三年及以上大数据相关工作经验；?
2、熟悉数据仓库、数据集市模型设计方法论，并有实际模型设计及ETL脚本开发经验；?
3、熟悉数据治理方法，包括数据标准化，数据质量，数据模型，元数据的管理等；
4、了解数据仓库的数据质量监控的方法，并且有相关工作项目经验；
5、熟练掌握Shell/Python脚本开发，精通hive sql，并且熟悉sql性能调优；
6、熟悉Hadoop生态圈，了解Hbase、Sqoop、MR、kylin、spark等大数据处理工具和技术；?
7、具备快速学习能力、沟通协调能力及团队精神，有较强的责任心和学习积极性。"
"职位描述：
        
        岗位描述：
1. 负责建设PB级数据仓库，参与或负责数据仓库设计、建模、研发等；
2. 参与或负责OPPO软件产品业务支撑系统数据平台相关数据开发和管理工作，如研发规范、质量规范、保障规范的制定与推动实施落地；
3. 支持业务团队的数据建设工作，支持公司的BI指标；
4. 参与数据特征仓库的构建和基础算法的应用落地。

职位要求：
1. 从事数据仓库领域工作至少2年以上，熟悉数据仓库模型设计方法论，有分布式数据存储与计算平台应用开发经验，在大数据资产管理与治理有一定成功产品化经验；
2. 熟悉Hadoop生态相关技术并有相关开发经验，精通SQL开发及SQL性能调优，熟悉基Hadoop, Hive等分布式计算平台的数据开发 ；
3. 精通数据仓库建模及ETL设计开发，有较为系统的海量数据性能处理经验；
4. 具备一定的Perl、JAVA、Python等至少一门语言的开发能力，掌握UDF和Map-Reduce开发；
5. 具有Spark/Flink/Storm开发经验者尤佳；
6. 具备数据挖掘和机器学习算法应用经验尤佳；
7. 良好的语言沟通与表达能力和自我驱动动力。"
"职位描述：
        
        主要职责：?
1.?负责Push业务的实时计算平台的开发与优化工作
2.?负责实时计算系统的运维，保证系统的高可用性和稳定性
3.?负责设计，开发，优化数据接入、数据存储、数据计算服务框架
4.?负责优化分布式框架，解决大并发下的各种问题
任职要求：?
1.?3年以上相关工作经验，本科或以上学历
2.?具备扎实的Java语言基础，熟练掌握NoSQL数据库等技术，有大规模分布式系统使用经验
3.?熟悉并行计算或者分布式计算原理，熟悉高并发、高稳定性、可线性扩展、海量数据的系统特点和技术方案
4.?有Spark/Storm等数据平台的开发和使用经验
5.?熟悉ZooKeeper/kafka/Hadoop/HBase/Flume/Redis等平台者优先
6.?具备良好的沟通能力和自我学习能力，优秀的分析及解决问题的能力，责任心强，细心耐心"
"职位描述：
        
        工作内容：?
1.负责广告平台大数据平台的建设和优化、统计平台设计和开发 2.用户性却标签挖掘?

任职要求：?

 211、985学校毕业
 2年以上大数据从业经验，对编程和技术充满激情，了解互联网广告业务者优先考虑
 熟练hadoop、spark, hive、hbase, storm, flink有环境搭建和优化经验
 熟练使用mapreduce、hive sql处理数据
 熟练使用linux shell"
"职位描述：
        
        岗位要求：
1、 配合各业务给予数据支持，对产品和运营数据总结和优化；?
2、处理用户海量数据，提取、分析、归纳用户属性，行为等信息，完成分析结果；?
3、发现并指出数据异常情况，分析数据合理性；?
4、集群管理。
任职要求：
1、3年以上使用hadoop/hive/spark分析海量数据的能力；?
2、优秀的设计和编码能力：针对具体的业务场景问题，快速设计和实现解决方案；对工程质量有很高的自我要求
3、扎实的编程基础，精通至少一门编程语言；熟悉Java,scala,Python 语言优先；
4、熟悉flume,kafka,Spark,Hadoop, Hbase, mysql,；拥有海量数据处理经验者优先；
5、具有良好的商业敏感度和优秀的数据分析技能，能够开发创新而实际的分析方法以解决复杂的商业问题。"
"职位描述：
        
        职位要求

l ?熟悉Spark，Kafka，HBase，ElasticSearch优先

l ?熟悉Java或者Scala语言

l ?有良好的系统分析，故障诊断能力者优先

l ?较强的团队合作能力"
"职位描述：
        
        职位要求

l ?熟悉Spark，Kafka，HBase，ElasticSearch优先

l ?熟悉Java或者Scala语言

l ?有良好的系统分析，故障诊断能力者优先

l ?较强的团队合作能力"
"职位描述：
        
        岗位职责：
1、负责蔚来汽车行为和行驶数据的处理，在分布式计算平台基础上建立高效、实时的数据 pipeline；
2、负责调度系统/推荐系统的数据分析，发现模式与规律，为实验解释、系统改进提供数据支持；
3、负责 Hadoop，Spark 等大数据基础设施和平台的改进，解决大规模生产环境集群可用性和性能优化问题。
?
岗位描述
1、本科及以上学历，计算机相关专业，每周可实习4天以上，持续3个月以上；
2、热爱计算机科学和互联网技术，优秀的编码能力，乐于快速学习和尝试新技术、新工具；
3、对数据敏感，掌握量化分析方法，善于从数据中发现问题，提出假设并使用数据进行验证；
4、对至少一项分布式计算平台有使用经验，例如 Hadoop，Spark，Hive，Storm，Kafka 等；
5、有参与开源项目对社区有贡献的经历，有互联网公司实习经历，有大数据处理或用户行为数据分析经验者优先。
6、有机器学习算法经验者优先。"
"职位描述：
        
        职位描述1. 参与部署和监控生产环境，并响应生产环境警报；2. 参与管理AWS S3/Athena和Apache Druid中的历史数据；3. 参与对基于Storm和TSDB的实时应用进行性能测试。任职要求1. 全日制本科或以上学历;2. 必要技能: Linux, Bash shell, SQL, Maven, Git；?????????????????? 英语读写3. 加分项： Java；?????????????????? AWS或其他云平台使用经验；?????????????????? Zookeeper/Kafka/Storm/Druid/Nginx经验。团队背景我们团队与纽约总部密切配合, 借助实时流式计算和AWS大数据技术, 帮助客户收集互联网视频观众的观看体验, 向客户提供24x7的实时数据服务.团队技能:??? ?Real-time streaming computation based on Kafka/Storm,??? ?Java-based distributed in-memory TSDB,??? ?Data visualization based on ECharts,??? ?Data Warehouse and OLAP,??? ?AWS"
"职位描述：
        
        职位描述1. 参与部署和监控生产环境，并响应生产环境警报；2. 参与管理AWS S3/Athena和Apache Druid中的历史数据；3. 参与对基于Storm和TSDB的实时应用进行性能测试。任职要求1. 全日制本科或以上学历;2. 必要技能: Linux, Bash shell, SQL, Maven, Git；?????????????????? 英语读写3. 加分项： Java；?????????????????? AWS或其他云平台使用经验；?????????????????? Zookeeper/Kafka/Storm/Druid/Nginx经验。团队背景我们团队与纽约总部密切配合, 借助实时流式计算和AWS大数据技术, 帮助客户收集互联网视频观众的观看体验, 向客户提供24x7的实时数据服务.团队技能:??? ?Real-time streaming computation based on Kafka/Storm,??? ?Java-based distributed in-memory TSDB,??? ?Data visualization based on ECharts,??? ?Data Warehouse and OLAP,??? ?AWS"
"职位描述：
        
        工作内容：
1、负责公司的数据平台的开发建设；
2、开发基于大数据技术的数据统计分析平台，OLAP引擎及大数据报表系统；
3、设计和研发数据分析相关的工具平台；
4、研究和设计公司的大数据仓库平台，负责数据仓库中的数据计算ETL pipeline的设计和开发，管理和维护。
?
任职资格：
1、熟悉linux下开发，有良好的至少一门语言 (Java、Python或者C++) 开发调试经验；
2、熟悉大数据开发相关技术，如hadoop、hive、spark、storm等；
3、熟练数据仓库，对多维数据建模有深入理解；
4、有olap引擎相关开发经验优先；
5、熟悉amazon、阿里云，包括但不限于s3, emr等技术优先；
6、熟悉常用数据挖掘与机器学习算法优先；
7、思维敏捷，有较强的钻研学习能力，较好的沟通能力、团队合作。"
"职位描述：
        
        职责：
1. 负责公司数据仓库架构设计与研发，建设数据平台和服务系统，实现高质量数据的互通与共享；
2. 负责数据产品与应用的数据研发，发掘数据商业价值，打造极致体验的数据产品；
?
?
要求：
1. 本科及以上学历，计算机等相关专业；
2. 5年以上工作经验，从事数据仓库领域至少4年以上，熟悉数据仓库模型设计与数据开发相关技术细节，掌握维度建模设计方法等思想，具备海量数据加工处理相关经验；
3、掌握如Hadoop或Spark等至少一种分布式平台开发技术，能灵活运用MR、SQL实现海量数据加工处理；
4、熟练掌握一门或多门编程语言(Java或Python优先)，有大型项目建设经验者优先；
5、熟悉数据仓库领域知识和技能者优先，包括但不限于元数据管理、数据开发测试工具与方法、数据质量、主数据管理等；
6、既能掌握大规模离线数据处理又能掌握实时流计算技术者优先，如Flink、Spark Streaming等；
7、良好的表达能力和自我驱动力
8.? 熟悉AWS的大数据工具和产品者优先"
"职位描述：
        
        职责：
1、负责共享项目产品、业务统计大数据需求的开发
2、负责大数据平台的建设
?
要求：
1、本科及以上学历，计算机、数理等理工科相关专业
2、2年以上数据仓库领域相关经验，对数据仓库系统架构具有良好的认知，了解数据仓库相关技术，如 ETL、报表开发，具备数据分析技术
3、熟练使用sql，较强的编码/调试诊断能力,扎实的数据结构和算法功底
4、熟练掌握一门或多门编程语言，熟悉Linux系统、shell脚本
5、熟悉AWS Redshift及相关工具链优先
6、学习能力强，肯吃苦，有团队观念，具备独立解决问题的能力"
"职位描述：
        
        Marin Software正在寻找经验丰富、富有激情的中层大数据工程师，开发基于Spark的复杂企业数据产品，管理数十亿美元的数字广告组合。

Marin开发SaaS产品来度量、优化和管理跨多个渠道和发行商的数字广告活动。Marin Software是目前管理谷歌广告活动的最大独立技术公司，管理着60亿美元的年度广告支出和40亿的关键词。我们也是Facebook广告客户领先的优化和管理工具。这使得Marin能够提供高附加值的跨渠道属性、报告和预算分配特性。

您将加入我们位于上海的大数据工程团队，并与伦敦和旧金山的其他团队合作。

职责


 拥有olap相关的微服务和Spark工作，并支持从设计、开发到生产支持的完整生命周期。
 使用Java/Scala和Apache Spark实现数据管道。
 编写产品质量代码，每2-4周发布一次。
 拥有代码所有权，长期追求简单、高效、可靠和性能;避免积累技术债务。
 测试驱动开发认真练习。
 与全球工程团队合作交付软件。
 对架构和设计问题做出贡献，并提出更好的替代方案。
 指导初级工程师并提供技术指导;积极参与其他团队成员的设计和代码评审。


要求


 4年以上软件开发经验。
 扎实的Java和/或Scala编程技能。
 优秀的解决问题、协作和沟通能力。
 具有较强的系统编程和调试能力。
 坚持编写单元测试和可测试代码。
 对Spark和Kafka有很好的理解。
 良好的英语沟通能力(书面和口头)。"
"职位描述：
        
        招聘要求?
1、2年及以上网页前端或全栈开发经验；??
2、熟练掌握响应式Web开发框架（AngularJS, Vue或React等），熟悉JavaScript，CSS，HTML；?
3、熟悉网站前后端架构，熟悉动态网页模板，熟悉动态加载和Ajax交互;??
4、熟悉常见数据图表的功能和展现方式（datatables等）；??
5、熟悉常见UI/UX布局和实现（bootstrap等）；??
6、对新技术敏感，权衡用何种技术能最有效率的实现目标；??
7、团队合作能力／乐于帮助别人并分享自己的经验和知识。 ??

岗位职责?
1、持续优化架构，代码，以适应高速增长的业务和用户规模。?
2、对游戏数据，进行自动ETL抽取，分析，并持续改进分析速度，分析指标，分析质量；?
3、持续改进运营数据分析系统（BI Report 和?Data Visualization）。 ??

其他?
第一天，你就有权利贡献代码到production上;?
第一周，你就可以贡献一个上线运行并实际使用的功能;?
在你入职的第一个月,?你就能接触到各个技术栈。从后端的 Web Server，Big Data，到前端的Bootstrap， AngularJS，到线上各种云服务等;?
在你入职的半年内, 你将会主导并重构公司某一个重要的技术，以适应公司高速增长的需要。 ??

加分项目：?
后端或全栈开发能力，熟悉NodeJs；"
"职位描述：
        
        招聘要求
4年及以上后端服务器开发经验；
熟练掌握NodeJs(Javascript)、Java、Python中至少1种开发语言；
熟练掌握常用关系型数据库及NoSQL数据库中至少一种；熟悉数据库设计和调优；
熟悉至少一种云平台(如 AWS，阿里云，腾讯云，QCloud，UCloud...)；
熟悉或了解主流的数据仓库和数据分析工具；
了解Web开发框架及基础的JavaScript，CSS， HTML；
对新技术敏感，权衡用何种技术能最有效率的实现目标；
团队合作能力／乐于帮助别人并分享自己的经验和知识。

岗位职责
持续优化架构，代码，以适应高速增长的业务和用户规模；
对游戏数据，进行自动ETL抽取，分析，并持续改进分析速度，分析指标，分析质量；
持续改进运营数据分析系统（BI Report 和?Data Visualization）。

其他
第一天，你就有权利贡献代码到production上;
第一周，你就可以贡献一个上线运行并实际使用的功能;
在你入职的第一个月,?你就能接触到各个技术栈。从后端的 Web Server，Big Data，到前端的Bootstrap， AngularJS，到线上各种云服务等;
在你入职的半年内, 你将会主导并重构公司某一个重要的技术，以适应公司高速增长的需要。

加分项
大数据产品经验（Hadoop，Spark，Presto，Kafka，Kinesis等）
广告投放平台经验"
"职位描述：
        
        职位描述：
1、参与存储、计算、监控当中的一个或多个方向，打造稳定可靠的大数据平台；
2、负责基于大数据平台的应用设计、开发和维护，对现有系统优化，提高性能；
3、规划设计大数据产品，解决大数据研发中遇到的难点。
?
任职资格：
1、计算机、数学相关专业全日制本科以上学历；
2、至少5年以上的Java开发经验，3年以上大数据应用系统的开发和设计经验；
3、熟悉Hadoop生态圈技术体系，对离线计算、内存计算和流式计算均有深刻理解，如Hadoop、hive、Spark、flink、presto等，熟悉开源数据交换工具如sqoop，streamset，kettle等；
4、精通Hive、HBase仓库设计，深刻理解MR运行原理和机制，能进行任务执行效率的优化；
5、熟练掌握Linux Shell、Flume、Kafka、Redis等相关技术；
6、熟练掌握Elasticsearch、Lucene、Solr、Kylin、Phoenix、Alluxio中一种或多种；
7、逻辑思维能力强，做事有条理，具备较强的分析问题和解决问题的能力；
8、思维活跃，性格开朗，责任感强，工作积极主动，执行力强，有良好的团队协作意识。"
"职位描述：
        
        数据研发工程师
 1) 负责Lazada数据和应用产品的数据体系的建设，通过数据+算法+工程化能力，不断完善Lazada的数据化运营能力；
2) 参与Lazada数据基础架构和技术体系的规划建设，包括数据处理、数据采集、数据质量及稳定性保障、数据治理、智能化和自动化建设。
3) 作为衔接Lazada数据新加坡团队和集团技术中台的桥梁，加速中台的产品向Lazada的输出。

职位描述

1) 有从事分布式数据存储与计算平台应用开发经验，有离线计算Hadoop/Spark/ODPS或流计算Storm/Flink的开发经验尤佳；
2) 较为丰富的数据仓库及数据平台的架构经验，精通数据仓库建模及ETL设计开发；有较为系统的海量数据性能处理经验；在数据质量、保障、治理等方面有一定实践经验；
3) 熟悉电商业务相关的业务和技术领域；
4) 具备一定的JAVA/Python语言的开发能力，有机器学习算法能力尤佳；
5) 有较好的英语听说读写能力；
6) 欢迎聪明、乐观、皮实、自省的您！"
"职位描述：
        
        职责描述:1.?负责客户业务需求、数据分析需求的调研、收集与分析;2.?负责?Kyligence Enterprise?大数据平台整体架构和数据架构设计;3.?负责技术设计及技术实现规范编制，指导开发团队进行项目设计、项目实现及技术 汇报;4.?负责项目重难点模块的功能设计和难点攻坚;5.?参与?Kyligence Enterprise/Apache kylin?的应用设计、开发、测试及优化工作。

任职要求:1.?计算机相关专业，本科及以上学历;2. 有 5 年以上工作经验，其中包括 2 年以上大数据平台架构和系统设计经验;3. 精通 Hadoop 、Hive、HBase 原理，熟悉大数据生态技术，如 Storm、Spark 、 Flink 、Kafka、Zokeeper 等，有大规模集群架构、开发及运维经验，能根据业务场景 设计合适的技术栈完成业务需求4. 熟练 SQL 语言，掌握 Oracle、DB2、MySQL 等一种或多种数据库系统的使用，有一 定的 SQL 性能调优经验;5. 至少熟悉 Java，Scala，Python ，Shell 等编程语言中的 2 种;6. 优秀的分析和解决问题的能力，对挑战性问题充满激情;7. 具备良好的团队合作精神，较强的沟通能力，具备良好的技术领导能力;8.?有数据仓库背景或者?Apache Kylin?的开发经验者优先考虑;"
"职位描述：
        
        职责描述:
1.?参与?Apache Kylin?下一代分布式查询引擎的设计开发工作；
2.?负责核心模块设计及实现，带领团队进行实现及技术汇报;
3.?保证项目按期高质量发布，并快速迭代；
?
任职要求:
1.?计算机相关专业，本科及以上学历;
2.?有?3?年以上工作经验，其中包括2年以上大数据平台架构和系统设计经验;?
3.?精通?Hadoop、Hive、HBase原理，熟悉大数据生态技术，如Storm、Spark、Flink、Kafka、Zookeeper等，有大规模集群架构、开发及运维经验，能根据业务场景设计合适的技术栈完成业务需求
4.?熟练SQL?语言，掌握?Oracle、DB2、MySQL?等一种或多种数据库系统的使用，有一定的?SQL?性能调优经验;
5.?至少熟悉?Java，Scala，Python，Shell等编程语言中的2种;
6.?具备良好的团队合作精神，较强的沟通能力，具备良好的技术领导能力;
7.?有数据仓库背景或者?Apache Kylin?的开发经验者优先考虑;?
8.?有参与过Apache?项目开发并贡献代码为佳，Apache Commiter?或PMC?优先；"
"职位描述：
        
        Job Title-研发工程师 Job Description
1.?与?Apache Kylin?核心开发者一起，研发下一代智能大数据分析引擎;2.?独立负责复杂的存储和并行计算模块;3.?参与?Apache Kylin?开源项目，成为?Apache Kylin?核心贡献者;4.?客户支持，故障排查，全栈工作;
岗位要求:
1.?计算机相关专业，本科及以上学历，2?年以上大数据相关经验;2.?扎实的?JAVA?编程基础，精通数据结构和算法，有?Hadoop?或?Spark工作经验;3.?优秀的编码、设计、算法、调优、故障排查能力;4.?优秀英文读写能力，可以流利的使用英文进行沟通;5.?开源项目?Owner，committer?或者?contributor，Apache?相关项目贡 献者优先录取。"
"职位描述：
        
        【职位描述】：1. 深入理解客路业务的需求，设计和构建数据仓库的各个数据层和视图2. 参与数据采集系统的开发，使用Google和AWS相应云服务对数据进行抽取、清洗和转化操作3. 参与客路数据平台的设计和开发4. 参与机器学习模型的开发
【职位要求】：1. 计算机或相关专业本科、硕士学历，两年以上数据开发相关工作经验2. 熟练掌握Go/Java/C/C++/Python等语言中的一种，具有良好的SQL语言开发技能，具有扎实的计算机基础和编程能力，熟悉常见的算法与数据结构3. 熟悉GCP或AWS云平台者优先4. 具有良好的沟通能力、团队合作能力、文档编写能力5. 具备良好的学习能力，能熟练阅读英文技术文档

【KLOOK福利】
1、舒适、健康、人性化的办公环境；
2、扁平化的团队管理，业务飞速发展，你的能力和价值很快会被大家看到；
3、开放和充满激情的国际化团队，男女高颜值并且比例协调，每个人都有那么一点传奇；
4、独特的创业团队氛围会让你在完成工作之余，还有自己的时间学习、成长；
5、还要跟Homie同富游：团队足迹踏遍国家50+，等你来一起占领地球；
6、团队天天下午茶，周周小聚餐，月胖三斤不是梦。"
"职位描述：
        
        岗位职责：
1. 负责数据应用整体技术方案选型、设计、评审、开发任务拆解和开发资源计划；
2. 带领团队完成产品或项目的开发交付工作，掌握进度和风险，解决技术难题；
3. 负责协调和沟通开发或实施各个环节技术相关内容；
任职要求：
1.有5年以上Java研发和软件设计经验及3年以上项目开发及技术部门管理经验；
2.有主导大型企业信息系统从0到1的设计开发集成实施经验（行业不限）;
3.有云迁移和微服务架构经验优先；
4.具备良好的系统分析能力，良好的抽象思维和逻辑思维能力，独立分析问题解决问题的能力；
5.有责任感，具备较强的沟通协调能力及团队合作精神。"
"职位描述：
        
        岗位职责：
1. 负责根据业务需求，完成整体技术方案设计，架构设计和开发规范制定；
2. 带领团队完成产品或项目的技术研发工作，把握项目的整体进度，解决技术难题；
3. 负责协调项目开发或实施的各个环节，以及各项目、部门和技术领域的合作。
?
任职要求：
1.5年以上Java研发和软件设计经验及3年以上项目开发及技术部门管理经验；
2.有主导大型企业信息系统从0到1的设计开发实施经验（行业不限）;
3.具有复杂项目的技术研发、管理及交付经验；
4.具备良好的系统分析能力，良好的抽象思维和逻辑思维能力，独立分析问题解决问题的能力；
5.有责任感，具备较强的沟通协调能力及团队合作精神。"
"职位描述：
        
        职位描述：

 以深厚技术背景领导一个数据工程团队，从零到完成项目；
 研究、评估和利用以海量数据处理为中心的新技术/工具/框架；
 设定技术方向，推动整个团队的工程质量；
 设计、构建和维护可扩展的数据通道，以提高速度和准确性；
 使用大数据生态系统中流行的工具和语言设计和实现分布式数据处理管道；
 推动设计、代码和测试计划的协作审查；
 与架构师合作，确保实施质量解决方案，并遵守工程要求；
 利用并推进持续集成和部署框架；
 解决复杂数据问题并执行根本原因分析，解决团队的技术瓶颈；
 跨团队合作以解决运营和绩效问题。

?
任职要求：

 python或scala经验优先；
 在Hadoop和相关处理框架方面有丰富的经验，如Spark、Hive、Sqoop、Airflow等；
 丰富的云平台大数据处理经验；
 深入了解测量和确保数据质量，以及监控和优化数据管道性能所需的工具；
 在制定计划和目标并执行这些计划和目标方面有出色表现；
 为团队成员提供指导，有效地影响团队成员和业务利益相关者并与之沟通；
 计算机科学或相关学科理学硕士/学士；
 7年以上大型软件开发经验，3年以上大数据开发经验；
 3年以上团队管理经验。"
"职位描述：
        
        岗位职责:? ? 1. 负责Hadoop & Spark集群的部署维护、性能监控、性能优化等。? ? 2. 负责大数据平台关键技术的调研，不断持续优化数据平台。? ? 3. 与业务开发团队完成应用数据产品的落地。任职要求:? ? 1. 本科以上学历，计算机、软件、数学等相关专业。? ? 2. 2年以上 Hadoop、Spark 管理调优经验。? ? 3. 熟练使用 Python、Java、Scala 中至少一种通用语言。? ? 4. 具有高度的责任心和团队精神、强烈的好奇心及耐心，认同自我管理、目标管理。良好的学习能力和对新技术的追求精神。"
"职位描述：
        
        职位描述：
1、负责对数字货币市场价格走势影响因素进行分析与建模
2、负责对核心金融分析模型、数字货币及衍生品估值模型的开发与迭代
3、负责量化投资策略的开发与迭代
4、依据对市场交易数据及链上数据的分析结果进行相关研究模型的开发、回测等
5、对区块链及数字货币市场的数据分析工具、指标的研发
6、其他数据分析、统计建模工作
?
职位要求：
1、统计学、金融工程、数学、计量经济学等相关专业硕士及以上学历，博士及985学校毕业生优先，海外留学生优先
2、三年及以上工作经验，两年以上金融工程等相关工作经验，有券商、基金等公司金融工程组经验者优先
3、掌握Python、R、Matlab、C++等相关语言及数据工具中的一种或多种，熟悉主流的数据分析方法
4、熟悉金融市场广泛应用的模型和数量方法
5、具有强烈的好奇心，热爱研究类工作"
"职位描述：
        
        职位描述：
1、负责对数字货币市场价格走势影响因素进行分析与建模
2、参与对核心金融分析模型、数字货币及衍生品估值模型的开发与迭代
3、依据市场交易数据及链上数据的分析结果进行相关模型的开发、回测等
4、对区块链及数字货币市场的数据分析工具、指标的研发
5、其他数据分析工作
?
职位要求：
1、统计学、金融工程、数学、计量经济学等相关专业硕士及以上学历（特别优秀的本科生亦可），博士及985学校毕业生优先，海外留学生优先
2、一年及以上数据分析、金融工程等相关工作经验，优秀者可放宽工作年限
3、掌握Python、R、Matlab等相关语言及数据工具中的一种或多种，熟悉主流的数据分析方法
4、熟悉金融市场广泛应用的模型和数量方法者优先
5、具有强烈的好奇心，热爱研究类工作"
"职位描述：
        
        岗位职责：?
1、利用hadoop生态相关技术，负责大数据中心的数据处理流程，包括数据清洗、融合、统计、挖掘等；
2、对hadoop生态的底层架构有一定的认知，可对其进行改进及优化；
3、负责大数据集群的日常维护、监控、异常处理等工作，保障集群稳定运行；
4、负责大数据自动化运维以及数据化运营平台开发工作；
5、负责大数据集群的用户管理、权限管理、资源管理、性能优化等；
6、深入理解数据平台架构，发现并解决重大故障及性能瓶颈，打造一流的数据平台；
7、负责公司其他存储系统的运维管理工作；
8、跟进大数据前沿技术，不断优化数据集群。
?任职要求：?
1、熟悉Hadoop、HBase、HIVE,Spark，redis能够进行常用的ETL开发工作以及MapReduce并行编程框架；
2、熟悉数据仓库产品，对数据处理、维度建模、数据分析等有深刻认识和实战经验，如Hadoop/Hive，Storm/Spark，Impala，MPP等的数据应用开发；
3、具备基于Hadoop大数据平台开发经验，精通Mysql等主流数据库，熟悉SQL、ETL工具，有一定大数据处理经验；
4、能够独立进行服务部署以及大数据查询服务引擎开发；
5、具备清晰缜密的逻辑思维能力，有较强的数据分析能力；
6、具备优秀的沟通能力、学习能力、执行能力、团队协作能力；
7、有互联网数据仓库平台经验优先；
8、相关专业本科及以上学历，或相关工作经验超过2年。"
"职位描述：
        
        1.参与构建数据中心基础设施的设计与开发。
2.参与数据仓库的建设，ETL开发。
3.参与完成数据挖掘、机器学习相关的技术工作。
任职资格:
1、丰富的Java研发经验，精通Java，熟悉Python/Scala中的一种；
2、熟悉Mysql，熟悉网络编程及并发技术，熟悉安全解决方案；
3、有丰富后端服务系统的设计和实现经验，有独立的系统级设计能力；
4、扎实的计算机基础，熟悉常用的数据结构和算法，熟悉Linux系统环境；
5、熟悉大数据技术栈，对Hadoop、Hive、Spark、Hbase、Kafka、ELK等开源组件有使用及优化经验者优先；
6、简单、真诚、负责、主动。"
"职位描述：
        
        岗位职责：
1、负责数据接入，数据清洗，数据转换，基于阿里云的基础设施来构建企业大数据处理平台
2、基于大数据处理平台，进行业务分析；
3、协助建立并完善数据的分析挖掘流程及体系；

任职要求：
1、本科及以上学历，计算机相关专业，三年以上数据库/数据仓库/数据分析/数据挖掘方面相关工作经验；
2、熟悉数据仓库和数据建模的相关技术，熟悉SQL/Hadoop/Hive/Spark等大数据分析工具；
3、能使用C++/JAVA/python/SHELL进行程序开发；
4、数学功底和建模能力强，理解数据挖掘，熟悉机器学习领域的常见算法者优先，有主导完成优秀应用或大型数据平台项目开发经验者优先；"
"职位描述：
        
        岗位描述
建立和维护大数据相关的各种基础，包括ETL流程、数据整合清洗、数据应用的设计和开发等，提升数据质量、稳定性和性能。

岗位要求?
1. 有大数据系统的丰富的使用经验，清晰的知道每种系统的用法，了解核心系统原理；
2. 熟悉Python、Scala、Java、Shell等语言；
3. 掌握并熟练使用常用算法和数据结构；
4. 熟悉Hadoop、Spark、HBase等大数据系统优先；
5. 良好的沟通能力，较强的抗压，独立工作和解决问题的能力。"
"职位描述：
        
        岗位职责：
1.负责基于Hadoop（CDH、HDP）平台架构的规划、设计和搭建；
2.独立或者带领团队完成各种面向业务目标的数据分析模型定义和应用开发；
3.针对海量的数据开发具有数据收集、统计、分析和挖掘能力的创新型产品；
4.基于MapReduce、Spark、Flume等的大数据开发；
5.学习和研究大数据技术最新动向以满足产品、项目的需求。
?
任职要求：
1.计算机相关专业本科及以上；一年及以上工作经验；
2.软件基础理论知识扎实，具有良好的数据结构、算法功底；
3.精通Hadoop等分布式开发，如：MapReduce、Spark，具有扎实的Java／Scala等开发语言功底；
?
4.熟悉Hadoop相关各种开源项目，如：Flume、Hive、Hbase等，并有实际应用者优先；
5.熟悉Solr／Lucene开发，熟悉NoSQL数据库者优先；
6.对新技术敏感，有一定独立分析，技术研究能力；
7.熟练使用Linux环境下开发者优先；熟悉至少一种版本控制工具，如：Git、SVN、Mercurial；
8.有个人开源项目或参与开源项目者优先；
9.有代码洁癖和自发组织Code Review的开发者优先。"
"职位描述：
        
        职责：?????????????????????????????????
? 按照规范及设计文档完成编码工作，并对代码质量负责；
? 编写及维护技术开发相关文档；
? 能够对自己开发的代码设计并编写单元测试及功能测试代码；
? 学习和研究新技术以满足产品的需求；
? 为产品改进、优化、效率提升设计开发产品内部工具。
?
要求：
? 计算机相关专业本科及以上；
? 软件基础理论知识扎实，具有良好的数据结构、算法功底；
? 熟悉Hadoop等分布式开发，了解Hadoop相关各种开源项目，如：Hive、Hbase等，并有实际应用，熟悉Storm、Spark者优先；
? 熟练应用Spring、Java Cache等开源框架；
? 熟悉MySQL等关系型数据库，熟悉NoSQL数据库者优先；
? 对新技术敏感，有一定独立分析，技术研究能力；
? 熟练使用Linux环境下开发者优先；
? 熟悉至少一种版本控制工具，如：SVN，熟悉分布式版本控制工具Mercurial或Git者优先；
? 有个人开源项目或参与开源项目者优先；
? 有代码洁癖和自发组织Code Review的开发者优先；
? 提供本人半年内写过的代码，不限开发语言；
?
工作态度：
? 具备良好的人际交往、语言表达和沟通能力；
? 具备高度的责任心、诚信的工作作风、优秀沟通能力及团队精神；
? 愿意接受挑战性的工作，能够高效及时完成工作；"
"职位描述：
        
        岗位职责：
1.参与大数据平台搭建，数据仓库建模等；
2.负责根据客户需求设计大数据技术解决方案；
3.利用大数据相关技术实现对数据进行etl处理、分析、挖掘、及数据可视化等相关工作；
4.负责大数据研发项目管理、维护、推进。
?
任职要求：
1.计算机及相关专业统招本科及以上学历；
2.3年以上hadoop的应用开发经验；
3.熟悉hadoop生态圈，可独立搭建hadoop平台，具备hadoop组件调经验；
4.深入理解大数据处理体系架构，熟悉hadoop/hbase/spark/hive等常用开源技术体系，具备复杂项目的实施落地能力；
5.精通JAVA语言，熟悉Linux开发环境，具有实际系统开发经验；
6.具有很强的学习能力、钻研精神、较强的沟通能力以及团队精神。"
"职位描述：
        
        岗位职责：
1、主导龙渊游戏业务大数据解决方案的制定与推行 ；
2、负责龙渊游戏大数据平台规划与建设游戏大数据工程师；

岗位要求：1、熟练掌握java语言，熟悉java web开发，具有良好的编码能力； 
2、熟悉SQL，具备良好的数据建模和数据处理能力；
3、三年以上java经验，一年大数据工作经验；
4、具备良好的学习能力、沟通能力及执行力； 
5、有主动思考能力，能够不断了解探索新技术以改进现有工作方式方法； 

加分项：1、有BI经验者优先； 2、熟悉spark，有大数据平台建设经验者优先；3、熟悉scala/python者优先；"
"职位描述：
        
        岗位职责：
1、参与数据仓库和大数据平台的环境搭建、架构设计、监控和优化；
2、负责离线和在线数据的采集、清洗和加载；
3、负责分布式批量数据处理、分布式内存计算、数据仓库OLAP类查询统计等离线计算；
4、参与实时数据流的数据处理、查询统计和分析预测等在线计算；
5、基于公司业务构建合适的模型算法；

岗位要求：
1、5年以上的大数据处理、数据挖掘等相关领域的科研/开发经验；
2、熟悉分布式OLAP，如Kylin/Druid等有实际使用经验以及平台集群搭建,精通Kylin并有实际项目经验优化；
3、精通Python或Scala，熟练掌握shell编程；
4、熟练掌握Hadoop、Spark、Flink等大数据计算技术，并在中大型项目中有相关实际经验；
5、熟练掌握presto、Spark???SQL、Drill等大数据即时查询技术，并有Trouble?Shooting的实际经验；
6、精通SQL，有较好的SQL性能调优经验，熟悉常用的sql分析函数，有Postgres数据库项目经验优先；
7、很强的自我驱动力、结果导向并极具责任感；
8、有良好沟通能力和团队协作精神；
9、对新兴技术有好奇心，有利用技术解决实际问题的热情，开源社区积极参与者优先；"
"职位描述：
        
        岗位职责：
1、参与数据仓库和大数据平台的环境搭建、架构设计、监控和优化；
2、负责离线和在线数据的采集、清洗和加载；
3、负责分布式批量数据处理、分布式内存计算、数据仓库OLAP类查询统计等离线计算；
4、参与实时数据流的数据处理、查询统计和分析预测等在线计算；
5、基于公司业务构建合适的模型算法；

岗位要求：
1、2年以上的大数据处理、数据挖掘等相关领域的科研/开发经验；
2、熟悉分布式OLAP，如Kylin/Druid等有实际使用经验以及平台集群搭建,精通Kylin并有实际项目经验优化；
3、精通Python或Scala，熟练掌握shell编程；
4、熟练掌握Hadoop、Spark、Flink等大数据计算技术，并在中大型项目中有相关实际经验；
5、熟练掌握presto、Spark???SQL、Drill等大数据即时查询技术，并有Trouble?Shooting的实际经验；
6、精通SQL，有较好的SQL性能调优经验，熟悉常用的sql分析函数，有Postgres数据库项目经验优先；
7、很强的自我驱动力、结果导向并极具责任感；
8、有良好沟通能力和团队协作精神；
9、对新兴技术有好奇心，有利用技术解决实际问题的热情，开源社区积极参与者优先；"
"职位描述：
        
        工作职责1、根据业务需求设计合理的ETL流程，执行ETL开发任务2、设计ETL任务调度，并监控和运维，保证日常数据质量3、定期对ETL系统进行优化与升级4、负责数据中台ETL流程、数据质量控制相关文档的制定和编写5、参与支撑海量零售数据的数据中台ETL、OLAP等开发工作；任职要求1、本科及以上学历，最少3年以上数据仓库ETL相关工作经验，熟悉数据仓库各类建模理论以及数据仓库数据层级关系，具备大型数据仓库逻辑模型和物理模型设计经验；2、扎实的SQL语言功底，熟练使用kettle、talend、DATAX、SQOOP等ETL产品中的一种或多种3、良好的Hadoop、Hive?SQL开发能力和程序调优经验；熟悉Postgresql优先4、良好的元数据管理、数据质量管理经验；4、有数据质量检查程序开发经验优先；5、积极上进，乐于学习，有团队沟通协作能力；具有较强的沟通能力、逻辑思维能力以及良好的团队合作精神。综合素质1、良好的沟通和表达能力；2、工作态度积极主动，有一定的抗压能力；3、优秀的自我管理和学习能力，进取心强；4、善于与他人合作，良好的团队合作意识；"
"职位描述：
        
        岗位职责：

 参与公司数据处理逻辑的设计和优化；
 参与公司各种数据模型的设计和优化；
 负责公司大数据基础架构平台的规划、设计。


岗位要求：

 熟悉HDFS、MapReduce和HBase的实现原理；
 熟悉至少2种分布式计算引擎的实现原理，具备故障定位、以及性能调优能力；
 熟练使用Java与Scala语言进行开发；
 具备3年以上的TB级别数据平台开发经验；
 良好的工作习惯、沟通能力和学习能力。"
"职位描述：
        
        岗位职责：

 参与公司数据处理逻辑的设计和优化；
 参与公司各种数据模型的设计和优化；
 负责公司大数据基础架构平台的规划、设计。


岗位要求：

 熟悉HDFS、MapReduce和HBase的实现原理；
 熟悉至少2种分布式计算引擎的实现原理，具备故障定位、以及性能调优能力；
 熟练使用Java与Scala语言进行开发；
 具备1年以上的TB级别数据平台开发经验；
 良好的工作习惯、沟通能力和学习能力。"
"职位描述：
        
        GrowingIO 是【增长黑客】理念在中国的布道者，通过精益数据分析，帮助客户提高收益。目前已经有 180+ 位优秀的增长黑客在 GrowingIO 工作，为超过 7000 家企业级客户提供服务，覆盖互联网、金融、新零售、运营商等多个行业。我们的工程师，每天处理 Billions 级别请求，处理和使用 TB 级别的数据，监控系统的健康度，如果你对做这些事情非常感兴趣，那么加入我们吧！大数据工程师主要职责：1、负责产品功能底层大数据开发，负责大数据清洗、存储、处理、分析等场景的开发；2、参与软件研发过程中的文档撰写。希望你：1、有三个月以上大数据处理相关实习经验；2、统招一本以上学历，计算机及其相关专业 2019 年应届毕业生；3、拥有扎实的计算机基础，热爱编程；4、具有良好的沟通能力和团队合作精神；5、有优秀的解决问题的能力，对分析和处理有挑战性的问题充满激情；6、有很强的学习能力，积极主动，能承担压力。"
"职位描述：
        
        岗位职责：
1、全面参与国双中间件（容器，服务框架、消息中间件、数据中间件等）的设计，核心代码开发，系统稳定性开发，性能优化，数据分析等工作；
2、帮忙业务方解决技术难题，用技术推动业务发展；
3、负责大数据平台的建设与开发,管理、优化并维护Hadoop、Spark等集群，保证集群规模持续、稳定。
任职要求:?
1、熟悉 Java 常见框架工具，有高并发、分布式网络通信、存储等相关经验；
2、3年及以上互联网或者其他企业大数据开发相关经验。
岗位专业技能：?
1、熟练Java服务端编程，有良好的编码习惯，有python 开发经验者优先；
2、熟练PostgreSQL、Redis等常用数据库；
3、扎实的编程能力，熟悉Hadoop/HBase/HDFS／Kafka／Sqoop／Zookeeper/storm/Spark/ELK，并有相关编程经验；
4、开源社区参与者和贡献者优先；
5、精通Linux使用，有丰富的脚本编写经验。"
"职位描述：
        
        岗位描述
1.? 负责大数据采集、存储、计算、分析等场景的通用架构设计和开发
2.? 负责流式数据的实时传递、清洗、转换和计算（实时统计、分析等）的设计和开发
3.? 负责大数据中间件的设计和开发
4.? 负责以上各种架构平台及相关基础技术组件的稳定性保障及源码级的bugfix
岗位要求
1.? 计算机相关专业，五年以上工作经验，具有大型系统的技术架构/应用架构/数据架构的的自主研发经验
2.? 深入使用Java，熟悉掌握常用的Java类库及框架，如多线程、并发处理、I/O与网络通讯，Velocity、Spring、Hibernate、iBatis等，对SOA模式有较深的理解
3.? 对Java虚拟机有较深了解，有运行态JVM分析及调优的实际经验，有Linux下的开发或运行环境操作经验
4.? 熟悉并使用过各种大数据相关框架或组件优先，如Kafka、Storm/JStorm、Hadoop/Spark、Hive、HBase等，特别是有Spark实战经验/海量数据处理经验者优先
5.? 具有良好的产品Sense，从商业需求到技术实现的映射能力，能够开发创新，以实际的分析方法去抽象分解复杂的业务需求问题
6.? 具有良好的沟通、团队协作、计划和主动性思考的能力，在互联网或大数据业界有一定影响力公司的工作经验者优先"
"职位描述：
        
        岗位职责：
1、负责大数据相关产品的后端核心逻辑开发；
2、按照产品要求，完成相应功能的服务端逻辑代码；
3、负责产品上线后的维护和优化。
?
?任职要求：
?1、计算机或相关专业毕业，5年以上Java服务端开发经验；
2、具有较为丰富的HBase, ElasticSearch应用开发经验；
3、熟悉数据湖、数据仓库技术，有实际构建经验优先；
4、熟悉Spring，mybatis等常用框架；
5、熟练运用数据库和SQL (Structured Query Language，结构化查询语言)，了解关系型数据库设计；
6、熟悉和掌握至少一种源代码管理软件（SVN/CVS/GIT）；
7、熟悉Azure上的基本PaaS和SaaS服务优先；
8、具有Linux上的开发经验，能够编写常用和基本的Shell脚本
9、具有良好的设计思维，能够高效地提供安全、高性能、可扩展的技术方案；
10、有敏捷开发实际项目经验，对新技术充满热情，积极学习；
11、高度的责任心以及良好团队合作精神。"
"职位描述：
        
        岗位职责：
1.基于国双大数据平台，负责大数据清洗、存储、处理、分析等场景的开发，完成高质量的代码编写； 2.完成项目和产品文档设计文档撰写； 3.培养并带领初级工程师，进行技术设计、代码编写的指导和评审； 4.视项目需要需要在客户办公场所驻场设计和开发。
任职要求：
1. 扎实的Java开发功底，熟悉scala编程，有丰富的并发编程经验， 2. 熟悉Hadoop、Spark、Flink、Kafka、Presto、ES、Hive、Flume等三门以上，熟悉原理源码、有二次开发优先。 3. 有参与构建海量数据存储、离线/实时计算、实时查询，大数据平台、BI平台的经验优先； 4. 擅于沟通和解决问题，乐于总结分享，有想法，有冲劲，有团队精神和主人翁意识和责任感。"
"职位描述：
        
        岗位职责：
1.基于国双大数据平台，负责大数据清洗、存储、处理、分析等场景的开发，完成高质量的代码编写； 2.完成项目和产品文档设计文档撰写； 3.培养并带领初级工程师，进行技术设计、代码编写的指导和评审； 4.视项目需要需要在客户办公场所驻场设计和开发。
任职要求：
1. 扎实的Java开发功底，熟悉scala编程，有丰富的并发编程经验， 2. 熟悉Hadoop、Spark、Flink、Kafka、Presto、ES、Hive、Flume等三门以上，熟悉原理源码、有二次开发优先。 3. 有参与构建海量数据存储、离线/实时计算、实时查询，大数据平台、BI平台的经验优先； 4. 擅于沟通和解决问题，乐于总结分享，有想法，有冲劲，有团队精神和主人翁意识和责任感。"
"职位描述：
        
        1、熟悉编程语言:Java、Python、Shell
2、熟悉常用数据库:Mysql、Oracle、Postgresql、db23、熟悉常用开源分布式系统：Hadoop、Hive、Spark、HBase、Elasticsearch、Druid
4、熟悉实时计算框架:Storm、Flink、Spark Streaming
5、其中之一并有实际项目经验
6、具备数据ETL经验:熟悉抽取工具如Kettle7、有数据分析经验、系统设计经验优先"
"职位描述：
        
        岗位职责：
1、负责 Hadoop 集群相关的开发、调优等工作；
2、大数据仓库的构建、数据治理；
任职要求：
1、五年以上大数据相关工作经验
2、精通Java/Scala，有较多代码优化经验；
3、理解 Hadoop 体系架构并有源码级开发经验；
4、精通或理解以下至少任意一项：
a、精通 MR 开发，并有相当优化经验；
b、理解 HDFS 体系架构，并有相当开发经验；
c、理解 HBase 体系架构，并有相当开发经验；
e、理解 Spark、Flink体系架构，并有相当开发经验；
5、非常好的自学及新技术研究探索能力；
6、良好的团队协作及沟通能力。"
"职位描述：
        
        
职位描述：
【关于我们】
?Gekko Lab 是一个年轻有活力的数据科学团队。85%是90后年轻人，气氛轻松有活力；Gekko Lab于2016年9月在美国硅谷成立，公司发展趋势迅猛，年轻却很strong。
Gekko Lab的主营业务是针对金融客户提供数据咨询服务，在监管科技领域内专注金融情报和金融调查。我们提供图形网络分析软件和内置专有数据库服务，帮助用户运用数据分析技术，提升发现和管控风险的能力。?
Gekko Lab的发展规划是针对二级股票市场，致力打造一个智能金融图谱引擎。
我们团队多元化，来自国际投行，海归博士和顶尖科技企业工程师，重视学习文化，工匠+极客精神，上升空间不设限。
团队火箭式成长，2017年2月获得香港数码港认可，成为培育企业，2018年7月，团队从160多家企业脱颖而出，成为全亚洲八家入围埃森哲“2018亚太区金融科技创新实验室”的公司之一。2018年12月于英国获得“2018年中国最佳金融科技奖”
欢迎有潜力爱学习的伙伴加入我们深圳团队，与我们共同成长。
?
工作内容:
1. 网站数据爬取
2. 数据分析
3. 数学模型
4. 建立数据清洗流程

任职要求:
1. 技术扎实，必须本科计算机系或相关以上2. 擅长Python，了解分布式，多线程，正则表达式(regex)
3. 自主学习能力，对各种新技术有热情，领导潜力
4. 有github开源项目，在校期间参加过竞赛，或独立完成完整网站项目的经验者会优先考虑
5. 跟我们业务/行业有相关经验者加分，如中文自然语言处理 (NLP)/机器学习/金融
6. 团队国际化，必须有足够英语沟通能力 (如看懂公司网站描述)

待遇 (6-10K):
视乎实力和经验，在校生兼职也欢迎，表现优秀者可以转正"
"职位描述：
        
        【关于我们】
Gekko Lab 是一个年轻有活力的数据科学团队。85%是90后年轻人，气氛轻松有活力；Gekko Lab于2016年9月在美国硅谷成立，公司发展趋势迅猛，年轻却很strong。
Gekko Lab的主营业务是针对金融客户提供数据咨询服务，在监管科技领域内专注金融情报和金融调查。我们提供图形网络分析软件和内置专有数据库服务，帮助用户运用数据分析技术，提升发现和管控风险的能力。?
Gekko Lab的发展规划是针对二级股票市场，致力打造一个智能金融图谱引擎。
我们团队多元化，来自国际投行，海归博士和顶尖科技企业工程师，重视学习文化，工匠+极客精神，上升空间不设限。
团队火箭式成长，2017年2月获得香港数码港认可，成为培育企业，2018年7月，团队从160多家企业脱颖而出，成为全亚洲八家入围埃森哲“2018亚太区金融科技创新实验室”的公司之一。2018年12月于英国获得“2018年中国最佳金融科技奖”
欢迎有潜力爱学习的伙伴加入我们深圳团队，与我们共同成长。
?
【岗位职责】
1.? 协助首席数据科学家开发与维护数据平台；?2. ?探索NLP在金融领域的创新应用；3. ?撰写数据分析报告；4. ?管理内部数据库，更新和输入数据。
?
【任职要求】
1. ?具有一定的独立研发能力，数学，物理或计算机相关专业硕士以上学历优先，有海外教育背景优先 ?
2. ?具有良好的编程能力，擅长Python，了解分布式，多线程，正则表达式(regex) ?3. ?掌握C++或C，并用其开发过复杂算法会优先考虑 ?4. ?掌握NLP算法基础理论，并能编写相关代码实现 ?5.? 有自主学习能力，对各种新技术有热情，有领导潜力 ?6. ?拥有良好的沟通能力，能把数据分析结果向非技术人员阐述清楚，并能书写数据分析报告 ?7. ?团队国际化，必须有良好英语阅读及沟通能力，可以无障碍的阅读英文算法论文 ?
?
【岗位待遇】
1.? 150-200元/天；
2.? 直接汇报给首席数据科学家，并全程参与公司的重大数据研发项目；3. ?学习金融数据特性并能了解到大型监管机构，国际投行等高端客户需求，有机会参加客户会议； ?4. ?了解人工智能算法在金融行业实际应用
?
【职位诱惑】
1．不设限的职业发展规划，公司领导会根据员工自身的意愿与能力进行职业培养与规划；
2．有竞争力的薪水：高于行业的薪水，表现优秀，奖金多多di；
3. ?零食、下午茶、嗨爆的聚餐、非主流又好玩的旅游团建。"
"职位描述：
        
        基础架构部-数据处理组
Lead Software Engineer
?
职责描述：
1.?规划与开发视频广告实时数据平台，包括ETL，数据存储以及应用支持，带领团队完成技术解决方案，帮助团队成员快速成长;
2.?与业务部门合作设计数据处理模型，并实现系统的开发、测试、部署;
3.?为业务部门提供大数据平台的技术架构支持，解决其技术难题与性能瓶颈。
任职要求：
1.?五年以上Hadoop及大数据生态圈产品实践经验;
2.?熟练掌握HBase/Kafka/MapReduce/Spark等开源大数据技术，有多种业务场景下的实践经验;
3.?具备良好的系统设计及系统架构能力;
4.?具备快速学习与解决问题的能力;
5.?强烈的责任心和自我驱动意识;
6.?良好的团队合作精神和沟通能力。
加分项:
1.?有?Golang开发经验;
2.?有AWS开发经验;
3.?对HBase/Kafka/MapReduce/Spark相关组件的性能优化和补丁跟踪等有实际经验。"
"职位描述：
        
        基础架构部-数据处理组
Lead Software Engineer
?
职责描述：
1.?规划与开发视频广告实时数据平台，包括ETL，数据存储以及应用支持，带领团队完成技术解决方案，帮助团队成员快速成长;
2.?与业务部门合作设计数据处理模型，并实现系统的开发、测试、部署;
3.?为业务部门提供大数据平台的技术架构支持，解决其技术难题与性能瓶颈。
任职要求：
1.?五年以上Hadoop及大数据生态圈产品实践经验;
2.?熟练掌握HBase/Kafka/MapReduce/Spark等开源大数据技术，有多种业务场景下的实践经验;
3.?具备良好的系统设计及系统架构能力;
4.?具备快速学习与解决问题的能力;
5.?强烈的责任心和自我驱动意识;
6.?良好的团队合作精神和沟通能力。
加分项:
1.?有?Golang开发经验;
2.?有AWS开发经验;
3.?对HBase/Kafka/MapReduce/Spark相关组件的性能优化和补丁跟踪等有实际经验。"
"职位描述：
        
        RESPONSIBILITIES:
?
A Lead Software Engineer in Reporting team will
Be responsible for a mission critical application or an application group, assisting manager in making technical decisions
Coordinate within and outside of the team to complete complex product feature or large scale infrastructure development on time with high quality
Oversee and be responsible for the architecture of the application or application group, work with architect group to accomplish technical initiatives
Lead and mentor technical members in the team, providing first hand performance review feedback to the manager of the team
?
ABOUT YOU
Extensive experience on (4+ years) on building and operating large scale data processing system
Solid foundation in CS, with strong competencies in DS/Algorithm/DB
Solid programming skills, in depth knowledge and hands on experience with C/C++/Java/Go/Python
Strong passion with learning / practicing new technics
In depth knowledge and hands on experience with big data ecosystem
Knowledgeable about?Linux or similar systems
Proficient in speaking, writing, reading and listening English
Logical thinking style, good communication skills
Team working spirit, flexible on working pressure"
"职位描述：
        
        ? ? ? Sr./Lead Software Engineer（大数据平台基础架构组）
?
职责描述：
1.???? 公司级大数据平台的架构规划与设计，以提升平台的存储与计算能力;
2.???? 大数据基础组件Kafka/HBase/YARN/Spark等的二次开发与性能优化;
任职要求：
1.???? 三年以上Hadoop及大数据生态圈产品实践经验，如Kafka/HBase/Presto/YARN/Spark等;
2.???? 深入了解分布式系统、大数据平台、消息队列等高可用高弹性架构;
3.???? 有志于建立大规模低延时数据处理系统，用于解决实际业务问题;
4.???? 具备快速学习与解决问题的能力;
5.???? 强烈的责任心和自我驱动意识;
6.???? 良好的团队合作精神和沟通能力;
7.???? 良好的英语听说读写能力。
???????? 加分项:
1.???? 有 Golang 开发经验;
2.???? 有AWS开发经验;
3.???? 对HDFS/Yarn/HBase/Hive/Spark/Presto相关组件的性能优化和补丁跟踪等有实际经验。
?
?
?
Sr. Software Engineer (大数据平台基础架构-实时数据计算组)
?
职责描述：
1. 公司海量数据实时计算平台的设计与实现，通过横向扩展与纵向优化保证系统的高吞吐和低延迟的能力.
2. 在线实时查询平台的开发与优化, 提供业务方基于海量数据的高维度, 低延迟的查询分析服务.
任职要求：
1. 三年以上分布式流处理计算开发和优化经验,并能深入理解其中某个计算框架, 如Spark/Flink/Kafka;
2. 三年以上OLAP查询分析框架的使用和优化经验, 并能深入理解其中某个框架, 如Druid/Kylin/Presto;
3. 具备快速学习与解决问题的能力;
4. 强烈的责任心和自我驱动意识;
5. 良好的团队合作精神和沟通能力;
6. 良好的英语听说读写能力。
加分项:
1. 有AWS开发经验;
2. 对Hadoop/Spark/Druid/Presto相关组件的性能优化和补丁跟踪等有实际经验。"
"职位描述：
        
        1 ． 基 于 流 处 理 (Spark Streaming) 的 实 数 据 服 务 。 为 客 户 提 供 实 时 的 投 放 数 据 帮 助 客 户 及 时 了 解 投 放 状 态 ，调整投放方案。?
2．基 于 SQL-on-hadoop (Presto) 的 数 据 查 洵 服 务 。 数 据 科学家 和 客 户 可 以 快 速 从 海 量 的 广 告 投 放 数 据 中 找 到 业 务 相 关 的 数 据 统 计 。?
3 ． 基 于 商 业 智 能 工 具 (Looker) 的 数 据 分 折 服 务 。?
客 户 可 以 灵 活 的 创 建 业 务 报 表 对 广 告 投 放 效 果 、 资 产 利 用 状 态 能 有 非 常 准 确 的 把握。

我 们 的 大 数 据 平 台 同 时 建 立 在 自 建 数 据 中 心 和 云 端 （ AWS ） ， 对 数 据 感 兴 趣 的 同 学， 这 里 是 成 为 数 据 工 程 师 (Data Engineer) 的 好 地 方 。"
"职位描述：
        
        Sr. Software Engineer (大数据平台基础架构-实时数据计算组)
?
职责描述：
1.?公司海量数据实时计算平台的设计与实现，通过横向扩展与纵向优化保证系统的高吞吐和低延迟的能力.
2.?在线实时查询平台的开发与优化,提供业务方基于海量数据的高维度,低延迟的查询分析服务.
任职要求：
1.?三年以上分布式流处理计算开发和优化经验,并能深入理解其中某个计算框架,如Spark/Flink/Kafka;
2.?三年以上OLAP查询分析框架的使用和优化经验,并能深入理解其中某个框架,如Druid/Kylin/Presto;
3.?具备快速学习与解决问题的能力;
4.?强烈的责任心和自我驱动意识;
5.?良好的团队合作精神和沟通能力;
6.?良好的英语听说读写能力。
加分项:
1.?有AWS开发经验;
2.?对Hadoop/Spark/Druid/Presto相关组件的性能优化和补丁跟踪等有实际经验。"
"职位描述：
        
        ? ? ??Sr.Software Engineer（大数据平台基础架构组）
?
职责描述：
1.????公司级大数据平台的架构规划与设计，以提升平台的存储与计算能力;
2.????大数据基础组件Kafka/HBase/YARN/Spark等的二次开发与性能优化;
任职要求：
1.????三年以上Hadoop及大数据生态圈产品实践经验，如Kafka/HBase/Presto/YARN/Spark等;
2.????深入了解分布式系统、大数据平台、消息队列等高可用高弹性架构;
3.????有志于建立大规模低延时数据处理系统，用于解决实际业务问题;
4.????具备快速学习与解决问题的能力;
5.????强烈的责任心和自我驱动意识;
6.????良好的团队合作精神和沟通能力;
7.????良好的英语听说读写能力。
?????????加分项:
1.????有Golang?开发经验;
2.????有AWS开发经验;
3.????对HDFS/Yarn/HBase/Hive/Spark/Presto相关组件的性能优化和补丁跟踪等有实际经验。"
"职位描述：
        
        
【 FreeWheel 】 ??
我们是一家做互联网视频广告投放的美资公司，成立于2007年，并于2014年被美国最大的传媒集团Comcast收购。FreeWheel拥有业界最完整的广告管理解决方案。专注服务于全新电视生态系统，我们帮助客户管理并变现高端视频内容，使之在品牌安全的条件下充分发挥商业价值。凭借领先技术和独树一帜的咨询服务，我们助力众多全球顶级媒体和娱乐公司开展广告业务。FreeWheel总部位于美国加州圣马特奥，在纽约、伦敦、巴黎、北京等全球各地设有分支机构。目前90%美国主流电视媒体和运营商使用我们的广告平台。 ? ??
? ? ? ? ??
【 Beijing 研发中心 】 ? ??
FreeWheel北京研发中心是FreeWheel在全球的第一个研发中心，也是最重要的产品技术中心。 ? ??
研发团队与产品、运维等团队紧密合作，负责世界上最大的视频广告平台的设计、开发、测试和维护工作，帮助美国和欧洲主流电视媒体运营每年数百亿美元的广告业务，在数字时代更好地挖掘其视频内容的商业价值。
【职责描述】
面向客户的数据产品开发，测试，部署、监控，涵盖实时报表和离线报表等不同类型的数据产品；
紧密配合产品经理，理解业务需求，梳理业务流程，针对不同业务需要和应用场景，制定合理的系统架构以及实现方式，可以独立完成技术解决方案；
周期性产品迭代，持续改进现有产品，包括业务流程和系统架构，与基础架构部门配合，解决技术难题与性能瓶颈。
【任职要求】
本科及其以上学历，三年以上大数据生态圈工作经验，二年以上数据产品实践经验；
熟练掌握数据产品相关设计原理，对数据产品设计、交互、系统架构有深入的见解；
熟悉Spark/MapReduce/HBase/Presto等开源大数据技术，有多种业务场景下的实践经验；
有数据仓库建模、数据平台搭建、ETL及相关数据分析经验；
具备良好的系统设计及系统架构能力；
具备快速学习与解决问题的能力；
强烈的责任心和自我驱动意识；
良好的团队合作精神和沟通能力。
【加分项】
有OLAP开发和开源项目实践相关经验
有AWS开发经验；
有Golang开发经验；
有敏捷开发经验
有Scala开发经验"
"职位描述：
        
        职位描述：
职责描述：
1.负责公司数据仓库的建设
2.负责数据仓库模型设计,开发与管理
3.进行数据分析平台的构建,对业务部门提供数据支持服务
4.编写和维护项目开发文档

能力&经验要求:
1.至少熟练掌握Java和一门额外的编程语言(Python,Erlang,Scala,Haskell,Lisp,C/C++等)
2.熟练掌握Linux操作和运维脚本编写
3.良好的算法/数据结构基础
4.拥有本科学位
5.具备较多JVM平台的性能调优经验
6.掌握下列两类开源生态中的任意一类
?(1)Hadoop,Hive,Presto,HBase
?(2)Kafka,Storm,Spark,Flink
7.良好的逻辑分析能力,分析问题和解决问题的能力,对数据敏感,良好的沟通能力跟执行力
8.不对自己的技术栈设限,愿意从结果出发选择自己需要的工具
9.有公开的内容输出,如技术分享,开源代码者优先
10.精通SQL,有较好的SQL性能调优经验者优先
11.熟悉BI开发流程,参与过大型数据仓库类项目者优先
12.精通分布式,缓存,消息,NoSQL等机制,熟悉Redis,Mongodb等NoSQL数据库者优先
13.具有业务分析及建模能力,熟悉电商行业相关业务流程者优先
14.对常见的数据分析模型有一定的了解,有海量数据分析项目经验,数据挖掘项目经验尤佳"
"职位描述：
        
        职位描述:

1.?负责电商行业数据整合与数据仓库模型的建立,维护和优化
2.?了解,监控应用需求及数据源的变化,并评估对数据仓库模型的影响
3.?设计数据模型的ETL实现,参与团队ETL流程的优化以及相关技术问题的解决

任职要求:

1.?熟悉数据仓库建设生命周期流程规范,并掌握主题建模,维度建模理论
2.?熟悉SQL/HQL,有较好的SQL性能调优经验,熟悉Python/Perl/Shell等至少一种脚本语言
3.?工作认真,踏实,负责,有良好的团队合作精神,良好的分析能力,沟通技巧
4.?对数据敏感,具有ETL设计与开发,数据建模,数据质量保障,元数据管理,指标体系建设等项目实践经验优先
5.?对电商行业有深入了解者优先"
"职位描述：
        
        职责描述：
1.负责公司数据仓库的建设
2.负责数据仓库模型设计,开发与管理
3.进行数据分析平台的构建,对业务部门提供数据支持服务
4.编写和维护项目开发文档

能力&经验要求:
1.至少熟练掌握Java和一门额外的编程语言(Python,Erlang,Scala,Haskell,Lisp,C/C++等)
2.熟练掌握Linux操作和运维脚本编写
3.良好的算法/数据结构基础
4.拥有本科学位
5.具备较多JVM平台的性能调优经验
6.掌握下列两类开源生态中的任意一类
?(1)Hadoop,Hive,Presto,HBase
?(2)Kafka,Storm,Spark,Flink
7.良好的逻辑分析能力,分析问题和解决问题的能力,对数据敏感,良好的沟通能力跟执行力
8.不对自己的技术栈设限,愿意从结果出发选择自己需要的工具
9.有公开的内容输出,如技术分享,开源代码者优先
10.精通SQL,有较好的SQL性能调优经验者优先
11.熟悉BI开发流程,参与过大型数据仓库类项目者优先
12.精通分布式,缓存,消息,NoSQL等机制,熟悉Redis,Mongodb等NoSQL数据库者优先
13.具有业务分析及建模能力,熟悉电商行业相关业务流程者优先
14.对常见的数据分析模型有一定的了解,有海量数据分析项目经验,数据挖掘项目经验尤佳"
"职位描述：
        
        职位描述
1.从事数据仓库或挖掘领域至少5年以上，熟悉数据仓库模型设计与ETL开发经验 ，掌握维度建模设计方法，具备海量数据处理经验
2.熟悉数据仓库领域知识和技能者优先，包括但不局限于：元数据管理、数据开发测试工具与方法、数据质量、主数据管理；
3.熟悉数据库技术，熟练运用SQL及其他Z言，能高效的与技术团队进行沟通；
4.有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验着优先，如Hdfs、Mapreduce、Hive、Hbase、Spark、Storm；
5. 对常规统计机器学习问题具有一定的理解，熟悉常用的模型；
6.熟练掌握一门或多门编程语言，并有大型项目建设经验者优先，如Java、Python、Shell；
7.良好的商业嗅觉，有丰富的数据分析经验，较强的数据、平台、技术理解能力；
8.良好的语言沟通与表达能力，自我驱动；"
"职位描述：
        
        公司介绍：
Flipboard的产品基因是为追求精致美好生活的人发现世界上的好内容。我们希望你对内容有热情，关注细节，大胆创新，有愿景要打造全球品质最好、颜值最高的新闻资讯服务。

Flipboard红板报2017年在中国全新发布。你将与顶尖团队，打造上千万用户喜爱且每天都使用的产品。 你将在融合着创新高效的硅谷创业文化中，快速学习和成长。团队的扁平架构让所有人直接沟通、合作和创新。开放式设计的办公室位于北京世贸天阶，先进的工作设备一应俱全。

岗位要求：
1.???? 熟悉Kafka/Storm/Hadoop等大数据架构，掌握Python, Java, C++语言编程和Shell脚本
2.???? 熟悉业务模块的测试、上线和后期监控，能够构建清晰的数据流程，满足业务需求，具备一定可复用性。能够主动发现已有系统的关键瓶颈，并推动优化，最终大幅提升系统可靠性
3.???? 本科或硕士毕业，或有2年以上工作经验"
"职位描述：
        
        职责描述：
1. 负责数据接入、数据清洗、底层重构，业务主题建模等工作；
2. 负责金融大数据整体的计算平台开发与应用；
3. 对系统存在的问题进行跟踪和定位并及时解决。

任职要求：
1. 计算机、软件工程等相关专业，本科及以上学历，具有3年及以上Java开发经验；1年及以上互联网或大数据分析工作经验优先；
2. 熟悉Hadoop或Spark生态相关技术，包括MapReduce、HDFS、Hive、Spark等，1个以上大数据平台项目实施经验； 熟悉Oracle或MySQL数据库技术；
3. 具有BI系统的开发实施经验，能够独立开发设计数据仓库、ETL设计、Cube建模、OLAP开发、报表开发等；一定的应用系统分析与设计能力，有良好、规范的编程习惯和文档编写习惯；
4. 有较强的学习能力，对技术有钻研精神，并有较高的热情，热衷于新技术、新理论、新开发实践的学习和实践；
5. 有第三方支付或金融业务经历者优先考虑。"
"职位描述：
        
        职位诱惑：扁平化管理,福利多
工作职责：
1.负责数据统计后台的开发；
2.负责公司数据报表的开发。

任职要求：
1.本科及以上学历，工作年限不限；
2.熟练掌握Sql语句的使用，熟悉sql各类关键字，函数的用法；
3.熟悉MySql数据库的特性和使用；
4.熟悉PHP语言开发、面向对象、函数、方法的使用；
5.逻辑条理性好，抗压能力强，学习力好；
6.熟悉PHP Yii框架优先。"
"职位描述：
        
        职位诱惑：玩前沿的技术，做有趣的事
职位描述：加入我们，您有机会和技术理念前沿的优秀工程师团队协作，形成良好的技术观念与思维，学习好玩的技术并学以致用，且深入接触最核心最专业的金融技术，成为跨界技术大拿。

职位要求：我们认为拥有正确的技术思维、观念和方法论比掌握层出不穷的具体技术更根本更重要; 此外，综合技术素质也同样关键。所以您必须向我们证明：
1、基本理论--您对数据、消息、同步异步、分布式CAP理论有深刻理解
2、方法论--您是一个quick learner - 无论是学习一个新的大数据生态技术、一个陌生的大数据理论，您都能在较短时间内正确掌握，并且具备成体系的学习套路与方法
3、具体基础知识--您深刻掌握了某种技术的原理，例如TCP/UDP协议栈、分布式文件系统、数据库基础、Java/Scala/Shell或者其他任何一种语言、Storm/Spark/Flink/Elasticsearch/Kafka/ELK相关技术… 我们相信技术都有共通点，请展现1-2门您自我感觉最良好的拿手好戏
4、交流沟通能力--我们鼓励团队成员大量阅读（不一定只是技术书籍，谁说历史哲学不能触类旁通），鼓励写作发表技术文章以及在各大峰会演讲。最起码您得逻辑的归纳总结和描述一个问题，并逻辑的描述它的解决方案
5、其他加分项--对于LambdaKappa框架有一定理解或者有实践经验… 具体不限，我们愿闻其详
6、流畅阅读英文--技术文档的能力必须具备，因为我们期望您能开拓自己的视野、并通过分享来开拓团队伙伴们的视野（所有成员都为彼此做同样的分享）金融领域经验和技术经验在我们这里不是唯一最重要的，技术热情、知识面、逻辑分析能力、好奇心、总体潜力与悟性更加关键。技术岗位也不是固定的，您可能先以个人最熟悉的技术作为切入点，但是您有相当高的机会被安排去尝试全新的领域。"
"职位描述：
        
        工作职责：
1.????负责公司的数据价值提炼以及数据应用的设计及开发
2.????负责基于公司相关平台的数据仓库/数据集市的相关模型设计及开发
3.????负责数据相关开发工作及数据的清洗及加工等，开源组件的改造和优化
4.????负责数据管理工具和数据迁移工具，数据质量检查，流程管控等工具开发
5.? ?负责ETL体系的架构设计开发及测试，包括批量数据ETL开发，实时数据ETL开发，ETL调度开发等任职要求：
1.????计算机相关专业本科及以上学历，3年以上开发工作经验
2.????对数据仓库有基本的理解，了解维度建模等思想
3.????能够熟练运用sql,hive sql进行数据清洗及数据加工，并有一定的优化能力
4.????熟悉Linux，java, python等至少一门开发语言，熟悉Mysql等关系数据库
5.????具备独立分析和解决问题的能力，积极主动，认真踏实的工作态度
6.? ?良好的服务意识，善于团队协作"
"职位描述：
        
        
Responsibilities:
・??????? Provide technical leadership and contribute to the definition, development, integration, test, documentation, and support across multiple platforms (Cloud, Big-data, RDBMS, etc.)
・??????? Provide technical leadership and contribute to the definition, development, integration, test, documentation, and support across multiple platforms (Cloud, Big-data, RDBMS, etc.)
・??????? Analyze, assimilate and integrate multi-technology data systems by building a unified back-end
・??????? platform and a web enabled front-end
・??????? Instill best practices for software development and documentation, assure designs meet
・??????? requirements, and deliver high-quality work on tight schedules
・??????? Involve in all phases of software development from review of functional specification through

Qualifications:
・??????? 3+ years of experience and knowledge of (Cloud, API’s, Python, RDMS, Rub, PHP, Javascript, Docker, NodeJS, etc.)
・??????? Bachelor’s degree in Computer Engineering or equivalent is desired
・??????? 4+ years of post-college working experience with full life cycle of ETL development in Data Integration projects using various ETL tool and Big Data technologies
・??????? 3+ years Linux/Unix/Perl experience, including scripting and version control with working knowledge of RDBMS (Prefer Oracle)
・??????? 3+ years of Unix development experience is required
・??????? 2+ years of Hadoop using Map Reduce or Hive or Pig or any other Big Data eco-system tool.
・??????? Expertise in Shell scripting, system/process automation is required
・??????? Expertise in data research/analysis with a focus on data quality and consistency is required
・??????? Proficient with Service Oriented Architecture Principles - Micro Services, JSON Structures, SOA integration patterns
・??????? Understand and have some experience working with cloud and other server-less technologies
・??????? Experience designing scalable cloud services
・??????? Experience developing microservices on public cloud (Google Cloud, AWS, Azure, AliCloud)"
"职位描述：
        
        岗位职责：
1、主导或参与公司环境管理大数据平台的架构设计和开发工作；
2、负责大数据项目相关的前期需求的沟通和方案的编制；
3、主导数据分析平台的建设；
4、负责项目组数据提取，分析和建模，相关报告素材编写；
5、参与数据采集方案，公司环境管理平台的升级改造工作和运维工作；
能力要求：
1、计算机相关专业,具有3年以上大数据开发经验，熟悉Java,Linux；
2、熟悉Hadoop大数据处理系统的开发,搭建及部署者优先；有大数据仓库开发，搭建经验者优先考虑；
3、熟练地处理数据模型、数据ETL以及存储管理；
4、熟悉HDFS/Hive/MapReduce/Kylin/HBase，能独自进行Mapreduce程序开发者优先；
5、熟悉分布式系统概念、架构，有大规模分布式系统设计、实现、部署等经验；
6、有较强的书面与口头沟通表达能力，独立分析、解决问题的能力。
7. 有钢铁冶炼/焦化/环保行业工作经验者优先"
"职位描述：
        
        岗位职责：
1、负责流处理平台的建设及维护；
2、负责流处理应用的设计、开发及维护；
2、负责数据模型设计及大数据开发工作；
4、结合公司产品和业务发展，研究相关的大数据前沿技术并应用。
岗位要求：
1、熟悉Hadoop等相关大数据技术，如Hive,HBase,Spark等；
2、熟悉kafka、flume、spark streaming等相关流处理技术；
3、熟练掌握JAVA、HQL、MR编程技能；
4、三年以上大数据平台及流处理系统开发工作经验，流处理方向；
5、本科以上学历。"
"职位描述：
        
        职位描述：
・ 负责重大开发项目(或项目的组成部分)的设计和交付
・ 获得客户数据的业务知识，更好地为技术决策提供信息并解决所提出的任何问题
・ 使用邓韩贝的ETL方法论和客户端软件监督相关技术项目
・ 积极主动地发现改进流程、工作方式和流程自动化的机会
・ 与其他IT数据团队合作，在预算范围内，无错误地按时交付高质量成果
・ 确保代码线符合行业标准，Pylint分数高于8

任职要求：
・ 本科以上学历
・ 6年以上开发经验，其中2年以上大数据架构或相关工作经验
・ 熟练掌握Python, PySpark, Hadoop大数据技术，了解ETL及数据仓库搭建
・ 逻辑思路清晰，工作严谨细致，团队合作精神
・ 良好的英语听说读写能力"
"职位描述：
        
        工作职责：
1. 开发Linux桌面应用程序；
2. 参与内部可视化工具的完善与维护。
任职要求：
1. 本科及以上学历；
2. 熟练使用Linux操作系统，精通C/C++、Python等常用的程序开发语言；
3. 熟练使用Vim、GDB、Git等常用的开发工具；
4. 精通Qt/QML、Gtk+、Electron等Linux下流行的UI库中的一种或几种；
5. 深刻理解多线程图形编程、多线程、协程编程、进程间通信；
6. 熟悉各种界面动画的原理及实现方式。"
"职位描述：
        
        岗位职责：
1.辅助管理Hadoop集群运行，稳定提供平台服务；
2.基于Spark、flink技术的海量数据的处理、分析、统计和挖掘；
3.维护和使用airflow、jenkins等一个或多个调度系统；
4.根据需求使用Spark、python、sqoop进行数据处理、查询和统计等工作。

任职要求：
1.本科及以上学历，计算机相关专业；
2.两年年及以上大数据开发经验；
3.熟练掌握HDFS/HBase/Hive/MapReduce/spark/zookeeper等hadoop组件的应用和原理，能独立完成cdh或其他大数据管理工具的安装升级维护；
4.熟悉Spark Streaming和Spark SQL 或者flink；
5.有sqoop、flume等ETL开发经验优先；
6.熟练掌握Linux操作系统，熟悉shell等脚本编程；
7.有在Spark或者flink相关项目中应用Java、scala或Python语言的经验者优先；
8.有过海量数据系统开发经验者优先；
9.有良好的语言沟通能力，能够协调团队成员及相关部门开展分工及合作。"
"职位描述：
        
        岗位职责：
1、负责大数据高性能存储平台、大数据计算平台的规划、建设；
2、负责大数据集群搭建、数据仓库建设、实时数据和离线数据体系的需求设计、方案设计； ? ?
3、负责数据平台规划与落地，数据建模、数据工程的构建，通过大数据平台和工具，支撑海量数据分析、数据挖掘、机器学习工作；
4、带领团队探索数据产品化的机会，跨部门协作，让数据在业务中发挥更大的价值。 ? ?
任职资格：
1、本科及以上学历，计算机相关专业，3年以上大数据开发和架构设计经验，深刻理解大数据技术特征和应用场景；
2、熟悉大数据的存储/计算/资源管理/检索等相关技术，例如hadoop、hive、spark、storm、flink、hbase、kafka、zookeeper等大数据生态圈常用组件；
3、熟练使用Java/Scala/Spark，有丰富后端服务系统的设计和实现经验，有独立的系统级设计能力， 熟悉MySQL、Oracle等常用关系型数据库及SQL调优等；
4、简单靠谱，自我驱动，具有钻研精神，乐于接受挑战。
【核心竞争力】：
超大规模设备流量，拥有极高的变现能力，商业化火速推进中；
核心成员是AI、搜索、推荐、NLP等算法方面专家，均来自一线互联网公司；
信息透明，自主决策，有清晰的成长路径，和专业靠谱的团队做最有价值的事；
显著高于行业水平的薪资、期权，完善的福利制度。"
"职位描述：
        
        职位描述：
???开发DataVisor用户分析界面，包括数据可视化以及数据库接口等功能，高效完成开发任务；
???不断创新，参与开发DataVisor大数据分析平台的后端开发，API接口等；
???关注业务，围绕业务目标，发挥自我创造力和生产力来实现业务需求。
???参与数据仓库架构设计与数据开发，建设共享数据仓库
任职要求：
???计算机相关专业，本科及以上学历。
???熟练掌握基本算法与数据结构，具有优良的编码风格和习惯。
???熟悉Java、Python等编程语言
???了解Postgresql、Mysql等数据库的使用和基本原理，熟悉常用的关系型、非关系型数据库并了解其特性和使用场景
???日常使用Mac或Linux开发环境，了解Docker技术优先。
???具有Apache Spark, Mesos, Hadoop, Elastic Search, HBase?使用经验者优先
???学习能力强，工作积极主动，能承担工作压力。
???良好的英文读写能力，善于交流。"
"职位描述：
        
        岗位职责：1.负责互联网/企业内部大数据分析计算、价值挖掘、数据智能化应用场景的技术方案设计，带领研发团队完成落地建设工作；2.负责大数据相关的技术研究，包括但不限于计算/查询性能提升、新组件调研；任职要求：1.本科或以上学历，计算机相关专业，三年以上工作经验；2.具备良好的需求理解、方案设计能力，具备良好的文档能力和表达能力；3.熟悉Hadoop、Spark等大数据计算框架，HBase、Hive、Elasticsearch等数据存储和查询引擎；熟悉Spring?Framework；熟练使用Java、Python等编程语言；4.需要有较强的学习能力和独立思考问题能力，责任心强，有良好的沟通能力?；5.有容器/自然语言处理/机器学习基础的的优先考虑。"
"职位描述：
        
        职位描述：
岗位职责
1.深度参与海量数据环境下的数据处理和存储的业务系统；2.在指导下参与大数据平台的优化和功能开发。
任职条件
1.本科或以上学历，计算机相关专业，有操作系统、数据库等专业知识基础；2.良好的数据分析、文档编写能力 ；3.需要有较强的学习能力和思考问题能力，责任心强，有良好的沟通适应能力；4.熟悉Python、Java、SQL等基础技术。加分项:1.实践并较熟悉一个以上大数据数据库或查询引擎（HBase、Hive、Cassandra、ElasticSearch等）；2.有技术负责过较大数据规模的项目经验 ；3.有非常强的自我驱动和学习能力，自信能弥补一定程度的经验不足。"
"职位描述：
        
        【你来负责的事】
1、负责ETL小组日常管理
2、负责数据仓库（ODS、EDW、CSL、ADM等）的设计与开发。
3、负责大数据ETL设计、开发和优化。
4、负责各业务系统数据源业务探查、数据探查、准确性完整性验证。
5、负责数据仓库日常管理、跑批、维护、监控、处理临时数据需求。

【我们需要你】
1、熟悉数据仓库建模理论和PowerDesigner建模工具,了解数据仓库数据分层架构、多维数据模型设计,熟悉数据处理流程,有2年以上的实际工作经验。
2、熟悉Linux 操作系统,具备一定的开发能力,熟悉至少一门脚本语言；(Shell/Python等),熟悉至少一门开发语言(Java/Go/C++等)；
3、熟悉关系型数据库(MySQL、Oracle、SQL Server等),熟悉掌握数据查询语言SQL,具有一定数据分析统计能力；
4、熟悉 Informatica 开发工具最佳，Kettel、Datastage 其次；
5、优秀的学习能力、沟通协作能力、逻辑思维能力。

【加分项】
1、熟悉数据仓库平台者优先(Oracle、Greenplum、Vertica、Teradata、SAP BW、SAP HANA等)
2、熟悉Hadoop生态圈Sqoop、Hive、Hbase优先。
3、有海量数据抽取、数据分析经验优先。"
"职位描述：
        
        岗位职责：
1. 配合公司完成相关教学资料（实训大纲、教学PPT、教学案例等）的研发、编写工作、培训课程的教学工作。
2. 按照教学大纲要求完成大数据课程的教学工作。
3.参与进行大数据项目课程研发和后期优化。
4.按照教学大纲高质量完成日常授课任务。
5.参与培训数据分析产品的研发。
6.负责攻关技术难点，学习最新的技术，整理文档并分享。
7.与课程研发相关的其他工作。
8.完成领导临时交办的其他工作。
岗位要求：
1.本科及以上学历，3年以上相关行业工作经合，计算机及相关专业毕业，有培训机构授课经验以及数据分析课程授课经验，有数据挖掘、数据分析、数据仓库、推荐算法等开发经验优先。
2.3年及以上大数据开发经验。
3.熟悉Hadoop体系结构、对Hadoop生态系统有较全面了解，同时具有源码级开发经验。
4.对Hadoop/Storm/Spark/Hive/HBase其中之一有较深的研究和实战经验。
5.熟悉linux操作系统并能进行shell脚本编程，熟悉mysql、Oracle等主流关系数据库和Redis、memcache等非关系数据库。
6.善于沟通，良好的表达能力，思路清晰、执行力强，乐于技术分享。
7.具有较强的技术文档整理、表达、分析与领导能力。"
"职位描述：
        
        职位描述：
1.? ? ?建立并维护数据处理系统平台，保证数据正确性和系统可靠性;
2.? ? ?参与数据库、数据仓库、数据平台设计，开发，维护与优化等工作;
3.? ? ?开发与维护数据展示、监控与报表系统;

职位要求 :

 本科或以上学历，有扎实的编程功底;
 3年以上数据仓库、数据平台开发经验；
 熟悉 Hive及MySQL 数据库，熟练使用SQL;
 熟练使用Python、Java或Golang，熟悉Linux系统;
 熟悉ETL任务调度，如Airflow;
 具有很强的责任心，对数据准确、结果可重复有执着的追求。


优先条件 :

 有过大规模数据处理或系统设计优化经验;
 掌握主流的大数据处理技术。"
"职位描述：
        
        岗位职责:

 负责大数据计算和存储平台的技术方案设计、平台搭建和开发协作;
 持续改进系统性能；


?
任职资格:

 计算机或相关专业本科及以上学历，5年以上工作经验，3年以上大数据开发经验,?扎实的数据结构和算法功底;
 熟悉Linux/Unix开发环境，精通python/java/scala/shell，熟悉java领域内的主流开源项目;
 熟悉开源分布式系统，对Hadoop/Hive/Spark/Flink/HBase/Druid中的某项或多项有深入了解;
 完整搭建过数据平台和数据产品，有处理实时大数据和解决大规模并发请求经验;?有后端系统运维经验;
 具有丰富的数据处理经验，对数据处理?、数据清洗，数据建模、数据分析等有深刻认识和实战经验;
 有数据挖掘、机器学习、自然语言处理等领域的理论基础和算法实现和优化经验者优先;
 清晰的逻辑分析和表达能力，热爱技术，乐于分享，对行业和技术的发展有独立与深刻的理解;
 良好的团队精神和合作意识，责任心强?，对工作有激情，良好的沟通能?;
 良好的英文读写和口头表达水平；



公司背景：
Conviva是一家基于人工智能的视频分析技术开发商，由Hui Zhang和Ion Stoica创建，其实时大数据平台是基于卡内基梅隆和伯克利大学的科研成果，为互联网视频收视体验的实时监测和优化领域的开创者和领跑者。Conviva是世界上最早实现视频播放自适应的视频分发平台之一：支持100多种视频播放客户端，25亿台不同的视频播放设备，每月50亿次视频播放，每秒3百万实时监测数据处理。在此平台上孵化出的Spark现已成为大数据产业的基石之一。现在公司基于多年视频播放和用户观看行为数据的收集，已跻身于世界上最大的视频观看数据平台行列，从而为给更多客户提供智能、个性化服务创造了独特的优势。
Conviva总部设在硅谷，并在英国，法国等6个国家设有分部。目前公司客户共计100多家，包括HBO、ESPN、Sky、Turner、和中国的CNTV等大型视频内容播放平台。Conviva的全球发行商网络服务面向超过180个不同国家的用户，覆盖超过25亿台诸如智能手机，机顶盒等视频播放设备。涉及视频直播、4A、影视发行出版等行业.如果深入了解，也许您也已经在享用我们的服务了！
目前中国研发团队正在全力筹建中，期待与英才携手并进！"
"职位描述：
        
        职位描述：
1、在这里，你可以参与公司大数据平台和数据产品的架构开发和平台建设；
2、在这里，你可以体验到海量数据的处理和架构，在此量级上探索成本和效率的优化；
3、在这里，你肩负着公司实时链路计算、离线计算、算法平台建设的重任；
岗位职责
1.、个性化实时推荐和搜索系统；
2、基于大数据和算法优化的自动广告系统；
3、高性能的跨境商品爬虫系统的开发和架构；
4、海量数据仓库搭建和优化；
5、 ETL链路优化和平台化；
6、 跨境的数据同步系统；
7、大数据任务调度系统的开发；
岗位要求：
1、具有扎实的编程基础，至少精通一门开发语言(java, c/c++等)，有大数据工程实现经验优先；
2、熟悉 hadoop/kafka/spark/storm/zookeeper/tensorflow 等类似 产品/框架中的一种或者多种者优先；?
3、加分项：对机器学习和深度学习算法有所了解；对互联网中间件(数据、消息、服务、软负载等）熟悉；
4、熟悉Linux操作系统;
5、具备很强的逻辑思维能力和较高的分析、处理问题的能力；
6、 善于团队合作，理解和适应变化，以结果和行动为准则，努力追求成功"
"职位描述：
        
        职位诱惑：
海量数据,世界级产品,核心业务，高复杂度

职位描述：
1、分析海量的用户行为数据以及电商数据，抽象整合出支撑运营和产品的数据建模层。
2、与业务方紧密合作，并能理解基础大数据架构，持续优化数据建模层。
3、通过专题分析，对业务问题进行深入分析，为业务的策略、产品优化提供数据支持。

职位要求:
1. 计算机或相关专业本科及以上学历?
2. 对数据建模、数据分析等有深刻认识和实战经验，良好的数据敏感度，能从海量数据提炼核心结果
3. 熟悉SQL和数据库系统，有一定的SQL性能优化经验
4. 非必需加分项：熟悉python等脚本语言,熟悉spark开发
5. 业务理解力强，对数据、新技术敏感，对云计算、大数据技术充满热情
6. 积极乐观、诚信、有责任心；具备强烈的进取心、求知欲及团队合作精神"
"职位描述：
        
        1.?深度理解公司数据业务,?运用大数据技术对个性化推荐、搜索，用户画像等进行迭代优化2.?负责设计系统架构,?编写核心代码3.?完成高稳定性,?高性能的服务开发,?解决各种技术难题任职要求：1.计算机/软件工程专业本科及以上学历2.一年以上大中型互联网企业算法/数据开发/数据仓库相关工作经历3.优秀的编程能力，熟练掌握python/Java，SQL4.对数据结构和算法设计有较好的理解，有过硬的编程能力5.具备良好的逻辑思考能力和快速学习能力加分项：1.熟悉?Spark，Kafka，Flink，熟悉大数据生态圈者2.熟悉数据挖掘、机器学习、自然语言处理之一领域，并具备相关实际工作经验者"
"职位描述：
        
        ?岗位主要职责：?
?1.参与数据产品线相关产品的研发工作，负责具体软件模块的设计、开发、质量保证及交付工?作。
?2.负责自己开发的模块进行单体测试及平台的发布部署；
?3.参与搜索，推荐及其他业务场景的数据处理分析及相关功能实现工作。

?岗位技术要求：?
?1.3年及以上Java开发经验，精通Java语言；?
?2.有Java?WEB开发经验，熟悉Spring、MyBatis等成熟框架；熟悉主流数据库的原理及使用，如?MySQL；熟悉常用中间件的使用，如Redis等；
?3.有互联网据相关数据处理分析经验并能够提出解决方案，对电商类推荐等场景熟悉的优先
?4.有搜索引擎开发经验，熟悉solr，elasticsearch等；
?5.有Hadoop/Spark/Kafka经验优先；?
?6.熟悉常用机器学习算法优先。"
"职位描述：
        
        职位描述：
1. 深度理解公司数据业务, 运用大数据技术对个性化推荐、搜索，用户画像等进行迭代优化
2. 负责设计系统架构, 编写核心代码
3. 完成高稳定性, 高性能的服务开发, 解决各种技术难题

任职要求：
1.计算机/软件工程专业本科及以上学历
2.一年以上大中型互联网企业算法/数据开发/数据仓库相关工作经历
3.优秀的编程能力，熟练掌握python/Java，SQL
4.对数据结构和算法设计有较好的理解，有过硬的编程能力
5.具备良好的逻辑思考能力和快速学习能力

加分项：
1.熟悉 Spark，Kafka，Flink，熟悉大数据生态圈者
2.熟悉数据挖掘、机器学习、自然语言处理之一领域，并具备相关实际工作经验者"
"职位描述：
        
        日常工作过程中检测和调查GRD（全球风险数据科学）分析解决方案的实时问题，并与不同的合作伙伴（例如建模人员、分析师、风险平台开发人员）合作去协同解决问题。通过监控数据，分析数据来解决问题?。即建立模型，模型上线，检测模型是否有问题，解决问题。本次招聘重点主要是检测model的问题，解决问题。同时团队也是高度自动化，平时会开发一些monitoring tool实现自动化工作。

要求1. 工程等相关理科计算机背景 本科2年经验，硕士1年以上经验
2. 有junior的大数据开发工程师愿意做数据监控，troubleshooting方向的人才。
3. 擅长分析和解决问题。能够综合信息和概括模式。4. SQL和大数据处理编程能力是big plus（Java/Python）。5. 英语读写听说ok。"
"职位描述：
        
        职责：1、在敏捷Scrum团队中负责数据开发的工作2、掌握ETL需求对接、代码实现和测试等工作3、设计API并在系统中实现4、为企业和用户提供优质服务要求：1、大学毕业，计算机科学或相关学科。2、熟悉Java、shell脚本、Python编程语言3、有丰富的ETL经验4、熟悉API设计知识，如REST和JSON等标准5、对关系数据库（Oracle或Teradata或DB2等）有丰富的知识和经验；对NoSQL数据库（Mongo?DB或HBase等）有丰富的知识和经验。6、良好的问题解决能力7、良好的英语沟通能力（书面/口头），粤语（可选）"
"职位描述：
        
        ・?BS/MS degree in Computer Science or equivalent
・?2~3 year experience on data warehouse domain
・?Be skilled at any RDBMS, Oracle is prefer
・?Be able to work on UNIX environment, shell script, python?or vi is a plus
・?Basic knowledge on ETL, knowing data model?(snowflake?or star Schema) is a plus
・?Strong responsibility and flexibility under work pressure
・?Knowledge?on ETL tool (Datastage,abinio ) or report tool is preferred?
・?Knowledge?on big data or java is a plus
`?KAFKA/SOLACE/SPARK"
"职位描述：
        
        Knowledge/Experience:?

?BS/MS degree in Computer Science or equivalent
?2~3 year experience on data warehouse domain
?Be skilled at any RDBMS, Oracle is prefer
?Be able to work on UNIX environment, shell script, python or vi is a plus
?Basic knowledge on ETL, knowing data model (snowflake or star Schema) is a plus
?Strong responsibility and flexibility under work pressure
?Knowledge on ETL tool (Datastage,abinio ) or report tool is preferred?
?Knowledge on big data or java is a plus
? Knowledge on ?kafka or solace is a ?big plus


Skills: (technical skills)

?Must be self-driven and result oriented on task assigned
?Willing to accept challenges work and extended roles?
?Be good at English, both oral and written
?Must be open and curiosity for new tech
?Excellent communication and presentation skills is a plus"
"职位描述：
        
        所需技能
?熟练使用Cloudera Manager中的Hadoop，Spark核心，Spark SQL，Hive和Impala编程。
?深刻理解Spark架构及其后端原理。
?精通IT技能和技术经验，包括核心Java，Scala以及SQL和shell脚本。
?丰富的火花性能调校经验。
?必须包括良好的沟通和协调技能，包括团队领导，关系管理和指导/辅导
?强大的分析和故障排除技能，有效的口头和书面沟通技巧
?深入了解技术和平台集成以及理解依赖关系，以支持积极的客户体验
?自我驱动，能够在压力下工作
?能够快速完整地管理，排列优先次序并解决问题"
"职位描述：
        
        Knowledge/Experience:
?
・?BS/MS degree in Computer Science or equivalent
・?2~3 year experience on data warehouse domain
・?Be skilled at any RDBMS, Oracle is prefer
・?Be able to work on UNIX environment, shell script, python?or vi is a plus
・?Basic knowledge on ETL, knowing data model?(snowflake?or star Schema) is a plus
・?Strong responsibility and flexibility under work pressure
・ Experience of Kafka/Solace project
? ?・?Knowledge?on ETL tool (Datastage,abinio ) or report tool is preferred?
・?Knowledge?on big data or java is a plus
・?Be good at English, both oral and written
・?Must be open and curiosity for new tech
? ?・?Excellent communication and presentation skills?is a plus"
"职位描述：
        
        【工作职责】
1、 参与数据指标的开发、测试；
2、 参与数据治理，数据清洗；
3、 参与CDH大数据平台和数据仓库的建设、运维、监控和优化工作；
3、 参与ETL/数仓作业调度设计、性能调优；
4、 参与开发各种CDH大数据平台和数据仓库自动化运维与监控工具；
5、 参与数据仓库、数据集市的相关文档的编写；
?
【任职资格】
1、大专以上学历，计算机相关专业优先；
2、2年以上工作经验，金融行业大数据、数据仓库相关项目经验1年以上，有银行数据治理，数据ETL经验者优先。
3、有使用hive等产品做ETL、数据迁移、存储过程调优等经验；
4、良好的沟通能力，工作细心负责，富有创新精神、团队精神，学习能力强，抗压能力强；"
"职位描述：
        
        岗位职责：?
1、结合业务需求，设计和开发公司数据服务平台，承担数据提取、转化等服务代码开发；?
2、结合业务需求，分析用户行为，为产品和运营提供决策支持，以数据驱动业务发展；?
3、结合业务需求，负责用户行为轨迹分析和标签体系建设。?

任职资格：
1、计算机相关专业，本科或硕士学历；??????????
2、3年以上开发经验，至少1年数据平台开发经验；?
3、具备独立思考问题能力，能够从业务的角度提出解决方案
4、熟练掌握Java开发语言，掌握Python更佳；有较丰富的kafka、MySQL、Hadoop、Spark开发经验；?
5、积极、主动的工作态度，责任心强。"
"职位描述：
        
        大数据工程师实习生
岗位职责：
1、参与构建金融数据中心体系；
2、金融数据的采集，校验，生产体系，工具链开发；
任职资格：
1、熟悉python；
2、熟悉数据库操作；
3、了解二级市场，具备一定金融知识优先。"
"职位描述：
        
        岗位职责
1. 负责设计和研发机器学习业务 PB 级数据的存储平台
2. 深入理解业务需求，设计开发大规模非结构化数据存储系统及其在线/离线查询分析系统
3. 跟踪业界先进的存储体系，不断优化并提升存储性能

岗位要求
1. 计算机相关专业毕业，本科及以上学历；
2. 三年以上大数据、数据挖掘方面的开发经验，熟悉大数据分析技术和可视化技术；
3. 熟悉分布式系统设计理论，有 PB 级数据的 HDFS/HBase/ElasticSearch/Kudu/Cassandra 集群架构、使用和运维经验。
4. 扎实的 Java/Scala 基础，有 Python 相关经验。
5. 具有良好的沟通、学习能力，思路清晰，保持对新技术的敏感性。
福利：年终奖+年底双薪+六险一金+房补餐补+出国游等～
～～～～～～～～可以选择base新加坡～～～～～～～～～～～"
"职位描述：
        
        岗位职责-负责Bigo消息中间件核心模块的设计和方案落地。-负责维护公司所有消息中间件集群的稳定性和性能。岗位要求-2年以上分布式系统相关经验，至少深度熟悉一种编程语言，Java或C++。-熟悉高并发、分布式通信、存储、开源中间件软件等相关技术者更佳。-有很强的与客户沟通和理解能力，有良好的团队协作精神、环境适应能力和执行力，在较大压力下保持工作激情。"
"职位描述：
        
        岗位职责-负责Bigo消息中间件核心模块的设计和方案落地。-负责维护公司所有消息中间件集群的稳定性和性能。岗位要求-2年以上分布式系统相关经验，至少深度熟悉一种编程语言，Java或C++。-熟悉高并发、分布式通信、存储、开源中间件软件等相关技术者更佳。-有很强的与客户沟通和理解能力，有良好的团队协作精神、环境适应能力和执行力，在较大压力下保持工作激情。"
"职位描述：
        
        岗位职责:
-负责Bigo大数据前端架构的设计和开发。
-负责BI数据平台的设计和研发。
岗位要求:
-本科及以上学历，拥有良好的计算机基础理论知识。
-熟练使用各种Web前端技术，包括HTML/CSS/Javascript等。
-熟练掌握一种以上主流的?PHP?框架。
-熟悉mysql等主流数据库，熟悉redis, memcached等NoSql存储优先。
-熟练linux的基本使用，熟练配置nginx、php-fpm优先。
啦啦啦，差点忘记写福利啦~
年底双薪+年终奖（2-3,6-7）+住房补贴+餐补+全勤奖+年度旅游+大幅调薪等等~"
"职位描述：
        
        工作职责:1、根据需求完成海量数据的处理任务；2、能够对关联数据进行并行图挖掘；3、开发高并发、实时的流处理作业；4、对Hadoop、Spark进行深度定制二次开发；5、对数据应用进行架构设计；6、运用开源大数据软件解决问题。任职资格:1、至少熟练掌握Java、Python、Scala中的两种语言；2、掌握Spark、MapReduce开发，掌握作业调优方式，有海量数据处理经验；3、掌握流处理框架开发，Spark Streaming、Flink、Storm；4、精通Hive、Spark SQL开发；5、熟悉主流NoSQL数据库和图数据库应用开发，如HBase、MongoDB、Rediis、Neo4j等，有过高并发读写调优经验；6、熟悉主流全文搜索框架开发，如Solr、ES；7、有大数据架构经验，能够根据需求完成大数据架构设计；8、熟悉Hadoop、Spark生态圈，能运用其解决问题；9、良好的沟通，团队合作意识，非常强的学习能力。"
"职位描述：
        
        工作职责：
1. 运用Python、R、SQL等工具，根据监管部门与金融机构需求进行大数据模型设计与开发；
2. 基于模型部署、测试、实施及模型应用效果监控工作，进行模型调优与维护；
3. 撰写大数据建模项目可行性方案、建模分析报告；
4. 根据实际的建模业务，负责提出并反馈流程、策略、人员等问题。
任职要求：
1、应用数学、统计、机器学习、计算机及相关专业，国内外知名院校硕士以上学历需3-5年工作经验，博士及以上学历需1年工作经验；
2、具有数学建模或大数据建模实际项目经验，熟悉数学建模与优化算法设计，掌握逻辑回归、决策树、神经网络等机器学习算法；
3、熟练运用Python、R、Matlab等常用数学建模与分析工具；
4、熟悉数据库结构，熟练运用SQL等数据库语言，熟悉数据清洗、预处理与特征工程，熟悉?
?Hadoop生态、Spark结构，C#语言；
5、具有扎实的统计分析功底，快速精准的分析能力，能够处理大量数据进行建模；
6、具有良好的业务问题分析，模型抽象能力和创新能力；
7、敬业、诚信，良好的职业素养。"
"职位描述：
        
        工作职责:1、负责数据平台的搭建、调优和维护，保障数据平台服务的稳定性与可用性；2、与产品沟通完成技术选型和详细技术方案设计落地。任职资格:1、2年以上分布式计算框架开发经验，熟悉Hadoop/Spark技术体系；2、良好的Java开发基本功，对JVM、Java多线程并发以及网络通信开发有良好的经验；3、熟练掌握MySQL、HBase、Elasticsearch、MongoDB、Hive、Redis等数据存储引擎的使用和开发；4、熟悉Linux系统，能熟练的使用Linux的常用命令；5、良好的学习能力、团队协作能力、创新能力和沟通能力。"
"职位描述：
        
        工作职责:1、根据需求完成海量数据的处理任务；3、开发高并发、实时的流处理作业；4、对Hadoop、Spark进行深度定制二次开发；5、对数据应用进行架构设计；6、运用开源大数据软件解决问题。（职位驻场）
任职资格:1、全日制统招本科及以上学历，计算机相关专业；2、至少熟练掌握Java、Python、Scala中的两种语言，掌握Spark、MapReduce开发，掌握作业调优方式，有海量数据处理经验；3、掌握流处理框架开发，Spark Streaming、Flink、Storm；4、精通Hive、Spark SQL开发；5、熟悉主流NoSQL数据库和图数据库应用开发，如HBase、MongoDB、Redis、Neo4j等，有过高并发读写调优经验；6、熟悉主流全文搜索框架开发，如Solr、ES；7、熟悉Hadoop、Spark生态圈，能运用其解决问题；8、良好的沟通，团队合作意识，非常强的学习能力。"
"职位描述：
        
        工作职责:1、负责接入海量多源异构数据，并对数据进行清洗和解析；2、负责数据处理服务的维护和升级；3、协助业务方，提供数据导出等数据服务;4、负责建立数据管理工作流程、规范和方法。任职资格:1、掌握使用Python进行复杂业务逻辑的数据处理，熟悉Java语言优先；2、至少具备1年以上大数据处理经验；3、能够具备很强的数据敏感度和逻辑分析能力；4、至少掌握一种关系型数据库/NoSQL数据库，熟悉常见数据库性能优化；5、有Spark/Hadoop大数据平台数据处理经验优先；6、熟悉Linux系统，能熟练的使用Linux的常用命令；7、良好的学习能力、团队协作能力、创新能力和沟通能力。"
"职位描述：
        
        职责描述：
1.配合产品经理，参与数据平台发展各阶段产品需求分析和功能设计；
2.基于确定的产品功能需求，参与平台后端系统架构设计、接口定义实现及测试、构建部署和运维等各阶段工作；
3.根据产品或技术实现发展需要，按需进行一些新技术的研究，并评估将其引入现有平台实现的可行性。

任职要求：
1.本科及以上学历，至少3年及以上的实际开发经验；
2.熟练掌握C/C++/Python/Java/Go/Javascript其中至少2种及以上程序设计语言，并且自认为具有良好的编程素养；
3.熟练掌握常用的数据结构及算法；
4.熟悉Linux系统开发，熟悉网络编程、文件系统，有分布式系统开发经验；
5.应具有熟练的技术领域相关的英文文献阅读能力；
6.有良好的沟通能力和团队合作能力，能够自主驱动，具备良好的问题定位分析能力。
?
优先考虑：
1.熟悉Containerization和Virtual Machine平台和相关技术，熟悉Docker、Kubernetes和KVM等，并具有相关的实际运用经验；
2.熟悉当前主流的云计算平台，如应熟悉AWS、Azure和阿里云其中至少一种平台的IaaS，并具有相关的项目经验；
3.有开源项目实际参与经验。"
"职位描述：
        
        职位描述：
1.配合产品团队了解业务、抽象业务需求、完成相应数据需求的定义；
2.参与数据系统的模块设计和开发；
3.负责数据的接入、清洗，统计分析等数据处理工作。

任职要求：
1.计算机、电子、数学统计等相关专业本科及以上学历，具有两年以上Python开发数据处理软件的经验；
2.熟悉numpy，scipy，matplotlib，pandas等数据处理方面常用的第三方python库；
3.有机器学习、深度学习和自然语言处理等项目经验者优先，熟悉sklearn、pytorch和tensorflow等框架者优先；
4.对技术有热情，具备良好数学思维能力和对数据的敏感度，有数据分析能力者优先；
5.良好的学习能力、沟通能力和团队合作能力。"
"职位描述：
        
        岗位职责：

 负责Amino数据平台全链路的打通和优化，开发自动化工具以实现数据智能，进而提升团队效能
 为产品和业务部门提供数据支持，根据不同用户的需求实现ETL流程，创建Cube，定制报表
 负责大数据管理平台和任务工作流处理引擎的研发
 开发A/B测试框架，从数据角度促进用户及业务增长
 负责数据治理、数据生命周期管理、数据质量监控以及数据血缘管理等
 负责用户画像、知识图谱项目的数据支持
 搭建、运维、监控和调优Amino大数据平台，包括HDFS, YARN, HBase, Spark, Flink, Kafka, Kylin, Superset, Airflow等组件



岗位要求：

 本科及以上学历，具备扎实的计算机功底，具备优秀的代码能力
 1年以上工作经验，有一定大数据项目的实际经验，特别优秀的对经验不做要求
 善于思考和总结，具备优秀的学习意愿和能力
 对大数据和机器学习方向有浓厚的兴趣
 有创业心态，愿意跟公司一起成长


加分项：

 英语流利，可作为工作语言"
"职位描述：
        
        岗位职责：
1. 负责公司Hadoop大数据基础平台的设计和开发工作；
2. 负责分布式数据仓库平台的设计和开发工作；
3. 使用Hadoop/Spark平台进行分析内部及外部的数据，配合业务团队进行定量和定性分析，把数据转化成为业务增值的信息；
4. 探索、评估新的技术和解决方案，提高数据并行计算能力和运行速度。

任职要求：
1. 计算机或数学相关专业本科以上学历；
2. 熟悉java，两年以上java相关开发经验，有scala语言开发经验优先；
3. 熟悉传统关系数据库、数据仓库技术，熟悉数据预处理技术、数据集成技术、NoSQL数据库技术、内存数据库技术，熟悉Hadoop（包括HDFS、MapReduce、HBase、HIVE等）和Spark集群相关技术者优先；
4. 熟悉统计以及数据挖掘、机器学习、人工智能技术，尤其是关联分析、分类预测、聚类分析、回归分析、时间序列分析等常用分析方法，熟练掌握SAS或R或Python；
5. 两年以上大数据开发经验，有高性能分布式平台开发经验，有金融行业风险分析建模经验优先；
6. 具有较好的沟通表达能力和团队合作精神，学习能力强，有较好的逻辑分析能力。"
"职位描述：
        
        工作内容
1.基于已有数据进行处理及落地；
2.建设数据仓库，并基于大数据对业务提供支持；
3.协助进行大数据平台的建设；
4.线上数据产品的研发及数据维护。

岗位需求
1.计算机、数理统计等相关专业本科以上学历，至少两年大数据相关经验；
2.熟悉 Java/Go/Python 中的一种或几种，精通数据库相关技术及优化，熟悉服务端编程技术，有数据治理经验优先；
3.精通SQL，有复杂SQL调优经验
4.有Hadoop、Spark、Hive、Hbase、Yarn、Redis、Kafka等技术的使用经验者加分；
5.具有分布式存储、NoSQL及优化处理的相关经验加分。"
"职位描述：
        
        职位描述:
1. 参与公司大数据系统平台与应用的设计、开发、维护；
2. 负责数据分析、加工、清理、处理程序的开发；
3. 参与用户/商品画像系统的研发工作。

任职条件：
1. 熟悉 Java/Scala/Python 其中之一或者全部皆可，具有熟练的编程能力是必要条件；
2. 熟悉常用的数据指标、数据分析工具和平台（Hadoop/Hive/Spark/Kafka等），了解数据分析的基本方法和常见问题；
3. 有1年以上使用 Spark Streaming 和 Spark SQL 进行数据处理和相关优化的经验；
4. 有大规模 HBase 集群运维经验或对 HBase 存储原理熟悉者优先；
5. 有推荐系统开发相关经验的优先。"
"职位描述：
        
        工作职责:1.负责公司 ELK（Elasticsearch/Logstash/Kibana） 集群的开发维护;2.开发维护自动化运维工具;3.负责跟进 ELK 在公司的推广使用;4.协助进行大数据平台的建设。任职资格:1.计算机、数理统计等相关专业本科以上学历，1-3年大数据相关经验;2.熟悉 Java/Go/Python 中的一种或几种;3.熟悉 Elasticsearch 相关原理，有集群运维经验和调优经验;4.有 Telegraf、InfluxDB、Grafana 等使用经验者加分;5.具有分布式存储相关开发经验加分。"
"职位描述：
        
        职位描述

 负责研发高可用、可扩展的统一计算平台，参与技术调研和选型。

?
任职要求

 3年以上大数据生态研发和实战经验，包括YARN，Spark，Flink，Hive，Presto等；
 理解大型应用的系统架构，能够对现有大数据系统进行二次开发；
 熟悉和理解分布式系统原理，以及不同系统的设计理念。"
"职位描述：
        
        岗位职责：
研发高可用、可扩展的统一数据平台，参与技术调研和选型。

任职要求：
1. 本科及以上学历，计算机相关专业；
2. 熟悉Linux开发环境，熟练掌握至少一门编程语言（包括但不限于Java/Scala/Python等），算法基础扎实，代码风格良好；
3. 具备良好的计算机体系结构基础，理解分布式架构和分布式系统原理，熟悉常用大数据平台和工具，如Spark，Hadoop，Hive，Impala，Presto等；
4. 学习能力强，具备优秀的分析和解决问题能力，具备良好的沟通能力和团队合作意识。"
"职位描述：
        
        岗位职责：
1. 进行数据收集、整理与分析工作，助力数据化运营业务，构建丰富多样的BI/CRM应用；
2. 支持产品部门下的运营、产品等各方面的数据整理和分析；
3. 在用户行为分析（用户画像、行为路径分析）、推荐算法优化（关联分析、协同过滤）、热力图等方面做数据分析建模；

任职要求：
1. 本科以上学历，计算机、统计、应用数学相关专业；
2. 良好的数据敏感性，善于从海量数据中提取有效信息进行分析挖掘和建模；
3. 熟悉常见的ETL工具和程序库；
4. 熟悉数据库技术，如oracle、SQL；
5. 熟练掌握 Python、R语言，熟悉C/C++或者JAVA；
6. 对于数学建模、数据挖掘、Hadoop大数据有实践经验者优先。"
"职位描述：
        
        ? 15k-25k? 本科及以上
岗位职责：
1、 基于Spark框架大数据架构的设计、开发和维护； 2、 根据相关需求使用Spark Streaming、SQL进行数据处理、查询和统计等工作；
?
职位要求：
1、计算机相关专业本科或研究生毕业
2、熟练掌握java开发语言，熟悉java相关技术栈，如maven，spring等
3、熟悉主流NoSQL数据库，如HBase、Redis等
4、熟悉Spark Streaming和Spark SQL；
5、有ActiveMQ、Kafka等开发经验"
"职位描述：
        
        1.2年以上前端开发经验，本科及以上学历，计算机相关专业；
2.负责数据分析可视化的设计与开发（K线图表方向）；
3.熟练运用HTML、CSS、Javascript构建高性能Web应用；
4.熟悉 HTTP 的基本工作原理以及常用 Web 开发调试工具；?
5.熟悉主流的数据可视化工具，有K线画线工具相关开发经验者优先；
6.熟练使用主流的数据可视化 JavaScript 框架，有相应框架开发经验者优先；
7.具有良好的沟通能力、学习能力和分析解决问题能力。"
"职位描述：
        
        1、负责需求设计和开发，包括大数据平台数据爬取、存储、加工处理、查询、及监控功能的开发
2、数据驱动，不断通过产品和技术数据进行改进，并完成快速迭代
3、能积极参与团队的技术创新
?
岗位要求：
1、有扎实的编程功底，了解常用数据结构和算法，熟练掌握Java
2、熟悉spring boot，quartz等框架
3、熟练掌握mysql、redis、kafka的使用
4、有rest、websocket接口开发经验"
"职位描述：
        
        岗位职责: 
1、标准产品开发；?2、定制化项目开发； ? ? ?任职要求:?1、统招本科及以上学历，计算机及相关专业； 
2、3年以上工作经验，精通Java语言程序设计，具有系统架构规划sense； ?3、精通Hadoop生态圈主流技术和产品，如Hbase,Hive,Storm,Flink,Spark,Kafka,Zookeeper,Yarn,Hadoop,ElasticSearch,Greenplum等，对复杂系统的性能优化和稳定性提升有一线实战经验，有多年实际开发和应用经验； ?4、熟悉Docker,Kubernates 是一个巨大的加分项；?5、具有一定的项目规划和决策能力，善于捕捉业务需求、架构设计存在的问题，并给出有效的解决措施和方法；?6、有快速和持续学习的能力，具有良好的沟通能力，动手能力强，有进取心、责任心强。"
"职位描述：
        
        工作职责:?1. 负责公司社交舆情分析产品的底层大数据架构和开发。?2. 负责社交舆情数据的清洗、计算和存储。?3 基于Elasticsearch进行数据的实时统计分析。?4. 基于Hadoop进行数据的离线计算。?5.参与调研前沿技术。??任职资格:?1.统招本科及以上学历，计算机相关专业，3年及以上相关工作经验。?2. 熟悉linux环境下的开发，能熟练使用Java开发，有过jvm调优经验。?3. 熟悉elasticsearch，mysql，能够熟练操作这些数据库，有一定的性能调优能力。?4. 熟悉Kafka，redis，spark等实时处理组件，有实际使用经验。?5. 熟悉Hadoop、HBase，清楚原理和机制，有MR开发经验。?6. 加分项：有NLP和机器学习相关开发经验。?7.善于归纳、分析、总结，有独立解决问题的能力，对前沿技术有深厚的热爱，有良好的团队合作精神。"
"职位描述：
        
        岗位职责：???1.基于?hadoop?生态进行海量数据应用系统开发；???2.负责日志数据的解析和清洗?,?海量数据查询和报表展现；管理结构化和非结构化数据，保证数据质量；???3.负责超大规模数据平台的搭建、维护和优化? ；?4.负责大数据采集、存储框架研究，参与在线或离线数据存储模型设计。???????任职要求：???1.计算机相关专业，统招本科及以上学历；?2.良好的学习能力、沟通能力、适应能力，责任心强；? ? ? ? ???3.较强的?java?基础,?深入理解高并发/jvm/设计模式,?熟悉?hadoop?生态系统源码加分；??4.较强的分布式存储架构设计能力和数据建模能力，熟悉?hadoop?平台框架以及相关组件的优势、劣势，能够根据业务需要合理选择架构；???5.三年以上数据平台经验，两年以上海量数据处理经验，有大规模数据存储、传输、处理，网络日志分析、?ETL?经验。熟悉?flume,kafka,spark?加分；?6.?对?hadoop?家族或其它大数据开源项目提过?patch?或自己修改过?bug?加分。"
"职位描述：
        
        工作职责:岗位职责:1、负责大规模海量数据实时计算平台设计和开发，负责云计算平台上的大数据产品的搭建、开发、维护，参与核心代码的开发；2、完善参与整个大数据分析的多个产品的兼容性和集成；3、负责BI项目的后端数据平台的需求分析、设计和开发工作；4、对云计算大数据平台的用户业务理解力强，协助分析遇到的问题，及时给出解决思路与方案；任职资格:任职资格: 1、精通一种或多种分布式计算、存储、调度框架（Hadoop/Hive/Hbase/Presto/Spark/Storm/Flink/ES/Kafka等），2、有实际的分布式平台系统的开发与调试经验；3、熟悉主流数据库技术，精通SQL，有较强的SQL编码及调优经验优先；4、熟悉linux、shell脚本或python、java脚本编程以及Git； 5、熟练掌握至少一种下列编程语言 java、python、golang、C++；6、具备较强的沟通能力及团队协作精神；"
"职位描述：
        
        工作职责:1. 负责公司Hadoop相关产品的代码开发和系统调优；2. 完善和优化现有业务的计算系统和存储系统，编写核心代码；3. 善于发现系统的性能瓶颈、设计缺陷，提出改进方案并实施；4. 对现有系统进行宏观的思考，规划形成统一的框架、平台或组件；5. 能够与产品经理、管理团队进行良好的沟通合作，按时保质保量完成开发任务。任职资格:1. 计算机科学或相关技术学科的学士、硕士学位（或同等学历）；2. Java相关开发经验1年以上，熟悉并理解缓存、消息、RPC调用、jvm 调优、序列化、nio等原理，对各种开源框架如Spring、netty等有一定了解，读过源代码、自己写过框架者优先；3. 熟悉分布式数据处理底层技术，包括但不限于：hadoop/elasticsearch/hbase/kafka/flume等，用过mysql，redis，hbase等开源存储；4. 具有强烈的责任心，良好的沟通、学习能力，良好的团队合作意识，勇于接受技术挑战；5. 有一定的统计学知识优先，熟悉go/c/c++语言优先6. (GitHub上)有自己开源小项目的优先；"
"职位描述：
        
        工作职责：  1. 负责Adhub平台数据的分析、挖掘等工作 2. 负责Adhub整个平台产品用户画像 3. 负责数据的可视化工作，以及商业智能，为提升用户体验提供数据支持 

职位要求： 1. 熟练掌握JAVA、python开发，熟悉掌握分布式应用开发原理，熟练掌握多线程开发，熟练掌握设计模式  2. 熟悉jvm，有线上调优经验  3. 熟悉常用的大数据分析框架，如hive、spark、flink、Impala等，并熟悉运行原理 4. 良好的计算机编程素养 5. 熟悉机器学习算法加分  6. 以上框架深入原理加分"
"职位描述：
        
        岗位职责：
1.负责 公司海量点位信息，订单相关信息抽取存储
2.负责 维护和管理Hadoop集群，参与新技术选型和调研，解决不断增长的海量数据带来的存储和计算挑战
3.负责 对司机端点位数据，订单数据进行分析统计
4 负责 优化和完善现有集群的工作流程和规范;

任职要求：
1. 本科及以上学历，2年以上大数据开发经验
2. 熟悉hadoop/hbase/hive/zookeeper/spark/kafka/sqoop/presto/oozie/azkaban等开源项目
3. 熟悉shell , 至少掌握java/python/scala 一种语言 ;?
4. 熟悉开源存储系统redis、mongodb、hbase、cassandra等；
5. 熟悉服务端相关开发spring mvc"
"职位描述：
        
        岗位职责：
1. 负责数据分析系统的架构设计和需求开发
2. 负责数据分析系统的稳定、性能优化工作
3. 结合版本运营计划定期产出分析报告

岗位要求：
1. 较强的逻辑思维和独立分析能力
2. 优秀的沟通、学习能力、较强的团队合作精神
3. 良好的数据结构和算法基础
4. 熟悉数据库原理及常用数据库
5. 2年Spark及Spark Streaming开发经验
6. 熟悉Hadoop生态体系开发和搭建
7. 熟练使用Python/Scala/Java/语言进行数据分析开发
8. 具备游戏行业运营数据分析经验"
"职位描述：
        
        岗位职责：
1、构架、维护和调优基于Hadoop的大数据分析平台；
2、使用Hadoop工具集进行数据作业的二次开发；配合需求方，开发各种的数据管道；
3、对数据来源做分层的收集、计算和存储；
4、结合游戏版本和运营计划，定期产出数据分析报告，支持运营决策。
岗位要求：
1、有大数据挖掘平台建设经验，包括搭建，维护，调优等；
2、对Hadoop的工具集有1-2年的二次开发经验；
3.能够使用Java/Python/R语言中的一种，进行数据分析开发；
4、熟悉游戏行业的关键指标和定义，参与过用户画像、用户流失、商业价值等专项的分析；
5、有游戏行业数据分析经验，至少参与一个游戏的运营数据分析。"
"职位描述：
        
        岗位职责：
1. 参与大数据平台各类基础系统架构设计和引擎开发，集群优化，技术难点攻关；
2. 集群数据安全相关体系建设，各种存储，查询方案构建；
3. 根据上层业务逻辑整合优化平台数据流程，对数仓和应用开发团队提供技术支持，方案规划；
4. 跟踪业界技术动态，推进平台持续迭代进步；

任职资格：
1. 本科及以上学历，3年以上工作经验，2年以上大数据领域工作经验；
2. 对调度系统 / 开发平台 / 权限系统 / 集群治理／ Hadoop / Hive ／HBase 相关技术中一个或多个的源码有深入的了解和实践；
3. 有上述相关系统为基础的实际成功的复杂系统项目的架构和开发经验；
4. 相关开源领域的活跃贡献者或大型互联网公司相关从业经验者优先。"
"职位描述：
        
        职位描述：
工作职责:
1. 参与大数据各类组件，平台和系统的开发及优化；
2. 参与大数据相关上层数据产品和应用开发和推广；
3. 参与数据挖掘与建模工作，开发数据模型，数据处理能力有优秀，具有数据调优的经验；
4. 跟踪业界技术动态，推动公司大数据相关技术的持续进步；
5. 不限以上，具体职责范围，岗位适配取决于你的能力大小，欢迎来挑战。

任职资格：
1. 本科及以上学历，3年以上工作经验，2年以上大数据领域工作经验；
2. 对HADOOP ／ Hive ／HBase ／ Spark ／Storm ／ Kafka ／ kylin / Druid 相关技术中一个或多个有深入的了解；
3. 相关开源领域的活跃贡献者或大型互联网公司相关从业经验者优先。"
"职位描述：
        
        岗位职责：
-参与基于大数据平台的网站用户行为分析业务;
?
任职要求：
-硕士学历，计算机软件开发等相关专业；
-软件基础理论知识扎实，具有良好的数据结构、算法功底；
-精通java, 对分布式计算、数据挖掘有深入了解者优先；
-熟悉Hadoop、Storm、HBase、Hive等框架者优先；
-思维敏捷，对工作有较高的热情和驱动力，具有良好的团队合作意识。"
"职位描述：
        
        你的工作:

1 负责基于hadoop/Spark平台数据处理；
2 负责大数据数平台等开发；
3 参与数据管理平台的开发，用户画像标签体系的建设与优化，以及相关基础服务开发；
4 通过Hadoop相关技术解决海量数据处理问题、大数据量的分析；
5 及时跟进大数据前沿技术的发展,并将合适方案引入业务场景。

我们需要你:
1. 本科及以上学历，计算机相关专业， 有工作责任心，有较强的主动性，良好的团队协作精神，有一定的承压能力；
2.? 熟悉 Linux 操作系统，有良好的编程能力，以及较强的动手和学习能力;
3.? 熟悉 Java,shell/python, Scala等其中两种编程语言；
4.? 熟悉hadoop生态体系(flume,kakfa,hadoop,spark,hive,impala,hbase,kylin等)，有相关经验者优先；
5.? 有用户画像系统或DMP系统的开发工作经验者优先；
6.? 熟悉spring cloud框架，熟悉docker相关技术，有微云服务相关开发经验者优先。"
"职位描述：
        
        岗位描述:1. 理解业务需求，开发及维护贴合公司业务的数据分析平台2. 支持数据业务需求岗位要求:1. 计算机相关专业，本科及以上学历2. 熟悉常用数据结构及算法,及熟悉Java/C++编程语言之一3. 熟悉网络IO、文件IO、多线程编程4. 熟悉Hadoop/Hbase/Spark/Hive/Kafka/Flink/Storm/Drill/Presto等开源数据处理系统优先5. 有较强的好奇心及学习能力6. 良好的沟通和表达能力做过大数据分析平台相关的模块或者项目优先，例如：ETL,离线计算、实时计算，Olap等~"
"职位描述：
        
        岗位简介：
基础大数据团队负责大数据平台的内核研发工作，主要是内核优化与 bug 修复等工作，平台包括：hdfs，hbase，cassandra,kafka,flume,storm,flink,spark 等主流大数据平台，我们侧重于深入研究系统原理，解决线上问题。而不仅仅是使用它们。

主要工作内容：
1.平台内核的优化与修复
2.深入研究系统原理
3.处理线上故障，分析问题原因，给出合理解决方案

岗位要求：
1.JAVA 基础必须好，即使你做 scala 方向
2.对多线程，线程安全与同步有深刻认识
3.掌握常用数据结构与算法
4.熟悉分布式系统相关知识，CAP，ACID，2PC 等理论

对于工作3年以下的同学，不要求对平台内核的原理有深厚的经验和认识，我们提供学习的机会；
对于5年以上工作经验的同学，要求必须从事过某个平台的内核优化工作。"
"职位描述：
        
        职责描述：
1、面向PB级超大规模数据问题，每天处理千亿增量的日志数据；
2、理解业务分析需求，设计和开发对应的数据仓库/数据集市，ETL开发和优化工作，完成结构层次合理、灵活、可扩展的数据仓库；
3、负责数据仓库模型设计、报表开发和维护；
4、负责数据仓库系统性能，模型性能设计与调优；
?
任职要求：
1、计算机、数学或统计学相关专业本科以上学历；熟悉互联网行业，3年以上DW/ETL/BI工作经验；熟练掌握至少一种主流ETL/BI解决方案；
2、精通数据仓库架构及原理，具备大型数据仓库架构设计、模型设计和处理性能调优等相关经验；精通SQL/Hive，有较好的SQL性能调优经验，有Java/Python开发经验者优先；
3、能够熟练应用一种或多种主流数据库（如：Oracle、MySQL等），有数据库设计经验者优先；
4、有大数据分布式计算平台开发经验,熟悉Hadoop, Hive，Sqoop，Spark，Flume，Kafka原理及应用；
5、工作认真、负责、仔细，有良好的团队合作精神，良好的分析能力、沟通技巧。"
"职位描述：
        
        大数据存储平台高级研发工程师
职责：
1. 负责公司HDFS平台设计，承担架构和核心代码开发工作
2. 负责平台性能优化和相关框架优化
3. 负责平台升级和新版本发布
4. 负责社区大数据开源系统的调研、性能调优、功能增加等系统深度优化工作
5. 负责系统安全方面的设计以及开发
6. 较好的沟通表达能力，逻辑思维清晰，抗压能力强，良好的团队合作精神
任职要求：
1. 精通Hadoop大数据平台架构及原理。
2. 熟练掌握java编程
3. 熟练掌握linux操作系统常见命令
4. 熟练使用常见开发工具及技术，如：maven,git等"
"职位描述：
        
        工作职责：
1、负责大数据的处理，以及ETL流程的开发和优化工作；
2、利用平台协助完成数据的整理、挖掘、分析和利用，并对未来提出更准确更全面的建议；
3、将产品和运营的需求转化成数据的思维，设计面向业务的OLAP模型；
4、参与元数据、数据质量、数据标准化等数据治理工作。


任职要求：
1、熟悉oracle、Mysql数据库，熟悉linux系统，熟悉shell编程，有数据仓库相关经验；
2、熟悉hdfs/hbase/hive/spark/flink/kafka等Hadoop生态圈组件并且能熟练使用，精通SQL、Python，有JAVA开发经验更好；
3、有大规模数据处理和日志处理经验的优先；
4、有数据治理相关经验的优先；
5、具备良好的逻辑分析能力和解决实际问题的能力；
6、可接受中短期出差。"
"职位描述：
        
        岗位职责：
1、负责基因组分析平台的数据导入，清洗，处理和计算部分的设计和开发；
2、将算法研究团队的算法改写为大数据实现；
3、优化大数据算法和计算框架，提升计算效率，降低成本；
4、新技术选型、研究与架构改进；

职位要求：
1、 大学本科及以上学历，计算机相关专业，具备3年以上开发经验；
2、有大数据开发实战经验，用过Hadoop，Spark，Flink，Pandas等，具备在20台以上服务器组成的集群中处理至少10TB数据经验；
3、具备一定的机器学习算法基础，使用过Spark ML，ScikitLearn，TensorFlow，PyTorch等机器学习/深度学习工具优先；
4、理解分布式大数据算法实现原理，具备分布式算法优化能力；
5、有敏捷软件开发和持续集成/持续交付经验；
6、有一定技术追求，自我驱动，热爱编程，能够独立做出技术决策，对代码质量有更高要求；
7、 能够熟练使用Python，Java，Scala中的至少两种编程语言。"
"职位描述：
        
        工作职责
1、大数据平台工具开发，包括AdHoc、OLAP等自助查询分析平台；
2、参与建设、维护、优化基于离线和实时技术的数据平台；
3、为业务提供易用的数据工具开发；
4、参与任务调度系统的设计和开发；
?
任职要求
1、本科及以上学历，计算机相关专优先；
2、5年以上Java研发经验，丰富的Java 研发经验；有丰富的后端服务系统设计和实现经验，具备独立的系统级设计能力；
3、有互联网公司中大型分布式系统经验优先，有使用 RPC和 Restful等经验；
4、了解Spring框架、熟悉AOP/IOC等原理；熟悉微服务模式开发，理解 JVM原理, 有JVM调优经验；
5、熟悉大数据技术栈，对Hadoop、Hive、Spark、Hbase、Kafka、ELK 等开源组件有使用及优化经验加分项
6、工作认真负责，具备主动推进业务的意识和能力"
"职位描述：
        
        工作职责:1、负责大数据平台工具开发，为业务提供易用的数据工具；包括AdHoc、OLAP等自助查询分析平台；2、参与建设、维护、优化基于离线和实时技术的数据平台；3、参与任务调度系统的设计和开发；
任职资格:1、全日制本科及以上学历，计算机、软件相关专业优先；2、5年以上Java开发经验，具备丰富的Java 项目研发经验、后端服务系统设计和实现经验，具备独立的系统级设计能力； 3、有互联网公司中大型分布式系统经验优先考虑；有使用 RPC和 Restful等经验；4、熟悉大数据技术栈，对Hadoop、Hive、Spark、Hbase、Kafka、ELK 等开源组件有使用及优化经验的优先考虑；5、了解Spring框架、熟悉AOP/IOC等原理；熟悉微服务模式开发；对 JVM原理有一定了解， 有JVM调优经验；6、工作认真负责，具备主动推进业务的意识和能力"
"职位描述：
        
        工作职责
1.负责建设企业级Docker与k8s集群管理监控及相关业务支撑；
2.负责企业级容器化落地，CI/CD/DevOps等工作；
3.编写各种运维脚本，推动业务自动化运维；
4.参与容器云平台的架构设计与开发、负责云平台集群的高可用和稳定性。
?
任职要求
1、本科及以上学历，计算机相关专业优先；熟练掌握 Python/Go/Shell三种语言中的二种，熟悉 Java/Scala优先
2、3年以上工作经验, 熟练掌握 Python/Go/Shell三种语言中的二种。熟悉 Java/Scala、
有大型容器运维经验优先
3、熟悉当前热门的容器生态核心开源项目，如 Docker/k8s/Etcd 等，能对它们进行二次开发
4、熟悉 Docker/k8s 生态项目，如监控、日志、网络等方案，并有运维能力，精通或者有实施经验者优先
5、有 DevOps背景，开源项目贡献维护经历者优先"
"职位描述：
        
        岗位职责：
1、负责集团数据仓库规划与设计，参与业务数据需求调研和数据开发。
2、根据产品需求文档，参与产品功能实现框架设计与评估，负责核心功能的开发。
3、指导和协助团队内其他成员，共同建立和维护数据类项目开发工作的流程、规范和方法。
4、负责研究云大数据平台产品(阿里云方向)在实际项目中的应用。?
职位描述：?
1、本科以上学历。计算机、数学或相关专业。4年以上数据类开发经验。
2、熟悉hadoop生态技术，包括但不限于spark、sqoop、flume、hbase、presto的原理和使用方法；
3、熟悉（Java/Python）一种以上语言编程。熟练使用至少一种BI前端工具
4、熟悉数据仓库各类建模理论和原则，以及数据仓库数据层级关系，有维度建模经验，实际参与过大型数据仓库建设，对BI后台技术有深入的了解；
6、有互联网电商数据仓库经验和用户行为数据开发经验优先；
5、熟练基于阿里云产品搭建大数据平台解决方案（maxcompute，ads，quickbi,dts,流计算,datahub等产品的实践经验）优先"
